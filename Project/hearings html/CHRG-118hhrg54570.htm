<html>
<title> - TOWARD AN AI-READY WORKFORCE</title>
<body><pre>
[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]












                      TOWARD AN AI-READY WORKFORCE

=======================================================================

                                HEARING

                               before the

               SUBCOMMITTEE ON CYBERSECURITY, INFORMATION
                 TECHNOLOGY, AND GOVERNMENT INNOVATION

                                 of the

                         COMMITTEE ON OVERSIGHT
                           AND ACCOUNTABILITY

                     U.S. HOUSE OF REPRESENTATIVES

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             SECOND SESSION

                               __________

                            JANUARY 17, 2024

                               __________

                           Serial No. 118-85

                               __________

  Printed for the use of the Committee on Oversight and Accountability








    [GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]








                       Available on: govinfo.gov 
                         oversight.house.gov or 
                             docs.house.gov 
                             
                                   _______
                                   
                 U.S. GOVERNMENT PUBLISHING OFFICE 
                 
54-570 PDF                   WASHINGTON : 2024 
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
                             
               COMMITTEE ON OVERSIGHT AND ACCOUNTABILITY

                    JAMES COMER, Kentucky, Chairman

Jim Jordan, Ohio                     Jamie Raskin, Maryland, Ranking 
Mike Turner, Ohio                        Minority Member
Paul Gosar, Arizona                  Eleanor Holmes Norton, District of 
Virginia Foxx, North Carolina            Columbia
Glenn Grothman, Wisconsin            Stephen F. Lynch, Massachusetts
Michael Cloud, Texas                 Gerald E. Connolly, Virginia
Gary Palmer, Alabama                 Raja Krishnamoorthi, Illinois
Clay Higgins, Louisiana              Ro Khanna, California
Pete Sessions, Texas                 Kweisi Mfume, Maryland
Andy Biggs, Arizona                  Alexandria Ocasio-Cortez, New York
Nancy Mace, South Carolina           Katie Porter, California
Jake LaTurner, Kansas                Cori Bush, Missouri
Pat Fallon, Texas                    Jimmy Gomez, California
Byron Donalds, Florida               Shontel Brown, Ohio
Scott Perry, Pennsylvania            Melanie Stansbury, New Mexico
William Timmons, South Carolina      Robert Garcia, California
Tim Burchett, Tennessee              Maxwell Frost, Florida
Marjorie Taylor Greene, Georgia      Summer Lee, Pennsylvania
Lisa McClain, Michigan               Greg Casar, Texas
Lauren Boebert, Colorado             Jasmine Crockett, Texas
Russell Fry, South Carolina          Dan Goldman, New York
Anna Paulina Luna, Florida           Jared Moskowitz, Florida
Nick Langworthy, New York            Rashida Tlaib, Michigan
Eric Burlison, Missouri
Mike Waltz, Florida

                                 ------                                
                       Mark Marin, Staff Director
       Jessica Donlon, Deputy Staff Director and General Counsel
             Raj Bharwani, Senior Professional Staff Member
                 Lauren Lombardo, Senior Policy Analyst
                      Peter Warren, Senior Advisor
      Mallory Cogar, Deputy Director of Operations and Chief Clerk

                      Contact Number: 202-225-5074

                  Julie Tagen, Minority Staff Director

                      Contact Number: 202-225-5051
                                 ------                                

 Subcommittee on Cybersecurity, Information Technology, and Government 
                               Innovation

                 Nancy Mace, South Carolina, Chairwoman
William Timmons, South Carolina      Gerald E. Connolly, Virginia 
Tim Burchett, Tennessee                  Ranking Minority Member
Marjorie Taylor Greene, Georgia      Ro Khanna, California
Anna Paulina Luna, Florida           Stephen F. Lynch, Massachusetts
Nick Langworthy, New York            Kweisi Mfume, Maryland
Eric Burlison, Missouri              Jimmy Gomez, California
Vacancy                              Jared Moskowitz, Florida
Vacancy                              Vacancy  































                         C  O  N  T  E  N  T  S

                              ----------                              
                                                                   Page

Hearing held on January 17, 2024.................................     1

                               Witnesses

                              ----------                              

Dr. William Scherlis, Professor of Computer Science, Carnegie 
  Mellon University
Oral Statement...................................................
Ms. Timi Hadra, Client Partner and Senior Executive for West 
  Virginia, IBM
Oral Statement...................................................
Dr. Costis Toregas (Minority Witness), Director, Cyber Security 
  and Privacy Research Institute, The George Washington 
  University
Oral Statement...................................................

Written opening statements and statements for the witnesses are 
  available on the U.S. House of Representatives Document 
  Repository at: docs.house.gov.

                           Index of Documents

                              ----------                              

  * Levin House Testimony; submitted by Rep. Mace.

  * Statement for the Record, Center for AI and Digital Policy; 
  submitted by Rep. Connolly.

  * Statement for the Record, Partnership for Public Service; 
  submitted by Rep. Connolly.

  * Statement for the Record, Johns Hopkins University; submitted 
  by Rep. Lynch.

Documents are available at: docs.house.gov.

 
                      TOWARD AN AI-READY WORKFORCE

                              ----------                              


                      Wednesday, January 17, 2024

                     U.S. House of Representatives

               Committee on Oversight and Accountability

 Subcommittee on Cybersecurity, Information Technology, and Government 
                               Innovation

                                           Washington, D.C.

    The Subcommittee met, pursuant to notice, at 2:16 p.m., in 
room 2154, Rayburn House Office Building, Hon. Nancy Mace 
[Chairwoman of the Subcommittee] presiding.
    Present: Representatives Mace, Timmons, Langworthy, 
Burlison, Connolly, Khanna, and Lynch.
    Also present: Representatives Krishnamoorthi and Beyer.
    Ms. Mace. Good afternoon. The Subcommittee on 
Cybersecurity, Information Technology, and Government 
Innovation will now come to order. Good afternoon and welcome, 
everyone.
    Without objection, the Chair may declare a recess at any 
time.
    And I will now recognize myself for the purpose of making 
an opening statement.
    Good afternoon, and welcome to this hearing of the 
Subcommittee on Cybersecurity, Information Technology, and 
Government Innovation. Today, America is indisputably the 
global leader in artificial intelligence, which is why you all 
are here today. This Nation has led the way on AI. During its 
liftoff stage, American companies and institutions have 
developed the most sophisticated AI models, like ChatGPT we 
hear so much about. American companies, universities, and 
research institutes are producing the bulk of the cutting-edge 
research that is pushing forward the frontiers of knowledge in 
the field.
    Going forward, maintaining America's edge in AI will be key 
to our continued national security and economic prosperity, but 
we cannot take that lead for granted. We are now entering a 
stage of widespread AI adoption. According to business leaders, 
AI technologies will be integrated broadly into the economy, 
both here and abroad. A large global survey of employers said 
they are highly likely to adopt AI over the next 5 years. They 
expect AI to create a lot of job churn but to ultimately lead 
to a 25 percent net increase in jobs. That is why they also 
identified AI and Big Data as among their top priorities for 
workforce upskilling. That means, going forward, keeping our 
global edge in AI will increasingly depend on the global 
competitiveness of a broader American AI workforce.
    We will still need to have the best computer scientists and 
software engineers. That report found AI and machine learning 
experts are projected to be among the fastest-growing jobs in 
the country. But we will also need to fill a much broader pool 
of AI-related work roles requiring various skill sets. There 
will be opportunities for both new workforce entrants and 
employees looking to retool and upskill.
    But this transition will also test our training pipeline, 
and America's pipeline in the STEM fields is a concern. Take 
cybersecurity, which is also critical to our national and 
economic security. We have a shortage of 700,000 cybersecurity 
workers across the private and public sector, and why is that? 
We know that our traditional education system does not produce 
nearly enough degreed grads in the field to fill the need. We 
also know that that shortfall would be much worse if not for 
the appearance of nimble educational alternatives that include 
short-term boot camp programs that issue non-degree 
credentials, like certifications and badges.
    Our witnesses today will testify about how these sorts of 
flexible, targeted programs that reduce borrowing needs are now 
being used to train young people for AI-related roles and to 
upskill older workers. We know that China is making a 
multipronged push to lead in AI talent. They have been trying, 
largely without success, to lure back home Chinese nationals 
graduating from top U.S. computer science programs, but they 
domestically produce many more STEM grads than we do, and the 
Chinese Ministry of Education has approved in recent years 
hundreds of new university AI programs, according to Georgetown 
University's Center for Security and Emerging Tech, which also 
found that AI is the most popular new major in China.
    Before I yield, I want to speak to the Federal workforce. 
It is critical the Federal Government has an appropriate AI 
workforce. We have a bill on the Committee reported last year 
that requires Federal managers to be trained on AI so the 
government can deploy it wisely. We had the Defense 
Department's chief AI officer testify before this Subcommittee, 
and it is clear DOD is at least making progress in this space, 
but the Office of Personnel Management is another story. It was 
tasked 3 years ago by Congress with identifying AI talent gaps 
across the Federal civilian AI workforce and with creating a 
new AI job series for Federal workers. It has done neither of 
these things, so we are still waiting.
    And then with that, are we going to waive on two Members?
    I am going to ask unanimous consent for Representative 
Krishnamoorthi from Illinois and Representative Beyer from 
Virginia to be waived onto the Subcommittee for today's hearing 
for the purposes of asking questions.
    And without objection, so ordered.
    And with that, I will yield to the Ranking Member for his 
introductory remarks.
    Mr. Connolly. I thank the Chair. A 2020 World Economic 
Forum study found that AI-generated machines could disrupt an 
estimated 85 million jobs globally by next year. Though that 
sounds scary, and is, the study also suggested that AI adoption 
could, on the other hand, create as many as 97 million new 
jobs. AI has to be a tool used to enhance the job, not replace 
the worker. If done correctly, we can create a new job sector 
that equitably spreads the benefits of AI to all parts of 
society while remaining a global technological leader.
    One requirement necessary for the U.S. to remain a global 
leader in AI is to build and invest in a robust workforce and 
talent pipeline that draws from every corner of the American 
educational system. We must prepare future technologists from 
the moment they enter elementary school and attract talent from 
all places, including community colleges, 4-year colleges, and 
trade schools. That is why I co-led the Chance to Compete Act 
with Virginia Foxx of North Carolina, which would allow 
agencies to hire based on one's ability to do the job. We 
believe the Federal Government should reward those based on 
merit rather than affiliation. Giving people the opportunity to 
retrain and reskill into new fields and professions based on 
achievement and ability will help unlock massive amounts of 
unrealized talent.
    To remain competitive with the private sector, the Federal 
Government must nurture its own talent pipeline. One way we can 
do that is to provide students with the opportunity to 
participate in meaningful paid internships. Much of the private 
sector, including large firms like IBM, Microsoft, Google, 
Nvidia, are already excelling in this process. The Federal 
Government must model internship programs and find ways to get 
great talent into agencies, whether it is for a quick stint or 
a lifelong career. Even a short time in government can be 
valuable and provides an opportunity to share knowledge between 
both the public and private sectors.
    The legislation I have introduced, the Building the Next 
Generation of Federal Employees Act, would do just that by 
increasing the availability and quality of paid internships 
across the entire enterprise of the Federal Government. I hope 
this is a source of bipartisan interest on the Committee as we 
work to reintroduce in the coming weeks. We also cannot forget 
about our current Federal employees and must provide them with 
technical and conceptual AI training resources. The President's 
executive order, which we had a hearing about a few weeks ago, 
makes it clear knowing how to use technology can be great, but 
knowing how to use technology responsibly is paramount.
    I have co-led the AI Training Expansion Act with Chairwoman 
Mace, which would expand the access and curriculum of these 
educational programs to employees up and down the 
organizational chart. We must make this training more than just 
an AI awareness exercise and ensure that such training enables 
employees to harness the power of AI in order to do their jobs 
smarter, faster, and to greater effect.
    Another way that government could benefit from AI is 
through joint ventures between the public and private sectors 
that drive toward collaborative solutions. Many have likened 
the AI revolution to the next space race, which is why Congress 
created the National Artificial Intelligence Resource Task 
Force in 2020 to explore ways to effectively foster AI research 
and application. Among the findings of the task force's January 
2023 final report was the need to increase the diversity of 
talent in AI by ``supporting the needs of researchers and 
students from diverse backgrounds who are pursuing 
foundational, use-inspired, and translational AI research. The 
report recommended that we look for this talent in academic 
institutions, nonprofits, startups, and small businesses.
    President Biden's Fiscal Year 2023 budget requested $1.8 
billion in non-defense R&D related to AI, including successful 
public/private partnerships. The budget also sought funding for 
critical resources for NIST, the National AI Research 
Institutes, and Federal agencies as they implement the 
Administration's recent groundbreaking AI directives. Those 
bodies are responsible for developing guidelines for evaluating 
and red teaming, promoting ethical and trustworthy systems and 
technologies, and contributing to innovative solutions. We must 
invest in educational resources and teachers who can help 
students prepare for the future and help employers identify 
those who will lead the AI workforce and AI innovation. We need 
a workforce that will use AI ethically and equitably, ensuring 
AI is used to benefit American families, communities, and 
businesses across the country.
    I look forward to a productive discussion today with our 
witnesses, specifically, how we can better prepare, not 
replace, our current workforce for the possibilities of AI. 
Thank you.
    Ms. Mace. Thank you. I am pleased to now introduce our 
witnesses for today's hearing. Our first witness is Dr. William 
Scherlis, Professor of Computer Science at Carnegie Mellon 
University. Our second witness is Ms. Timi Hadra, Client 
Partner, and Senior Executive for West Virginia at IBM, and our 
third witness is Dr. Costis Toregas, Director of the 
Cybersecurity and Privacy Research Institute at the George 
Washington University. We were also going to be joined today by 
Dr. Richard Levin, a former president of Yale University and 
Senior Advisor at Coursera. Unfortunately, Dr. Levin fell ill 
over the weekend and could not be here in person today. We want 
to wish him well and hope for a speedy recovery. In lieu of his 
attendance, I ask unanimous consent to enter his testimony into 
the record.
    So, without objection, so ordered.
    Welcome, everyone. We are pleased to have you this 
afternoon.
    Pursuant to Committee Rule 9(g), the witnesses will please 
stand and raise their right hands.
    Do you solemnly swear or affirm that the testimony that you 
are about to give is the whole truth and nothing but the truth, 
so help you God?
    [A chorus of ayes.]
    Ms. Mace. Let the record show that the witnesses all 
answered in the affirmative. We appreciate all of you being 
here today and look forward to your testimony. We will remind 
the witnesses that we have read your written statements, and 
they will appear in full in the hearing record. Please limit 
your oral statements to 5 minutes. As a reminder, please press 
the button on the microphone in front of you so that it is on, 
and the Members up here can hear you. When you begin to speak, 
the light in front of you will turn green. After 4 minutes, it 
turns yellow, and when the red light comes on, your 5 minutes 
has expired, and I will ask you to wrap it up very politely.
    So today, I will now recognize Dr. Scherlis to please begin 
his opening statement.

                  STATEMENT OF DR. WILLIAM L. SCHERLIS

                     PROFESSOR OF COMPUTER SCIENCE

                       CARNEGIE MELLON UNIVERSITY

    Dr. Scherlis. Chairwoman Mace, Ranking Member Connolly, 
Members of the Subcommittee, thank you for the opportunity to 
participate in this important hearing. I am William Scherlis, a 
professor of computer science at Carnegie Mellon, but I should 
also mention that I have government experience, the honor of 
serving two tours at DARPA, the Defense Advanced Research 
Projects Agency, with a mission to advance innovations in 
information technology for national security, including AI and 
cybersecurity.
    We are at a critical time with modern AI, neural networks 
for machine learning, large language models, LLMs, ML. This 
places, as you note, extraordinary demands on our workforce. 
How do we harness the power of AI while avoiding the pitfalls? 
How do we stay current with the exceedingly rapid pace of 
innovation? How do we stay ahead of competitors? That is why 
H.R. 4503, that you together have introduced, is so vital for 
the Nation.
    Many have spoken about the potential for modern AI, and I 
am very excited about this, so many applications, but for our 
conversation today, we need to understand the whole picture, 
and this includes some not so obvious weaknesses and 
vulnerabilities, the pitfalls, and you have mentioned some of 
those as well. We hear about issues of bias and fairness and 
accuracy. Even with fully correct training data, we can get 
wrong answers--machine learning, mis-categorizing LLMs, 
hallucinating--and we struggle to explain.
    We also have cyber adversaries. AI turns out to be an easy 
target. Undergraduates learn to spoof neural nets for face 
recognition. It is unclear whether this spoofing is fully 
preventable. LLM providers provide guardrails, so systems do 
not do bad stuff--inventing new kinds of fraud, for example, 
but researchers know how to bypass those guardrails.
    So, there are four ways that we address these challenges. 
First is what we call AI engineering. AI is actually generally 
a capability within a system, and systems operate within 
operational workflows. AI engineering is about designing and 
testing the systems, the workflows, and the AI inside. Our 
engineering college at Carnegie Mellon has master's degree 
programs for AI engineering, each for a specific engineering 
discipline. The Software Engineering Institute, a CMU FFRDC for 
the Defense Department, develops AI engineering practices for 
the DOD and others. So, that is the first.
    The second is we need to continuously make improvements to 
the machine learning and LLM algorithms. The third is, in 
addition to that, we have to aggressively develop new kinds of 
AI technologies that will take us beyond the purely statistical 
neural nets. Remember, we are just getting started with AI, but 
the fourth point, and most important, is awareness, what the AI 
workforce needs to understand. Now, AI researchers have many 
opinions on this, but that is the way it should be, and my 
point is that there is a wide range of AI-related skills and 
expertise, data wranglers, LLM prompt writers, interaction 
designers, systems engineers.
    The executive order that was mentioned, 14110, on 
trustworthy AI highlights the role of AI red teams to mitigate 
weaknesses and avoid hazards. They are like cyber red teams but 
with sophisticated AI skills. Everybody at all levels needs to 
understand the pitfalls as well as the benefits, and when we 
put this together, the roles and skills that they need, we see 
a very broad range of needs for the AI workforce.
    At Carnegie Mellon, we help the AI workforce in many ways. 
Degree programs, we have AI Ph.D.s, and I am going to say this, 
that go back to the 1950's. We have the Nation's first 
undergraduate degree in AI. We have about 2 dozen master 
programs. The curricula draw from computer science, statistics, 
data science, math, but also ethics, psychology, humanities, 
and the arts. Nondegree programs are essential to broaden 
access and to scale up. We partner with the Army Futures 
Command and the Army AI Integration Center on offerings that 
are tailored to the huge diversity of Army AI developers and 
users.
    At the other extreme, for K through 12, we have CS Academy, 
now used for free by 7,000 teachers in all 50 states. 
Pittsburgh Public Schools asked for this kind of capability. We 
developed it, and it took off. We also engage the workforce 
directly. Hotel and transit workers, for example, directly 
participate in our programs to ensure that the AI that they use 
aligns with their experience with benefits both to the 
employees and the employers, and we have government-focused 
executive education. With Learning by Doing, students gain 
hands-on AI experience tailored to their mission.
    So, to summarize, AI offers tremendous opportunity and 
tremendous challenges, many of which are non-obvious. Success 
with AI depends on unique skills and expertise. There are many 
kinds of AI roles and applications, which means many kinds of 
workforce needs. Our CMU experience illustrates a few ways to 
meet many of those needs, but we need to keep pace because it 
is a very fast-moving environment. The proposed legislation to 
expand AI training----
    Ms. Mace. We are over time. Thank you.
    Dr. Scherlis [continuing]. Vital for the Nation.
    Ms. Mace. Thank you, and then, Ms. Hadra, you are 
recognized for 5 minutes.

                      STATEMENT OF MS. TIMI HADRA

                  CLIENT PARTNER AND SENIOR EXECUTIVE

                           FOR WEST VIRGINIA

                                  IBM

    Ms. Hadra. Good afternoon, Chairwoman Mace, Ranking Member 
Connolly, and distinguished Members of the Subcommittee. Thank 
you for the opportunity to testify today. My name is Timi 
Hadra, and I am a client partner at IBM and have been 
supporting Federal agencies for over 20 years. I also serve as 
IBM's Senior Executive for West Virginia, where I lead our 
Regional Innovation Center, driving innovation and promoting a 
skills-first talent perspective.
    IBM has been a proud partner to the U.S. Federal Government 
for decades, helping agencies use technology to accomplish 
their missions, meet new challenges, and drive innovation. 
Today, we have over 4,300 IBMers working alongside Federal 
workers. IBM has been at the forefront of innovations, such as 
AI, for decades. You may recall in 2011, IBM's Watson won 
Jeopardy and ushered AI and machine learning into the living 
rooms of America. And now, in an era of accelerated, generative 
AI adoption, IBM's AI platform for enterprise, Watson X, is 
helping business and governments manage their data with trusted 
governance and innovative, open-source solutions.
    Today, I will share how IBM has helped prepare people to 
work alongside AI, created new pathways for technology jobs, 
and reskilled our own workforce to maximize opportunities 
created by technologies. And last, I will share our 
recommendations on how the Federal workforce can be AI ready.
    First, let me underscore IBM's commitment to responsible 
development and deployment of AI. When harnessed and deployed 
responsibly with ethics at its core, AI can enrich and advance 
human ingenuity in ways that could solve the most pressing 
problems of our time. We are also mindful of the impacts new 
innovations have on society and what skills people will need to 
work with emerging technologies, and here are three examples.
    In 2021, IBM unveiled a global commitment to help skill 30 
million people by 2030, and most recently, we pledged to train 
2 million people in AI by 2026. This will be accomplished 
through IBM's SkillsBuild, our online platform with free 
coursework for teachers, students, and adult learners. It 
offers free coursework in AI fundamentals, chatbots, AI ethics, 
and generative AI. We are collaborating with universities and 
leveraging our network of experts to build faculty and student 
AI capacity. I encourage you to share with your constituents 
the free AI courses that they can start taking today.
    Ten years ago, IBM embarked on a skills first journey, 
creating opportunities for well-paid jobs for those without 
college degrees, including apprenticeships for technology jobs. 
Today, more than 50 percent of our U.S. job postings no longer 
require a 4-year degree, and almost 20 percent of our U.S.-
based hires do not have college degrees. As generative AI 
begins to transform industries, skills play an even more 
crucial role in meeting the talent need of employers. That is 
why IBM places skills at the center of our people strategy. IBM 
requires employees to complete at least 40 hours of learning 
annually and provides the tools for that learning. IBMers with 
the highest learning hours are 20 percent more likely to move 
to a new role and 44 percent more likely to get a promotion.
    As AI adoption accelerates, we believe Congress must double 
down on actionable ways to ensure the Federal workforce is 
ready to safely procure, govern, and work alongside AI. It is 
time to put implementation into high gear. Specifically, we 
believe there are two key ways Congress can help advance an AI 
ready workforce. First, foster a culture of upskilling and 
lifelong learning. The Federal Government must place skills at 
the center of the people strategy and invest in quality, 
relevant, and accessible tools for the span of each worker's 
career. Second, scale skills first hiring in the Federal 
Government and on Federal contracts.
    AI is here. It is redefining work, and it will require more 
people to work with technology. IBM looks forward to continuing 
to work with Congress to advance a risk-based approach to 
regulating AI while ensuring Americans, including the Federal 
workforce, have access to skills training in the era of AI 
adoption. Thank you for the opportunity to testify today.
    Ms. Mace. Thank you. I now recognize Dr. Toregas to please 
begin your opening statement.

                    STATEMENT OF DR. COSTIS TOREGAS

                                DIRECTOR

             CYBER SECURITY, AND PRIVACY RESEARCH INSTITUTE

                      GEORGE WASHINGTON UNIVERSITY

    Dr. Toregas. Chairwoman Mace, Ranking Member Connolly, and 
Members of the Subcommittee, I appreciate the opportunity to 
testify today. I am Dr. Costis Toregas, Director of the 
Cybersecurity and Privacy Research Institute of the George 
Washington University, and a fellow of the National Academy of 
Public Administration, chartered by Congress in 1984 to help 
address critical societal challenges.
    I applaud your efforts to focus attention on the critical 
workforce shortages looming ahead in the artificial 
intelligence field and the impact such shortages may have on 
American strength and prosperity. The truth is that while AI 
has been around for many years, as we heard, from the 50's, 
interest and concern peaked only recently as its use has become 
easy for the general public, and they know. Rather than talking 
about what is AI or how can we develop or regulate AI, I am 
going to focus my remarks on how can we develop a workforce 
pipeline that can use AI to strengthen the U.S. economy.
    We have very few markers to help us answer this third 
question. We know that we do not yet have adequate numbers of 
teachers and faculty to teach AI. We are not sure how we can 
test students and workers for AI readiness. AI courses in high 
schools, community colleges, and universities are not organized 
around national best practice, so we are at the beginning of 
the adoption curve for this powerful technology, and things are 
kind of messy. So, how should we proceed?
    I suggest that we look at another critical workforce 
pipeline, that of cybersecurity that you are very familiar 
with, and learn from the 10-plus years of investments we have 
been making and focusing on developing larger numbers of cyber-
ready workers. The systems, the networks, the incentives, the 
educational strategies we created can help us develop AI 
counterparts and perhaps even use the same performers, the same 
strategies to good effect.
    In my written testimony, I have identified several 
cybersecurity experiences to consider: the importance of 
diversity in the workforce, the challenge of organizing 
educational programs across disciplines, the rapid change of 
the underlying technology itself, and, most importantly, the 
difficulty of confronting 50 diverse educational programs at 
the state level that may approach the workforce issue and the 
educational streams supporting it differently. These all 
contribute to a difficult learning curve for cybersecurity 
workforce, and yet, we learned a lot, and I want to encourage 
you to look at the strong lessons learned in the cybersecurity 
world and support their transfer in the AI domain rather than 
spend valuable time and resources building AI responses from 
scratch.
    Let me now offer five action suggestions for your 
subcommittee. One, develop a statistical capacity at national 
level to track current numbers of students and teachers in AI 
by region, as well as estimated AI workforce needs of 
government and industry in the future. We will not know if we 
are succeeding if we cannot measure our outcomes. Two, 
encourage states to harmonize AI programs for K through 12 
through national conversations of experts and discussions of 
circular frameworks and rubric, and promote the broad notion of 
a digital citizenship program for all students that will 
include not just AI, but digital literacy, cybersecurity, 
privacy, and civics in the digital era.
    Three, support the development and maintenance of curricula 
focused not only on the ``what is AI?'' or ``how can AI be 
improved?'' but, rather, how can AI be used in this space. Good 
candidates for execution are the more than 1,000 locally based 
and supported public, independent, and tribal community 
colleges, and they can be strong performers in the new field of 
AI workforce development. They are able to change courses 
quickly and adopt AI-focused curriculum, degrees, or 
certificates far faster than other types of educational 
institutions.
    Four, focus on the need for additional AI educators
    --we need teachers, which we do not have now--and establish 
support programs that incentivize their attraction and 
retention at high school, community college, and university 
level. My good friend Janelle Strzok, who is the Chairwoman of 
Women in Cybersecurity, has three words to describe how you can 
support a network of individuals. She says, connect, inspire, 
and guide. We need to do that for our faculty, for our 
teachers.
    And then finally, help launch a tripartite partnership 
between private sector, education, community, and government 
around workforce development issues in AI. We currently speak 
in isolation, and we need to come together and create viable 
solutions with all stakeholders at the table. The mandate could 
include establishing a long-term vision and the steps necessary 
to align academic performance to industry needs. Industry and 
academia must come together. You can help do that. Thank you 
very much.
    Ms. Mace. Thank you so much, and I will now recognize 
myself for 5 minutes.
    My first question goes to Ms. Hadra. Thank you for being 
here today. Your testimony states that robust implementation of 
the AI and Government Act by the executive branch would be a 
key first step in preparing the Federal workforce for a new way 
to work using AI. In that law Congress adopted 3 years ago, 
Congress told the Office of Personnel Management to find out 
how many employees at each Federal agency have AI skills and 
how many more we need. It also recommended OPM create an AI job 
series. OPM has done none of that. How can Congress ensure the 
Federal workforce is AI ready if we do not know the current 
skill level in agencies or their future needs?
    Ms. Hadra. Thank you for that question, and a good place to 
start, I mentioned in my written testimony and in my oral 
testimony about IBM SkillsBuild. This is a free online platform 
for students, teachers, and adult learners, so it applies to 
our Federal workforce. It is a place that we can get started 
quickly to start having our Federal workforce learn the AI 
skills that they need, while each agency works to employ the 
requirements in the OMB memo.
    Ms. Mace. Has IBM attempted to determine how many of its 
employees are AI qualified company-wide?
    Ms. Hadra. I do not have the specific numbers, and I can 
get those for you on our company-wide numbers.
    Ms. Hadra. But we have a curriculum that we implemented in 
the summer of 2023 that all IBMers were required to complete. I 
think it was about 12 hours of curriculum, and the thing that 
we did on top of----
    Ms. Mace. So, you have a metric that you are tracking, at 
least with your employees' qualifications.
    Ms. Hadra. Right.
    Ms. Mace. Mm-hmm.
    Ms. Hadra. And then have them put that to use. I mentioned 
in my written testimony about our Watson X challenge, which was 
in August 2023, where after they took the curriculum, we had 
teams come together and solve a business problem using our 
Watson X platform, so that they were not only taking courses on 
learning the AI technology but also how to put it to work.
    Ms. Mace. Right. Why do you think it is so hard for the 
Federal Government or certain agencies to adopt this kind of 
nimble attitude toward AI?
    Ms. Hadra. That is a great----
    Ms. Mace. Smart and nimble, right.
    Ms. Hadra. It is a great question, and it is a challenging 
topic, but I think sometimes, as some of my fellow panelists 
mentioned, we are not talking across agencies. Maybe we are not 
talking across industry. I think it is important for the 
Federal Government to look at what industry has done and try to 
implement and use the tools that are out there, like our 
SkillsBuild, like the other platforms that are widely 
available, and start getting those in use sooner.
    Ms. Mace. We need a Khan Academy of AI is what we need. You 
also mentioned in your testimony that Federal contractors are 
rarely able to place an individual without a 4-year degree on a 
technology services contract, regardless of their 
qualifications. Are you saying that the terms of the Federal 
contracts IBM is asked to sign prohibit the work be done by 
those without college degrees? Does that inhibit your ability 
to fill those roles?
    Ms. Hadra. Yes, it is an issue, and let me explain. In my 
experience with Federal contracts, a lot of times you have 
labor category descriptions and requirements that say, if you 
have a cybersecurity analyst, these are the minimum 
qualifications that they must meet. In some cases, we have seen 
change, so it is not that the regulations are not being 
implemented, but it is just not enough. So, as an example, that 
cybersecurity analyst, it may say as an entry level, you need a 
bachelor's degree plus 1 year of experience, or it might say 
bachelor's degree, or you can substitute 4 years of experience. 
But our cybersecurity apprenticeship program is a 6-month 
curriculum. Those people do not have 4 years of experience, but 
they are immersed in 6 months, and they are ready to hit the 
ground running on those programs. And because they do not meet 
that minimum qualification, we are not able to put them on that 
contract.
    Ms. Mace. They might even be more qualified than someone 
with a 4-year degree because they put that skill set into 
practice. I am going to move on as I am running out of time, 
and I apologize. Dr. Scherlis, my last question today is 
Carnegie Mellon and other leading universities now offer a 
variety of AI-related education options, including traditional 
degrees, boot camps, certifications, et cetera. Are there 
effective alternatives to traditional undergraduate and 
graduate degrees that will be instrumental in preparing the 
American workforce to be AI ready? What do you advise?
    Dr. Scherlis. Thank you for that question. I mentioned one 
example, which is working directly with the workforce. In this 
case, it was related to hotels and transit workers, right, and 
working directly with the workers and their employers so that 
when the employers are building AI systems, they can craft 
those systems in a way that aligns well with the workers' 
experience and knowledge and how the workers can evolve in 
those roles. So, that is one example of direct outreach.
    Ms. Mace. Thank you. Thank you so much, and I have run out 
of time, so I will hand the microphone over to recognize my 
colleague from Virginia for his 5 minutes.
    Mr. Connolly. Thank you, and before the clock starts, can I 
ask unanimous consent to enter a statement from Johns Hopkins 
University and the Center for AI and Digital Policy into the 
record?
    Ms. Mace. Without objection.
    Mr. Connolly. I thank the Chair.
    Mr. Connolly. Dr. Toregas, you stated in your testimony 
that standard terminology for AI skills is still under 
development. Why is it still under development, and why is it 
even important?
    Dr. Toregas. Thanks for that question. It is important 
because, otherwise, we cannot classify and promote specific 
skills for specific jobs, and we met the same circumstance in 
cybersecurity. It has taken them at least 8 years to develop a 
typology for cybersecurity skills development. We also have 
several agencies, each of which promote their own typology. As 
a consequence, I think it is vital with AI, since we are still 
in the beginning, to jump first and to insist that there be 
some kind of a mechanism that defines what are the skills, how 
do you prove that you have those skills, and how do they mesh 
to job requirement.
    That is the last thing I said when I talked about industry. 
It is very difficult sometimes for an academic institution to 
hear what industry needs.
    Mr. Connolly. Yes.
    Dr. Toregas. So, sometimes it gets lost in translation, so, 
therefore, surrogates come in. Do you have a bachelor's degree? 
OK, good. You are good to go. That should not be the case.
    Mr. Connolly. Yes.
    Dr. Toregas. It should be the case that we align to 
specific skills and specific preparations. That is what is 
needed in standardization. Thank you.
    Mr. Connolly. Yes. Yes. That is actually something that has 
always fascinated me, that gap between lab bench research, 
science, academia, and what IBM needs, and trying to translate 
that is not always easy. We certainly saw that in the 
commercialization of technology once the cold war was over. 
DARPA, where you were, Dr. Scherlis, you know, had lots of 
technology that was classified. For example, one no longer 
classified is sound cancellation technology, you know, used for 
submarines. Well, we are using it all the time now in the 
commercial sector, but it took somebody to understand the 
application, and who are those people. And they may not need a 
degree. They may have common sense and private sector 
experience, knowing what the environment demands.
    Dr. Scherlis, you were at DARPA. You have sort of been at 
the beginning of this, well, beginning of this explosion of 
this fascination with AI. What keeps you up at night? What 
worries you about where we could go with AI?
    Dr. Scherlis. So, I have a concern regarding the various 
pitfalls that I mentioned in my statement and elaborated in 
some detail in the written statement. My concern is not about 
those pitfalls, but my concern is, rather, that those who are--
because the AI applications are so compelling and so 
transformative, not just enhancing productivity but creating 
new ways of doing business, that we get so enamored of those 
that we do not have that awareness of what the pitfalls are, 
and we get stuck, and we get surprised. And that is one of the 
characteristics, in fact, of the world of cybersecurity, is 
that we build systems. We can measure what the system does and 
how long it takes to build that system and how much it costs. 
We cannot easily measure how secure it is, and so we let 
security attributes kind of evolve and unfold over time, so 
that is a significant challenge.
    And I think that part of this AI education and training 
process is to help people be aware of the various pitfalls, the 
weaknesses and vulnerabilities, and also the mitigations, the 
various techniques that we can use as we engineer systems and 
as we place systems into workplace contexts to use those 
systems safely.
    Mr. Connolly. Yes. Sometimes, though, I have seen it in 
cyber. I have looked at cyber protection programs, but they 
also train people in cyber techniques we would prefer they not 
be trained in, but to protect, you have to, but it can be used 
for good and bad once you have trained somebody.
    Dr. Scherlis. Right. Actually, I just want to make one more 
point, which is the point about measurement of cybersecurity 
risk, the point about measurement of similarly AI risk 
educational outcomes. These are all hugely challenging research 
questions. As we think about putting programs in place, I think 
it is important to think also about what kind of research we 
can do to measure and assess outcomes, both for the systems and 
also for the people who are entangled with those systems, 
recognizing how fast the technology is evolving.
    Mr. Connolly. I was going to ask Dr. Toregas the same 
question. Real quickly, what keeps you up at night?
    Dr. Toregas. Three things. Equity, the fact that in many 
cases, human beings are not before AI impacts operations, and 
then the replicability. You cannot force a scientist who is 
into AI to replicate an experiment because AI works in 
mysterious ways, so, therefore, we cannot be sure of how 
exactly is it working. Those are the three things.
    Mr. Connolly. Thank you.
    Dr. Toregas. Thank you.
    Ms. Mace. Thank you. I will now recognize Mr. Timmons for 5 
minutes.
    Mr. Timmons. Thank you, Madam Chair. I think the challenge 
we are facing is bifurcated in two areas. One is the existing 
workforce. How do we elevate the capacity of our existing 
workforce to maximize the benefits that AI offers our economy, 
our businesses? And I think that is separated into two areas. 
One is government because government generally does not adopt 
best practices as fast as the private sector. I think that is 
an understatement. The other is, how do we develop undergrad 
and graduate degree programs that will increase our capacity to 
further develop AI and advance the potential positive impacts 
that it has? And I think that part is relative to our 
competitiveness in the international community, and the first 
part is making sure the U.S. economy is continuing to be 
competitive in the global economy.
    Dr. Scherlis, would you agree that that is a good way of 
looking at it? How do we increase our capacity of our workforce 
and separate that between the government and the private 
sector, and then how do you develop our capacity long term to 
be a leader in this in the global community.
    Dr. Scherlis. So, thank you for that question. So, I will 
agree that there is some separation, but I think the separation 
is largely, arguably, a cultural outcome that in government, it 
is really important for us to have strong programs of 
professional development and advancement for our technology 
workforce. Otherwise, people do not stay current. And I think 
that it may be that in many firms in the private sector, 
certainly in the tech sector, that is an active element of the 
employer handshake.
    But I think, you know, when I look at what is going on, for 
example, in the Defense Department, for example, our 
conversations with the Army, the role of leadership and the 
ability of leadership to think in imaginative ways, to think 
about what kinds of risks can we safely take, that can bubble 
down through an organization and affect, for example, who is 
involved with acquisition, with engineering, with developing 
strategy, with planning. All those kinds of positions are going 
to be affected by AI, so if we create an environment where we 
are receptive to change, we are receptive to education and 
learning, I think that would make a significant difference.
    Mr. Timmons. Would you agree that human nature generally is 
going to facilitate increased usage of AI? I mean, if it can 
make it easier for you, might as well try to use it. A lot of 
people out there have tasks that they do not want to do in 
their job and in their lives, and if you can press the easy 
button, you are likely going to do it. So, a lot of it is 
awareness in that respect. Is that fair?
    Dr. Scherlis. Well, that is why awareness of the AI 
pitfalls is so important because if we make it very easy to 
adopt AI for purposes for which it may not be well matched, 
then all of those problems of bias and fairness and 
vulnerability to adversarial attacks, all of those bubble up. 
So, the adoption process, on the one hand, should be attentive 
to the potential to not just improve productivity but to create 
new capabilities on the one hand, but on the other hand, to do 
that in a way where we are attentive and alert to the risks and 
safety issues----
    Mr. Timmons. And I guess I want to talk about those risks. 
Dr. Toregas, you mentioned this. If you use ChatGPT and you ask 
a question, and then you say, answer that question if you are 
in Saudi Arabia or if you are in Yemen, it is actually quite 
different. Certain words are entirely gone. The word that they 
use as ``ethics'' instead of ``equity,'' instead of ``DEI,'' it 
actually is culturally different. So, I mean, how do we have 
this conversation in a productive way without kind of imposing 
our cultural values on the planet? Does that question make 
sense? If your biggest concern is equity and your view of 
equity and your values are very dissimilar from other cultures 
that are also going to be using AI, how do you reconcile that? 
How do you deal with that?
    Dr. Toregas. Thank you for that question. It has no simple 
answer, alas. I would say that the very technology of AI 
includes a session where AI learns--you kind of stuff the 
machine with things--before you even use it. What you stuff the 
machine with is vital, and many different countries are 
beginning to use AI by including and incorporating training 
regimens that reflect their own values, so their AI is 
different from our AI. There is no independent AI. So, as a 
consequence, I think, ultimately, as a society, we are going to 
have to learn to reflect in what we expect of AI our own 
values.
    Mr. Timmons. Thank you for that. I yield back, Madam Chair.
    Ms. Mace. Thank you. I now recognize Mr. Lynch for 5 
minutes.
    Mr. Lynch. Thank you, Madam Chair. Initially, I would like 
to ask unanimous consent to enter into the record a statement 
from the Partnership for Public Service, a nonpartisan, 
nonprofit organization dedicated to better government and 
stronger democracy. I assume that is OK. I was looking for 
unanimous consent on this, yes.
    Ms. Mace. Yes.
    Mr. Lynch. OK. Great. Thank you.
    Mr. Lynch. I assume that, but lately you do not want to, 
you know, leap to conclusions. First of all, I want to thank 
the witnesses for your good work in helping the Committee with 
its task.
    So last year, the Biden Administration launched a National 
Cybersecurity Workforce and Education Strategy, and then 
recently, as recent as last month, the National Science 
Foundation launched a new initiative called the Education AI 
Initiative. So, we have seen some work within our university 
systems across the country. I know that in my own district, 
UMass Boston University of Massachusetts, Boston, which is home 
to the Paul English Applied Artificial Intelligence Institute, 
has begun their work with a goal of, you know, attracting 
students for that specific discipline. In Bridgewater State 
University, also on the edge of my district, they have created 
a first-of-its-kind cybersecurity program with the help of 
Federal grants to try to inculcate students in that curriculum, 
and as well, Northeastern University in my district has the 
Institute for Experiential AI, which helps actually solve AI 
research problems.
    So, we are beginning to see energy and resources being put 
into this effort, but one of the gaps is the availability of 
teachers in this discipline. I mean, I founded a charter school 
in Massachusetts, and while we might have 90 applicants for a 
teaching position in English, we might have 11 applicants for a 
similar position in math and science. And so, what is happening 
is, especially in the Boston area, and it is happening 
everywhere, I am sure, is private industry is scooping up 
anybody with a certain talent or skill set. How do we get at 
that problem where we actually create the teachers who will be 
able to sort of multiply the effort and help us either catch up 
to some of the countries that seem to have taken a lead in this 
or actually maintain our edge? Dr. Toregas?
    Dr. Toregas. Thanks again for that question. I think 
experimentation and boldness are the keys. In my own University 
of George Washington, the National Science Foundation and NIST, 
the National Institute of Science and Technology, has provided 
a grant to develop a comprehensive way to look at law and 
society. It is called Trustworthy AI in Law and Society. The 
key there is the combination of different disciplines which can 
inspire teachers to want to become involved in it.
    A second simple example is the networking of professionals 
together. National Science Foundation
    --again, bravo to the National Science Foundation--has 
funded something called the National Center for Training and 
Education in Cybersecurity. They assemble more than 300 
universities and community colleges, they develop common 
curricula, and they help faculty careers. The same model can be 
used in the AI field. There is no reason why we cannot begin to 
develop multiple solutions as opposed to one good program here, 
one good program there. We can develop a network of programs.
    Mr. Lynch. That is great. Ms. Hadra, your thoughts?
    Ms. Hadra. Thank you for that question, and we do agree 
that there is an urgent need to train the student and faculty 
capacity in AI, and that is why IBM continues to invest as an 
industry partner in programs that are free, such as the IBM 
SkillsBuild platform. And that is for teachers, that is for 
students, that is for adult learners, so that we can provide 
that fast start to help build that capacity that we need now.
    Mr. Lynch. That is great. Dr. Scherlis?
    Dr. Scherlis. So, I mentioned in my remarks the CS Academy, 
which was in response to exactly this challenge that you just 
identified, and it came to us from teachers in our public 
school system. And it is basically an upskilling program 
intended to help teachers develop skills in computer science, 
and because it is free, it has been adopted extremely widely. 
And it is not just 7,000 teachers, but it is more than 380,000 
students that have benefited from this. But we also have an, 
since you mentioned the NSF, an NSF-funded program focused 
specifically on AI for K through 12, and that is a program 
where we have been developing curriculum. We were a co-lead in 
the creation of that curriculum, and it is now being piloted in 
schools in Georgia. So, this is a really important topic.
    I will just mention when computer science itself burst onto 
the scene in the 1980's, we had similar programs to upskill 
college professors to help them understand the basic features 
of computer science. These are traditionally teachers of 
mathematics and physics.
    Mr. Lynch. Great. Madam Chair, I yield back.
    Ms. Mace. Thank you. I will now turn to Mr. Burlison to be 
recognized for 5 minutes.
    Mr. Burlison. Thank you, Madam Chair. You know, having come 
from the IT industry, there is a very broad array of jobs and 
roles and responsibilities. I recall oftentimes, though, people 
lumped them all in the same thing. They think that everybody in 
IT can fix their computer. You get where I am going. So, with 
that being said, it has already been alluded to that there is a 
varying scope that is broad in the different fields that are 
going to be within this industry, and I will give opportunity 
for each of you to elaborate on what careers or jobs that are 
going to be. What is the range that you see happening, and what 
is the one that is most in demand?
    Dr. Toregas. Thanks for the question. Again, this is why I 
emphasize the importance of typology. How do we describe jobs 
in the AI field? We have already heard that there are jobs, 
like, how do you shape a question? That has become a job now. 
How do you shape a question for ChatGPT? There is also the 
computer science behind it. How do you make better AI 
machinery?
    My kind of North Star would be to make sure that we develop 
our faculty because the key area is faculty. If we do not have 
faculty at the high school level, on the community college and 
university level, we will lose the battle 10 years from now 
because they are being diverted in other fields. And we 
desperately need educators, so that is where the focus has to 
be.
    Ms. Hadra. Thank you for the question. In addition to the 
roles that he just mentioned, I think it is really important to 
think about AI is going to change 90 percent of jobs, right? 
So, we need to think about how, one of the Members mentioned, 
around freeing people up from redundant tasks that you may not 
want, that is not the most exciting part of our work. We have 
done this at the VBA, the Veterans Benefits Administration. I 
mentioned in my written testimony that we used AI and 
automation to help them process a lot of the information that 
comes in, increasing that process time and freeing those 
overworked VBA employees up to do more higher value work for 
the veteran.
    So, I think it is really important that as we are 
considering the era of AI adoption, how we help each employee, 
each Federal worker, think about how their job can change, 
maybe what they can free up to do, and then if their job is----
    Mr. Burlison. Without feeling that their job is threatened.
    Ms. Hadra. Yes. I absolutely acknowledge the uncertainty, 
but if we have transparency about more jobs that are being 
created, jobs are being elevated in our H.R. function. As an 
example, in IBM, when we have done a lot of this reskilling 
already, most of the people in our H.R. job function are now 
one job band higher because we have used AI to----
    Mr. Burlison. Yes.
    Ms. Hadra [continuing]. Automate some of the work that----
    Mr. Burlison. To magnify productivity.
    Ms. Hadra. Exactly.
    Dr. Scherlis. So, I will mention a few elements of this. 
One is, of course, enhancing productivity. Another is providing 
good over-the-shoulder advice. That is the sweet spot for both 
machine learning and large language models, but also, of 
course, developing new kinds of capabilities, but in addition, 
let us think about the network of various roles in an 
organization. Think of that as kind of a workforce supply 
chain, so to speak, and we can take a holistic view of those 
supply chains and think, OK, with the advent of AI, maybe we 
can reconfigure roles that maybe have a traditional 
configuration that could be improved because of the benefits of 
AI.
    And so, we have a program at the Block Center at Carnegie 
Mellon that is doing exactly this. It is a supply chain-focused 
initiative. So, instead of taking existing job roles within 
existing structures, we are looking at the structures 
themselves to see maybe there are ways that we can reconfigure 
how we do the overall body of work within an organization, 
rather than just trying to optimize the individual elements of 
an existing organizational structure. Thank you.
    Mr. Burlison. Quickly, Dr. Scherlis, regarding China, where 
would you place America in its competitive stance when it comes 
to AI with China?
    Dr. Scherlis. I do not have a strong judgment on that point 
because I do not have particular visibility. Everything I read 
tells me that China is definitely investing very heavily. They 
have close connections between universities and government and 
industry that allows them to move very quickly, and I think we 
need to learn how to move very quickly within the structures of 
our democracy.
    Mr. Burlison. Thank you. I yield back.
    Ms. Mace. Thank you. I will now yield to Mr. Khanna for 5 
minutes.
    Mr. Khanna. Thank you, Madam Chair. Thank you for convening 
us.
    Paul Krugman writes about the power loom, that initially, 
obviously, it had high compensation remuneration for those who 
knew how to use it, and then eventually, the technology became 
sufficiently deployed and that the skills required for it were 
not as much, and so you saw a leveling of the income disparity 
as the access to new technology became easier. One of our big 
challenges in the digital revolution, combined with the AI 
revolution, is how we avoid the growing disparity in income 
that we have seen so far and disparity of opportunity. I often 
say, you know, my district, I represent a $10 trillion market 
cap with Apple, Google, Intel, Yahoo, and Tesla, and many other 
parts of the country do not have that economic opportunity.
    Dr. Scherlis, what are a few major initiatives we can 
undertake to create more equality of opportunity when it comes 
to digital wealth generation?
    Dr. Scherlis. I think that starting early is essential, and 
that is one of the reasons why at Carnegie Mellon, we focus so 
closely on K through 12 programs, outreach programs. One, we 
get to people early so they can become kind of acculturated 
with the new technologies, first computer science and now AI, 
and then that also puts them into a state of improved readiness 
so that they can participate, for example, in our degree 
programs with strong backgrounds. In the early days of computer 
science undergraduate degrees, we reached out to K through 12 
for exactly this purpose, to improve the applicant pool for our 
programs so that we could operate those programs at a high 
level. So, I think starting early is the most important lever 
we can push.
    Mr. Khanna. I agree with a far more need for technology 
education starting very, very early on. That does not mean that 
people have to go become computer scientists or programmers, 
but they need to have the facility and understanding, as all of 
you have testified, because these are going to be every job in 
this country. Whether it is manufacturing, retail, or services, 
it is going to require technology proficiency, and I think our 
schools are woefully behind in creating the technology 
proficiency that is going to be required of every individual.
    When we go beyond that and think of the 60 percent who may 
not have college degrees, how do we bridge that divide in what 
I think will be a lot of digital trades jobs, jobs that may 
require 9-month, 12-month, 18-month credentialing and be able 
to pay a lot, but we are not preparing them. I mean, one of the 
programs I have done with Google and HBCUs, community colleges, 
and HSIs is, actually, Google, with other technology companies 
have come, and Carnegie Mellon, I think, is actually involved 
in it, in providing some of the curriculum and then creating a 
pathway for these folks after 18 months to get a job. And 
candidly, some of the community colleges I went to, they could 
have all the education in the world. They would be woefully 
unprepared to actually get a job and no pathway to a job.
    So, how do we get private industry and the right folks who 
understand the curriculum that is going to be needed for hiring 
involved in this kind of partnership? Maybe I will ask everyone 
on the panel. Dr. Scherlis, we can start with you, and then Ms. 
Hadra and Dr. Toregas.
    Dr. Scherlis. So, I will just mention one example. We have 
a program at Carnegie Mellon called Social and Interactive 
Learning--SAIL--which is a platform that is directly targeted 
to community colleges. We have about 40 community college 
systems across the country that make use of this platform to 
help provide certificates for IT career growth, and so in a lot 
of cases, we collaborate with industry so that these 
certificate programs can be tailored to local needs of local 
employers.
    Ms. Hadra. A quality of opportunity was really the 
foundation of our Skills First talent perspective. One of the 
tools that we use to put this in action is our apprenticeship 
program. You mentioned trades. The apprenticeship programs that 
we have, there are 35 roles registered with the Department of 
Labor, recognized by industry. They get a completion 
certificate when they graduate. And for the workforce that you 
mentioned that might not have the skills to even begin in an 
apprenticeship program, we have also published free pre-
apprenticeship program course work that people can take to 
prepare themselves to become an apprentice.
    But it should be mentioned that our IBM apprenticeship 
program is a full-time paid learn-while-you-earn full benefits 
program, and we have successfully hired over a thousand 
apprentices just in the U.S. since we deployed it, 50 in my 
state of West Virginia.
    Mr. Khanna. My time has expired.
    Ms. Mace. Apologies. You had great questions, by the way. 
They were good. All right. Mr. Langworthy, you are recognized 
for 5 minutes.
    Mr. Langworthy. Thank you, Madam Chair. I would like to 
thank all of our witnesses for being here with us today to 
discuss America's path to an AI-ready workforce, and it seems 
like each passing day is bringing AI more incorporated into 
everyday Americans' lives. Leading experts believe AI will 
completely change the workplace and significantly increase all 
of our productivity, but the bottom line is this: the American 
people need to be prepared for a future where AI technology 
plays an even greater role than it does today. Additionally, we 
need to ensure that AI is harnessed as a job creator and that, 
as this technology is more widely used, effective guardrails 
and training are in place to ensure that it is ethical, and it 
is responsible in its use.
    Ms. Hadra, I would like to start with you and talk about 
our population who is already in the workforce and may not have 
the skill set necessary to be prepared for an AI-integrated 
work product. Many Americans are still new to AI and may only 
see its uses in mainstream models like ChatGPT. How does IBM 
approach the process of retraining and upskilling existing 
employees?
    Ms. Hadra. Thank you for that question. Investing in 
upskilling, reskilling, and lifelong learning is just in IBM's 
DNA. And as we usher in new technologies like AI, we must 
ensure that both our employees and our society more broadly 
have opportunities to gain these skills, and we do this in real 
time. We want our employees to remain valuable to our clients, 
so we employ reskilling and upskilling programs annually. I 
mentioned in my testimony that we require a minimum of 40 hours 
of education learning annually for every employee.
    An example of where we see employees' jobs that are being 
affected by AI, we are reskilling and being transparent about 
what their next path could be. All of our job roles in IBM have 
an associated learning path that shows you what continuous 
learning you need to do to stay on your current role and 
progress in your current role or progress out of your role, so 
we have a multipronged approach to making sure that people have 
transparency. We use a co-creation strategy, so they are part 
of the solution and really have them help buy in to wanting to 
learn the skills because they see the opportunity to grow their 
careers.
    Mr. Langworthy. Thank you, and turning toward college-age 
students and recent graduates, Dr. Scherlis, from a long-term 
perspective, what are the benefits of a traditional 4-year AI 
degree?
    Dr. Scherlis. So, the 4-year AI degree is closely aligned 
with our 4-year computer science degree. It is very intensely 
focused on the mathematics of computer science, on the 
development of software code, on algorithms, on all of the 
technical foundations that are necessary for a full career in 
computer science. Given that the field of computer science is 
moving so quickly, we want to provide our students with a 
foundation that will endure. And so similarly with AI, we are 
focused on that foundation in statistics and data science, in 
computer science, in the design of the computing hardware and 
the computing software so they have a very full background in 
all those capabilities, and then they will be ready to be 
involved in the creation of new kinds of AI capabilities, as 
well as in the application of AI capabilities in ways that are 
safe, that avoid the pitfalls, and that also push the envelope 
in terms of the kinds of things that we can do with AI.
    Mr. Langworthy. OK. You know, my district is a rural 
district, New York's 23d congressional District, where many of 
our high school students, they would choose a career in the 
trades or vocational skills over maybe a 4-year degree. Are 
there opportunities for high school graduates and college-age 
Americans who do not want to go down a traditional 4-year 
degree route to learn the same AI skills?
    Dr. Scherlis. So, that is one of the reasons why I 
mentioned the work that we are doing with community colleges 
but also directly with employers and employees and the program 
that is looking at these so-called supply chains, the structure 
of organizations, because we have to look at the influence of 
AI on everybody, not just the leaders in the technology field.
    Mr. Langworthy. Great. Want to open up this question to all 
of our witnesses because I feel like there are several 
approaches. In terms of school-age children, what programs are 
in place to begin teaching our youngest generations how to be 
proficient with AI, and is there anything that the educational 
system should be doing better to prepare this and for 
subsequent generations? Quickly. Oh, I did not realize. My time 
has expired, so anything that you have to offer in writing, we 
would certainly appreciate that, and I yield back.
    Ms. Mace. Thank you so much. I will now recognize Mr. 
Krishnamoorthi for 5 minutes, sir. Thank you for your presence 
today.
    Mr. Krishnamoorthi. Hey. Thank you, Madam Chair, thank you 
to our Ranking Member for this excellent hearing. Thank you to 
the witnesses.
    [Chart.]
    Mr. Krishnamoorthi. I have this visual here. I did not come 
up with this. I thought it was a really neat visual created by 
Opportunity at Work, and it talks about something called the 
paper ceiling, and it is defined as the invisible barrier that 
comes at every turn for the 70 million workers who are STARs. 
Now, you might be wondering what is a STAR? They define a STAR 
as a person skilled through alternative routes other than 
college, 4-year college. And so, maybe I will start with Ms. 
Hadra.
    Ms. Hadra, I assume that the people that are in your earn-
and-learn program are precisely these types of people, these 
STARs, correct?
    Ms. Hadra. Thank you for that question, and I am so glad 
you brought that up, because, actually, one of our apprentices 
at my center, in Rocket Center, and I mentioned her in my 
written testimony, Cindy, was featured on a STARs campaign ad, 
so yes. Yes.
    Mr. Krishnamoorthi. Oh, great. So, the answer is yes.
    Ms. Hadra. Exactly. Yes, hundred percent.
    Mr. Krishnamoorthi. And so, you know, one of the big 
concerns that I have is that, are you familiar with these 
automated hiring systems that a lot of employers use?
    Ms. Hadra. Not as much, no.
    Mr. Krishnamoorthi. OK. Dr. Scherlis, I think I saw you 
nodding your head. These automated hiring systems basically 
screen resumes to look for certain indicia of whether the 
applicant can do the job that is being posted, but oftentimes, 
what they do is they screen out people without a 4-year college 
degree. Dr. Scherlis, have you seen this automated hiring 
system at work?
    Dr. Scherlis. I have not seen it up close, but when I talk 
with young students who are entering the workforce, this is one 
of the topics of their conversation is what are the magic 
keywords to include----
    Mr. Krishnamoorthi. Right.
    Dr. Scherlis [continuing]. In my resume that will allow me 
to get caught in the net. But I just want to mention that 
outreach to nongraduates is an essential piece of the story. We 
have an outreach program called CMU Computer Science Pathways, 
that works with community organizations to engage with people 
who are traditionally maybe not entering the high-tech 
workforce because they are under resourced, or we could say 
underestimated.
    Mr. Krishnamoorthi. I am glad you have that. I want to 
focus for a moment on these automated hiring systems because 
they are ubiquitous. Most large employers use them, and 
apparently, according to 90 percent of employers in a recent 
study, they felt that because of those automated hiring 
systems, they are screening out precisely those STARs who could 
otherwise do the job. And so, because of that, we have 
introduced legislation called the Opportunity to Compete Act, 
H.R. 5960, to ``tear the paper ceiling and prevent automated 
discrimination against applicants without bachelor's degrees so 
that these STARs could flourish.'' What is your opinion of 
that, Ms. Hadra?
    Ms. Hadra. Well, as I mentioned in my written and oral 
testimony, 50 percent of our job postings at IBM in the U.S. do 
not require a college degree anymore. So, we are definitely 
moving to a skills first perspective, and we encourage that 
adoption in the Federal Government as well.
    Mr. Krishnamoorthi. And what is the barrier to adopting 
that skills first mindset among your peers?
    Ms. Hadra. I think it is really getting the demands of the 
learning institutions and industry together to help identify 
which roles can be more apprenticed. Like, we are saying AI, 
cybersecurity. There is a shortcoming in the workforce system 
around these requirements, so I think a lot of it is, you know, 
dialog, and I think we would be happy to have a follow-on 
conversation with you because we are very passionate about the 
success of our skills-based hiring program.
    Mr. Krishnamoorthi. Well, we would love to see more people 
talk about this legislation and the need to allow people who 
can do the job to be able to prove they can without presenting 
a diploma to prove they can. And so, what do you do, for 
instance, to allow STARs to be able to prove that they have 
those qualifications to meet the skills of the job?
    Ms. Hadra. So, our apprenticeship program, which, again, 
registered with the Department of Labor, 35 different job 
roles, there is a clear curriculum and a clear completion 
criteria. So, our Application Developer Apprenticeship Program, 
as an example, has around 500 hours of specific learning that 
we provide, and then there is also some specific performance 
objectives. Have you been able to develop in this code? Do you 
get a good performance review, you know, the whole learn-as-you 
earn, and then they have a graduation because they have 
completed all of the criteria.
    And it is important to note that we registered our 
apprenticeship programs with the Department of Labor, so they 
were portable, so they were recognized, and they were not just 
this is what we are saying is important. It is an industry 
standard.
    Mr. Krishnamoorthi. Great. Thank you so much.
    Ms. Mace. Do you have any more questions that you want to 
ask? We have, like, 30 seconds to a minute. We are waiting on 
Mr. Beyer to get here.
    Mr. Krishnamoorthi. Can I----
    Ms. Mace. Yes.
    Mr. Krishnamoorthi. OK. OK.
    Ms. Mace. Please do, 30 seconds. He is running as fast as 
he can, but you got it.
    Mr. Krishnamoorthi. OK. Well, in that case, let me ask you 
this. How do we in Congress use artificial intelligence to do 
our jobs? Have any of you thought about that because, you know, 
I do not see automatons taking our jobs because we are going to 
make that illegal probably, but I could see AI someday being 
used to perform certain functions in our office. And I would 
just be curious if you have ever thought about that or what 
your thoughts are on that.
    Mr. Khanna. We have AI ask a question, and we can 
filibuster it.
    Mr. Krishnamoorthi. That is right. ChatGPT, please 
filibuster here.
    Dr. Toregas. If I can take that quick question, I am sure 
that your staff uses AI today. Well, they use it to get 
background information, they use it to shape arguments, and 
then they perform a very important function. They use human 
intelligence after AI to give you the advice that you need. So, 
that would be my guess, that you are already in it.
    Ms. Mace. Thank you, and we properly filibustered for you, 
Mr. Beyer, this afternoon, and Mr. Krishnamoorthi, we use AI in 
our office, just quick write-up stuff, so I think we should not 
ban it. Helps our comms teams. Mr. Beyer, you are now 
recognized, if you are ready, for 5 minutes.
    Mr. Beyer. Madam Chairman, thank you so much for 
filibustering for me. I do not want to make it a habit on this 
side of the Capitol, though, but thank you.
    Dr. Scherlis, in your testimony, you spoke about 
explainability, transparency, bias, fairness, accuracy, and 
reliability of the AI models. Just last month, we introduced a 
bill called the AI Foundation Model Transparency Act to try to 
address the issue and shed some light into the black box of AI 
foundation models. My bill would call for the model deployer to 
make certain information about the training data, how the model 
is trained, publicly available. The hope is that users should 
know why the model is giving certain results, so it is not used 
in a discriminatory way.
    So, the question, Dr. Scherlis, is, do you think this type 
of transparency effort would support the Federal Government's 
existing workforce with evaluating AI models?
    Dr. Scherlis. Thank you for that question. I think there 
are tremendous challenges with the AI foundation models, and, 
in fact, some of the inventors of those models have stated 
openly that they themselves do not fully understand how those 
models come to certain conclusions and outputs. There is a 
challenge because within a large language model, you can have 
hundreds of billions of parameters that are all adjusted as it 
goes through its learning process. So, to understand what goes 
on inside of one of those models is like doing brain surgery on 
a person as a way to undercover what their opinions might be on 
various issues. It is a frighteningly difficult challenge. And 
so, from a research perspective, explainable AI is a very 
significant problem, and there are many possible solutions and 
a lot of discussion and disagreements within the AI research 
community.
    There is another pitfall, which is because these models are 
fundamentally statistical in nature--they are like predictive 
statistics--even if I train it on a hundred percent correct 
training cases, I can still get hallucinations coming out, 
certainly with the current systems, and so that is because the 
statistical nature kind of lumps similar things into buckets. 
The distinctions go away in that learning process.
    So, there are lots of actions that AI people are taking to 
mitigate this problem, to make the outputs a little bit more 
accurate, but to get to a hundred-percent pure accuracy with 
full explanations, that is, I think, still in the future.
    Mr. Beyer. Yes. We participated in a red teaming exercise 
late last week that Congressman Jay Obernolti put together, and 
they told me that they could get up to an 80 percent on AP 
calculus test, and I found a couple of people there that had 
got a hundred percent without using AI, so.
    Ms. Hadra, you know, one of the things we pulled out of the 
President's executive order is the notion of mandating the NIST 
AI framework for Federal Government agencies using it, bill 
last week, bipartisan--Zach Nunn, Marcus Molinaro, Ted Lieu, 
and I--the Federal Artificial Intelligence Risk Management Act. 
Can you comment on both the notion of can we begin to move to 
the private sector by first working on the NIST framework 
within government contracting?
    Ms. Hadra. Thank you for that question, and IBM is urging 
governments to focus on three priorities as we have been 
advocating for a risk-based approach to regulating AI. We have 
been advocating for that since 2019. Our three priorities are 
regulation of the specific application of AI, not the 
underlying algorithm; prioritizing liability over licensing; 
and supporting open-source AI innovation. So, specifically to 
your question, I think we could offer a follow-on AI focused 
briefing, but it is important to mention our three priorities 
as it relates to the risk that my fellow panelist is 
mentioning.
    Mr. Beyer. Thank you very much. Dr. Toregas, the biggest 
thing that has come out of our AI Caucus so far is the Create 
AI Act, you know, creating a massive data set, not the 6 
trillion words that Sam Altman scrubbed off the internet, but, 
rather, a curated data set for researchers and the like. Are we 
on the right track? Will this help us overcome some of the 
biases, the hallucinations, the incorrect information, or is it 
hopelessly naive?
    Dr. Toregas. Thank you for your question. I think anything 
is good as long as it feeds the workforce question. We are here 
discussing workforce development, and workforce development 
cannot happen unless we understand the technology underlying 
AI. So, your efforts and the efforts, by the way, of other 
nations in this same sphere are helpful in that regard, yes.
    Mr. Beyer. Thank you. Madam Chair, I yield back.
    Ms. Mace. Great questions. Thank you. In closing today, I 
want to thank our panelists once again for their testimony, and 
do you have any closing remarks, Mr. Ranking Member?
    Mr. Lynch. No.
    Ms. Mace. OK. Mr. Lynch does not, and with that, without 
objection, all Members will have 5 legislative days within 
which to submit materials and to submit additional written 
questions for the witnesses, which will be forwarded to the 
witnesses for their response.
    Ms. Mace. If there is no further business, without 
objection, the Subcommittee stands adjourned.
    [Whereupon, at 3:33 p.m., the Subcommittee was adjourned.]

                                 [all]
                                 
                                 
                                 
</pre></body></html>
