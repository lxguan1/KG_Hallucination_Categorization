<html>
<title> - THE FUTURE OF DATA PRIVACY AND ARTIFICIAL INTELLIGENCE AT VA</title>
<body><pre>
[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]


                     THE FUTURE OF DATA PRIVACY AND
                     ARTIFICIAL INTELLIGENCE AT VA

=======================================================================

                                HEARING

                               BEFORE THE

                SUBCOMMITTEE ON TECHNOLOGY MODERNIZATION

                                 OF THE

                     COMMITTEE ON VETERANS' AFFAIRS

                     U.S. HOUSE OF REPRESENTATIVES

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             SECOND SESSION

                               __________

                        MONDAY, JANUARY 29, 2024

                               __________

                           Serial No. 118-47

                               __________

       Printed for the use of the Committee on Veterans' Affairs


                    Available via http://govinfo.gov
                    
                               __________

                   U.S. GOVERNMENT PUBLISHING OFFICE                    
54-927                      WASHINGTON : 2025                  
          
-----------------------------------------------------------------------------------                       
                 
                     COMMITTEE ON VETERANS' AFFAIRS

                     MIKE BOST, Illinois, Chairman

AUMUA AMATA COLEMAN RADEWAGEN,       MARK TAKANO, California, Ranking 
    American Samoa, Vice-Chairwoman      Member
JACK BERGMAN, Michigan               JULIA BROWNLEY, California
NANCY MACE, South Carolina           MIKE LEVIN, California
MATTHEW M. ROSENDALE, SR., Montana   CHRIS PAPPAS, New Hampshire
MARIANNETTE MILLER-MEEKS, Iowa       FRANK J. MRVAN, Indiana
GREGORY F. MURPHY, North Carolina    SHEILA CHERFILUS-MCCORMICK, 
C. SCOTT FRANKLIN, Florida               Florida
DERRICK VAN ORDEN, Wisconsin         CHRISTOPHER R. DELUZIO, 
MORGAN LUTTRELL, Texas                   Pennsylvania
JUAN CISCOMANI, Arizona              MORGAN MCGARVEY, Kentucky
ELIJAH CRANE, Arizona                DELIA C. RAMIREZ, Illinois
KEITH SELF, Texas                    GREG LANDSMAN, Ohio
JENNIFER A. KIGGANS, Virginia        NIKKI BUDZINSKI, Illinois

                       Jon Clark, Staff Director
                  Matt Reel, Democratic Staff Director

                SUBCOMMITTEE ON TECHNOLOGY MODERNIZATION

              MATTHEW M. ROSENDALE, SR., Montana, Chairman

NANCY MACE, South Carolina           SHEILA CHERFILUS-MCCORMICK, 
KEITH SELF, Texas                        Florida, Ranking Member
                                     GREG LANDSMAN, Ohio

Pursuant to clause 2(e)(4) of Rule XI of the Rules of the House, public 
hearing records of the Committee on Veterans' Affairs are also 
published in electronic form. The printed hearing record remains the 
official version. Because electronic submissions are used to prepare 
both printed and electronic versions of the hearing record, the process 
of converting between various electronic formats may introduce 
unintentional errors or omissions. Such occurrences are inherent in the 
current publication process and should diminish as the process is 
further refined.
                         C  O  N  T  E  N  T  S

                              ----------                              

                        MONDAY, JANUARY 29, 2024

                                                                   Page

                           OPENING STATEMENTS

The Honorable Matthew M. Rosendale, Sr., Chairman................     1
The Honorable Sheila Cherfilus-McCormick, Ranking Member.........     2
The Honorable Mariannette Miller-Meeks, (IA-01)..................     4

                               WITNESSES

Mr. Charles Worthington, Chief Technology Officer, Office of 
  Information & Technology, U.S. Department of Veterans Affairs..     5

        Accompanied by:

    Mr. Gil Alterovitz, Ph.D., Director, VA National Artificial 
        Intelligence Institute, Veterans Health Administration, 
        U.S. Department of Veterans Affairs

    Mr. John Oswalt, Deputy Chief Information Officer, Office of 
        Freedom of Information Act, Office of Information & 
        Technology, U.S. Department of Veterans Affairs

    Ms. Stephania Griffin, Director, Information Access and 
        Privacy Office, Veterans Health Administration, U.S. 
        Department of Veterans Affairs

Ms. Shane Tews, Nonresident Senior Fellow, American Enterprise 
  Institute......................................................     6

                                APPENDIX
                     Prepared Statements Of Witness

Mr. Charles Worthington Prepared Statement.......................    27
Ms. Shane Tews Prepared Statement................................    30

                        Statement For The Record

2022 Ars Technica Article Submitted by Representative Mariannette 
  Miller-Meeks, (IA-01)..........................................    33

 
      THE FUTURE OF DATA PRIVACY AND ARTIFICIAL INTELLIGENCE AT VA

                              ----------                              


                        MONDAY, JANUARY 29, 2024

             U.S. House of Representatives,
          Subcommittee on Technology Modernization,
                            Committee on Veterans' Affairs,
                                                   Washington, D.C.
    The subcommittee met, pursuant to notice, at 3:32 p.m., in 
room 360, Cannon House Office Building, Hon. Matthew M. 
Rosendale, Sr. (chairman of the subcommittee) presiding.
    Present: Representatives Rosendale, Mace, Self, Cherfilus-
McCormick, and Landsman.
    Also present: Representative Miller-Meeks.

      OPENING STATEMENT OF MATTHEW M. ROSENDALE, CHAIRMAN

    Mr. Rosendale. Good afternoon. The subcommittee will come 
to order. I want to welcome our witnesses today to a hearing, 
examining how the brave new world of Artificial Intelligence 
(AI) will impact data and privacy at the VA.
    This is the subcommittee's third privacy hearing. We take 
this subject very seriously. Veterans entrust the VA with data 
on every aspect of their lives, often more information than any 
other government agency or company possesses. Yet the VA 
struggles at every level to comply with the law and keep 
veterans' health, personal and financial information secure. 
Data breaches happen every few months and they have taken many 
different forms. We have seen mass errors by a contractor 
mailing letters to the wrong veterans.
    We have seen employees lose or steal records and send files 
beyond the VA network where their ultimate destination is 
unknown. We have also seen companies gain access to veterans' 
data under false pretenses. No successful large scale cyber 
attack on the VA has been disclosed in several years. We also 
know the Department is the target of thousands of attacks every 
day. It remains a constant risk.
    The VA can be the target and at fault, sometimes both in 
the very same data breach. No organization can prevent every 
breach. In many of these incidents, VA officials did not 
realize that the veteran's information had been mishandled 
until well after the fact. In these situations, time is 
critical. The only way to step in before veterans' data makes 
its way from unwitting recipients to criminals is to move fast.
    Employees reported most of the breaches we will discuss 
today, and I commend them for that. The examples I just 
described are a significant problem and put veterans in a 
precarious position. They represent the stone age compared to 
the privacy risk posed by artificial intelligence.
    Much has been said about AI here on Capitol Hill. 
Unfortunately I think most of it can be characterized as 
utopian and apocalyptic. The AI companies and their emissaries 
want us to focus on speculative, civilizational threats rather 
than the practical problems that are right before us.
    AI has been with us for several years in different forms, 
but it is quickly becoming ubiquitous. The VA is accustomed to 
operating as an island. That has many downsides but in research 
and technology it can actually be beneficial for protecting the 
private information.
    The AI business model is moving quickly and overtaking the 
island. AI is being embedded into all sorts of software, dual 
use AI models are proliferating and narrow AI applications are 
broadening. In other words, the days of putting one data set 
into an AI model that only does one thing or ending. The VA has 
thousands of contractors and partner companies that access 
veterans' health and personal data today.
    Controlling how they apply AI will be extremely difficult. 
Without a doubt, I think the VA is using AI for some admirable 
purposes. Applying machine learning to analyze medical images 
can save lives by recognizing indicators of illnesses that the 
most experienced doctors may miss.
    Chatbots for customer service can be helpful if done well. 
The VA has a lot of catching up to do. Sophisticated automation 
can cleanup the VA's troves of disorganized administrative data 
in hours, whereas employees have been struggling with it for 
years. On the other hand, using AI to predict clinical outcomes 
for mental health problems may be powerful, but it presents a 
host of ethical problems.
    Even if the VA manages to prevent this bias, the imposition 
on civil liberties cannot be ignored. My goal here is to learn 
more about what the VA is already doing with AI and, how our 
witnesses plan to adapt the Department's old fashioned process 
as the technology evolves around them. I appreciate our 
witnesses being here to explain all that.
    With that, I yield to Ranking Member Cherfilus-McCormick 
for her opening statement.

OPENING STATEMENT OF SHEILA CHERFILUS-MCCORMICK, RANKING MEMBER

    Ms. Cherfilus-McCormick. Thank you, Mr. Chairman and thank 
you to our witnesses for being here. Our hearing this afternoon 
touches on topics that are old and new to our subcommittee, 
data privacy and the integration of artificial intelligence or 
AI at VA.
    In an ever growing and ever connected digital world our 
attention in matters of data privacy and budding technology is 
more important than ever. While this interconnectedness has 
brought us closer to our friends, colleagues and even strangers 
it has also raised numerous concerns about the privacy of user 
data especially in healthcare.
    In the past 10 to 15 years nearly 6,000 healthcare breaches 
of 500 or more records have been reported to Health and Human 
Services (HHS)'s Office of Civil Rights. Several of these 
reports originated out of the VA itself. It has been almost 2 
years since our last hearing on data privacy.
    In that time VA has reported at least seven data breaches, 
affecting over 4,000 veterans across the country. While this 
committee has heard repeatedly from VA about their IT 
infrastructure, as well as their privacy and security programs 
I look forward to hearing about VA's current and future efforts 
to protect veterans' data as a result of these breaches.
    We also plan to discuss VA's rapidly expanding use of 
artificial intelligence. While AI has been around for many 
years, it has recently become a hot topic in the media. I am 
interested in hearing from VA how they intend to utilize these 
tools while protecting veterans private and health information 
and Personally Identifiable Information (PII).
    In 2019 VA stood up the VA National Artificial Intelligence 
Institute in the AI network bringing experts clinicians and 
researchers together to collaborate on innovative AI proposals 
that seek to reduce administrative burdens, improving staff 
experience and provide better patient outcomes.
    In October 2023, the Biden administration released an 
Executive Order (EO) on the safe, secure and trustworthy 
development and use of artificial intelligence which provides a 
governmentwide framework to establish responsible AI 
development and application across Federal agencies and 
offices.
    This EO builds off previous Trump administration guidance 
encouraging Federal agencies to promote confidence and trust in 
AI in their respective jurisdictions while still maintaining 
integrity and patient user safety.
    In a briefing proved to committee staff VA acknowledged 
that they are still early in their development in adoption of 
AI and have committed to a cautious delivery of these tools. As 
this committee knows the rollout of any enterprisewide 
technology or even a new tool just one Veterans Administration 
Medical Center (VAMC) requires much planning and collaboration 
amongst leadership, staff and patients alike. For successful 
integration of AI into healthcare business claims, processing 
and IT infrastructures, VA must remain committed to gradual and 
intentional growth of these systems.
    Similarly, this committee must remain committed to 
providing consistent and clear oversight to ensure better 
outcomes than what we have seen in other IT modernization 
efforts. Our VA employees, veterans and their families deserve 
this much.
    However in shying away from technological advancements in 
the name of protecting our veterans, we only end up creating a 
VA that is less responsive, outdated and at times less 
transparent.
    VA has a place to define itself as both a leading 
healthcare provider and a large Federal employer in how it 
adopts emerging technology. Integrating these advances when 
they are beneficial for both patients and providers is not 
something we should shy away from, but rather something we 
should welcome albeit cautiously.
    Thank you, Mr. Chairman, I yield back.
    Mr. Rosendale. Thank you Ranking Member Cherfilus-
McCormick.
    Before we proceed I ask unanimous consent that any members 
of the Health Subcommittee be permitted to participate in this 
hearing.
    Without objection, so ordered.
    Dr. Miller-Meeks, would you like to make any opening 
remarks?

         OPENING STATEMENT OF MARIANNETTE MILLER-MEEKS

    Ms. Miller-Meeks. Thank you for recognizing me, chair.
    Good afternoon, I want to thank chairman Rosendale and 
Ranking Member Cherfilus-McCormick for having me here today. I 
chair the Health Subcommittee for the VA. I also am a physician 
and a veteran.
    As the utilization of AI in healthcare becomes more common 
it is important that we recognize the risks and challenges that 
come with it. AI has immense potential to transform the way VA 
delivers healthcare, including access. This committee will 
ensure that the VA does so with caution and an understanding of 
the risk. The burden of safeguarding that information is 
enormous. It also requires infallibility.
    This standard would be difficult to meet in a closed system 
but Veterans Health Administration (VHA), like other health 
systems requires outside partners to execute its mission. Like 
other health systems the VA has seen data breaches that occur 
with alarming frequency. An example is the breach in Veterans 
Integrated Services Networks (VISN)s 1, 2, 4 and 5 at the end 
of last year that affected nearly 50,000 veterans. Some 
breaches are the result of internal mistakes and some are the 
work of malicious actors.
    In some cases seemingly innocuous internal errors are taken 
advantage of by external actors such as the publication of 
source code on GitHub in 2022 with was cloned by 6 foreign IP 
addresses. This committee will take responsibility seriously as 
we explore VA's use of AI and its adaptation to ensure the 
security of veterans' data.
    I appreciate or witnesses' willingness to do so and I yield 
to chairman Rosendale.
    Mr. Rosendale. Thank you very much.
    Representative Miller-Meeks.
    I will now introduce the witnesses in our first and only 
panel. From the VA we have chief technology officer Charles 
Worthington. Mr. Worthington excuse me, serves as the chief AI 
officer. It is good to see you again.
    We also have Dr. Gil Alterovitz. Okay, the director of the 
VA's National Artificial Intelligence Institute.
    In addition we have deputy chief information officer John 
Oswalt who serves as the chief privacy officer.
    Ms. Stephania Griffin, the director of information access 
and privacy office in the Veterans Health Administration.
    Finally we have Ms. Shane Tews, a nonresident senior fellow 
at the American Enterprise Institute.
    I ask the witnesses to please stand and raise your right 
hands.
    [Witnesses sworn.]
    Mr. Rosendale. Thank you. Let the record reflect that all 
the witnesses have answered in the affirmative.
    Mr. Worthington, you are now recognized for 5 minutes to 
deliver your opening statement on behalf of the VA.

                STATEMENT OF CHARLES WORTHINGTON

    Mr. Worthington. Good afternoon, Chairman Rosendale, 
Ranking Member Cherfilus-McCormick, and distinguished members 
of the subcommittee. Thank you for the opportunity to testify 
today about the Department of Veterans Affairs efforts in 
patient data and privacy and artificial intelligence.
    My name is Charles Worthington, I am the Chief Technology 
Officer and the agency's Chief Artificial Intelligence Officer 
in VA's Office of Information and Technology (OIT). I am 
accompanied today by Mr. John Oswalt, the deputy Chief 
Information Officer, Freedom of Information Act and Records and 
Assessment Compliance office, in OIT.
    Dr. Gil Alterovitz, the director of the National AI 
Institute and VHA's Chief AI Officer. Ms. Stephania Griffin, 
Director of Information Access and Privacy Office within VHA.
    VA is committed to protecting veterans' data privacy while 
responsibly harnessing the promise of artificial intelligence 
to better serve veterans. While AI can be a powerful tool, we 
must adopt it with proper controls, oversight and security.
    The department is taking a measured approach as we begin to 
scale AI solutions to ensure that we are adopting these 
powerful tools safely. As the largest healthcare and benefits 
provider in the Nation and an early adopter of an Electronic 
Health Record (EHR) many decades ago, VA has a complex 
technical ecosystem, including one of the world's largest 
health record repositories.
    While we are enthusiastic about the vast potential of AI, 
the VA is equally concerned about privacy, ethical use and 
effectiveness of AI. Governance plays a key role in how VA has 
approached AI development, given the technology's unique risks 
and challenges.
    We will continue to invest in governance to ensure our use 
of AI comports with VA's security and privacy policies and with 
the Trustworthy AI framework that our National AI institute 
launched under the leadership of Dr. Alterovitz last year.
    Regarding privacy, securing veteran data is a top priority 
as my colleagues John Oswalt and Stephania Griffin can attest 
to. The VA uses the National Institute of Standards and 
Technology (NIST) risk management framework to comprehensively 
manage and report on privacy and security risks.
    This NIST framework requires independent privacy and 
security reviews to prevent conflicts of interest in privacy 
and security assessments and audits. Furthermore, VA security 
controls reduce the risk and impact of potential incidents by 
deploying a diverse technologies within the department's 
environment.
    Of course we must consider how our data security and 
privacy solutions interact with our users, veterans and vendors 
to ensure that we are taking a balanced risk management 
approach that provides guardrails while also enabling 
exploration of emerging technologies such as those AI solutions 
being pioneered by Dr. Alterovitz and VHA. VA has long been a 
leader in healthcare research and innovation and we seek to 
continue that leadership position.
    In conclusion, I believe that AI represents a generational 
shift in how our computer systems will work and what they will 
be capable of. If used well, AI has the potential to empower 
our employees to provide better healthcare, faster benefits 
decisions and more secure systems.
    Similar to other major transitions such as cloud computing 
or the rise of smartphones VA will need to invest in and adapt 
our technical portfolio to take advantage of this shift. With 
the strategies, policies and programs currently in place the 
Department will continue in its mission to protect the security 
and privacy of the data entrusted to us by the veterans we 
serve.
    Mr. Chairman, ranking member and members of the 
subcommittee, thank you for the opportunity to testify before 
the subcommittee today to discuss this important topic. My 
colleagues and I are happy to respond to any questions you may 
have.

    [The Prepared Statement Of Charles Worthington Appears In 
Appendix]

    Mr. Rosendale. Thank you, Mr. Worthington. The written 
statement of Mr. Worthington will be entered into the hearing 
record.
    Ms. Tews, you are now recognized for 5 minutes to deliver 
your opening statement.

                    STATEMENT OF SHANE TEWS

    Ms. Tews. Thank you, Mr. Chairman.
    I have to admit when the staff called I do not have any 
background in the veterans affairs area. I have been doing 
privacy for over 20 years. I have learned a lot over the last 
2--actually last week I have been very impressed with the work 
that the agency already has done in this area. Quickly I will 
just highlight some things that are in my written testimony.
    All the offers of immense improvement for veterans' well-
being really can be enhanced with AI tools but the most 
important part is instilling trust in the system. As you 
mentioned early on the challenges we have of people possibly 
being taken advantage of.
    Then early on in your opening statement quite a few of the 
things you said had human intervention elements to them. Now we 
add the speed of AI to it, we need to make sure we sandbox 
these things so they are safe.
    We need to be concerned about privacy, security fairness. 
The accountability from the start in developing responsibility 
we can enable to provide to make faster and better informed 
decisions for our veterans and allow them to focus more on 
patients with AI tools.
    In my written testimony I do go more in depth about 
potential advancements for diagnostic treatments, pretty good 
healthcare for preventive measures and early intervention 
virtual healthcare assistance for VA healthcare desks and 
telemedicine enhancements.
    Data integration and enhanced healthcare providers with AI 
tools, mental health support and many more advancements we will 
see with AI. To realize this future we need to be dedicated to 
the cross functional VA teams that evaluate every AI tool using 
metrics for security and addressing bias before approval.
    We must institute the same privacy rules as the Health 
Insurance Portability and Accountability Act (HIPPA) limit 
reliance on personal data and develop AI research and training 
and retain the VA's governance to build confidence. Annual 
audits will be a further accountability item you need to 
incorporate.
    The payoff of adopting AI tools across diagnostics, 
predictive health care, telemedicine, mental health support and 
more are too great to not purposely use AI thoughtfully.
    In closing, I urge earnest focus on ethics, inclusivity and 
communications to unlock AI's potential while veterans' trust. 
I look forward to your questions and look forward to hearing 
from the panel.

    [The Prepared Statement Of Shane Tews Appears In The 
Appendix]

    Mr. Rosendale. Thank you very much, Ms. Tews. The written 
statement of Ms. Tews will be entered into the hearing record.
    Now we will proceed to questioning. I recognize myself for 
5 minutes.
    Mr. Worthington, the VA has a national AI center, a working 
group, oversight committees and Institutional Review Board 
(IRB) for AI, many of these seems like talking shops. Who vets 
proposed AI projects and decides what gets approved, what is 
inappropriate and how veterans' data will be used?
    Mr. Worthington. Thank you for the question. The agency I 
would say is in our early stages of standing up with governance 
of AI as a separate category. Our framework that we have put in 
place with the National AI Institute which Dr. Alterovitz can 
talk more about was basically designed to catalogue use cases 
of AI across the agency and then assess those use cases for 
consistency with our Trustworthy AI principles, basically in 
relation to the earlier executive order on AI.
    At this moment what we are attempting to do is document all 
of the cases that the VA is experimenting with and bringing use 
cases into production and ensuring we have those documented so 
we can assess them using the government standards that will 
continue to evolve.
    Mr. Rosendale. Who is ultimately taking this information 
and making the final determination about what it will be used 
for and what it will not be used for? Is it a panel, is it a 
group--who is making the final call?
    Mr. Worthington. In the new executive order guidance we 
have been provided by Office of Management and Budget (OMB) we 
are asked to stand up an AI governance committee chaired by 
myself and the agency deputy secretary. We are in the process 
of finalizing that.
    That is a requirement that is going to come from OMB to the 
VA. In the previous--in the past what we have been using VA's 
Data Governance Council framework where AI used cases come up 
to that council, which is able to look at the work of the 
National Artificial Intelligence Institute staff and assess it.
    Dr. Alterovitz. I just want to add in there is kind of 
multiple layers at the local level with the medical centers, we 
have been piloting the AI oversight committee.
    We have been doing that for four centers to see how that 
could scale. There is other work at the VISN level. Finally, as 
was mentioned, the AI Working Group at the central VA level 
part of the data governance agency governance body.
    In this new executive order there is a statement basically 
about elevating that up so that there are higher level people 
on that committee but still, tying it down to the central 
office.
    Doing that you are able to triage different risk profiles 
and be able to scale these different types of analyses.
    Mr. Rosendale. That gives me another question though. Mr. 
Worthington, if we have these decisions being made at the local 
level we have them being made at the VISN level and then we 
have them being made at your level. Has anyone ever rejected an 
AI use case?
    Mr. Worthington. I would have to go back----
    Mr. Rosendale. How do we make sure that we have got some 
type of conformity or consistency amongst----
    Mr. Worthington. I think consistency is exactly what we 
want to create at the central level so that we can cascade that 
out to the field so decisions could be made locally for smaller 
pilots or for earlier stage risk.
    It is important I think to point out, though, that anything 
that is going live into production and touching veteran data, 
that would follow the same processes as existing IT systems 
have to follow in terms of an authority to operate and an 
authority to connect.
    If we are talking about bringing a system into production, 
whether it involves AI or not, there is sort of an existing 
technology assessment process that we would use to approve the 
use of those.
    Mr. Rosendale. Okay, Dr. Alterovitz, there are now three 
executive orders setting guiding principles for AI. It is up to 
you and your colleagues to interpret and apply them. You have 
created some new offices.
    You have not yet updated most of your policies for AI. Let 
me ask you a simple question, how do you know a bad AI use case 
when you see one.
    Dr. Alterovitz. We have been working together on 
integrating all of the different policies into our Trustworthy 
AI framework that came out this July. It integrates those 
executive orders as well as NIST, and agency specific guidance 
that we have, like a data ethics framework for example.
    It actually became the first department-wide trustworthy AI 
framework that includes all those latest items. Using that and 
the implementation guide that we have been now developing there 
are a series of questions that we analyze and determine if a 
use case falls under the consistent or inconsistent category 
with the principles and thereby being consistent or 
inconsistent with the different guidances like the EO 13960, 
14110 and the other ones--and so that is our process.
    We have done it now a couple years and we are going to 
upgrade it now with the now executive order that came out.
    Mr. Rosendale. Thank you.
    I will now recognize Ms. Cherfilus-McCormick for 5 minutes 
of questioning.
    Ms. Cherfilus-McCormick. Thank you, Mr. Chairman. VA hosts 
the largest integrated healthcare system in the country making 
it's responsibility for a wide swath of data, most which must 
remain secure and protected. How is VA working to bring 
groundbreaking technology to benefit veterans while also 
balancing potential privacy?
    Mr. Worthington. Thank you for the question. It is a great 
question because obviously we are hearing a lot about 
artificial intelligence. In some ways the problem of deciding 
which technologies we can use at the VA that ensure veterans 
data and privacy intact that problem is not new.
    The VA, especially our OIT office, has a lot of existing 
policies in place to ensure that any new system that we bring 
onto the network or entrust veteran data inside complies with 
VA's existing data privacy and data security policies. We would 
expect to apply many of those same policies and most in the 
same ways whether or not that system uses AI or is a more 
traditional competing system.
    Ms. Cherfilus-McCormick. This is question is for Ms. 
Griffin.
    Ms. Griffin, over the past 2 years VA has been the subject 
of several data breaches jeopardizing the PII and the Protected 
Health Information (PHI) of thousands of veterans. What 
safeguards does the VA currently have in place to help protect 
against future breaches.
    Ms. Griffin. Thank you. There are numerous mechanisms and 
processes that VHA has in place to safeguard veterans PII and 
PHI, along the lines of not only policies and procedures but 
training of our staff. We also have compliance monitoring and 
audits that are performed, as well as many other processes that 
we put in place to comply with various Federal privacy laws and 
regulations including the HIPAA Privacy Rule requirements. I 
would be happy to give greater detail if you would like for the 
record.
    Ms. Cherfilus-McCormick. That would be wonderful. Could the 
new bastion of this new AI infrastructure exacerbate any 
existing privacy issues at VA how might AI assist in protecting 
against future breaches?
    Ms. Griffin. The Federal privacy laws and regulations, 
including the HIPAA Privacy Rule, they are technology neutral. 
They put the same processes and mechanisms in place to protect 
and safeguard data regardless of the technology.
    However, certainly as you look to new technologies we look 
to the privacy impact analyses that we have to perform and may 
put additional security and information security processes in 
place and enhancements around that technology to ensure 
privacy.
    Ms. Cherfilus-McCormick. My next question is really about 
the biases in AI from Mr. Worthington as we continue to support 
improving and expanding access to care among minority veteran 
populations we must be mindful the biases that accompany the 
application of AI. How is the VA working to combat these biases 
that may impact with access to care for minority veterans?
    Mr. Worthington. It is a wonderful question and it is one 
that our colleagues in VHA who designed the Trustworthy AI 
framework had really been thinking a lot about as have both 
administrations with the executive orders. I think the key to 
understanding how any particular AI may introduce biases is to 
understand the data that it was trained on and then the outputs 
that it gives given a set of inputs.
    Assessing the potential for bias in each of the models is 
one of the six principles of our ethical or trustworthy AI 
framework. It is one of those things the governance bodies are 
looking at when they are assessing each of the use cases.
    Ms. Cherfilus-McCormick. The VA has historically struggled 
when it comes to collecting data on veteran's racial, ethnic 
and LGBT+ identities. How is the VA compensating for gaps in 
status to ensure that bias is mitigated in AI projects?
    Mr. Worthington. That is a great question. I may have to 
take part of that back for the record. I think that, you know, 
obviously the VA's health system is very large and we have lots 
of data. The veteran population also is not, you know, exactly 
representative of the country in terms of gender and other 
attributes.
    Every time we create a model or any sort of analysis using 
only VA data, the researchers have to be cognizant of the 
limitations inherent in that data set.
    Ms. Cherfilus-McCormick. Ms. Tews, what problems or risks 
do you expect to see if VA is not able to successfully account 
for biases in AI products?
    Ms. Tews. First of all I want to reiterate the importance 
of transparency and accountability. Throughout the entire 
process you always know what is being looked at and how it is 
being reviewed. Part of that is then making sure that in the 
areas where you are concerned about wanting to fund results 
without knowing who it is that you disaggregate the data.
    You do not have certain data sets that are compiled into 
that. That will help just alleviate--sometimes we share too 
much candidly. We have that problem not only in the VA but just 
in general use of data as we just tend to grab everything that 
we can. When you are doing information flow you make sure that 
you are only using the pieces that need to be participated in 
disaggregating the pieces that do not need to be here.
    That does not mean that you cannot make sure that you are 
looking for things around bias. Besides bias and minorities you 
realize that women have had this challenge all along in 
healthcare as well. I mean, during COVID I had a friend of mine 
who said why would I want to give my mother a shot that was 
designed for a 180 pound man? I had not really thought about 
that.
    I did not have a problem with the shot. I was, like, I see 
your point. We have done a lot of that throughout our history. 
I think while we are reviewing all this we an opportunity to do 
a lot of corrections in a way that we have been doing 
healthcare in general for a long time so I think this is a good 
opportunity.
    Ms. Cherfilus-McCormick. Thank you, Mr. Chairman. I yield 
back.
    Mr. Rosendale. Thank you, Ranking Member Cherfilus-
McCormick.
    I now recognize my good friend from Texas, Representative 
Self.
    Mr. Self. Thank you, Mr. Chairman.
    Once again and this is my common comment we are talking 
about inputs, so I want to try to get to outputs.
    Dr. Alterovitz, how many projects or use cases do you 
currently have underway.
    Dr. Alterovitz. Clarification, is that a question for our 
group specifically or for the VA in general or----
    Mr. Self. Your national institute.
    Dr. Alterovitz. The national institute. We collaborate and 
engage in I would say the between 15 to 20 projects.
    Mr. Self. 15 to 20. How many are in widespread use, as 
opposed to test?
    Dr. Alterovitz. We typically start with the early stage. 
The goal is that eventually they may end up to be widely used. 
We started a few years ago and through various mechanisms such 
as AI Tech Sprints, we have had a few of them launched to 
become pilots that are used in up to four or so medical centers 
and then the next stage beyond that is scaling up.
    Mr. Self. How many are in widespread use?
    Dr. Alterovitz. If you define widespread as across the 
network.
    Mr. Self. I will let you define it.
    Dr. Alterovitz. Then I would say maybe like three.
    Mr. Self. Three. When do we expect to see significant 
outputs from these uses.
    Dr. Alterovitz. Significant outputs. Could you clarify?
    Mr. Self. Improvement in veterans' healthcare. That is 
always the bottom line here. We talk a lot about theory on this 
committee, we talk a lot about processes, we talk a lot about 
inputs. I am more interested in the output in the health 
benefits to the veteran.
    Dr. Alterovitz. Great, because some of them also involve 
efficiency cost savings. All of those are designed to do that 
actually, the three that I was thinking about. I should say 
just that the ones we are looking at are just one piece of how 
we look at AI solutions; we have different mechanisms, like I 
said, e.g. AI Tech Sprints.
    Mr. Self. When do you expect to see an output?
    Dr. Alterovitz. Well, with an AI Tech Sprint, you see 
output in 90 days, if it is something useful that you want to 
then go on to contracting.
    Mr. Self. These three are giving you significant outputs 
today?
    Dr. Alterovitz. Yes.
    Mr. Worthington. I might just add that in addition to the 
projects that Dr. Alterovitz is describing where his group 
works specifically to shepherd them along, there are other uses 
of AI in production today across our health system. Primarily 
these are things in categories like medical devices. For 
example, there is a product called GI Genius which helps 
oncologists or others identify scans and look for cancers.
    In addition to those that this organization helped with, 
the VA does have a number of more traditional AI models in 
production now.
    Mr. Self. Okay. I understand you got about 1,100 petabytes 
of sensitive information you are rolling this out. A sentence 
in the packet here that got my attention is the commercial 
sector has eaten up all of the available data sets and now they 
need nonpublic data sets.
    How many--I mean, how in the world are you going to protect 
1,100 petabytes of sensitive information because there is the 
only saying, a secret is something you tell one person at a 
time. How are you going to protect against the cascading 
release across the commercial sector?
    It seems to me like it is impossible to put the horse back 
in the barn once its out. Can you talk to me about that?
    Mr. Worthington. It is a great question and it is something 
we think about all the time how to protect that data. We do 
have existing contractual, you know, rules around what vendors 
can do with the data.
    In general when we are building models or analyzing this 
data, that is happening within the VA environment with tools 
that we are hosting internally as opposed to sending that data 
outside of the VA.
    Mr. Self. I am about out of time. What is a sanction? If 
someone releases the data, what is the sanction you have on 
them?
    Mr. Worthington. I defer to Mr. Oswalt on that.
    Mr. Oswalt. Well, it defers back to the contractual 
language. In the IT realm there is standard language in every 
contract which lays out the expectations.
    Mr. Self. Give me an example of a sanction for someone that 
would release sensitive information.
    Mr. Oswalt. Well, I know there - it is an acquisitions 
question, but I have seen contracts over my career that have 
been canceled because of nonperformance to the letter of the 
contract. For egregious activity, it would probably be turned 
over to our inspector general's office for investigation.
    Mr. Self. Has that happened within of--yes, I know it has.
    Mr. Chairman, I yield back.
    Mr. Rosendale. Thank you very much, Representative Self.
    I now recognize Representative Miller-Meeks from Iowa.
    Ms. Miller-Meeks. Thank you very chair Rosendale, Ranking 
Member Cherfilus-McCormick thank all our witnesses for being 
here.
    It seems as we go through this information that we think of 
AI, but AI in and of itself is not necessarily a source of 
release of private healthcare information or PII, that simply 
having electronic or digitization of data can lead to leaks. 
Often it seems the human link having worked in the healthcare 
field for numerous years may be the weakest link.
    I think as we identify potential pitfalls that we have to 
remember that we have to have the best cybersecurity and safety 
and access to care and keep all of those in mind as I juggle 
through this.
    As a clinician, I understand the value AI can bring to the 
practice of medicine. It can help with everything from the 
diagnosis of disease to transcription of clinical notes, to the 
development of a response back to be a patient from repetitive 
machine learning and from creating staffing plans to coaching 
health behaviors.
    I can also see the potential as the The Sergeant First 
Class Heath Robinson Honoring our Promise to Address 
Comprehensive Toxics (PACT) Act is unveiled and as we are still 
determining toxic substances that we can identify and prevent 
and form causation or causality from toxic substances which we 
have only scratched the surface on. This integration I think is 
really important and we see the value, but we also understand 
that there are challenges ahead.
    Ms. Tews, thank you for testifying before the committee 
today. In your written testimony you state that the VA must be 
vigilant in creating proper safeguards around veteran data 
privacy and security. In your opinion, how can the VA implement 
AI and algorithmic technologies to increase efficiency that 
both administrative items and the delivery of care without 
compromising patient safety and privacy.
    Ms. Tews. One thing to keep in mind is that you are dealing 
with a closed loop which I think a lot of us when we think 
about artificial intelligence right now are really fascinated 
with the learning language model, the LLM. A lot of data going 
out from a lot of sources.
    You have a very finite, it is a lot of terabytes of data, 
but it is a finite area where you can actually do some amazing 
sandbox studies that you cannot do in the open public.
    I would think not a clinician, but the whole idea of what 
you can do in an environment like Veterans' Affairs on medicine 
is very amazing as long as we make sure that those guardrails 
are in place. We do have the terms of use, I call it policy 
through procurement. You make sure that those are fines, you 
know.
    You get outside your remit you are going to see probably a 
major financial fine for doing that, I will keep you inside the 
guardrail. Then knowing ahead of time what it is you are trying 
to discover so you keep within the sandbox where you are 
looking to participate.
    They are not overly complicated, you have to actually 
commit to them and make sure that the information does not go 
outside of where it is supposed to go and you do with the 
information what you say you are going to do.
    Ms. Miller-Meeks. Mr. Worthington, does the VA use the 
Large-scale Artificial Intelligence Open Network (LAION) data 
set to train AI?
    Mr. Worthington. I am not familiar with that.
    Dr. Alterovitz, are you familiar with that one?
    We may have to take that back for the record.
    Dr. Alterovitz. We can certainly take that back for the 
record. There is not a standardized approach to doing that at 
this time.
    Ms. Miller-Meeks. The reason for asking that question 2022 
Ars Technica article found that the LAION data set contained 
pictures that originated from medical records which made their 
way into the data set without authorization from patients who 
were the subjects.
    Now as a clinician and a physician who has published you 
have to get permission from patients to use their images in any 
publication that you utilize. How does the VA assure that PHI 
and PII whether images or text are not leaking into publicly 
available data sets either by accident, omission or 
purposefully, especially through contractors and their business 
associates who have access to data use to deliver or assist the 
VA in delivering healthcare.
    Mr. Worthington. Thank you for the question, Congresswoman. 
We have I would say robust existing privacy policy on all 
vendor and IT contracts that really is explicit about what our 
partners are allowed to do with VA data and what is not 
allowed. Any time we are allowing a vendor access to VA data it 
is usually--it is under the strict confines of what that 
contract is for. My colleagues could talk more about the 
specifics, but we would be seeking to avoid cases where veteran 
data or really any of our data would wind up in some general 
purpose model that it was not expected to be.
    Ms. Miller-Meeks. Well, certainly if an employee can be 
terminated in the healthcare system for talking about a patient 
in an elevator, I would think that sanctions, loss of contract 
and especially financial sanctions would be appropriate.
    Mr. Chair, I would like to enter into the record the Ars 
Technica article I mentioned from 9/22/21.
    Mr. Rosendale. Without objection.
    Ms. Miller-Meeks. Thank you and I yield.
    Mr. Rosendale. Thank you, Representative Miller-Meeks.
    Dr. Alterovitz and Ms. Griffin, on this same topic about 
the patients themselves, what is going on with their 
information, do you notify and or do you believe that you have 
a responsibility to notify veterans or any American when their 
health or personal information is fed into an AI model and 
whether the analysis that effects them was done by AI rather 
than a person.
    Ms. Griffin. Thank you for that. The--as I indicated 
earlier, the Federal privacy laws and regulations that we 
adhere to including the HIPAA Privacy Rule does not--is not 
technology specific. It is technology neutral.
    It is regarding the use of personally identifiable 
information and protected health information for purposes such 
as treatment, payment and healthcare operations.
    It is not focused on giving notice as it relates to 
specific technology. We are required to give notice to our 
veterans and our patients, how we use their data, how we 
collect their data, how we share their data for the purposes, 
but again it is not specific to a technology.
    Mr. Rosendale. Okay. My question is then it sounds like 
they are not notified. It is not disclosed to the patient if 
their information is being analyzed by AI. Is that correct?
    Ms. Griffin. Correct, there is not a specific notice----
    Mr. Rosendale. Do you think that that is something that 
should be in policy so that an individual knows that their 
information is being analyzed by AI and now is subject to all 
of the different potential problems that could take place that 
we have not even identified yet.
    In addition to the fact that they may be getting some type 
of an analysis given to them that was created by AI.
    Ms. Griffin. I think that is something that the data 
governance council and the AI framework that is being set up 
needs to look at more closely. In terms to whether there is a 
specific use case notice that needs to be given, we often give 
informed consent in the healthcare setting for various 
processes and procedures and it is possible that is something 
that needs to be looked at more closely.
    Mr. Rosendale. Yes, I would highly recommend that if that 
disclosure is not going out and someone's information is going 
to be analyzed by AI, that certainly the patient should be made 
aware of that. It could present all types of issues going 
forward.
    If the groups that are doing all that analysis of what is 
and what is not acceptable, a disclosure at the very beginning 
would be a good place to start.
    Ms. Tews, how do you feel about this?
    Ms. Tews. I think in general it goes to my idea--
transparency and accountability are important whenever you are 
using technology. You always want to regulate or put license on 
the outcome not the technology.
    I mean, the idea is what is it you are trying to accomplish 
and do not worry about what the actual tech is because it is 
going to change. Absolutely I think that any time you--any time 
somebody uses your healthcare information or you enter into 
something you should know what is going on just as a human 
element.
    I think we do that continue our general healthcare system. 
We absolutely should the should be doing that in the veteran 
system. I would believe it probably is going on. I also am 
somebody though that I am the first one to volunteer and be 
like you want to throw that in the machine, please do.
    You know, I idea of having AI look at my results first and 
then an intern I do not have a problem with that. I think that 
actually would probably perhaps get me an earlier recognition 
on a few things but I would want to be notified.
    Mr. Rosendale. Thank you very much.
    Mr. Oswalt, most of your data breaches happen when letters 
or digital files get sent to the wrong veterans or when paper 
records are misplaced.
    Typically an employer or contractor makes a mistake and an 
employee discovers it. Once you realized a breach has happened 
what do you do to trace down where the information went and 
also what are you doing--what actions are you taking to get 
that information back again.
    Mr. Oswalt. When a data breach happens and it is either 
employee self report or a veteran might have received something 
that was not theirs, the privacy officer or the information 
security officer at the subject facility will enter an incident 
ticket in a system we call say PSETS, which is Privacy Security 
Event Tracking System and there is a Data Breach Response 
Service team, a group of individuals who work for me who begin 
the investigation of what happened.
    They work with the medical center folks, the staff, the 
veterans, a lot of times the individuals. Based on what they 
adjudicate, there is a VA wide body called the Data Breach Core 
Team which investigates further and makes the determination 
whether it is a worthy--whether one, is VA is at fault and two, 
is credit monitoring offered, warranted and also what type of 
event it is, PII or PHI.
    Mr. Rosendale. Thank you. My time is up. I will now 
recognize Representative Cherfilus-McCormick.
    Ms. Cherfilus-McCormick. Thank you, Mr. Chairman.
    I want to examine some of the AI governance issues that we 
might potentially have. VA has moved to the Cerner millennium 
electronic health record has highlighted concerns about the 
quality of VA's healthcare data, specifically the fact that the 
majority of the data does not conform to the standard data 
definition. How is VA counting for this variation when 
developing new AI models.
    Mr. Worthington. That is a wonderful question. I do not 
think any of us up here are experts on the EHR program. In 
general I think that you are raising a very important challenge 
that we have when we are adopting AI which is it is very rare 
that an AI product would live by itself.
    We need to figure out how to integrate these models and 
these insights into our existing software ecosystem, which as 
you noted is very complex.
    I am sure that that would require a lot of testing to make 
sure that it worked with both the Cerner data models as well as 
the legacy Veterans Health Information Systems and Architecture 
(VistA) data models.
    Ms. Cherfilus-McCormick. Would anybody know how the 
variations impacting the quality of the AI output?
    Mr. Worthington. I am not familiar with that issue in 
particular.
    Dr. Alterovitz. I just wanted to add that one of the things 
that is most complicated when you are using AI in the 
healthcare setting is embedding in the work flow. If someone 
has to enter another password or something like that, it takes 
them out of their work-flow. Sometimes you lose data 
potentially as you have to kind of translate from one system to 
another.
    Essentially the closer it is into the native pipeline of 
data, the better you are going to be in terms of output, how it 
will affect and be able to be stored, and then used by future 
physicians for clinical decision-making.
    Ms. Cherfilus-McCormick. Thank you.
    My staff recently visited one of the automationsites for 
Veterans Benefits Administration (VBA)'s claims automation. 
While these seems to be beneficial to the automated decision 
support staff, staff's perception of its usefulness was a 
little inconsistent. How was VA soliciting feedback from the 
frontline staff about ADS and other AI projects.
    Mr. Worthington. Well the ADS project in particular I am 
not personally familiar with. I think you are raising a great 
point around engaging with our workforce on the topic of AI. 
The way that AI I think could be most usefully applied in the 
VA and elsewhere is by augmenting the capabilities of our 
existing people.
    That means giving them new capabilities but also training 
them how to use it. What it can and cannot do. What its 
limitations are. I think we are going to have to have a lot of 
engagement with the workforce, not just AI experts but really 
anyone that is using the VA software--including this system--
about what the system is intending to do, how it works and 
getting to the point about transparency and explainability.
    I think being very communicative about what the system did 
and why is an important way to build that trust with our users.
    Ms. Cherfilus-McCormick. How is VA validating these models 
working effectively?
    Mr. Worthington. As part of the governance framework we are 
looking at basically what these models output compared to what 
should be expected. Each time something is put into production 
they are tested based on what is expected, what should be 
given, given a set of inputs.
    Ms. Cherfilus-McCormick. I want to go back to the question 
before real quick. Is there a processing place where you are 
actually getting data and feedback from the frontliners 
presently?
    Mr. Worthington. With regard to that program in particular 
I am not familiar with it enough to let you know one way or the 
other. We can take the question back for the record. We do have 
a broader system I know that is designed to gather feedback 
from employees on their experiences with various programs.
    Ms. Cherfilus-McCormick. If not I would like to see a 
implementation plan so we can have that information there. A 
lot of times we talk about getting feedback but we never get 
around to actually getting that feedback. If we have them able 
to articulate what their needs are and actually build it in I 
think that would be the best case scenario for us.
    How are they measuring how often the output does or does 
not met the expectation?
    Mr. Worthington. Again, I would have to take that one back 
for the record for that program.
    Ms. Cherfilus-McCormick. Mr. Chairman, I yield back.
    Mr. Rosendale. Thank you very much, Ranking Member 
Cherfilus-McCormick.
    I now recognize Representative Self.
    Mr. Self. Thank you, Mr. Chairman.
    I want to revisit both of the my lines of questions from 
the first question. First of all, for this hearing you provided 
a list of 128 AI use cases. To the Senate you provided a list 
of 300 AI use cases. You have said there are 21 that have 
advanced implementation. Why the difference in what you 
testified in the first round to these numbers in the second 
round?
    Mr. Worthington. Well, that is a great question. I think 
what you are seeing is use case inventory is a work in progress 
for us. Different points in time the inventory has been created 
to comply with various OMB memos.
    I am not familiar with the specifics of the communication 
that you just mentioned about the inventory, but I think the 
inventory has been growing over time so at various points of 
time----
    Mr. Self. The way I understand from the committee's staff 
that these are numbers that you provided to us the 128 and the 
21. Is that correct?
    Dr. Alterovitz. I just wanted to clarify what these numbers 
could be in terms of----
    Mr. Self. Well, no, I do not want a speculation, doctor. I 
appreciate it. My point is that we get this fairly often up 
here who is in charge, who is on first. I just ask you to make 
sure who is in charge.
    I am also not satisfied with your sanctions answers, a 
general contract acquisition answer is not satisfactory because 
of the importance, the potential devastating consequences of a 
breach of 1,100 petabytes of data, sensitive data.
    I think it is got to be first you have got to identify some 
sanctions and they have got to be fairly severe sanctions and 
they have got to be in policy up front. This is not--this is 
something you have got to settle in policy early.
    I do not--frankly in my mind, it is not going to be 
sufficient to say we are going to cancel a contract, because as 
Dr. Miller-Meeks pointed out, this is more serious and than 
simply canceling a contract for a medical device. You are 
talking about personal data here.
    I think you need to take a more serious look at what are 
going to be the sanctions written up front into your contracts 
when you give sensitive data for 1,100 potentially 1,100 
petabytes of data across the commercial sector. This is 
concerning to me.
    With that, Mr. Chairman, I yield back.
    Mr. Rosendale. Thank you very much.
    Mr. Oswalt, there are recently two data breaches at the 
Ashville, North Carolina medical center. Please tell us what 
happened. How the medical center reacted to that, and how your 
office responded and how long that response took.
    Mr. Oswalt. One of the Asheville incidents was three 
individuals received electronic files containing, I think 
approximately 1,500 veterans' protected information. I believe 
that it was through My Healthy Vet portal so it was not open 
email. The three individuals, one of them self reported back to 
the medical center, like, hey, I think I got something that I 
should not have gotten.
    Two of the messages were indicated as being read. The third 
was retrieved; pulled back. The normal process of responding to 
that would be as I indicated before working with the privacy 
officer at the facility, the information security officer and 
then the Data Breach Response Service will do the investigation 
and the adjudication of how that--and I believe this indicated 
it was a personal protected health information so it did 
warrant notification to HHS as a protected HIPPA entity and 
resulting in a press release also.
    The other event----
    Mr. Rosendale. Excuse me. How long did it take to turn that 
scenario around, that exercise around to get the information 
collected and protected?
    Mr. Oswalt. I would have to get back to you and the 
committee with that information, sir because I do not want to 
speculate. The primary emphasis is to make sure we identify the 
affected veterans first.
    We want to make sure we get it right before we actually 
initiate the outreach. There are prescribed days, number of 
days in policy where we have to act, especially with a PHI 
HIPPA related event.
    Mr. Rosendale. Mr. Oswalt and Ms. Griffin, let me ask you 
about the Clarksburg, West Virginia incident. The medical 
center sent 700 veterans' letters with their Social Security 
numbers (SSN)s instead of their ZIP Codes in the address line.
    First of all, was not the VA supposed to phaseout using 
veterans' Social Security numbers for the purposes many years 
ago? Again what was the response? How long did that response 
take?
    Mr. Oswalt. Well, I--to address the question about the 
Social Security end use, we do have a department wide 
integrated project team now which is identifying systems that 
have Social Security numbers that need to be remediated from--
from use.
    Social Security number use is not to be totally eliminated 
because there is an initial identification period but for 
authentication we will eliminate use of that. There is also 
Social Security number use, by law where we have to share with 
other agencies like Internal Revenue Service (IRS) and Social 
Security Administration and things, like, like that.
    Social Security number use by itself will not go away, but 
a number of the business practices in the administrations and 
staff offices will change to integrate or to use what they call 
an integrated control number, an ICN, which is a masking 
identifier for veterans.
    Mr. Rosendale. That is great moving forward. What do we do 
about the 700 veterans and their Social Security numbers going 
out on the mail and what was the response to that? What kind of 
response time did we have?
    Mr. Oswalt. Again, sir I would have to go back and ask for 
your forbearance. Put the information in the record. The 
process remains the same that there is an initial reporting by 
whatever entity discovers it, an investigation and an 
adjudication and a determination made, there is credit 
monitoring offered. Generally in the case of SSN use and a name 
or even a date of birth, credit monitoring offers are tendered 
to the veterans.
    Mr. Rosendale. Okay, that sounds like a very timely 
process. I am thinking about someone's Social Security number 
and their information floating around out in the public 
somewhere and that is very problematic because I think everyone 
in this room certainly understands it does not take that long 
for someone to take that kind of information and use it in a 
nefarious way against our veterans.
    How long do you think it is going to take to clean up this 
process which would remove the Social Security numbers from 
these other documents in the cases where they do not--they are 
not necessary?
    Mr. Oswalt. We have identified approximately 250 
applications, IT applications that use SSN that require this 
type of remediation. A number of those are legacy systems that 
will be retiring. Rather than invest in removing the SSN for 
those which are going to be retired in the foreseeable future, 
we take a risk management approach to try and eliminate that 
because in an austere fiscal environment we can only attack so 
much.
    There is a request in the President's fiscal year 2024 
budget for funds to be begin this remediation effort. The 
biggest part of this is and it is not necessarily an IT issue, 
it is the business practices of the administrations. I liken it 
to an iceberg where there is the IT part that is above the 
water but underneath the surface is a whole set of business 
practices from VBA, VHA.
    Mr. Rosendale. Yes, that is what we call bureaucracy around 
here. We understand that very thoroughly. I have run out of 
time, Mr. Oswalt.
    I now recognize Ranking Member Cherfilus-McCormick.
    Ms. Cherfilus-McCormick. Thank you, Mr. Chairman.
    How does VA intend to structure its governance to ensure 
that the organization takes a strategic enterprise-wide view of 
the use and oversight of AI at VA?
    Mr. Worthington. Thank you for the question. We are still 
in the process of standing up the governance as--as per the 
memo that is coming out after the executive order.
    At a high level, I think what we are looking to do is to 
maximize the impact that we can get from these systems by 
focusing on the Agency's strategic priorities.
    Topics like clinician burnout and mental health, things 
that are consistent with the overall Agency's priorities, we 
want to understand what are the most promising places where 
artificial intelligence might be applied to help with those 
priorities and then obviously pursue those in a way that 
minimizes the risks that AI could introduce.
    Ms. Cherfilus-McCormick. Mr. Worthington, you and chief 
information officer, Kurt DelBene, recently hosted a press 
conference where you discussed the impact that Congress' 
failure to pass a long-term budget has on hiring VA for those 
with AI capabilities.
    If Congress continues to be unable to pass the standing 
funding what is VA's plan for working around this hurdle?
    Mr. Worthington. Well, we are--we are working with what we 
have. You know, we are pretty tight in terms of the number of 
employees within OIT, and so the ability to bring new folks on 
with that expertise is limited.
    I think what we are looking to do is, as best we can, 
shuffle existing resources to explore these priorities, but 
obviously it is hard to start new things when we are focused on 
running all of our existing things.
    Ms. Cherfilus-McCormick. What additional resources do you 
need to ensure that modernization can happen in a safe and 
strategic way?
    Mr. Worthington. I think that having experts, both on the 
IT side as well as in the administrations, that understand how 
to use these tools effectively is really important. The talent 
that we need in the government, not just at the VA but in the 
government, writ large, that has this expertise, is in 
extremely high demand across the country right now.
    We do have a really compelling mission, though. I think 
there are a number of these experts that are willing to do 
public service if only we can provide them, you know, a pathway 
into government.
    I think first and foremost, making those opportunities 
available to people so that some of our country's best AI 
experts can easily serve is probably our top priority.
    Ms. Cherfilus-McCormick. Well, I wanted to shift a little 
bit and talk about the academic affiliates. We have received a 
lot of outreach from VA's academic affiliates about a proposed 
new rule that would close inactive accounts after 30 days as 
opposed to the current 90-day rule.
    Can you explain how having inactive accounts poses an 
additional privacy risk?
    Mr. Worthington. I--this is not a topic that I am an expert 
on. I know at a high level what we are seeking to do is ensure 
that the folks that have access to VA medical data, that that 
list is reviewed regularly and kept up to date.
    The specifics of how that is implemented, I would have to 
probably defer to some of my other colleagues and bring that 
back for the record if you had specific questions about that.
    Ms. Cherfilus-McCormick. I saw Dr. Alterovitz. Did you want 
to comment on that or--because I have another question if not.
    Dr. Alterovitz. No, go ahead.
    Ms. Cherfilus-McCormick. Okay. The academic affiliates are 
concerned that given how long it takes VA to credential new 
users' accounts, their students will be losing a lot of 
education opportunity if they rotate in and out of VA's 
facilities.
    If this proposed rule is adopted, how is VA going to ensure 
that students are not left sitting around for days or weeks 
waiting for their user accounts to be re-created?
    Mr. Worthington. Again, it is a great question. I would 
have to defer to my colleagues and take that back for the 
record, but I do understand the concerns, and we obviously need 
to balance the security, you know, maintaining the secure list 
of folks that should have access, with the ease of use of 
getting the right people provisioned. That is constantly a 
balance we are on struggling to maintain.
    Ms. Cherfilus-McCormick. Thank you.
    I yield back, Mr. Chairman.
    Mr. Rosendale. Thank you very much, Ranking Member 
Cherfilus-McCormick.
    Representative Self.
    Mr. Self. Thank you, Mr. Chairman.
    The breach of Lighthouse, that one or more claims sharks 
apparently, as we referred to them, monetized personal 
information, was that process, was that security, 
cybersecurity, was it employee, how did that breach happen?
    Mr. Worthington. Thank you for the question. I am not sure 
that we have called that a breach, but I guess what I 
understand from the situation is that our Office of General 
Counsel (OGC) assessed that some of the partners that were 
using the Lighthouse program were not in compliance with the 
Title 38 rules, and so we removed them from that program.
    I think that that was discovered as a part of the 
assessment that all partners of Lighthouse should be put 
through a framework that we assess all public-private 
partnerships with, and as a part of that, the OGC group that 
reviews partnerships like that, identified a potential issue 
with these.
    Mr. Self. We are back to my sanctions. You simply remove 
them from the project. In the future, that will be an incentive 
for your partners to monetize, to use the information 
improperly. They will use it improperly, they will get the 
benefit from it, and you will simply remove them from the 
program. In my mind, that is not a significant-enough sanction.
    You have a--Dr. Alterovitz, you have a very high sounding 
name--the National AI Institute. Is this the National AI 
Institute with overall jurisdiction for AI development in the 
Nation? Are there other national institutes for AI?
    Dr. Alterovitz. We are the one within the VA. We were 
started as a joint effort between the Office of Research and 
Development and the Secretary's Center for Strategic 
Partnerships.
    Mr. Self. Are there any other national institutes in the 
United States?
    Dr. Alterovitz. Oh, there are definitely other national 
institutes on a number--I mean like----
    Mr. Self. Which department has overall jurisdiction for the 
development of AI?
    Dr. Alterovitz. There is no one--to my knowledge, there is 
no one department that is associated with developing all of AI. 
A number of agencies--the Department of Energy, HHS--they have 
either centers of excellences or institutes----
    Mr. Self. Okay.
    Dr. Alterovitz [continuing]. for AI.
    Mr. Self. That brings me to my last point, Mr. Chairman. We 
have heard--we dealt with the EOs here, the executive orders. I 
have not heard a lot about law. One of the issues that this 
Congress is starting to deal with is clawing back Article I 
authority in light of the overreach of Article II authorities 
through EOs, through executive orders.
    Mr. Chairman, I recommend we get into that. Why are we 
focused on EOs, executive orders? Why are we using them as the 
baseline here? What is the law that is going to operate not 
only with this national institute, but the national institutes 
across the United States? I think we have got a bigger issue 
here that we perhaps this committee could delve into and lead 
the way toward, what is the law on AI development?
    Thank you. I will yield back.
    Mr. Rosendale. Thank you very much, Representative Self, 
and that is a truly good concept, and you are right, we have 
been working toward that, to regain the power for Congress and 
for all of us.
    Dr. Alterovitz, another of your priority AI uses cases is 
applying machine learning to patients' genetic and phenotypic 
information to predict and optimize surgery outcomes. That is 
how their genes affect or responds to medication and their 
observable physical traits. What ethical challenges do you 
think that could pose?
    For example, if AI says, do not do the surgery based on a 
veteran's genes, what is the surgeon's responsibility? Again, 
is that patient advised of who generated this prognosis, man or 
machine?
    Dr. Alterovitz. Thank you for your question. I think there 
are a number of use cases that we are evaluating at different 
stages, and that is one of the key things that we are looking 
at Trustworthy AI at the beginning. There are a number of 
principles there, and a number of the areas that you mentioned 
are ones that we would look at.
    A few that come to mind, as you said: the genetics, you can 
have different demographics, you may have to look at different 
types of polymorphisms. Basically, different parts of the 
genetics may be applicable. How do you quantify those surgical 
outcomes in different settings?
    I mean, there are a lot of questions like that, and so when 
they are research projects, there is more time to engage and to 
do that.
    Then in other projects, if we do not find it consistent, 
there is time to make a consistency plan where we kind of keep 
going back and getting more questions answered and maybe 
analyzing some of that data.
    Mr. Rosendale. Dr. Alterovitz----
    Dr. Alterovitz. Yes.
    Mr. Rosendale. Look, I understand. Additional information 
is good. We have all of that data coming in, but, again, the 
first thing that I go back to is, should not this be disclosed 
to the veterans? Should not this be disclosed to the patients, 
that they understand exactly who is performing this analysis 
and creating this prognosis?
    Dr. Alterovitz. Well, for research studies, we do have, 
informed consent through Institutional Review Boards (IRB)s. 
Through non-research, we have developed and are piloting 
something called a model card, which basically is like a 
pamphlet that explains how the AI is being used for different 
settings.
    One setting may be for the patient. Another setting may be 
for the doctor who is interested in other parts of how the AI 
works.
    Model cards are a way that are now pioneering, and we are 
not the only ones pioneering this, but we are really looking at 
it in the healthcare setting and piloting to see how that works 
across the network.
    Mr. Rosendale. Okay. Dr. Alterovitz, here is another 
example. You are using natural language processing to extract 
signals of suicide risk from clinical progress notes and other 
medical records.
    We need to do whatever we can to prevent veteran suicide. 
We know that--I have heard everything from 19 veterans a day to 
as high as 24, but we need to be extremely careful.
    First of all, how prone to false positives is the software, 
and what level of accuracy do you consider acceptable? I am 
concerned that this could lead to a violation of veterans' 
rights, limiting personal freedoms and gun ownership.
    Dr. Alterovitz. Thank you for your question. I think 
everything you have said are concerns that need to be looked 
at, where this uses AI is in the natural language process, 
looking at those notes and extracting potential meaning out of 
it.
    There are always a human in the loop that then looks at the 
results, and so this is a way to help them shift through a 
large amount of text and----
    Mr. Rosendale. There is a human reviewing that, but there 
is also a human who is creating those notes. We have a very 
subjective component that is part of this analysis that we have 
to be very, very careful of.
    Do the veterans know that the VA is using this technology, 
and if so, could it color, could it taint what they are willing 
to tell their healthcare providers?
    Dr. Alterovitz. For ones that are involved in research and 
there is a consent form, then they could be aware. For ones in 
operations, generally there are tools used that have been 
publicized on our website, through the inventory, that explain 
how they use AI and----
    Mr. Rosendale. Okay. We still do not have a good, 
consistent disclosure process that is being utilized and being 
signed off by our veterans, correct, across the system?
    Dr. Alterovitz. That is correct. I do not----
    Mr. Rosendale. Okay. Again, please, that has got to be 
elevated to a top priority. It absolutely has to be elevated to 
a top priority. I would yield to--have no more? Have no more. 
Okay. Goodness gracious. Okay. Where do I go?
    I want to thank our witnesses for joining us this 
afternoon. It is been an enlightening discussion. It truly has.
    I will yield to Representative Cherfilus-McCormick for a 
closing statement then.
    Ms. Cherfilus-McCormick. Thank you. Thank you again for the 
witnesses for being here today. It is absolutely crucial that 
we do everything in our power to ensure that the data veterans 
have entrusted VA with is protected and that we ensure that no 
one, VA and its vendors alike, is monetizing that data for 
personal gain.
    I am also grateful for today's conversation about the use 
of artificial intelligence at VA. The opportunity that AI 
provides to improve patient care and access as well as reducing 
the administrative burden of VA personnel are exciting.
    However, as the proverb goes, with great power comes great 
responsibility. We have already seen how AI can be used for 
less noble purposes. AI deepfakes have been all over the news 
recently. These uses of the technology are unacceptable.
    I am convinced that this is just the beginning of our 
oversight of AI and how it can safely be applied at the VA.
    Thank you, Mr. Chairman, for this great discussion, and I 
yield back.
    Mr. Rosendale. Thank you very much, Representative 
Cherfilus-McCormick.
    Again, I would like to thank everyone for joining us this 
afternoon. It has been an enlightening discussion. I think that 
we all have identified some areas that right now, immediately, 
we are going to be able to go out and take some action items 
for Congress to do their part and for the Veterans 
Administration to do their part to make sure the veterans are, 
again, getting the best possible care that they can.
    This is by no means the last hearing that the committee 
will hold on artificial intelligence. It is an expanding, 
complex area that warrants serious oversight.
    I want to thank Dr. Miller-Meeks and the Health 
Subcommittee for working with us and for delving into AI 
projects that the Veterans Health Administration has under way.
    With that, I ask unanimous consent that all members have 5 
legislative days to revise and extend their remarks and include 
extraneous material.
    without objection, we will adjourn.
    [Whereupon, at 4:46 p.m., the subcommittee was adjourned.]
    
=======================================================================


                         A  P  P  E  N  D  I  X

=======================================================================


                     Prepared Statements of Witness

                              ----------                              


               Prepared Statement of Charles Worthington

    Good afternoon, Chairman Rosendale, Ranking Member Cherfilus-
McCormick, and distinguished Members of the Subcommittee. Thank you for 
the opportunity to testify today about the Department of Veterans 
Affairs (VA) efforts in patient and data privacy, and Artificial 
Intelligence (AI). I am accompanied today by Mr. John Oswalt, Deputy 
Chief Information Officer of Freedom of information Act, Records and 
Assessment Compliance, Office of Information and Technology (OIT); Dr. 
Gil Alterovitz, Director, VA National Artificial Intelligence Institute 
and Chief AI Officer, Veterans Health Administration; and Ms. Stephania 
Griffin, Director, Information Access and Privacy Office, Veterans 
Health Administration (VHA).
    VA is committed to protecting Veterans' data while responsibly 
harnessing the promise of AI to better serve Veterans. While AI can be 
a powerful tool, its use and application needs to have the proper 
controls, oversight, and security guided by VA's Zero Trust 
Cybersecurity Strategy; and Executive Order 14110 on the Safe, Secure, 
and Trustworthy Development and Use of AI.
    In order to run the largest integrated health care system in the 
nation and deliver a myriad of benefits to eligible veterans, VA has a 
complex data ecosystem with over 1,100 petabytes of sensitive 
information, and an extensive digital footprint spanning over 500,000 
desktops across 2,000 locations. To protect this environment, VA's 
Cybersecurity Strategy was established to unify an enterprise-wide 
solution that protects the Department's data at-rest, in-use, and in-
motion.
    The Department leverages sound cybersecurity practices to protect 
the confidentiality, integrity, and availability of our information and 
information systems now and in the future. These practices include 
physical, technical, and administrative controls and enables 
cybersecurity professionals to monitor, detect, and respond to cyber 
threats. These protections constitute a strong defense-in-depth 
strategy comparable to those deployed in the commercial sector. 
Identity Management is key in this area. Federal departments and 
agencies should require least privilege access to data resources and 
tiered user permissions to enforce separation of duties to those 
resources that house data. This testimony provides an overview of all 
VA currently does to protect Veterans' data, as well as note what 
challenges we currently face and where resources can best be allocated.

Protecting Data at Risk

    VA uses the National Institute of Standards and Technology (NIST) 
Risk Management Framework (RMF) to comprehensively manage and report on 
privacy and security risk throughout the IT system lifecycle (hardware 
and software components). This enforces independent privacy and 
security reviews that prevent conflict of interest when conducting 
privacy and security assessments and audits. The overall RMF does not 
involve vendors in the determination of system security risk nor in the 
performance of security audits. As part of RMF, VA deploys a 
comprehensive Assessment and Authorization (A&A) program that requires 
independent or third-party security assessors to perform assessment 
reviews, testing, and audits against vendor hardware and software 
components to ensure that security risk is identified and mitigated or 
remediated to an acceptable level prior to deployment. Within the A&A 
process, the Authorizing Officials use the security and privacy posture 
of a system to determine if the risk to organizational operations and 
assets are at an acceptable level, in accordance with VA risk 
management strategy.
    VA risk management aligns with NIST Special Publication 800-53, 
Security and Privacy Controls for Information Systems and 
Organizations. VA security control requirements deploy a diverse set of 
information technologies for VA systems within the Department's IT 
footprint to reduce the risk and impact of potential exploitations of 
specific technologies and to defend against common mode failures. 
Additionally, the Department is aligning the program to VA's Data 
Governance Council to provide strategic direction and visibility across 
the enterprise.
    This balanced risk management approach deliberately provides VA the 
guardrails it needs when considering emerging technology tools that 
have a large potential to improve Veteran health care and benefits such 
as Artificial Intelligence (AI).

Artificial Intelligence

    VA is committed to responsibly harnessing the promise of AI to 
better serve Veterans. VA is excited about the potential of emerging AI 
technologies and how those technologies can empower the Department's 
mission on delivering world-class, secure technology solutions that 
enable a seamless, unified, efficient Veteran experience. To that end, 
VA was one of the first five Federal agencies to publish an AI 
strategy. VA's AI Strategy, published in 2021, which articulates a 
clear vision to improve outcomes and experiences for Veterans by 
developing trustworthy AI capabilities. It is imperative that VA and 
other government agencies implement AI responsibly and securely. VA 
needs to be very intentional and strategic about its implementation to 
ensure these technologies do not perpetuate bias or introduce 
inaccuracies. VA's goal is to maximize the potential value of AI to 
improve Veteran health and benefit outcomes and comply with Executive 
Order 14110 and upcoming Office of Management and Budget (OMB) 
memorandum.
    As you know, VA has one of the Nation's largest and most 
extensively curated collections of health and benefits data in the 
world, representing a great opportunity to use AI with the potential to 
unlock improved outcomes for Veterans. AI at VA is at a transition 
point, where solutions that leverage AI will graduate from the lab into 
enterprise-grade systems. VA's current execution plan for AI has the 
following four main workstreams: governance; execution of several high 
priority use cases; AI workforce development; and AI infrastructure.

Overview of VA's Use of AI in Health Care Delivery

    VA has embraced the power of AI to revolutionize health care 
delivery. The Department is strategically leveraging this tool to 
improve the health care experience for the Nation's Veterans by 
enhancing patient care, streamlining administrative processes, and 
improving health care outcomes. By integrating AI into various aspects 
of Veteran health care, such as decision support systems, predictive 
modeling, and personalized care plans, VA is enhancing diagnostic 
accuracy and efficiency. VA is actively using AI in the area of 
predictive analytics, which uses vast amounts of data to identify 
patterns and trends, including predicting risks of cancers \1\ and 
adverse outcomes, allowing for early and personalized interventions, 
ultimately improving health outcomes for Veterans. AI tools such as 
these hold the promise of optimizing efficiency of VA's health care 
delivery, while improving the quality of care provided to our 
beneficiaries.
---------------------------------------------------------------------------
    \1\ The official OIT Compliance, Risk, and Remediation AI Use Case 
Inventory submitted to OMB shows 10 use cases related to cancer.

---------------------------------------------------------------------------
Benefits and Potential of AI in Veteran Health Care

    VA is building a network of cross-disciplinary experts to 
capitalize on VA data and drive AI research, development, and practical 
AI implementation to improve Veterans' health and benefit services. 
With over 120,000 clinicians serving more than 9 million patients 
across 1,200 medical facilities, VA possesses an unparalleled wealth of 
health care data. These data, which include over 10 billion medical 
images and the world's largest genomic data base tied to medical 
records, can be leveraged to propel the United States to the forefront 
of AI leadership. Furthermore, as the Nation's largest integrated 
health care system, VA is uniquely positioned to test and scale 
effective AI solutions.
    Effective AI implementation can improve staffing, development of 
novel treatments, patient safety monitoring, and disease prediction. VA 
is focused on using AI to alleviate provider burnout by reducing 
administrative tasks such as data entry. VA is currently hosting an AI 
Tech Sprint to source tailored AI solutions to further reduce burnout. 
In addition to reducing burnout, VA is also dedicated to accurately 
identifying health care providers, improving provider directories' 
accuracy to over 90 percent,\2\ and enhancing access to care and 
patient safety. VA is leveraging AI in clinical settings as another 
tool available for providers. One example of AI in clinical use is GI 
Genius, a U.S. Food and Drug Administration--authorized system that 
aids in detecting concerning polyps during colonoscopies, leading to a 
50 percent reduction in missed colorectal polyps compared to standard 
procedures.\3\
---------------------------------------------------------------------------
    \2\ Council for Affordable Quality Healthcare (CAQH). (2023). 
Improve provider data management and accuracy. Available at: https://
www.caqh.org/solutions/provider-data.
    \3\ Wallace MB, Sharma P, Bhandari P, East J, Antonelli G, 
Lorenzetti R, Vieth M, Speranza I, Spadaccini M, Desai M, Lukens FJ, 
Babameto G, Batista D, Singh D, Palmer W, Ramirez F, Palmer R, Lunsford 
T, Ruff K, Bird-Liebermann E, Ciofoaia V, Arndtz S, Cangemi D, Puddick 
K, Derfus G, Johal AS, Barawi M, Longo L, Moro L, Repici A, Hassan C. 
(2022, July). Impact of Artificial Intelligence on Miss Rate of 
Colorectal Neoplasia. Gastroenterology. 163(1):295-304.e5. doi: 
10.1053/j.gastro.2022.03.007.

---------------------------------------------------------------------------
    Addressing Concerns and Ensuring Accountability in AI Utilization

    The main risks associated with AI are data breaches, biased 
predictions in health care, and patient safety. However, the use of 
Trustworthy AI \4\ can mitigate these risks and lead to increased 
adoption, decreased risks, improved competitiveness, and higher returns 
on investment for VA. To ensure the safe and responsible use of AI, VA 
has developed its own Trustworthy AI framework aligned to VA's mission. 
Adopted in July 2023, VA's Trustworthy AI framework outlines six 
principles for all instances at the agency to ensure that they are 
Purposeful, Effective and Safe; Secure and Private; Fair and Equitable; 
Transparent and Explainable; and Accountable and Monitored.
---------------------------------------------------------------------------
    \4\ This framework helps organizations develop ethical safeguards 
across seven key dimensions of AI governance and compliance, ensuring 
the network remains: Private; Transparent and Explainable; Fair and 
Impartial; Responsible; Accountable; Robust and Reliable; and Safe and 
Secure.
---------------------------------------------------------------------------
    Within the National Artificial Intelligence Institute AI Network, 
VHA currently has several pilot efforts in place to increase safety, 
transparency, and trust in AI. The AI Institutional Review Board (IRB) 
module incorporates Trustworthy AI principles into the existing IRB 
process to protect Veterans participating in AI research and enhance 
transparency and trust in AI. The AI Oversight Committee pilot is 
another mechanism to instill trust and empower medical center directors 
to establish processes and systems of governance that support 
compliance.

Collaborations and Partnerships for AI Advancement in Veteran Health 
Care

    We practice a high-level of continuous collaboration, while 
building many strategic partnerships, all to advance the development of 
Trustworthy AI innovations for Veterans, their survivors and 
caregivers, and American citizens, fostering a global impact. Our 
collaborations span multiple sectors--including other VA entities, 
Federal organizations,\5\ academia, the military, international bodies, 
and private industry--enabling us to identify AI use cases; advance 
research and development capabilities; expand our reach to diverse 
populations and demographics; connect with top data science talent; and 
disseminate Trustworthy AI solutions. AI Tech Sprints are a prime 
example of how VA fosters connection with innovators outside of 
government to develop new solutions and improve Veteran care and 
experience. VA will complete two in this calendar year. \6\ The current 
AI Tech Sprint focuses on reducing provider burnout and administrative 
burden, ultimately improving care for Veterans. Teams from across the 
Nation are competing to develop AI solutions in two distinct tracks 
that will support health care workers. Track one will focus on AI 
powered, advanced health care record integration, while track two will 
identify an AI solution to enable ambient dictation for clinical 
encounters to improve provider-Veteran patient connection and reduce 
clinicians' documentation burden. Additionally, utilizing Cooperative 
Research and Development Agreements provides us with the flexibility to 
transfer commercially useful technologies to the non-Federal sector.
---------------------------------------------------------------------------
    \5\ Current collaborators in the federal sector include the Office 
of the National Coordinator for Health Information technology; the 
Departments of Health and Human Services, Defense, and Energy; the FDA; 
the Defense Health Agency; the Center for Medicare and Medicaid 
Services; the National Institute of Health; and others.
    \6\ As required by EO 14110, Safe, Secure, and Trustworthy 
Development and Use of Artificial Intelligence (October 20, 2023). 
Available at https://www.govinfo.gov/content/pkg/FR-2023-11-01/pdf/
2023-24283.pdf.

---------------------------------------------------------------------------
Ethical Considerations in AI-Powered Decision-Making

    With the vast potential of AI, VA is equally concerned about the 
ethical and effective use of AI. Governance plays a key role in 
building in proper checks and balances and guidance on how AI is 
ultimately put to work--ensuring AI initiatives conform with wider 
accepted practices. AI has risks and challenges, so VA is focusing on 
an AI strategy, ethical guidelines, and best practices across VA and 
with external partners to deploy trustworthy, secure AI, that benefits 
our delivery of health care and benefits to the Veteran community.
    Currently, VA is piloting VA AI Oversight Subcommittees, created an 
AI Working Group, and created an AI IRB Pilot, which allows 
comprehensive vetting of AI use cases to determine if an AI model 
follows the principles of trustworthy AI per EO 13960 and other Federal 
regulations that protect human subjects. Finally, VA recognizes the 
importance and need for AI transparency and publishes AI use cases on 
our VA AI Inventory website, sharing VA's inventory with other 
government agencies and the public.

Conclusion

    VA's patient and data security solutions must consider the 
interaction with users, the value to the Veteran, as well as the 
confidentiality, integrity, and availability of VA's information 
resources. With a balanced, risk-managed approach toward secure 
computing, we will maintain the confidence and trust of Veterans, our 
stakeholders, and the public. With the strategies, policies, and 
programs in place, the Department continues in its mission to protect 
and secure the information of, and services for, the Veterans. Mr. 
Chairman, Ranking Member and Members of the Subcommittee, thank you for 
the opportunity to testify before the Subcommittee today to discuss one 
of VA's top priorities. I am happy to respond to any questions that you 
have.
                                 ______
                                 

                   Prepared Statement of Shannon Tews

    Chairman Rosendale and esteemed members of the Committee, thank you 
for inviting me to testify today regarding the responsible and ethical 
use of artificial intelligence to enhance healthcare for our nation's 
veterans.
    As the VA increasingly looks to incorporate AI tools to improve 
efficiency, accuracy, and personalization of care, we must be vigilant 
in creating proper safeguards around veteran data privacy and security. 
If implemented conscientiously, AI systems present a tremendous 
opportunity to better serve veterans' health needs. My testimony will 
focus on best practices and considerations for that responsible 
integration.
    First, any AI tools leveraged by the VA must be deployed in 
accordance with the Department's Trustworthy AI Framework centered on 
six fundamental principles: purposeful, safe, and effective, secure and 
private, fair and equitable, transparent and explainable, and 
accountable and monitored. Adhering to these values can foster 
confidence and adoption of AI innovation among veterans.
    The VA should assemble dedicated, multidisciplinary teams combining 
healthcare expertise, technical capabilities, and ethics specialization 
to evaluate AI systems at every phase - from initial procurement and 
design through validation, implementation, and continuous improvement. 
These teams can ensure tools align with intended use cases while 
meeting stringent standards around security, explainability, and 
unbiased outputs that impact care.
    Ongoing community participation is also instrumental. Veterans 
should have opportunities to actively inform system requirements and 
provide feedback on AI experiences as part of closing the loop--their 
real-world insights further accountability while enhancing utility. 
External third-party testing around safety, security, and fairness 
further verifies performance to standards for VA procurement approval 
before systems interact with sensitive data.
    Any AI tools or platforms brought in must then operate within 
comprehensive data privacy environments matching the rigor of HIPAA 
controls already governing healthcare data security - including 
encryption, access management, activity monitoring, and audits.
    The Veterans Affairs Department should institute de-identification 
techniques like differential privacy to minimize reliance on personal 
information for development or analytics while preserving analytical 
validity. When systems utilize private data temporarily, they should 
quickly dissociate any data, securing veterans' details.
    The VA must retain clear ownership and governance of veterans' 
healthcare data through this AI journey, avoiding reliance on external 
software vendors or open data bases that cannot provide assurances on 
control or appropriate use aligned to individuals' preferences.
    Here are some additional ideas for the Veterans Affairs Department 
to consider regarding the enhancements available to current systems by 
using artificial intelligence in veterans' healthcare:

    Advanced Diagnosis and Treatment: There is massive potential for AI 
to assist healthcare providers with more accurate and timely diagnosis 
of veterans' health issues. AI can analyze vast medical data sets, 
including electronic health records, imaging, and genetic information, 
to identify patterns and suggest personalized treatment plans. These 
enhancements could lead to quicker interventions and improved health 
outcomes.

    Predictive Healthcare: The power of AI to utilize predictive 
analysis in potential health issues for veterans could be a key asset 
for early medical treatments that could get ahead of larger problems 
with scheduled monitoring and counseling earlier in the process. 
Machine learning algorithms can analyze historical data to identify 
veterans at higher risk of specific conditions, allowing for preventive 
measures and early interventions.

    Virtual Health Assistants: Eventually AI-powered virtual health 
assistants can provide veterans with 24/7 access to healthcare 
information, answer questions, schedule appointments, and even provide 
mental health support, improving the overall patient experience once 
the processes have been tested for accuracy and consistency in their 
responses to enable a cohesive network application available to 
Veterans who want to use the AI driven program.

    Data Integration: Thoughtful introduction of AI systems integration 
could enable VA healthcare infrastructure to ensure that AI tools 
complement and enhance the work of healthcare providers rather than 
disrupt their workflows.

    Telemedicine: AI can improve telemedicine services for veterans, 
making it easier for them to access healthcare remotely. AI-driven 
chatbots and virtual consultations can provide immediate assistance and 
reduce the burden on VA healthcare facilities by unitizing chatbot 
technology for the first layer of questions for the operators 
interacting with a patient that is then sent to the right branch of the 
medical practice group after the stated concerns of the patient have 
been reviewed while looking at health patterns and their health 
history. A human would be the most important element of a telemedicine 
visit, but AI could speed up the initial entrance into the visitation 
system.

    Mental Health Support: AI can play a crucial role in identifying 
early signs of mental health issues, providing resources, and 
connecting veterans with appropriate care through more efficient 
pattern recognition and effective solution set matching to the 
diagnosed problem .

    Ethical AI Use: The importance of adhering to ethical guidelines 
must be part of the development and deployment phases AI in healthcare. 
Transparency in AI algorithms so that veterans and healthcare providers 
can understand the use of artificial intelligence tools in decision-
making is critical.

    Education and Training: The VA will need to invest in training 
healthcare professionals to work effectively with AI systems. Proper 
education and understanding of AI technologies will ensure a higher 
level of the healthcare professionals responsible and effective use of 
the AI toolsets.

    Collaboration with AI Industry: The potential for collaboration 
with AI companies and researchers to leverage the latest advancements 
in AI technology for veterans' healthcare can accelerate progress in 
this field.

    Data Sharing and Research: Collaborative research efforts can lead 
to breakthroughs in veterans' health. However, the importance de-
identified healthcare data for research purposes is vital for ensuring 
privacy and security must be a top priority.

    Continuous Monitoring and Improvement: The practice of ongoing 
monitoring and evaluation of AI systems with regular audits and 
assessments can ensure that AI tools continue to meet the highest 
standards of performance, fairness, and security.

    Veteran Inclusivity: Making AI tools and services accessible to 
veterans of all backgrounds, including those with disabilities is a 
crucial part of this effort. Veterans Affairs must ensure that medical 
system's design utilizing AI systems includes inclusivity.

    Public Awareness: Clear communication can alleviate concerns and 
build trust among veterans and their families. There should be 
educational initiatives to raise public awareness about AI's benefits 
and responsible use in veterans' healthcare.

    International Collaboration: The potential for collaboration with 
international partners in AI research and healthcare will allow for the 
sharing of knowledge and best practices globally, which can lead to 
faster advancements.

    Budget Allocation: Adequate budget allocations are vital for AI 
initiatives in veterans' healthcare. Funding is essential to support AI 
system research, development, implementation, and ongoing maintenance.
    By incorporating many of these additional ideas the Department of 
Veterans Affairs could provide a more comprehensive overview of the 
benefits veterans' healthcare will receive from using AI tools in the 
decision-making processes while ensuring the responsible and ethical 
use of artificial intelligence.
    In closing, I reiterate my conviction that AI and machine learning 
can unlock immense potential in enhancing experiences, outcomes, and 
care availability for those who bravely served our country. As the VA 
advances its AI strategy for veterans, instilling Trustworthy AI 
principles centered on security, fairness, and accountability at every 
step is paramount to delivering on that promise.
    I welcome any questions on components of the framework or 
recommendations to actualize AI's benefits for veterans while upholding 
their rights to informed consent and confidentiality through this 
transition. Getting the balance right will prove key to unlocking AI's 
immense potential while retaining foundational trust.

                        Statement for the Record

                              ----------                              


   2022 Ars Technica Article Submitted by Representative Mariannette 
                         Miller-Meeks, (IA-01)
                         
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]

                                 [all]
</pre></body></html>
