<html>
<title> - WHO IS SELLING YOUR DATA: A CRITICAL EXAMINATION OF THE ROLE OF DATA BROKERS IN THE DIGITAL ECONOMY</title>
<body><pre>
[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]


                      WHO IS SELLING YOUR DATA: A CRITICAL EXAM-
                       INATION OF THE ROLE OF DATA BROKERS 
                       IN THE DIGITAL ECONOMY

=======================================================================

                                HEARING

                               BEFORE THE

                          SUBCOMMITTEE ON OVERSIGHT 
                               AND INVESTIGATIONS

                                 OF THE

                    COMMITTEE ON ENERGY AND COMMERCE
                        HOUSE OF REPRESENTATIVES

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             FIRST SESSION

                               __________

                             APRIL 19, 2023

                               __________

                           Serial No. 118-26
                           
[GRAPHIC NOT AVAILABLE IN TIFF FORMAT]                           


     Published for the use of the Committee on Energy and Commerce

                   govinfo.gov/committee/house-energy
                        energycommerce.house.gov
                        
                               __________

                   U.S. GOVERNMENT PUBLISHING OFFICE                    
55-269 PDF                  WASHINGTON : 2024                    
          
-----------------------------------------------------------------------------------     
                       
                    COMMITTEE ON ENERGY AND COMMERCE

                   CATHY McMORRIS RODGERS, Washington
                                  Chair
MICHAEL C. BURGESS, Texas            FRANK PALLONE, Jr., New Jersey
ROBERT E. LATTA, Ohio                  Ranking Member
BRETT GUTHRIE, Kentucky              ANNA G. ESHOO, California
H. MORGAN GRIFFITH, Virginia         DIANA DeGETTE, Colorado
GUS M. BILIRAKIS, Florida            JAN SCHAKOWSKY, Illinois
BILL JOHNSON, Ohio                   DORIS O. MATSUI, California
LARRY BUCSHON, Indiana               KATHY CASTOR, Florida
RICHARD HUDSON, North Carolina       JOHN P. SARBANES, Maryland
TIM WALBERG, Michigan                PAUL TONKO, New York
EARL L. ``BUDDY'' CARTER, Georgia    YVETTE D. CLARKE, New York
JEFF DUNCAN, South Carolina          TONY CARDENAS, California
GARY J. PALMER, Alabama              RAUL RUIZ, California
NEAL P. DUNN, Florida                SCOTT H. PETERS, California
JOHN R. CURTIS, Utah                 DEBBIE DINGELL, Michigan
DEBBBIE LESKO, Arizona               MARC A. VEASEY, Texas
GREG PENCE, Indiana                  ANN M. KUSTER, New Hampshire
DAN CRENSHAW, Texas                  ROBIN L. KELLY, Illinois
JOHN JOYCE, Pennsylvania             NANETTE DIAZ BARRAGAN, California
KELLY ARMSTRONG, North Dakota, Vice  LISA BLUNT ROCHESTER, Delaware
    Chair                            DARREN SOTO, Florida
RANDY K. WEBER, Sr., Texas           ANGIE CRAIG, Minnesota
RICK W. ALLEN, Georgia               KIM SCHRIER, Washington
TROY BALDERSON, Ohio                 LORI TRAHAN, Massachusetts
RUSS FULCHER, Idaho                  LIZZIE FLETCHER, Texas
AUGUST PFLUGER, Texas
DIANA HARSHBARGER, Tennessee
MARIANNETTE MILLER-MEEKS, Iowa
KAT CAMMACK, Florida
JAY OBERNOLTE, California
                                 ------                                

                           Professional Staff

                      NATE HODSON, Staff Director
                   SARAH BURKE, Deputy Staff Director
               TIFFANY GUARASCIO, Minority Staff Director
              Subcommittee on Oversight and Investigations

                      H. MORGAN GRIFFITH, Virginia
                                 Chairman
MICHAEL C. BURGESS, Texas            KATHY CASTOR, Florida
BRETT GUTHRIE, Kentucky                Ranking Member
JEFF DUNCAN, South Carolina          DIANA DeGETTE, Colorado
GARY J. PALMER, Alabama              JAN SCHAKOWSKY, Illinois
DEBBIE LESKO, Arizona, Vice Chair    PAUL TONKO, New York
DAN CRENSHAW, Texas                  RAUL RUIZ, California
KELLY ARMSTRONG, North Dakota        SCOTT H. PETERS, California
KAT CAMMACK, Florida                 FRANK PALLONE, Jr., New Jersey (ex 
CATHY McMORRIS RODGERS, Washington       officio)
    (ex officio)
                             C O N T E N T S

                              ----------                              
                                                                   Page
Hon. H. Morgan Griffith, a Representative in Congress from the 
  Commonwealth of Virginia, opening statement....................     2
    Prepared statement...........................................     3
Hon. Kathy Castor, a Representative in Congress from the State of 
  Florida, opening statement.....................................     7
    Prepared statement...........................................     9
Hon. Cathy McMorris Rodgers, a Representative in Congress from 
  the State of Washington, opening statement.....................    11
    Prepared statement...........................................    13
Hon. Frank Pallone, Jr., a Representative in Congress from the 
  State of New Jersey, opening statement.........................    16
    Prepared statement...........................................    18

                               Witnesses

Laura Moy, Associate Professor of Law, Georgetown University Law 
  Center.........................................................    20
    Prepared statement...........................................    23
Marshall Erwin, Chief Security Officer, Mozilla..................    34
    Prepared statement...........................................    36
Justin Sherman, Senior Fellow and Research Lead, Data Brokerage 
  Project, Duke University Sanford School of Public Policy.......    42
    Prepared statement...........................................    44

 
 WHO IS SELLING YOUR DATA: A CRITICAL EXAMINATION OF THE ROLE OF DATA 
                     BROKERS IN THE DIGITAL ECONOMY

                              ----------                              


                       Wednesday, April 19, 2023

                  House of Representatives,
      Subcommittee on Oversight and Investigations,
                          Committee on Energy and Commerce,
                                                    Washington, DC.
    The subcommittee met, pursuant to call, at 2:00 p.m., in 
room 2322, Rayburn House Office Building, Hon. H. Morgan 
Griffith (chairman of the subcommittee) presiding.
    Members present: Representatives Griffith, Burgess, 
Guthrie, Duncan, Palmer, Lesko, Armstrong, Cammack, Rodgers (ex 
officio), Castor (subcommittee ranking member), DeGette, 
Schakowsky, Tonko, Ruiz, Peters, and Pallone (ex officio).
    Also present: Representative Trahan.
    Staff present: Sean Brebbia, Chief Counsel, Oversight and 
Investigations; Deep Buddharaju, Senior Counsel, Oversight and 
Investigations; Sarah Burke, Deputy Staff Director; Lauren 
Eriksen, Clerk, Oversight and Investigations; Tara Hupman, 
Chief Counsel; Sean Kelly, Press Secretary; Peter Kielty, 
General Counsel; Emily King, Member Services Director; Chris 
Krepich, Press Secretary; Michael Steinberg, GAO Detailee; John 
Strom, Counsel, Oversight and Investigations; Michael Taggart, 
Policy Director; Joanne Thomas, Counsel, Oversight and 
Investigations; Austin Flack, Minority Junior Professional 
Staff Member; Waverly Gordon, Minority Deputy Staff Director 
and General Counsel; Tiffany Guarascio, Minority Staff 
Director; Lisa Hone, Minority Chief Counsel, Innovation, Data, 
and Commerce; Liz Johns, Minority GAO Detailee; Will McAuliffe, 
Minority Chief Counsel, Oversight and Investigations; Christina 
Parisi, Minority Professional Staff Member; Harry Samuels, 
Minority Oversight Counsel; Caroline Wood, Minority Research 
Analyst; and C.J. Young, Minority Deputy Communications 
Director.
    Mr. Griffith. The Subcommittee on Oversight and 
Investigations will now come to order.
    The Chair now recognizes himself--that would be me--for 5 
minutes for an opening statement.

OPENING STATEMENT OF HON. H. MORGAN GRIFFITH, A REPRESENTATIVE 
         IN CONGRESS FROM THE COMMONWEALTH OF VIRGINIA

    Welcome, everyone, to what I hope will be a productive, 
fact-finding hearing on the current state of the data broker 
ecosystem.
    It is obvious from the testimony that a staggering amount 
of information is collected on Americans every day, frequently 
without their knowledge or consent. This data then gets shared, 
analyzed, combined with other data sets, bought, and sold. In 
some cases, this data is not even anonymized, meaning that it 
is easy for bad actors to find deeply personal information on 
individuals such as their location, demographic data, health 
information. Some of these data brokers are companies that most 
people are familiar with, but others operate in the shadows, 
with many Americans never knowing that they have collected--
that their data has been collected, bought, or sold.
    The Federal Trade Commission recently fined an online 
mental health company, BetterHelp, 7.8 million for disclosing 
patients' personal health information to advertising platforms 
such as Facebook and Google without the users' consent.
    Siphoning off private data of Americans on mobile apps is 
so incredibly easy. All a data broker has to do is pay an app 
developer a nominal fee to implant a program within the app 
that is designed to capture the data of all users. Companies 
rely on these convoluted and unclear terms of service and 
privacy policy documents, knowing full well users will find it 
far too tedious to read them before unwittingly agreeing to 
have their sensitive data accessed by third-party strangers.
    There's a complete lack of safeguards surrounding this 
data, and I am particularly concerned with the implications 
that has on the sick, the elderly, the youth, and the military. 
Recent research from Duke University has found data brokers 
without any accountability can freely collect and share 
Americans' private mental health data.
    We have all heard about the national security concerns 
raised about the Chinese Communist Party-influenced ByteDance, 
the parent company of TikTok video app, operating in our 
country and collecting data on Americans, while also having the 
ability to potentially manipulate American public opinion on 
any given subject matter.
    While the current state of play is--the current state of 
play in the data broker industry presents some of these same 
concerns, according to what we will hear today from these, our 
invited experts, data brokers gather, package, and advertise 
highly sensitive data on current and former members of the U.S. 
military, posing privacy and safety risks to all 
servicemembers. This, in and of itself, could be considered a 
security risk if the data collected is identifiable. By 
collecting and selling data at will, these companies put all 
Americans at risk.
    I look forward to learning from our witnesses today more 
about how data brokers are collecting, packaging, and analyzing 
data on Americans, and possible safeguards that we should 
explore.
    [The prepared statement of Mr. Griffith follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mr. Griffith. And with that, I yield back and now recognize 
the ranking member of the subcommittee, Ms. Castor, for her 
opening statement.

  OPENING STATEMENT OF HON. KATHY CASTOR, A REPRESENTATIVE IN 
               CONGRESS FROM THE STATE OF FLORIDA

    Ms. Castor. Well, thank you, Mr. Chairman, for calling this 
hearing. Thank you to our expert witnesses for being with us 
today to share your insight on the excesses of the data broker 
industry. I am grateful that we can take on these issues in a 
true bipartisan fashion.
    These incessant surveillance and data gathering for profit 
by data brokers affects every American. Data brokers are often 
invisible to consumers. They rarely interact directly with us, 
but they are constantly collecting our personal, private 
information, including names, geolocation data, addresses, 
health data, age, political preferences, and much more. And 
they collect it no matter how private and sensitive that data 
may be.
    I believe each and every American should determine what 
personal information to share with a corporation, and then not 
be held over a barrel if they choose not to do so, especially 
with the track record now of data breaches and scammers and 
scalpers and advertisers. These privacy abuses are leading to 
mental, physical, and financial harm, and the harms are well 
documented and affect some of the most vulnerable among us, 
including the elderly, veterans, and people of color.
    But there are few things more concerning to me than the 
ways Big Tech, including data brokers, have proliferated the 
surveillance and targeting of our kids. Take Recolor. Recolor 
is an online coloring book operated by KuuHubb. Recolor 
provides images that consumers can color in on their mobile 
devices, including kid-friendly images like animated characters 
and cartoons.
    In 2021, KuuHubb was found to have collected and disclosed 
personal information about children to third parties, including 
advertisers, without their parents' consent. Like so many 
others, this company enticed children onto their platforms only 
to monetize their data for the company's own commercial 
benefits.
    Furthermore, in 2021 a data broker called OpenX was fined 
$2 million after collecting personal information about children 
under 13, opening the door to massive privacy violations and 
predatory advertising. We know that Big Tech has enabled 
advertisers to target children for a whole range of damaging 
products, ranging from tobacco and e-cigarettes to low-calorie 
diets that can create and exacerbate body image anxieties. Data 
broker profiteering is excessive, and it is this shameful 
collection, monetization, and selling of data on our kids that 
gets me so animated.
    The U.S. now--we have fallen too far behind in prioritizing 
the protection of all people online, but especially young 
people. Because we do not have a national data privacy 
standard, we are currently stuck with this patchwork of State 
laws and narrow protections that leave a wide swath of our 
neighbors vulnerable to privacy abuses, including by data 
brokers.
    Fortunately, there is much that Congress can do. This week 
I plan to reintroduce my landmark Kids Privacy Act to keep 
children safe online and curb the power of companies to 
indiscriminately track and target children.
    I also strongly support the bipartisan American Data 
Privacy and Protection Act, which would bring much-needed 
transparency to the brokerage industry and minimize the data 
available for them to collect.
    As ranking member of this subcommittee, I am committed to 
holding accountable data brokers that infringe on our rights. 
This is especially true for those who seek to profit from our 
kids over their best interests and the concerns of their 
parents. So I am glad we are doing this critical work on a 
bipartisan basis, and I look forward to hearing from the panel 
today.
    [The prepared statement of Ms. Castor follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Ms. Castor. And with that, I yield back.
    Mr. Griffith. I thank the gentlelady. Now I recognize the 
Chair of the full committee, Mrs. McMorris Rodgers, for her 5 
minutes for an opening statement.

      OPENING STATEMENT OF HON. CATHY McMORRIS RODGERS, A 
    REPRESENTATIVE IN CONGRESS FROM THE STATE OF WASHINGTON

    Mrs. Rodgers. Thank you, Chair Griffith, for convening this 
hearing about the role data brokers play in the digital 
economy, and thank you to our panel of witnesses here this 
afternoon.
    This is our fifth in our series of hearings this Congress 
across the committee for strong data privacy and security 
protections for all Americans. Today we seek to expose and 
learn more about how pervasive and invasive the collection and 
selling of people's data has become.
    Data brokers are harvesting people's data, selling or 
sharing it without their knowledge, and failing to keep it 
secure. A stunning amount of information and data is being 
collected on Americans: their physical health, mental health, 
their location, what they are buying, what they are eating. 
With more Americans than ever using apps and digital services, 
this problem is only getting worse. People have no say over 
whether or where their personal data is sold and shared. They 
have no guaranteed way to access, delete, or correct their 
data, and they have no ability to stop the unchecked collection 
of their sensitive personal information.
    We must continue our work for a national data privacy 
standard so that individuals can exercise their rights, 
businesses can continue to innovate, and government's role is 
clearly defined.
    Today we explore ways that we have become just dollar signs 
for data brokers and Big Tech. We need a national data privacy 
standard that changes the status quo and ensures Americans 
regain control of their personal information. Right now there 
are no robust protections, and current privacy laws are 
inadequate, leaving Americans vulnerable.
    For example, during government-enforced COVID-19 lockdowns, 
GPS and mobile phone data collected by a data broker was used 
by the State to spy on Californians exercising their right to 
attend church services. It certainly raises questions of how 
data brokers aren't just violating people's privacy but their 
civil liberties as well. This is unacceptable, and it is more 
what you would expect out of the Chinese Communist Party's 
surveillance state, not in America.
    Data brokers' days of surveilling in the dark should be 
over. People should trust their data is being protected. We are 
at an inflection point to ensure our personal information is 
responsibly collected, especially since this data may be used 
to train or develop artificial intelligence that may or may not 
align with our values. We need to ensure that the metaverse 
doesn't become the next frontier for exploiting our kids. That 
requires a broad, comprehensive bill that will address all 
Americans' data and put even stronger guardrails around our 
kids' information.
    That is why the American Data Privacy and Protection Act 
included the strongest internet protections for children of any 
legislation last Congress. And privacy protections should not 
stop with kids. We need a Federal privacy law that gives 
everyone data protections, no matter where they live and no 
matter their age. We will continue to build on our work from 
ADPPA this Congress and get the--these strong protections for 
kids and all Americans signed into law.
    Thank you, Ranking Member Pallone and my colleagues across 
the aisle, for continuing to work with us on this. I look 
forward to today's hearing as we continue to explore how data 
collectors and brokers are manipulating our lives and our 
security.
    [The prepared statement of Mrs. Rodgers follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mrs. Rodgers. Thank you. I yield back.
    Mr. Griffith. Thank you, Madam Chair. I now recognize Mr. 
Pallone, the ranking member of the full committee, for his 5 
minutes of an opening statement.

OPENING STATEMENT OF HON. FRANK PALLONE, Jr., A REPRESENTATIVE 
            IN CONGRESS FROM THE STATE OF NEW JERSEY

    Mr. Pallone. Thank you, Chairman Griffith and Ranking 
Member Castor.
    This is an important hearing, as the committee continues 
its bipartisan work to protect people's privacy online by 
addressing privacy abuses in the unregulated technology sector.
    Today we are examining data brokers. Most Americans don't 
even know what a data broker is, but they would likely be 
shocked at just how much personal information these brokers 
have compiled on each and every one of them.
    Data brokers are companies that collect and market troves 
of personal information about American consumers. The data 
broker industry exists on collecting more and more data and 
selling it to nearly any willing purchaser. In 2014 the FTC 
reported that data brokers collect and store information 
covering almost every U.S. household and commercial 
transaction.
    One broker possessed information on 1.4 billion consumer 
transactions. Another data broker's database covered $1 
trillion in consumer spending. A third had 3,000 separate 
pieces of data for nearly every consumer in the entire country. 
This is more than $200--this is more than a $200 billion 
industry that continues to rake in massive profits year after 
year on the backs of consumers. And as you can imagine, this 
has resulted in serious abuses and infringements of Americans' 
privacy.
    And there is a reason most Americans have never heard of 
data brokers, because the industry operates in the shadows of 
the technology industry, with virtually no transparency as it 
profits from the mass collection of our personal information. 
And what makes data brokerage particularly problematic is that, 
unlike platforms like Facebook and Twitter, data brokers rarely 
interact with consumers at all. Consumers do not provide data 
directly to brokers, and that is why most consumers have no 
idea that these brokers exist or what information these brokers 
have about them. That is extremely troubling, considering that 
these brokers collect highly sensitive personal data like 
health information and precise geolocation data that identifies 
a consumer's location within 18 feet.
    Now, how exactly do brokers get this information? Well, we 
know that they scour the internet for data on consumers' 
bankruptcy records, property records, criminal records, headers 
from credit reports, web browsing activities, and other details 
of consumers' everyday interactions. The data brokers also use 
hidden tools like software development kits and tracking pixels 
embedded in consumer cell phones and in the websites we visit 
to monitor online behavior.
    But that is not all. Based on this raw data, these 
companies also make inferences about consumers, lumping them 
into a number of categories based on where they live, their 
ethnicity, their income, or even by projected healthcare 
spending. And with this data, companies can target children 
with manipulative advertisements or create people-search 
products that can lead to stalking, harassment, and violence.
    Data brokers also sell information to scammers, including 
those that target the elderly with bogus sweepstakes and 
technical repair scams and that market sham businesses, 
educational or investment opportunities to veterans.
    And it is no wonder the American people don't think they 
have any control over their online data today. While there are 
some limited protections for children's health and credit data, 
these laws have left us with a patchwork of protections that 
leave large swaths of our private information available for Big 
Tech's profiteering.
    So thankfully, this committee has taken the lead to rein in 
these invasive practices and to give people back control of 
their information.
    First, we need to pass a national comprehensive privacy 
bill. I think we all agree on that. This would create a 
national data privacy standard and stop unrestrained collection 
of personal information on consumers by both Big Tech and data 
brokers.
    And our legislation also finally shines light on the shadow 
world of data brokers by requiring them to register with the 
FTC. This will provide consumers with a single mechanism to 
direct all data brokers to delete the personal information they 
have already collected and to opt out of further data 
collection by all registered brokers.
    So second, we have to make sure that the FTC continues to 
receive the funding necessary to carry out its work and has its 
Federal court authority restored and improved. And these 
important steps would both provide transparency into this 
industry and restrain the collection of unnecessary data.
    So I look forward to hearing from the experts today. But, 
you know, I did want to say, if I could, that when I mentioned 
some of these scams--you know, I think I mentioned targeting 
the elderly with bogus sweepstakes, technical repair scams, 
market sham, educational investment, opportunities for 
veterans.--I am just not mentioning these in a general sense. A 
day does not go by without somebody calling my district office 
and talking about how they have been scammed. So this is real. 
This is--you know, this we hear in our district offices and 
from people on the streets.
    [The prepared statement of Mr. Pallone follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mr. Pallone. So thank you, Mr. Chairman. I yield back.
    Mr. Griffith. The gentleman yields back. That concludes the 
Members' opening statements.
    The Chair would like to remind Members that, pursuant to 
committee rules, all Members' written opening statements will 
be made part of the record. And please make sure you provide 
those to the clerk promptly.
    I want to thank our witnesses for being here today and 
taking the time to testify before the subcommittee. You will 
have the opportunity to give an opening statement, followed by 
a round of questions from Members.
    Our witnesses today are Professor Laura Moy, faculty 
director, Center on Privacy and Technology at Georgetown Law 
Center; Marshall Erwin, vice president and chief security 
officer of Mozilla; and Justin Sherman, senior fellow and 
research lead for data brokerage project at Duke University's 
Sanford School of Public Policy. Thank you all very much for 
being here, and we do appreciate it greatly, because this is 
how we learn and how we can then work together to make good 
legislation.
    Now, witnesses, you are aware the committee is holding this 
as a part of our oversight hearing. And when doing oversight 
hearings, we have the practice of taking testimony under oath. 
Do any of you have an objection to taking testimony under oath?
    Seeing that no objection is presented, we will proceed.
    The Chair also advises you that you will be advised by 
counsel--or that you have the right to be advised by counsel--
pursuant to House rules. Do any of you desire to be advised by 
counsel during your testimony today?
    All right. And all three have responded in the negative.
    Seeing none, please rise and raise your right hand.
    [Witnesses sworn.]
    Mr. Griffith. And all three witnesses answered in the 
affirmative.
    You are now sworn in and under oath, and subject to the 
penalties set forth in title 18, section 1001 of the United 
States Code.
    With that, we will now recognize Ms.--Professor Moy for her 
5-minute opening statement.

STATEMENTS OF LAURA MOY, ASSOCIATE PROFESSOR OF LAW, GEORGETOWN 
UNIVERSITY LAW CENTER; MARSHALL ERWIN, CHIEF SECURITY OFFICER, 
 MOZILLA; AND JUSTIN SHERMAN, SENIOR FELLOW AND RESEARCH LEAD, 
   DATA BROKERAGE PROJECT, DUKE UNIVERSITY SANFORD SCHOOL OF 
                         PUBLIC POLICY

                     STATEMENT OF LAURA MOY

    Ms. Moy. Thank you so much. Good afternoon to both the 
chairs and ranking members of both the subcommittee and the 
full committee. I am really grateful for the opportunity to 
testify today on this important issue.
    So in 2018, CNN published a story about a man named Kip 
Koelsch who noticed that his 84-year-old father was receiving 
mountains of scam email every week. And then his dad called to 
tell him that he had won a Mercedes and $1 million. And it 
turns out that for years his dad had been spending money, 
thousands of dollars, on supposed fees for prizes that he had 
been scammed into thinking he had won.
    Now, Mr. Koelsch's problems--or his father's problems--
probably originated with data brokers. He probably ended up on 
what is known as a suckers list. After a person falls for a 
scam once, they may end up on other suckers lists, categorized 
by areas of vulnerability such as sweepstakes lovers. And this 
is not an isolated incident. The Justice Department actually 
recently brought cases against multiple data brokers, alleging 
that over the course of several years they had refined and sold 
lists of millions of elderly and otherwise vulnerable 
individuals to scammers. In one instance, the company was aware 
that some of its clients were even defrauding Alzheimer's 
patients and yet continued to let it happen.
    So I hope this story has your attention as we talk about 
data brokers today and think about what is at stake. There's 
three points that I would like to highlight.
    So first, data brokers hold tremendously detailed 
information about all of us. In the story about Mr. Koelsch, 
data brokers were maintaining lists of people who might be 
vulnerable to scams, but data brokers also deal in other, more 
revealing types of information: health information; visits to 
doctors; children's information; purchase history, including of 
specific items; and information scraped from social media; even 
information that users have deleted.
    Some data brokers also deal in detailed location data. A 
few years ago, a team of journalists reviewed a data set 
containing locations from more than a million phones in the New 
York area, presumably information shared by apps that were 
installed on those phones, and they were able to use that 
location information to identify specific people. And they also 
explained how they could use that information to learn intimate 
details about those people's private lives, like where they 
worked and where they lived, where they worshiped, and when 
they spent the night at another person's home.
    Second, Congress has to act to protect us from data brokers 
because we individuals cannot do it ourselves. We are all aware 
that we are constantly generating digital information about 
ourselves as we go about our daily lives. Eighty-one percent of 
adults now say they have little or no control over the data 
collected about them by companies, and that number doesn't 
indicate acceptance or resignation. On the contrary, 79 percent 
of adults say that they are somewhat or very concerned about 
how companies are using that data. That is why it is so 
important that Congress scrutinize this important issue, as the 
subcommittee is doing today.
    And third, the booming data broker industry does real harm 
to real people. I have already talked about mass scams like the 
type that affected the Koelsch family. But let me touch on a 
few more examples. So in addition to fueling scammers, data 
brokers also expose private information to stalkers and 
abusers, to marketers of predatory products such as high-
interest payday loans, and to malicious attackers who breach 
and mine data brokers' databases for nefarious purposes, 
including to sell to foreign entities or over the dark web to 
sophisticated fraudsters.
    In addition, law enforcement agencies sometimes turn to 
data brokers to make an end run around the Fourth Amendment, 
one of our most fundamental civil liberties, purchasing 
information that they wouldn't be able to get through lawful 
order. So a few years ago, it was revealed that the IRS had 
purchased access to large amounts of location data to fuel some 
of its investigations. And last fall, researchers found that 
one broker that claims to have location data for over 250 
million devices was selling to nearly two dozen agencies.
    Also, data brokers might be contributing to locking people 
out of important job and housing opportunities due to 
historical data that is inaccurate or skewed by discrimination. 
For a variety of important eligibility determinations, 
including for housing and employment, decision makers sometimes 
rely on scores provided by data brokers, oftentimes without 
even knowing exactly what information is behind those scores.
    And finally, data brokers put minors at risk when they deal 
in information about families and children. A few years ago, 
researchers reported that one broker of student data was 
offering information about kids as young as 2 years old. And in 
2021 it was revealed--and I know this was mentioned, as well, 
in the opening statements--it was revealed that a family safety 
app was selling kids' and their families' locations to 
approximately a dozen different data brokers.
    So these are just a few of the harms that I would 
highlight, but I look forward to your questions. Thank you.
    [The prepared statement of Ms. Moy follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mr. Griffith. I thank you very much, and now recognize Mr. 
Erwin for his 5 minutes of opening statement.

                  STATEMENT OF MARSHALL ERWIN

    Mr. Erwin. Chair Rodgers, Ranking Member Pallone, Chair 
Griffith, and Ranking Member Castor, thank you for holding this 
hearing today on such an important topic.
    My name is Marshall Erwin. I am the vice president and 
chief security officer at Mozilla.
    Mozilla is a unique public benefit organization and open 
source community owned by a nonprofit foundation. We are best 
known for the open source Firefox browser, which is used by 
hundreds of millions of people around the world. Privacy is an 
integral part of our founding principles, which state that 
individuals' privacy and security online must not be treated as 
optional.
    The internet today is powered by consumer data. While that 
data has brought remarkable innovation, it has also put 
consumers at direct risk. Many of the harms we see on the 
internet today are in part a result of pervasive data 
collection and the underlying privacy threat. The targeting and 
personalization systems in use today can be abused, resulting 
in real-world harm to individuals and communities. These 
targeting and recommendation systems are powered by data, data 
that is often sold or shared by parties that shouldn't have 
that data in the first place.
    Now, at Mozilla we believe the internet can do better. A 
huge amount of the work that we do focuses on building 
protections into the browser itself to prevent data collection 
in the first place. And if we are able to prevent that data 
collection, it never gets to the actual data broker. So we 
specifically work to protect consumers' browsing activity. This 
is the data that you create as you navigate from website to 
website. It can be incredibly sensitive, provide a really 
detailed portrait of your online life, which is why we work 
quite hard to protect it.
    So we work, for example, to block what we call cross-site 
tracking, or sometimes you will hear this referred to as 
cookie-based tracking. In 2019 we enabled something called 
enhanced tracking protection that blocks this in the Firefox 
browser. We turn that on by default, because we believe 
consumers cannot be expected to protect themselves from threats 
that they don't even understand or see.
    Now, despite this progress, huge privacy gaps still exist. 
We know from our experience in Firefox that we can't solve 
every privacy problem with a technical fix. Dark patterns, for 
example, are pervasive across the software people use. 
Consumers are being tricked into handing over their data with 
deceptive design patterns, and that data is then used to 
manipulate them.
    Once a consumer has been tricked into handing over their 
data, that is where the data broker comes in. And while 
browsers have some visibility into online tracking, we lose 
that visibility entirely once the data lands on a company's 
servers in a shared on what we sometimes call the back end. 
Companies may then share or sell that data for eventual use by 
other parties. This type of back-end data transfer is something 
that browsers and consumers cannot see. And because it is--
because of this limited visibility, it is nearly impossible to 
fully understand the extent of this data selling and sharing.
    As a browser--as browsers move to clamp down on the leading 
forms of online tracking, parties are increasingly using other 
forms of tracking and back-end data sharing and selling. For 
example, we are concerned about the growing use of identity-
based tracking. Often when you visit a website, you are 
encouraged to create an account and hand over your email 
address when you create that account. What many consumers do 
not realize is that their email address may then be handed over 
to other parties, including data brokers, that may then use 
that to build a profile of their browsing activity.
    Lack of privacy online today is a systemic problem. We 
therefore believe that law and regulation have an essential 
role to play and the passage of strong Federal privacy 
legislation is critical. We supported the American Data Privacy 
and Protection Act in the last Congress and are eager to see it 
advance in this Congress.
    ADPPA defines sensitive data to include information 
identifying an individual's activity over time and across 
third-party websites and online services. This is incredibly 
important. Regulatory regimes need to move beyond narrow 
categories of what is traditionally referred to as PII. 
Browsing data must be protected both by the platforms that 
people use, like Firefox, and also by the regulatory regimes 
intended to protect privacy.
    I will close by noting this is actually the 25th 
anniversary of Mozilla's founding. So we have been working to 
protect our consumers for 25 years. We established the first 
bug bounty program almost 25 years ago, the first company to 
encrypt our users' web traffic.
    Unfortunately, the privacy regulation has not kept up with 
this progress, and it is time for Federal privacy--Federal 
policy to step in and protect consumers.
    Despite being a powerhouse of technology innovation for 
years, the United States is behind globally when it comes to 
recognizing consumer privacy and protecting people from 
indiscriminate data collection, use, sharing, and selling.
    We appreciate the committee's focus on this vital issue and 
look forward to continuing our work with policymakers to 
achieve meaningful privacy reforms. Thank you.
    [The prepared statement of Mr. Erwin follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mr. Griffith. I thank the gentleman. I recognize Mr. 
Sherman for his 5-minute opening statement.

                  STATEMENT OF JUSTIN SHERMAN

    Mr. Sherman. Chair Griffith, Vice Chair Lesko, Ranking 
Member Castor, and distinguished members of the subcommittee, I 
appreciate the opportunity to testify about data brokers and 
threats to Americans' civil rights, physical safety, and 
national security.
    I am a senior fellow at Duke University's Sanford School of 
Public Policy, where I run our research project on the data 
brokerage ecosystem, the virtually unregulated, multibillion-
dollar ecosystem of companies collecting, aggregating, and 
selling data on Americans.
    Data brokerage threatens Americans' civil rights, 
consumers' privacy, and U.S. national security. While I 
strongly support a comprehensive privacy law, Congress need not 
wait to resolve this debate to regulate data brokerage.
    Today I will make three points: Congress should first 
strictly control the sale of data to foreign companies, 
citizens, and governments; ban the sale of data completely in 
some categories, such as with health and location data and 
children's data, and strictly control the sale of data in other 
categories; and third, stop data brokers from circumventing 
those controls by inferring data.
    Our research at Duke University has found data brokers 
advertising data on hundreds of millions of Americans, 
including their demographic information, political beliefs, 
home addresses, smartphone locations, and health and mental 
health conditions, as well as data on first responders, 
students, teenagers, elderly Americans, people with 
Alzheimer's, government employees, and current and former 
members of the U.S. military.
    Data brokers can track and sell your race, religion, 
gender, sexual orientation, income level, how you vote, what 
you buy, what videos you watch, what prescriptions you take, 
and where your kids and grandkids go to school. This harms 
every American, especially the most vulnerable. And I will give 
three examples.
    Data brokers sell sensitive data on members of the U.S. 
military. Criminals have bought this data and used it to scam 
servicemembers, including World War II veterans. Foreign states 
could acquire this data to profile, track, and target military 
personnel. The Chinese Government's 2015 hack of the Office of 
Personnel Management was one of the most devastating breaches 
the U.S. Government has ever suffered. But there is no need for 
the Chinese Government or any other foreign state to hack many 
databases when so much data can be bought on the open market 
from data brokers.
    In a forthcoming study, our team at Duke purchased 
individually identified data on military servicemembers from 
data brokers with almost no vetting and as low as 12.5 cents a 
servicemember. Data brokers known as people search websites 
aggregate millions of Americans public records and post them 
for search and sale online. Abusive individuals for decades 
have bought this data to hunt down and stalk, harass, and even 
murder other people, predominantly women and members of the 
LGBTQ-plus community. There is little in U.S. law stopping data 
brokers from collecting and publishing and selling data on 
survivors of gendered violence.
    Government personnel are at risk too. In 2020 a violent 
individual bought data online about a New Jersey Federal judge 
and her family. He then went to her home, shot her husband, and 
shot and killed her 20-year-old son.
    Data brokers also advertise data on Americans' health and 
mental health conditions. Companies can legally buy this data 
from data brokers and use it to target consumers, such as teens 
suffering from depression.
    Data brokers have also knowingly sold data on elderly 
Americans and people with Alzheimer's to criminal scammers 
because they made money off the sale, who then stole millions 
of dollars from those people. Foreign governments could even 
use this data to target government personnel.
    Our research has found that companies selling this data 
conduct relatively little know-your-customer due diligence and 
often have very few controls, if any at all, over the use of 
their data.
    There are three steps Congress should take now.
    First, strictly control the sale of Americans' data to 
foreign companies, citizens, and governments, which currently 
can entirely legally buy millions of U.S. citizens' data from 
U.S. data brokers.
    Second, ban the sale of data completely in sensitive 
categories, such as with health data and location and address 
data, which can be used to follow, stalk, and harm Americans.
    Third, stop companies from circumventing those controls by 
inferring data, using algorithms and other techniques to 
basically derive information that they haven't technically 
collected.
    Congress can and should act now to regulate data brokers 
and their threats to civil rights, consumers' privacy, personal 
safety, and national security. Thank you.
    [The prepared statement of Mr. Sherman follows:]
    [GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
    
    Mr. Griffith. Thank you, and I appreciate your testimony.
    Seeing there are no further Members wishing--got too far 
ahead in my script.
    [Laughter.]
    Mr. Griffith. I now recognize myself to begin the question-
and-answer section. I recognize myself to start that with 5 
minutes of questioning.
    Mr. Sherman, you got my attention.
    [Laughter.]
    Mr. Griffith. Inferred data. So what kind of information 
would they infer--if we block the others and they start to 
infer data, what are we talking about there? Inferring that I 
live in a particular town? Inferring that I live on a 
particular street? And how do they do that?
    Mr. Sherman. Inference is one of the three main ways that 
these companies get data. So it is a huge data source for data 
brokers.
    Inference might be something really basic. For example, do 
you have a Christian prayer app on your phone, or a Muslim 
prayer app on your phone? And that single data point can be 
used to understand something so sensitive as an American's 
religion, something that they may never have inputted into a 
form, all the way to more sophisticated things. If you have 
location data, if you can follow people as they visit medical 
facilities, divorce attorneys, you name it, you can also from 
that derive information about them that they similarly have 
never typed into a form and have no expectation is out there, 
but then that is put into these data sets for sale.
    Mr. Griffith. And do all the companies--or are all the 
companies out there doing that, and do some of them just keep 
the data for themselves?
    As an example, Sunday morning I am going to church, boom, 
pops up, Google tells me how long it is going to take me to get 
to church, because it is Sunday morning and I am pulling out of 
the driveway. I haven't asked them to tell me how long it is 
going to get to church or what the directions are, but it just 
offers it to me. Is that part of what we are talking about, or 
is that considered acceptable?
    Mr. Sherman. I think that is what we are talking about, 
right? What can you learn about people based off location data?
    As you said, different kinds of companies collect that for 
different reasons. A ride app might collect it because they 
need to know where you are to send the car, versus a data 
broker wants to collect that so they can profit off selling it.
    Mr. Griffith. All right. And, you know, we have talked 
about it. And for everybody watching, if I type in my email 
address, if I am shopping for something or if I decide to buy 
something--and mostly that would not be me, but other members 
of my family--and I do it for--put down the address, the 
website, my email, put down my address so I can get it shipped, 
what is the chain of custody to the data broker and beyond? And 
where does my email address end up, or even my street address?
    Mr. Sherman. This is another main source for data brokers. 
There is a lot of what we will call first-party collectors, 
right? The one that the consumer directly interacts with--as 
you said, an app or a website--will then turn around in some 
cases and sell that directly to a data broker, or sometimes 
they will share it with advertisers. And then that enters an 
equally opaque sometimes system where data brokers can get the 
information from there.
    Mr. Griffith. All right. So how do we craft legislation 
that protects that, but at the same time gives me the 
opportunity to actually let somebody know my location?
    For example, many of the members of the committee know I am 
an avid birdwatcher. So when I am out birding, I have several 
different apps. And, you know, if I am in a location, I want 
them to know where I saw that bird, so that other people can go 
see the bird. I want them to share that information.
    How do we craft legislation that protects the privacy, but 
allows me to say, OK, I spotted the particularly rare bird or 
an unusual bird in Virginia at a certain location and I want 
other people to know that? How do we protect it, but also allow 
it when I want to share my location?
    Mr. Sherman. As mentioned, I strongly support a 
comprehensive privacy law. I think giving consumers more 
control over what data is collected would help with that. So 
would controls specifically targeted at the sale of data.
    As mentioned, it is not just data brokers who sell this 
data. Sometimes the way they get it is a weather app or other 
app selling location data without people knowing it. And so 
that is also part of this system you mentioned, where that then 
gets out there for sale.
    Mr. Griffith. And part of what I have always envisioned--
and we will have to craft the legislation appropriately--is 
that, as opposed to the small print that goes on for--you know, 
I am scrolling down, down, down--I used to read those. I have 
gotten numb like so many others, and I am just like, OK, I want 
to get this done. How can we get a box that just says, OK, you 
can share or you can never share, something simple that we can 
click on?
    Mr. Sherman. I think you just said it. It needs to be 
simple.
    You know, data brokers, among others, hide behind this 
completely bad-faith nonsense argument that people read privacy 
policies. I don't read privacy policies for everything I use, 
right? We don't have the time.
    And so making that simple so someone can actually read it 
and understand it is really, really essential.
    Mr. Griffith. All right. I appreciate that. My wife always 
used to make fun of me when I would read those privacy notices, 
and I did it for years. But I have given up.
    I appreciate your testimony, and I yield back.
    And now I recognize Ms. Castor, the ranking member, for her 
5 minutes of questions.
    Ms. Castor. Well, thank you. And thank you again to our 
witnesses for your outstanding testimony.
    So you have provided some very stark examples, Mr. Sherman. 
Can you dive into the kids' privacy for a minute and give us an 
example?
    There is a minimum privacy law on the books. COPPA was 
adopted in 1998. The world was entirely different then, but 
they still collect vast amounts of data on kids and use it to 
exploit them. Give us an example so we can focus on--on the 
harm.
    Mr. Sherman. I would put these issues around children's 
data and data brokers into two categories. So I will give an 
example.
    So our team, through our research ethics process, also buys 
data from data brokers to understand the privacy risks. We 
recently asked a data broker, ``Could you sell us'' because 
they said they had some data on children. They told us no. They 
cited COPPA. But they said, ``We could allow you to get 
information on their parents.'' And so that is not covered. 
That is something you could use to target a household, knowing 
there is maybe a certain number of children in that household, 
or children with a certain condition in that household. So 
there is that question of the controls there.
    The second piece is COPPA only focuses on children under 
the age of 13. And so there is a massive market. You can go buy 
it right now of, literally, lists on 14-to-17-year-olds sold by 
data brokers out there on the market. And so targeting that, I 
think, is a key part of this as well.
    Ms. Castor. Right. Dr.--or Professor Moy, you also are very 
well familiar with COPPA. It says they have to maintain 
reasonable procedures to protect the confidentiality, security, 
and integrity of personal information. But that is not 
happening, is it?
    Ms. Moy. No, no, I don't think at all. Nor--there is also a 
prohibition in COPPA that services not collect more information 
than is reasonably necessary from a child to provide the site 
or service. And I don't think that that is happening either.
    Ms. Castor. So we have the ability in the law to put some 
guardrails, to adopt some guardrails. What about--could we, in 
the law, say that there are certain time limits on information 
that is gathered, and after a certain timeframe it has to be 
deleted?
    Ms. Moy. I absolutely think that that would be a good idea.
    I mean, I think that one of the things that many people 
don't quite understand about the information that they generate 
about themselves as they go about their daily lives is that 
that information can live forever, even after they think that 
they have deleted it from a site or service. Once it has been 
collected by a data broker, it might exist in databases 
forever.
    And so I absolutely think children lack the capacity to 
consent. Oftentimes their information is not provided directly 
by them, but in fact by their parents and families. And there 
should be a retention limit on information that is collected.
    Ms. Castor. And just like Mr. Erwin highlighted how Mozilla 
has built into their browser design from the very get-go 
certain enhanced tracking protections to an encryption, we 
could do that in the law, couldn't we?
    We could--we could set guardrails, Mr. Sherman, on--in 
addition to time limits on privacy settings, default--just what 
Chairman Griffith said, it is default private first. And people 
have to have some kind of meaningful consent in to share, and 
we can have time limits around that. Is that right?
    Mr. Sherman. That is right. And kids is such an important 
category to protect that I think there is even more reason, as 
you are saying, to do that focused on children.
    Ms. Castor. There is no law right now that prohibits these 
data brokers from selling this data to malign foreign actors 
whatsoever?
    OK. I hear you loud and clear. We have a lot to do on this. 
So, Mr. Erwin, how--why have you all decided in the wild, wild 
West of data to remain committed to online privacy? That is not 
in your--that is not profitable for you. Or is it--is it 
profitable for you?
    Mr. Erwin. It is not as profitable as we would like. You 
know, I think the reality is privacy is so opaque that it 
doesn't--the privacy properties that we built into the browser 
don't drive consumer awareness or action as much as we would 
like.
    We build these things into the browser because we know 
fundamentally people need to be able to trust the platforms 
that they are using in order to engage online. And so, while 
they might not know in, like, in detail exactly who is 
collecting their data, they are going to know that Firefox or 
the platform they are using is trustworthy. And that is 
something that we find to be valuable. It doesn't, like I said, 
drive our business interests as much as we would love, but it 
is something that we take very seriously.
    Some of the other major platforms I think have moved sort 
of in lockstep with us, particularly, I would say, like, 
Apple's privacy protections are also quite strong, and applaud 
some of the steps they have taken. That covers roughly half of 
the browser and mobile operating system market. However, the 
other half, the average consumer uses of the other platforms, 
are still not benefiting from some of these core protections, 
and they are still--their privacy is----
    Ms. Castor. Thank you very much.
    Mr. Erwin [continuing]. Is still in jeopardy.
    Mr. Griffith. The gentlelady yields back. I now recognize 
the chairman of the full committee, Mrs. McMorris Rodgers, for 
5 minutes of questioning.
    Mrs. Rodgers. Thank you, Mr. Chairman, and I appreciate you 
inviting everyone to be here today, and your testimony. And I 
wanted to start with an issue that has been debated for many 
years, and that is targeted advertising.
    So, Mr. Erwin, I just wanted to start with you and ask for 
you to give us some insights as to the ways websites collect 
data on users and the life cycles of that data.
    Mr. Erwin. Yes. So targeting--targeted advertising really 
drives a large amount of the Web ecosystem today.
    You know, roughly sort of a decade ago, targeted 
advertising was much more simple, and it seemed to power the 
Web just fine. So you had things like advertising for your 
average sort of news platform that you visited. It seemed to 
generate a fair amount of revenue for that platform, yet it 
wasn't nearly as sophisticated as it is today in terms of being 
able to draw on deep profiles of data, some of that data being 
collected offline and shared with ad tech platforms and some of 
it being collected online and shared with ad tech platforms. 
Once you have that really rich profile of data, that then 
allows the--whatever site that you are using to draw on that 
data, to target ads to exactly the target audience that they 
want.
    And the challenge is that that opens up really serious 
concerns for abuse, because the more you know about someone, 
the more you can manipulate them. You can target your message 
to exactly who you want. And in some cases, that can be fine if 
you are sort of making a standard sort of consumer offering. 
But in other cases it can be terribly problematic.
    Mrs. Rodgers. And then would you speak to the life cycle of 
that data?
    Mr. Erwin. Yes. So I think that data is often sort of 
immediately actionable. So the data is collected. You will 
visit a site, you will--the ad tech platform will see, oh, you 
visited that site, you put something in your shopping basket, 
and then a week later they see you again and say, hey, you 
never finished that purchase. We still know exactly who you 
are. We still think that you--we want you to buy that thing. 
You are going to see a targeted ad on a completely different 
platform. So that is sort of the immediate life cycle of the 
data.
    However, that data is really valuable, and it can then leak 
in many other places to data brokers, to other programmatic ad 
platforms, and the data will live on for extended periods of 
time.
    Mrs. Rodgers. Thank you.
    Mr. Sherman, I wanted to ask if you would just maybe give 
some more insights around this, because in your testimony you 
referenced how data brokers collect data on elderly, on 
Americans with mental health concerns, on teenagers. Would you 
just discuss in more detail how they use this information to 
target and harm vulnerable Americans?
    Mr. Sherman. There are a variety of things that data 
brokers do with data. So they will point out--which they do, 
the--some companies do things like fraud prevention, identity 
verification, all the way to essentially building these 
packages, these targeting profiles, if you will, on different 
subsets of Americans. So maybe that is 30-to-40-year-olds in DC 
who like coffee, maybe that is elderly Americans with 
Alzheimer's, and then seeing who they can sell that to to make 
a profit off of it.
    And so, as you alluded to, in some cases that has 
included--in many cases, that has included data brokers selling 
to scammers because they get paid for it. And then, as 
Professor Moy testified, they get put on what are called 
suckers lists and then used to be targeted for astrology scams 
or all kinds of other fraudulent activities.
    Mrs. Rodgers. Well, so last month we had a hearing with 
TikTok's CEO, Mr. Chew, and certainly concerns about how the 
data is being ultimately controlled and its connection to the 
Communist--Chinese Communist Party. And so there's the national 
security concerns around TikTok. But would you speak to their 
ability to--you know, speak to the Chinese Communist Party and 
other foreign adversaries' ability to collect American data by 
buying it from data brokers, either directly or indirectly?
    And then do the data brokers have any protections in place 
to prevent this from happening?
    Mr. Sherman. We have not found in our work that brokers 
often vet who they sell to. Hence the scamming example. Hence 
also there is absolutely a risk that a foreign actor could 
approach a company or lie to a company about their intentions 
and buy a bunch of data on Americans.
    We are also all familiar with the Equifax breach, right, 
when the Chinese military stole hundreds of millions of 
Americans' data. Equifax is a major data broker and an example 
of what happens when a company with that much data is not 
properly protecting it. Now a foreign actor has all of that 
information on Americans that has been precompiled, 
prepackaged, presorted, and ready for targeting.
    Mrs. Rodgers. Yes. So lots of opportunities for 
manipulation and abuse.
    Lots more questions, but I am going to yield back, Mr. 
Chairman.
    Mr. Griffith. Thank you, Madam Chair. I now recognize the 
ranking member of the full committee, Mr. Pallone, for his 5 
minutes of questioning.
    Mr. Pallone. I just wanted to say, Chairman Griffith, that, 
you know, I just was--found it so interesting, what you said 
about the birdwatching, because I think that maybe you, like 
me, you know, we are in a world, you know, a few years ago, 
where, you know, people would say, oh, there is where the bird 
is, why don't you go look at it, right, and you don't even 
think about the fact that somebody may do something nefarious 
with that information, because we are kind of naive about what 
is out there.
    And so, if I could ask Ms. Moy, I mean, you did this tweet, 
and you were--you know, and I think you said that people would 
be shocked by the type of information that was available. So 
why don't you tell us what would--what would surprise Americans 
about the scope of the data that is collected about them by 
these data brokers?
    Ms. Moy. Yes. I mean, I think that--I think there are a 
couple things that I would highlight.
    So one is there are all kinds of things that people think 
of as sensitive information that they think is already 
protected by certain laws that's actually not within the scope 
of the laws that we have protecting those types of information.
    So some examples are health information. A lot of people 
think like, well, we have a health privacy law. And that is 
correct, but there is a lot of information that is collected 
outside the context of actual medical services that people 
would think of as health information: purchases of--you know, I 
think I read in the 2014 Senate report about purchase 
information of yeast infection products and laxatives, that 
that was in a data broker file; information from wearable 
health devices; information about how frequently someone 
visited a doctor. That information--people would expect that it 
is protected, but it falls outside the scope of our existing 
laws.
    And then I think another thing that people would be really 
surprised about is that the information--again, the information 
potentially lives forever. So people may think that something 
that they posted a while ago on a social media platform, like 
on Twitter, and later deleted is gone. But it is not. If it has 
been scraped by a data broker, it may live forever.
    Mr. Pallone. And then this whole issue you wrote in your 
testimony, it says, ``If well-informed individuals wanted to 
remove their own information from data brokers, as a practical 
matter it is nearly impossible.'' What does that say about the 
amount of control that consumers currently have over how their 
data is collected?
    Ms. Moy. Yes, I mean, I think people really have very 
little control right now, as I think everyone on this panel has 
highlighted. This is a very opaque industry. Oftentimes 
individuals don't have relationships with these companies.
    And so--but even when there is an opt-out, there are--a 
couple of journalists have written about this, about their 
attempts to erase their own information. I have done it myself. 
It is really hard. One journalist described it as a 
labyrinthine process to try to opt out and said that opt-outs 
are hard to find out about, much less navigate, and she pointed 
out that it is actually much easier to buy records about your 
neighbors than it is to scrub your own personal information 
from brokers.
    Mr. Pallone. Well, Mr. Sherman, in your testimony you talk 
about the same issue.
    So what--I mean, it seems to me what we really need is like 
a one-stop shop for consumers to use to request that data 
brokers delete information. And I know that the comprehensive 
Federal privacy legislation, which myself and Chair Rodgers and 
I think everybody on the committee has cosigned, does have that 
kind of a mechanism.
    So how would you--what would you suggest about creating a 
mechanism that helped--limits data brokers' power to profiteer, 
and restore control?
    Mr. Sherman. A one-stop shop would certainly help, right? 
Part of the issue now is consumers not knowing this is 
happening, and then having to go figure out which of 1,000 or 
so companies--more than that--to contact. And so having a one-
stop shop to do that would be good.
    The other thing I would add is that, with people search 
websites, where public records are scraped or home addresses 
are posted, the source of stalking, the source of the attack on 
the judge's home, in part--those are often exempt from a lot of 
these bills and these State privacy laws that have been passed 
because they have broad carve-outs for publicly available 
information.
    And so I think that is another challenge, is to say yes, of 
course, we want public records out there. We are a democracy. 
We want things to be available. But we need to recognize the 
immense risk to individuals by having that posted, as Professor 
Moy said, online for easy purchase.
    Mr. Pallone. Well, thank you so much. This panel is 
fantastic, and this hearing is so important.
    Thank you, Mr. Chairman.
    Mr. Griffith. Thank you very much. The gentleman yields 
back. I now recognize the gentleman from Texas, Dr. Burgess, 
for his 5 minutes of questioning.
    Mr. Burgess. Thank you, Mr. Chairman. And again, 
fascinating panel.
    Let me just ask--sort of like asking for a friend.
    [Laughter.]
    Mr. Burgess. What is the value of--someone aggregates data 
and sells it to someone. What is, like, the cost per person? 
What is the return on investment there? Like, how much do you 
get per deliverable, per person's personal information? Is it, 
like pennies? Is it, like a dollar?
    Mr. Sherman. So oftentimes brokers will not--large brokers 
will not sell you a single person's information, but they will 
give you a data set, as you said, with a price per record.
    As mentioned in a study we have coming out, we bought 
individually identified data on military servicemembers for as 
cheap as 12\1/2\ cents a servicemember. You can also buy lists 
of teenagers or people with Alzheimer's, and maybe it is 30 
cents or 40 cents a person.
    So even if you are buying a few thousand records, you are 
only spending a couple hundred dollars to get this information.
    Mr. Burgess. So several years ago, there were a number of 
well-publicized data breaches and--like for an insurance 
company--and the comment was made, well, this was data at rest, 
this wasn't data that was actually being used for anything. 
What is the value of that to someone who then steals that kind 
of information? Are they able to monetize it and turn it around 
and make it a commodity that is for sale?
    I guess, Mr. Sherman, I will stick with you.
    Mr. Sherman. It depends what is in the data, but it 
absolutely can be valuable. We know that, from various studies, 
that health information is some of the most valuable sold on 
the dark web. You can buy that. As my fellow panelists 
mentioned, a lot of that is not covered by HIPAA. Companies are 
legally allowed to sell it.
    Another example in the national security context, you can 
imagine location data or other information on government 
personnel that you could get and then could be used in a 
variety of ways.
    Mr. Burgess. Well, this committee, the subcommittee, had a 
very good hearing. Professor Moy in her written testimony 
talked about the scamming of elder individuals, and we had a--
quite an involved hearing on how elder abuse that was actually 
happening in that way. Is there a certain type of information 
that people go after to get at these--at a list of people who 
might be susceptible to making these types of purchases?
    Ms. Moy. I mean, so I think, you know, these suckers lists 
often might contain information, could just be contact 
information, but it might be information also--detailed 
information about the types of scams or the types of 
solicitations that individuals had responded to in the past. 
And so that was certainly at issue in some of these cases that 
the Justice Department brought.
    Some of the brokers had been observing the types of 
solicitations that individuals responded to, and used that 
information to refine and further categorize users based on 
their particular vulnerabilities.
    Mr. Burgess. So, Mr. Chairman, I wonder if they actually 
compare to the birders list on that. Just a hypothetical 
question.
    Mr. Sherman, let me just ask you on the health data, 
Federal protections for American citizens right now that are 
required of these brokers.
    Mr. Sherman. HIPAA is often referred to as the U.S.'s 
health privacy law. Sometimes it is easy to forget that the P 
in HIPAA is for portability, it is not for privacy. And so 
there are privacy rules associated with it, but it only covers 
a narrow set of entities: hospitals, healthcare providers.
    There are lots of apps, websites, particularly health and 
mental health apps, that exploded during the pandemic that are 
not connected to a covered entity and therefore are not bound 
by HIPAA. The FTC has been shining a light on this recently, as 
well.
    Mr. Burgess. So let me just ask you. And we have all done 
this. You buy a new wearable device, and you sign up for 
something. Is that in perpetuity? If I no longer use that 
health app, how long does that license exist?
    Mr. Sherman. If you are referring to the data, there is no 
limit on how long a broker could keep that information.
    Mr. Burgess. And so the data that is generated by a 
wearable, for example, is continuously accessible by whatever 
person you originally signed on with?
    Mr. Sherman. It depends on the specific device. As 
mentioned, some companies like Apple are more privacy 
protective. Others do not have those protections in place.
    Mr. Burgess. Fascinating discussion.
    Thank you, Mr. Chairman. I will yield back.
    Mr. Griffith. The gentleman yields back. I now recognize 
the gentlelady from Colorado, Ms. DeGette, for her 5 minutes of 
questioning.
    Ms. DeGette. Thank you so much, Mr. Chairman, and I want to 
thank you and the ranking member for holding this important 
bipartisan hearing.
    Mr. Sherman, both you and Professor Moy talked just a few 
moments ago about the fact that healthcare data is not 
protected, but people think it is protected. I am wondering if 
you can expand on what types of healthcare data are not 
protected.
    Mr. Sherman. As mentioned, it is less about the type of 
data and more about the source of the data. So there is health 
information that if you told your doctor they can't go shout it 
on the street corner, they can't write it up and sell it. But 
if you tell that to a certain app or website, they are allowed 
to do so. And so you can get data on Americans with depression, 
with anxiety, with PTSD. You can get information about the 
prescriptions that people are taking for sexual health 
conditions, mental health conditions. You can get data related 
to pregnancy and fertility and motherhood and all kinds of 
things.
    Ms. DeGette. So--and, of course, we expanded telehealth 
during the pandemic. So would that also expand to telehealth?
    Mr. Sherman. It often does. And many of the mental health 
apps that surged during the pandemic, whether that was to set 
up appointments or do meditation, or----
    Ms. DeGette. Let me stop you for a minute. Mental health, 
but also physical health consultations. If somebody is 
consulting by telehealth with a doctor, that could also be 
vulnerable, that data.
    Mr. Sherman. If an app is connected to a HIPAA-covered 
entity, so if it is an app for a hospital, for example, that is 
covered.
    Ms. DeGette. OK.
    Mr. Sherman. If it is outside of that, that might not be 
covered.
    Ms. DeGette. OK. So basically, data brokers are collecting 
lists of people living with diseases and ailments like 
diabetes, depression, even women who are pregnant, and selling 
this information to people who can exploit the consumers. Is 
that right?
    Mr. Sherman. Yes.
    Ms. DeGette. Professor Moy, would you agree with that?
    Ms. Moy. Yes.
    Ms. DeGette. Now--so are you aware, Mr. Sherman, that law 
enforcement agencies have purchased data broker information on 
U.S. citizens, ranging from home utility data to real-time 
locations, even though the information may not be complete, 
current, or accurate?
    Mr. Sherman. Yes.
    Ms. DeGette. So all--so theoretically, if a--if a law 
enforcement agency can purchase this information, they could 
purchase any of the kinds of information we were just talking 
about.
    Mr. Sherman. Correct.
    Ms. DeGette. Right? It wouldn't be limited to, like, 
utilities or location. They could purchase any of this 
information about medical information.
    Mr. Sherman. Yes.
    Ms. DeGette. Now, have data brokers sold location 
information linked to specific devices that could track 
individuals' movements to reproductive health clinics and other 
sensitive locations that you know of?
    Mr. Sherman. There have been a few journalistic 
investigations on this indicating that they have. The question 
comes back to how identifiable is the data. It might not 
literally be a name, but I would say, yes, it can be linked to 
a device.
    Ms. DeGette. It can be linked to that. Now, in your 
testimony--or Dr. Moy, did you want to add to that? No?
    Ms. Moy. No, no.
    Ms. DeGette. Do you agree?
    Ms. Moy. I agree, yes.
    Ms. DeGette. OK. In your--now, so Mr. Sherman, in your 
testimony you recommended three steps that Congress could take 
to address this. I am wondering if you can--if you can hone 
that in specifically to health and location data that could 
protect American consumers.
    Mr. Sherman. I think banning the sale of health and 
location data is the best route to prevent those harms. As 
mentioned, health and location data are very sensitive. They 
can be used very harmfully. Both Democrats and Republicans 
agreed almost 30 years ago now with HIPAA that health privacy 
is important and must be protected. Location similarly is 
unique to individuals. You can also learn other things by 
following people around, as you mentioned. And so those, I 
think, are two really important categories to focus on.
    Ms. DeGette. Great. Well, thank you. And I look forward to 
working with my colleagues on this, because it is almost 
inconceivable to us to see how far the tentacles of these 
intrusions go. But I think they can go in very, very bad ways.
    And I yield back.
    Mr. Griffith. I thank the gentlelady and agree, and now 
recognize the gentleman from Kentucky, Mr. Guthrie, for his 5 
minutes of questions.
    Mr. Guthrie. Thank you, Mr. Chair. I appreciate the 
opportunity. Thanks for all the witnesses being here.
    Mr. Erwin, in your testimony you refer to dark patterns, 
and you stated dark patterns, for example, are pervasive across 
the software people engage with daily. Consumers are being 
tricked into handing over their data with deceptive patterns. 
Then the data is being used to manipulate them.
    So my questions are how are consumers being tricked into 
handing over their data? What are examples of these deceptive 
patterns? And are there technical fixes to prevent them?
    Mr. Erwin. Yes. So we heard earlier--I thought the example 
of location data from the chairman was interesting because, 
ideally, a consumer should be able to hand over their location 
to a party explicitly and have some value exchange. They are 
getting a service in return.
    The challenge we see online today is you are handing over 
your location or your other data, and you might be giving that 
directly to the website you visit, and you know you are doing 
that, but you don't realize because there is some click-through 
box and some long, long text that you are never going to read 
or some deceptive sort of always-on data collection button that 
you never realize is on, and therefore you are going to be 
sharing more data than you expect, or sharing it with parties 
that you don't expect. Those are the type of design patterns 
that we see across many of the websites that we all use on a 
daily basis.
    Mr. Guthrie. Are there technical fixes to that?
    Mr. Erwin. So I think one of the many things that I like in 
ADPPA is a call-out trying to define consent and establishing 
that manipulative design patterns that do not provide 
meaningful consent and try to trick consumers into consenting 
data collection without fully understanding are--that is--it is 
simply not an acceptable practice.
    I think that is a good approach, and one--like I said, one 
of the many things that I like in the draft.
    Mr. Guthrie. OK. Yes, location data. For instance, there 
has been a couple of criminal cases, one in South Carolina, one 
in--the horrible incident in Idaho, where the location on the 
person's phone--you can't think of everything if you are going 
to cover your tracks. Your phone tells a lot of things you 
don't think about. And so it has been beneficial in some ways, 
but it certainly is concerning for us.
    So you also say in your testimony we are reaching the 
limits of what we can do in the browser to protect people from 
this data collection. And so, as you were talking about, there 
is--what are--so I guess my question would be, why do you think 
we are reaching the limits?
    What types of browser information can we protect, and what 
can we not protect?
    And then what would be your message to websites and tech 
companies if they want to better protect their users?
    Mr. Erwin. Yes. So just historically, one of the 
interesting sort of arcs of narrative about privacy is it was 
not built in early enough into your browsing experience in 
your--in the browser, in the operating systems you use, in the 
mobile operating systems you use. And at least some companies 
have been very forward-leaning in trying to correct that early 
mistake.
    And so we have done things like--for example, we talk about 
deprecating cookies, or blocking what we call cookie-based 
tracking. This is the standard tracking mechanism online, 
historically, that has been used to build a profile of what you 
are doing on the Web. However, there are some underlying 
techniques that we know we can do much less about.
    So one of these--and just to go into the weeds for a 
moment--we call browser fingerprinting. The basic idea, almost 
like a fingerprint that you have, is there are certain 
characteristics of your browser--the screen size, for example; 
the fonts that you have installed in your browser--that, 
actually, if you collect this data--and it is data that is 
really critical to your usage of the browser, but it actually--
if you collect enough of it, it becomes a unique identifier 
that then follows you around. That is what we call a browser 
fingerprint.
    And again, that is the type of thing which, like--there 
were explicit identifiers, cookies, ad IDs that were built into 
platforms like the browser that we have removed and that we 
have made real progress. But there's some things like this--
like I said, browser fingerprints that we can actually do very 
little about. We are working on it, but we know that it is a 
much, much more difficult space for us.
    Mr. Guthrie. OK, thanks.
    And I guess, Mr. Sherman, we had the TikTok hearing, and 
the TikTok CEO testified that he could not say with 100 percent 
certainty that the Chinese Government did not have access to 
American user data.
    If you couldn't--could the Chinese Communist Party get the 
same data by purchasing it if they get it just from TikTok, 
which they own?
    Mr. Sherman. It might not be all the same data, right? But 
you can get a lot just by buying it. Or if you are someone like 
the Chinese Government, just stealing it from the companies 
that are doing the work to precompile and package it.
    Mr. Guthrie. Well, so that is the question I was getting 
to. So if we passed all kinds of privacy laws, but there's bad 
actors and bad players that own companies, they would still 
have access to the data, even if the law says you can't share 
this data or it can't be submitted or so forth, correct?
    Mr. Sherman. There is always a risk of hacking. And so we 
do need to think about cybersecurity protections for all kinds 
of data alongside the privacy controls on them.
    Mr. Guthrie. Because we learned that--a lot of these 
deceptive practices are--people call me all the time and say, 
well, if it is a website from Russia, it is tough to prosecute, 
and those kinds of things. So we need to be aware that there's 
deceptive players all around.
    My time has expired, and I will yield back.
    Mr. Griffith. The gentleman yields back. I now recognize 
the gentlelady from Illinois, Ms. Schakowsky, for her 5 minutes 
of questions.
    Ms. Schakowsky. I really want to thank the witnesses.
    You know, for the purpose of this hearing, I think there's 
two things that we know: one is that most Americans worry about 
their data privacy, that--and are concerned that it is not 
being protected; and two, as has been said over and over again 
during this hearing, is that most consumers don't know a thing 
about, you know, the data brokers, who they are, what--how it 
works.
    So I wanted to call attention--and this has been mentioned, 
too--about our American Data Privacy and Protection Act in 
which we say that we would require all data brokers to 
register, essentially, so that we would--everyone would have 
access to a list. And you could, with one push of the button, 
actually disconnect from that. You could, you know, take 
yourself out.
    And I wondered how you think--if this is an effective way 
to go, and that this would be a really important advance for 
consumers.
    I just want to point out still I think we would have to 
educate people that this is going on. If they see the term 
``data broker,'' they still might not know what it is, but we 
would give them the opportunity to opt out. What do you think?
    I would like each of you, if you have an answer, that would 
be great.
    Ms. Moy. I am happy to start. Yes. So I think--I mean, a 
registry would certainly be a good place to start, as well as a 
one-stop shop for people to opt out. Yes, the--it is incredibly 
opaque right now. A registry would both help the Federal Trade 
Commission exercise oversight, help people gain some insight 
into what is happening, and a one-stop shop would be really 
important for opting out.
    I think a few things to think about are what the incentive 
is to register. So right now I think the penalty is $10,000 for 
not registering in the bill, and that is something to think 
about, whether that is a sufficient penalty.
    And I think a couple of questions that this approach raises 
also are what we do about first parties that are collecting 
tremendous amounts of information that maybe kind of are data 
brokers but do have relationships with individuals, and what we 
do about publicly available information, which--a lot of data 
brokers claim to be dealing entirely in publicly available 
information.
    Ms. Schakowsky. Thank you.
    Ms. Moy. But it is a very good start, I agree.
    Mr. Erwin. Yes, we support a combination of what we think 
of as universal opt-outs plus sort of default privacy 
protections.
    So in some cases, the opt-out, especially along the lines 
of what you are suggesting, is really critical and valuable. 
There's similar opt-out mechanisms that people have proposed in 
your web browser so that you don't have to opt out from every 
website to website. So decreasing the opt-out friction is 
really critical, because it is so easy right now to hand over 
your data and really hard to prevent parties from collecting 
that data.
    The one challenge with that, though, is we know that 
consumers typically aren't--still aren't going to use a lot of 
these opt-out mechanisms. That is why it is also critical to 
have some baseline protections, prohibitions against data 
selling, default strong protections so that users don't always 
have to opt in. And in some cases that is actually a better 
outcome than leaning on opt-out mechanisms as the sole 
mitigation.
    Ms. Schakowsky. Before I get to you--but I want you to 
answer this question, Mr. Erwin--is there a really good 
rationale for data brokers, period?
    Mr. Sherman. I will answer that one first. Again, as I 
mentioned, data brokerage covers a wide range of activities. So 
there are companies that will sell to employers and to 
landlords and say, ``If you want to do income verification for 
someone you are looking to hire, give us their name, we will 
tell you what we have.'' There is still a privacy question 
about that, but it is all the way to, as mentioned, some really 
egregious cases where I think the case is really strong for 
regulation and not for allowing, for example, health data to be 
sold, right?
    The marginal benefit, potentially, is someone gets marketed 
a product that they could use for health condition --that is 
even then questionable--all the way to, as we have seen, 
scamming people with Alzheimer's and dementia, things that are 
patently harmful.
    Ms. Schakowsky. And the idea of our language that we have 
in our bill?
    Mr. Sherman. Yes, I like it. I think it is a great first 
step. I would agree with what Professor Moy and Mr. Erwin said. 
I think thinking about enforcing the opt-out is important.
    There have been folks, as my fellow witness mentioned, who 
have tried to get their name taken off these people search 
websites. They might opt out. The company might say, ``OK, we 
will do it,'' and the next day their name is back on there 
because it repopulates or because, if you click on my sibling, 
then my page pops back up.
    So making sure they are actually deleting that data, 
actually stopping the sale, I think, is the second big piece of 
that solution.
    Ms. Schakowsky. Great.
    Thank you to all three of you. I appreciate it.
    Mr. Griffith. The gentlelady yields back. I now recognize 
the gentleman from South Carolina, Mr. Duncan, for his 5 
minutes of questioning.
    Mr. Duncan. Thank you, Mr. Chairman, a really informative 
committee hearing.
    This might be off topic, but are these things listening to 
us and sharing our data?
    Mr. Erwin. So it is interesting. In fact, they are not. 
But, you know, the major----
    Mr. Duncan. I mean, how can you say that? Let me preface 
it.
    Mr. Erwin. Yes.
    Mr. Duncan. You know, I may have a discussion with Kelly 
Armstrong about the beaches at Normandy and--or the Battle of 
the Bulge. And then I go to a social media site and within 
seconds an ad will pop up on that topic. And it could be 
oriental rugs. It could be something that, you know, is just 
off topic that I normally wouldn't talk about, but because I 
did in a setting, ads pop up. And it happens too many times for 
me to think they don't.
    Mr. Erwin. Yes, it is pretty amazing, isn't it? I think it 
is even scarier, though, because what is really happening is 
many of the major tech platforms know so much about you that 
they can predict your behavior. They can predict your 
conversation.
    Mr. Duncan. They can't predict something like an oriental 
rug.
    Mr. Erwin. In fact, they can. That is--it is remarkable, 
how sophisticated some of these companies are. And so that is 
actually what is happening. They are not listening to you, but 
they have such incredible predictive power that they can figure 
it out.
    Mr. Duncan. I am going to say Hermes ties, and I will bet 
you at some point this afternoon I will have--let's move on. I 
think they are, and I think it is scary, the amount of data----
    Mr. Erwin. It is, yes.
    Mr. Duncan [continuing]. That these devices are collecting.
    I was in the auction business, did real estate marketing, 
and I was able to buy MEL list using an OSC code, I think it 
was called, and did direct mail marketing to people I thought 
may want the property I was selling. Unsolicited mail pops up 
in your mailbox. How is this different than what marketing 
companies were doing then through buying those mail lists?
    Mr. Sherman. I can maybe start. I would say it is not 
entirely different, right? There are brokers who sell those 
kinds of marketing lists now.
    I think the questions come back to the scale of the data 
collected, the depth of the data, as Mr. Erwin mentioned, that 
is out there.
    And the third piece is, are you actually vetting who you 
are selling to? As you mentioned, if you are perhaps doing 
marketing for your small business, that might be one thing. But 
there was a case where the Justice Department went after 
Epsilon, a multibillion-dollar broker that got sample scam 
mails that the criminal scammer was going to send to elderly 
Americans, and approved the sale anyway.
    And so it comes back to that question of what are you 
actually doing to make sure that someone is not going to use 
that same information in a harmful way.
    Mr. Duncan. I yield to Armstrong.
    Mr. Armstrong. Well, I just have a secondary question to 
that real quick, and I agree with that. But even on its best 
scenario, right, I mean, even whether it is legitimate or 
illegitimate, there is still a difference between contextual 
advertising and actually targeted advertising. Like, if you are 
buying old mail lists and you are going to elderly people, that 
is not--I mean, you are targeting a specific group in a 
contextual capacity. This is microtargeting at a much more 
sophisticated and, quite frankly, dangerous level, right?
    And I yield back.
    Mr. Sherman. Absolutely, yes. And you can buy lists that 
maybe are not just name and one column with interest in real 
estate. You could buy with health and all kinds of other things 
we have mentioned in that same data set to really, really get 
precise about targeting people.
    Mr. Duncan. Thank you for that. Let me just ask this. In 
your written testimony you talk about various State laws, 
including those in California and Vermont, that define and 
require data brokers to register with the State governments. 
There's also laws in Delaware, Michigan, Virginia, Colorado, 
and others.
    Are these laws sufficient in protecting American privacy? 
Yes--if yes, why? If not, why not? And then--that is for you, 
Mr. Sherman.
    Mr. Erwin, I would like to ask what would be the advantage 
of having a Federal law defining and regulating data brokers, 
as opposed to the patchwork of State laws?
    Mr. Sherman. I would say no on the registry laws. They are 
an important step, but they don't do anything to block the sale 
of data. They force some companies defined narrowly to 
register. A lot of that information actually is wrong or 
outdated. And so we do need to do more on that front, such as 
actually controlling the sale of data in regulation.
    Mr. Erwin. Yes, we think the Federal law is really 
critical.
    The challenge with State law is, one, it is going to leave 
a large number of people unprotected where those laws haven't 
passed. And that, to us, is the biggest problem. A lot of 
Americans today aren't going to benefit from the privacy 
protections in CCPPA, for example.
    The other challenge with having a patchwork of State laws 
is, you know, when your legal team looks at that, and you see 
this complexity of the regulatory environment, it kind of looks 
for, like, the bottom line. What is the minimum? And the 
challenge--and that is really not good for consumers, either, 
because it means we are not setting a high bar that everyone 
can be held to. Rather, your legal team is just doing legal 
risk mitigation, and that is not a great situation to be in. It 
is not good for consumers either. So the Federal law, to us, is 
much preferable.
    Mr. Duncan. I still think the phones are spying on us and 
sharing that information with some social media platforms until 
I am convinced otherwise.
    And I yield back.
    Mr. Griffith. Many of my constituents would agree with you, 
Mr. Duncan.
    That being said, the gentleman yields back and I now 
recognizes the gentleman from New York, Mr. Tonko, for his 5 
minutes of questioning.
    Mr. Tonko. Well, thank you, Chair Griffith, and thank you, 
Ranking Member Castor, for hosting this hearing.
    I think it is important to hear from you folks at the 
table, so thank you to our witnesses.
    The data brokerage industry's practices are deeply 
intrusive. This industry monetizes personal data, including 
sensitive information like data on mental health and addiction. 
Americans already face many barriers to seeking out treatment 
for mental health and substance abuse without data brokers 
trying to exploit their condition for profit. So what people 
struggling with mental health and addiction need to know is 
that they are not alone and that real help is available.
    So, Mr. Sherman, have you found that data brokers are 
capitalizing on the mental health crisis in this country to 
boost their profits?
    Mr. Sherman. I think so. The more that mental health 
services that are not regulated are collecting mental health 
data, the more they are able to sell it to data brokers.
    Mr. Tonko. Any--do the other two witnesses have any 
comments on--or any experience in knowing about any of the 
mental health community?
    OK. I understand that many data brokers collect data to 
feed targeted advertisements, including those directed toward 
vulnerable populations like those struggling with addiction. In 
February I introduced the Betting on our Future Act to stop 
sports betting's harmful advertising that preys on the 
estimated 7 million people in the United States who have a 
gambling problem or addiction.
    So, Mr. Sherman, how have you seen data brokers collect and 
market data on people struggling with addiction?
    And how has that data been used by companies to capitalize 
on these given addictions?
    Mr. Sherman. As mentioned, some of the health data that is 
out there could include things like drug addictions. You can 
also go buy from data brokers data on gambling addicts or data 
on people who--and I am no medical expert or anything, but 
might not be addicts per se but go to the casino a lot, for 
instance. So that stuff is out there for purchase.
    Mr. Tonko. Yes. Well, we heard from some individuals when 
we did a roundtable discussion in my district on this--the 
gambling addiction. And, of course, people who were in, for 
example, 30 years recovery from gambling were targeted for that 
sports gambling, as were, however, those who were 10, 15 years 
in recovery from illicit drug addiction. So it is just amazing 
to me that they can target these vulnerable populations for the 
purpose of financial benefit.
    Mr. Erwin, what should online platforms be doing to ensure 
that users' browsing history isn't exploited by data brokers 
and advertisers to fuel addiction?
    Mr. Erwin. Yes, I mean, it is a remarkable example of a 
much broader problem, which is, again, like the more you know 
about something, you know their vulnerabilities, it becomes 
easy to exploit those vulnerabilities to financial gain.
    One of the major things we have advocated for is disclosure 
of what we call bulk advertising libraries, the basic idea 
being, especially for the major platforms like Google and 
Facebook, you know, all of the ads that are surfaced there 
should be available for the rest of us to inspect, to do 
analysis on and to figure out if this is happening and people 
are being harmed. We should have the means to identify that 
harm and do something about it.
    But because all of this content right now is so targeted, 
it is also invisible to the rest of us who aren't getting, for 
example, gambling ads. I am not going to see a gambling ad, and 
many of you might not. That harm is only happening to that 
specific set of individuals, and they are not even aware it is 
occurring. And so those are the types of things that we would 
like to see as well, bulk ad libraries being a good example of 
the type of transparency that is necessary to get ahead of the 
types of harms that you are identifying.
    Mr. Tonko. Interesting. Any other thoughts on that from--
Ms. Moy?
    Ms. Moy. Yes, sure. I think I would just add that thinking 
about the vulnerabilities and the way that messages can be 
targeted to folks--addiction is a stark example. But similarly, 
folks who are financially struggling can be targeted for 
predatory products.
    Similarly, folks who are vulnerable to certain types of 
messages could be targeted, microtargeted with certain 
political messages, could be targeted with any kind of 
messaging that someone wants to deliver to sway a group of 
people. And that is very concerning, as well, as a possible 
threat to democracy.
    Mr. Tonko. Well, it is kind of indicative of how difficult 
these situations become for people who are struggling and are 
in recovery. And to know that they were preyed upon by outside 
groups because of their past experience is kind of a cruel 
approach, really. So whatever we can do to fix that is 
certainly something that we should pursue.
    Big Tech's preying on vulnerable populations, including 
people with addiction and mental health concerns, is deeply 
troubling, especially at a time when we need to be lifting up, 
not exploiting those who struggle in America with any given 
addiction. So I thank you for drawing attention to these 
issues.
    And with that, Mr. Chair, I yield back.
    Mr. Griffith. The gentleman yields back, and I now 
recognize the vice chair of the committee, Mrs. Lesko, for her 
5 minutes of questioning.
    Mrs. Lesko. Thank you, Mr. Chair.
    Mr. Sherman, have foreign governments obtained data on 
American military veterans?
    Mr. Sherman. I don't know. I can't say decisively one way 
or the other. I think the question is about risk, right? And 
risk always is a matter of possibility. And if this much data 
is this available and we have seen brokers sell it in other 
cases where it is harmful, there is a real risk here.
    Mrs. Lesko. Thank you.
    Mr. Sherman, do data brokers advertise to prospective 
clients that they have personal information on U.S. military 
personnel?
    Mr. Sherman. Yes.
    Mrs. Lesko. And what kind of information about U.S. 
military personnel do they advertise?
    Mr. Sherman. You can essentially purchase anything we have 
mentioned related to members of the military. That could be 
health data, that could be political data, that could be data 
on children in the home, that could be marital status, location 
data, even.
    Mrs. Lesko. Thank you.
    To any of you, we have passed out of the House last 
Congress a data privacy legislation. We have heard from some 
business sectors, including small business groups, that they 
are worried that there will be unintended consequences, that 
they will lose business, and so on and so forth. Do you have 
any recommendations, or do you have any concerns about that, or 
have recommendations on how we can structure the data privacy 
legislation?
    Ms. Moy. I mean, I think that size thresholds can be 
helpful. However, I also think that there are good reasons to 
still place obligations on even small businesses to 
appropriately protect individuals' information. And Cambridge 
Analytica was a very small entity, and was able to do a 
tremendous amount of harm. So unfortunately, it is an area that 
just needs responsibility.
    Mr. Erwin. Yes, I agree with all that. I would just add, 
you know, it is important to keep in mind, like, the internet 
is a remarkably innovative place with low barriers to entry, 
and that will continue to be the case once Federal privacy 
legislation comes into existence. It will remain an innovative, 
good place for businesses to go and build their business.
    And we have, I think, at Mozilla a huge amount of respect 
for the innovative capacity of the internet. And you can take a 
big hammer to the internet and it is going to keep going. So I 
think those arguments are a little bit overstated, frankly. And 
like I said, I have a large amount of confidence that it will 
remain an innovative place for businesses to engage.
    Mrs. Lesko. Good, OK.
    Mr. Sherman, I like your idea to ban sale of location and 
health data at a minimum, and also sell--and ban selling data 
to foreign entities. I think those are--and I may be wrong, but 
it seems like a more direct way just to protect very sensitive 
of data.
    I do have--since I have a minute and 40 seconds left, I 
have a question for you, if you know the answer. So, you know, 
when you use Uber, as most of us do in Washington, DC, you have 
to turn on the location data, right? And so do you know if Uber 
sells that data, the location data?
    Mr. Sherman. I do not know that. I will say this is a 
challenge with tackling this issue, is lots of apps don't 
really share data. They just want to keep it to themselves and 
use it for, as you said, business purposes for what they need 
it for. Others share it all over the place, and sometimes it is 
hard to tell and get more transparency into that ecosystem 
without regulatory levers to crack it open.
    Mrs. Lesko. Yes, I mean, I often get these apps that you--
it might pop up and say, ``Do you''--``This will share data and 
have access to your camera and your files'' and blah, blah, 
blah, ``Do you want to do it?''
    And I am like, well, if I am going to be able to use the 
app, I kind of have to do it, right? And so that is the 
problem, correct?
    Ms. Moy. Yes. I mean, that is definitely--that is one of 
the problems with brokers claiming that they have consent for 
some of the information that they have, is that, as a practical 
matter, folks can't do that.
    I would also just add about the location data point 
specifically: In the example that the chairman gave about a 
birdwatching app, if that app is advertising-driven, then even 
if the app developer itself is not selling location data, if 
the app is sharing location data with an advertising entity 
that is also present on the app, then that entity could be 
sharing location information. So there are multiple ways that 
location information could go from your phone through an app to 
another entity.
    Mrs. Lesko. Thank you, and I yield back.
    Mr. Griffith. The gentlelady yields back. I now recognize 
the gentleman from California, Dr. Ruiz.
    Mr. Ruiz. Thank you.
    Data brokers have been collecting data on consumers from 
apps and public records for many years, with real implications 
for Americans, particularly for historically disadvantaged 
groups. We know that brokers routinely compile and sell 
countless segmented lists of consumers based on characteristics 
like income level, race, ethnicity, often without consumers 
even realizing it.
    But that is not all. Brokers have callously lumped 
consumers of color into categories, and then they sell those 
lists for a profit. One broker, for example, created and sold a 
list of consumers that it titled, quote, ``Ethnic Second City 
Strugglers,'' unquote.
    Mr. Sherman, can you explain why data brokers are 
interested in collecting data on race and ethnicity?
    Mr. Sherman. They collect it because they can make money 
from selling it. And as you said, even if it is something very 
sensitive like targeting historically disenfranchised 
communities, economically vulnerable people, there probably is 
a company out there interested in marketing to those people, or 
maybe a scammer interested in targeting those people that's 
going to buy that data package.
    Mr. Ruiz. So data brokers also hold vast quantities of 
information that can be used to exploit vulnerable populations 
and discriminate against protected groups. Brokers have used 
their vast collection of data to insert themselves into 
potentially life-changing decisions such as Americans' housing, 
credit, and employment.
    Mr. Sherman, can you explain how data on racial and ethnic 
minorities could be used to discriminate against vulnerable 
communities?
    Mr. Sherman. There are many ways. As mentioned, there are, 
essentially, no ways for consumers to know that this is going 
on, and so there is no opportunity to potentially correct 
information that could be wrong. And so situations already 
laden with bias could have incorrect information further 
entered, all the way to we know that health insurance 
companies, for example, will buy information on consumers, 
including things like race, income, education level--and yet 
again, another system with many, many gaps in access and 
quality of care, and it is hard to know what they are doing 
with it.
    Mr. Ruiz. OK. Professor Moy, how have you seen brokers 
capitalize on the lack of meaningful regulation by using data 
on Black and Brown Americans in a discriminatory way, 
particularly in areas such as housing, employment, and service 
eligibility?
    Ms. Moy. Yes, so I think--so the folks at the organization 
Upturn have done a lot of really useful work on this. And one 
of the things that they have pointed out is that some data 
brokers collect information about things like eviction records, 
and then might roll that into scores that then are relied upon 
by, for example, landlords to make housing decisions.
    Now, this makes a lot of--this makes intuitive sense, but 
the fact of the matter is that in certain areas, more 
economically depressed areas, landlords might be much more 
likely to move directly to eviction proceedings when payments 
are--when rent payments are late than in other areas. So as a 
result, the historical data is biased against people of color 
in economically disadvantaged areas. And when those scores are 
then relied upon--provided by data brokers to make decisions, 
then unbeknownst to the landlords they might actually be making 
decisions in a way that is discriminatory.
    Mr. Ruiz. Mr. Erwin, so you have commented before on the 
use of sophisticated algorithms that can use personal data to 
discriminate against people based on race or gender. Could you 
speak a little more about what you have observed in terms of 
discriminatory data use and what we should be aware of as we 
try to address these issues here in Congress?
    Mr. Erwin. Yes. So the canonical example of this is just 
basic targeting. ``Targeting'' is the term that we use for any 
advertisement. In this case, it is targeting towards particular 
demographics of housing and jobs, a practice that historically 
we would have said this just looks like redlining, it is 
illegal. But in an internet context, it is easy to do and 
opaque to the rest of us. And it means that some demographics 
are going to see particular jobs or particular ads for houses, 
and other demographics are not. And that is a big problem.
    Mr. Ruiz. Well, thank you to our witnesses for shedding 
light on this critical privacy issue, which has deep 
implications for the civil rights of vulnerable communities in 
our Nation.
    I yield back.
    Mr. Griffith. I thank the gentleman for yielding back, and 
now recognize the gentleman from North Dakota, Mr. Armstrong, 
for 5 minutes of questioning.
    Mr. Armstrong. Thank you, Mr. Chairman, and I wish I had an 
hour.
    We are far into this hearing, and I agree with the privacy 
concerns at this--on these levels of everything. But I want to 
talk about the Fourth Amendment, because this is one of the 
places where I think we don't spend nearly enough time talking 
about it, and the Fourth Amendment has withstood listening 
devices, telephoto lenses, satellites, drones, location 
trackers. Currently, you know, Carpenter redefined third-party 
carrier. There's geolocation warrant cases going through the 
system. Side note: I don't know how a geofence warrant is 
legal--constitutional, anyway. It is a general warrant, not a 
specific warrant, but that is a longer question. Facial 
recognition.
    But we don't talk--we don't have a long enough conversation 
about what this means with data brokers. And we have seen it. 
We have seen it in our hearings. And it is not always DoJ, 
right? It is CDC, IRS. We have had people on election integrity 
talk about backdoors into voting machines. Even the SECURE Act. 
And when we are talking about TikTok, there is, in my personal 
opinion, too much potential government intervention into those 
things. And it can be things as specific and dealing with all 
of those different issues that exist, or it can be something as 
innocuous as when you are using energy in your house, right?
    It turns out there is a really good public safety benefit 
from knowing where everybody is, what they are doing, and who 
they are at any given point in time in any community across the 
country. And it is not just Federal law enforcement, it is 
State law enforcement and all of those different issues.
    But, Mr. Sherman, in your testimony you advocate for 
strictly controlling the sale of data to governments, which 
includes State, local, and Federal law enforcement, right?
    Mr. Sherman. The reference in my testimony to government 
sale was vis-a-vis foreign governments. But I agree it is an 
important question, right?
    Mr. Armstrong. Well, I agree with foreign governments too. 
I just don't want the U.S. Government to be able to purchase it 
on the third party if it would require a warrant either.
    Mr. Sherman. No, no, I agree. I fully agree with that. I 
think, as you said, we have had, you know, years of 
conversations about how do we properly put legal evidence 
barriers and other things in place to make sure law enforcement 
is not overstepping, is violating Americans' freedoms.
    The fact that any law enforcement agency can end-run around 
that by buying whatever they want from a data broker with no 
warrant, I think, is a huge problem.
    Mr. Armstrong. Well, and the response back to us would be 
if I--if Kelly Armstrong, a Member, just a guy from North 
Dakota--can buy this information on the civilian marketplace, 
why shouldn't law enforcement be able to buy it? And that is 
a--I mean, I disagree with that response, but it is truly a 
valid response.
    Mr. Sherman. I would say neither law enforcement should be 
able to buy it without a warrant, nor the scammer running 
around targeting someone. And so I think that is a sort of 
circular argument that gets passed.
    As you said, the question of government overreach, the 
question of what is the oversight of that level of 
surveillance, and the answer is there currently isn't any.
    Mr. Armstrong. Well, and I agree with that. I mean, and 
anything that would require a warrant on direct source, being 
able to circumvent that from third party is something we should 
be very--I mean, and we know this.
    Various law enforcement groups have expressed concern about 
the ADPPA's effect on criminal investigations. And in September 
of 2022 they sent us a letter, and it says, ``This legislation 
would also make common investigative tools unavailable or 
extremely limited. The ADPPA would likely complicate the 
private sector's ability to continue its ongoing efforts to 
cooperate and share voluntarily, share certain information with 
law enforcement.''
    Law enforcement claims that data purchased from data 
brokers largely consists of publicly available information, 
meaning data brokers merely aggregate this data for law 
enforcement in a more efficient manner. Ms. Moy, do you agree 
with that statement?
    Ms. Moy. So I will just point out that, with both 
telephones and banking, we--the Fourth Amendment--the Supreme 
Court found that this information was not protected, and, in 
fact, that is what spurred Congress to act, right?
    I mean, like, that was the situation with United States v. 
Miller, and that is why Congress passed the Right to Financial 
Privacy Act, you know, so I think that certainly law 
enforcement has grown to rely on some of these methods, just as 
law enforcement during Prohibition had grown to rely on 
wiretaps. And that will be a change. But it needs to happen. We 
need these fundamental----
    Mr. Armstrong. Well, and I think the courts have already 
shown--I mean, I think this really is the next step in the U.S. 
v. Carpenter third-party carrier, right?
    I mean, the courts were very willing to change how they 
viewed ``third-party carrier'' in the digital age. I mean, 
that----
    Ms. Moy. Absolutely.
    Mr. Armstrong. That ruling was limited to persistent 
tracking and geolocation data through shell site--or cell site 
information, but I think the principle is the same. And----
    Ms. Moy. Absolutely.
    Mr. Armstrong. So, I mean, there has been a massive 
expansion of--and the other answer is that I think we don't--we 
still talk about the data collection. We have AI, ChatGPT, all 
of these different things. The amount of information they can 
analyze in real time is the second conversation that we need to 
have about this, because it is a truly scary--it is scary on 
the civilian market, and it is very scary when government is 
doing it, as well.
    Ms. Moy. Yes, and if I can just respond to that very 
briefly, because I think this is a response also to what Mr. 
Duncan was pointing out. Yes, these analytical tools render the 
factual context fundamentally different. You know, maybe having 
a list of addresses on paper at one time was something that 
didn't give people much cause for concern.
    Now those lists of addresses, historical address 
information, can be mined to learn information about people's 
relationships and their, you know, their religion and their 
habits. And the same with location information. It is very 
different with the analytical tools we have now and in the 
future.
    Mr. Armstrong. Yes, and that is before you get into 
profiling and all of these other things that are--traditional 
things would have real civil liberty protections.
    I am sorry, Mr. Chairman, I yield back.
    Mr. Griffith. I know you are passionate about it, and I 
appreciate it, but we have got to move on.
    I now recognize Mrs. Trahan of Massachusetts for her 5 
minutes.
    Mrs. Trahan. Thank you, Chairman Griffith, Ranking Member 
Castro for--Castor, excuse me--for allowing me to waive on to 
this hearing.
    You know, over a year ago I introduced the DELETE Act with 
Senators Cassidy and Ossoff. This bipartisan legislation would 
require data brokers to register with the FTC and delete all 
the data related to a consumer at the consumer's request.
    Now I am glad that a similar provision was rolled into 
ADPPA. That is a great sign that both parties are fed up with 
the lack of control consumers have over their data that is 
being collected and sold by brokers. But without Congress 
requiring transparency, the best way that I have found to learn 
what data brokers are up to is on AWS. I mean, literally, on 
the Amazon Web Services data exchange there's thousands of data 
sets with personal information under categories like health 
data, financial data, automotive data, and all are available 
for sale.
    Now, a lot of these data sets include loan balances and 
clinical trial participation. Some of their descriptions say 
that they are anonymized. We know that that is not necessarily 
true. Mr. Erwin and Mr. Sherman, you discussed in your 
testimonies the ways that data brokers use different persistent 
identifiers to connect data to an individual.
    So Mr. Sherman, is data that contains any persistent 
identifier truly anonymized?
    Mr. Sherman. Absolutely not. And I think this is the really 
key point, is that are there statistical privacy protecting 
techniques that are really important? Yes. But exactly to your 
point, when data brokers use the word ``anonymized,'' it is a 
marketing term. It is not a technical term. And they use that 
to suggest that taking a name out of a data set somehow 
prevents it from being linked back to a person. And that is 
just not true. There's decades of computer science research 
showing the complete opposite.
    And in fact, I would add that part of the whole business 
model of data brokers is aggregating and targeting people. The 
notion that they would not be able to do that or would not want 
to do that is just ridiculous.
    Mrs. Trahan. So that is exactly right. I mean, to follow 
up, would it not be a drafting mistake to treat personal data 
that is linked or can be linked to a persistent identifier as 
anonymized data?
    I mean, if Congress passed such language, how would a data 
broker take advantage of that situation?
    Mr. Sherman. A broker could remove something superficially 
from data like a name, and perhaps keep something else in there 
that they can combine with other data to identify that person--
so not violating the law, but rendering the protection 
effectively ineffective.
    Mrs. Trahan. Thank you. And that is exactly why we need to 
be so careful when we are crafting these laws and why we have 
to ensure that ADPPA is as strong as it was in the last 
Congress, if not stronger.
    Now, when we talk about data brokers, we have to 
contextualize this in the real harms and dangers that their 
overcollection presents. When a user taps a popup and consents 
to the use of geolocation data, or when they drive their car 
and geolocation data is transmitted to the auto manufacturer, 
that should not be an invitation to an opaque chain of 
advertisers, individuals, and law enforcement to invade their 
private lives, hunt them down and, as we have already seen from 
cases over the past year, prosecutors jail them for seeking 
reproductive care. Data brokers enable that process, and giving 
consumers back control over their privacy and the ability to 
opt out of data broker collection is how we can immediately 
stop it.
    But geolocation data is not a persistent identifier. It is 
a unique type of data that is overcollected, valuable to 
advertisers, and providers--provides some of the most pervasive 
insights into our personal lives, as Congresswoman Lesko and 
others have raised today. So Dr. Moy, does the transfer, sale, 
and disclosure of geolocation data warrant additional scrutiny 
from Congress? And how could it be abused?
    Ms. Moy. Absolutely. And just to tie this to your 
anonymization question, even when location data has been wiped 
of a person's name, you know, I mean, there are very few people 
who were present both at Georgetown Law School and here in the 
Rayburn building today. So if you had that information about 10 
people, you would know that one of them was me. And if you 
added in my home address, then--and found a location point near 
there, then you would absolutely just be able to reidentify 
that information. So supposedly anonymous information is 
usually not pseudonymous and can be linked back to an 
individual.
    I absolutely think that geolocation information should be 
protected with heightened protections. It can be used to learn 
not only about someone's specific whereabouts for the purpose 
of targeting them but also sensitive information like where 
they worship, where their kids go to school, where they live 
and work, whose house they visit overnight, those types of 
things.
    Mrs. Trahan. Well, thank you. I would just like to say that 
I am grateful for your work at my alma mater, Georgetown. They 
would find me too, both of us. Georgetown has established 
itself as a leader in all things tech policy, and your 
expertise is a big reason why. So thank you for being here 
today.
    Ms. Moy. Thank you.
    Mrs. Trahan. I yield back.
    Mr. Griffith. The gentlelady yields back. I now recognize 
the gentleman from Alabama, Mr. Palmer, for his 5 minutes of 
questioning.
    Mr. Palmer. OK, I want to do this very quickly, because I 
have got a number of things I want to ask you.
    The Fourth Amendment was mentioned--obviously, the right of 
people to be secure in their persons, houses, papers, and 
effects.
    The Supreme Court of the United States said that data 
brokers can be sued if they provide incorrect information. What 
I would like to know is, can they be sued if they misuse 
accurate information, Professor Moy? And I mean, like, if they 
sold it to scammers, as has been mentioned.
    Ms. Moy. So----
    Mr. Palmer. Could you make it really quick, because----
    Ms. Moy. They--yes, they--under the Federal Trade 
Commission section 5, in theory, yes, cases could be brought 
against----
    Mr. Palmer. Could they be sued if individuals made it clear 
that they didn't want their information sold? Should that be a 
requirement on any transaction that says--where you can say, 
``I do not want my information to be shared or sold or 
transmitted to any other party''?
    Ms. Moy. I believe so, yes.
    Mr. Palmer. Should that be part of our legislation?
    Ms. Moy. Yes, and I think the default should be don't share 
unless people agree in most cases.
    Mr. Palmer. Right, yes. It should be a positive decision, 
not negative.
    OK. The other thing is, does the Fourth Amendment 
protections apply to sharing data with foreign governments? 
Because the Fourth Amendment protections that have been applied 
to data brokers has prohibited them from sharing information 
with the U.S. Government, although that is happening through 
certain Federal agencies.
    Ms. Moy. Yes. I mean, so the Fourth Amendment potentially 
does not protect against the sale of information to the U.S. 
Government or to foreign entities either.
    Mr. Palmer. OK. And that is another thing that needs to be 
in our legislation.
    The foreign use--I am--one of the things I am very 
concerned about is the foreign use of data that they are 
purchasing for a number of things. One is counterintelligence, 
because they can use this in--to inform themselves on 
counterintelligence operations, where they can target people 
they have identified as key individuals.
    We should not be allowing any of this information to be 
shared with, I think, any foreign entity, because you do not 
know whether or not it would be in the hands of adversarial--
whether they are adversarial nation states or actors, and then 
for propaganda purposes. And this is one of the things that 
concerns me right now, is how so much misinformation is out 
there on social media, and they are targeting people that, you 
know, maybe that have conspiratorial leanings. And I think that 
this is becoming an issue, you know, microtargeting election-
type messages.
    The other thing I want to talk about is, you know, the 
European Union has the general data protection regulation. Has 
this been effective? And any one of you who know anything about 
this can--has this been effective for protecting personal data 
for people in the EU?
    Mr. Erwin. Yes. I mean there are a few things that GDPR did 
right.
    Mr. Palmer. Make it really quick, because----
    Mr. Erwin. It has not been as effective as----
    Mr. Palmer. That is what----
    Mr. Erwin [continuing]. Would have liked.
    Mr. Palmer [continuing]. Find out. Thank you.
    And what about California's Consumer Privacy Act? Because 
it does open up opportunities for civil litigation, I believe.
    Ms. Moy. I think that it is making an impact. Certainly, 
the privacy officer is making an impact, as is the rulemaking 
authority that is given to it.
    Mr. Palmer. OK. I would like your--and maybe--I had to step 
out to go speak to a group--I would like for you to provide 
some information in terms of how we can work to get information 
that is already out there removed.
    And again, my concern is the privacy protections that 
companies offer. But there are companies out there that will--
that you can pay to try to remove your information. But there 
are so many of these places where this information is, they 
could remove it from 500 and it would still be innumerable 
places where your information is still available, and some--
whether they are legal or illegal.
    How would you recommend that we go about crafting a bill to 
allow people to, as definitively as possible, get their 
information removed?
    Ms. Moy. So I do think that a lot of the information just 
shouldn't be out there in the first place, right? I mean, like, 
the fact that so many entities--hundreds, potentially 
thousands--may have some of the same data points, thousands of 
data points about each individual, that should not be the case. 
We should not have to opt out of those brokers having our 
information.
    But, you know, in the event that they do, it should be 
very, very simple for a person to opt out everywhere, or it 
should only be collected on an opt-in basis.
    Mr. Palmer. I thank the chairman. I--this is another 
example this week of a bipartisan hearing that I think has been 
very valuable, and I really appreciate the witnesses' time and 
your responses to allow me to get all these things in. So, Mr. 
Chairman, I yield back.
    Mr. Griffith. The gentleman yields back, and I appreciate 
that, and now recognize the gentlelady from Florida, Mrs. 
Cammack, for her 5 minutes.
    Mrs. Cammack. Thank you, Mr. Chairman. Thank you to our 
witnesses for hanging in there with us. It is one of those 
crazy days where we are all in and out. So I appreciate you 
all.
    I may have missed some of this, so if this is repetitive, I 
apologize. But in your estimation--and I am going to direct 
this to you, Mr. Erwin--in your estimation, what percentage of 
internet users are using Web browsers that are privacy 
invasive?
    Mr. Erwin. Probably more than half the market. And by 
privacy invasive, I would take that to mean they don't have the 
baseline set of privacy protections----
    Mrs. Cammack. Right.
    Mr. Erwin [continuing]. That protect them from cross-site 
tracking, cookie tracking, those type of protections.
    Mrs. Cammack. Don't worry, I won't ask you to name your 
competitors. I think we can draw our own assumptions on that. 
But more than half, it is pretty terrifying.
    What kind of pushback have you and your company received 
from website advertisers or users as your company has 
implemented tools that block cross-site tracking?
    For example, do they have a worse ad experience? Is the 
algorithm tweaked to downplay impressions?
    Mr. Erwin. Yes, I think when we launched the initial 
version of our protections in 2019 we heard that users were not 
going to like it. And many what we call ad tech companies 
pushed back and essentially said the sky is going to fall. And, 
you know, our consumers generally are positive. This has not 
degraded their experience at all. Rather, they have a better 
experience in Firefox because we are blocking this tracking.
    The feedback we have gotten from ad tech providers, from 
advertisers, is not as positive, which is something that we 
would expect. And, you know, sometimes it is a positive thing 
when we hear negative feedback back like that. So----
    Mrs. Cammack. Did you guys take a hit in terms of revenue 
generation from advertising?
    Mr. Erwin. We--it probably negatively impacted our revenue, 
but not by a significant degree.
    Mrs. Cammack. OK. Thank you for that. And I may have missed 
it, but there may have been a conversation today had about the 
possibility of a data brokerage that is in line with 
compensating users and consumers for their data with their 
consent to be--to sell their data. I don't know if that has 
been discussed today, but I would love to get your feedback on 
how something like that might happen.
    If a consumer consented to having their data sold, how 
would we go about compensating them for doing that? I am not 
talking about a class action suit or anything, but a 
marketplace system where we could do that. You look very eager 
to answer that question, Mr. Sherman.
    Mr. Sherman. I think the challenge with that here is that, 
when we talk about data brokers, we are not talking about that 
first-party app or website necessarily you are giving it to to 
use the data for a business purpose. We are talking about that 
company selling it to third parties, we are talking about third 
parties consumers often don't know exist that are selling it 
for profit.
    And so oftentimes--most of the time, I would say--this is 
done with no consent whatsoever from the consumer.
    Mrs. Cammack. Absolutely, right. And I think we all 
acknowledge that most of the data that is sold today, it is 
done without their consent. I mean, there is that veil of you 
consent to the terms and services of this app, whatever, and 
therefore we do what we will with your data that we collect and 
sell.
    But shouldn't there be a way in which consumers can then 
earn a commission or something off of that, or something as 
simple as being notified when their data has been sold?
    Mr. Sherman. I think consumers should be made aware of this 
practice. Again, I think, you know, companies will--an app or 
something will throw out these insanely long privacy policies 
that nobody actually reads, and then say that is consent.
    I still think we need to prohibit the sale of some kinds of 
data, but I agree with what you said, that those terms should 
be made easy to read. It should take a few minutes maybe to 
scan through and see what kinds of data is this app collecting, 
is it sharing it or selling it with any third parties. That way 
the consumer has that information.
    Mrs. Cammack. Absolutely. And I want to yield the remainder 
of my time to my colleague from the great State of North 
Dakota. Thank you.
    Mr. Armstrong. I just have one more--well, I have 1 minute, 
so I am going to be very quick.
    Section 101 of the ADPPA prohibits the collection, 
processing, or transfer of covered data to what is necessary 
and proportionate to provide the specific product or service 
requested by the individual or permissible purpose. 
``Permissible purpose'' includes collecting, processing, or 
transferring data to prevent, detect, protect against, or 
respond to illegal activity, which is defined as a violation of 
a criminal law that can directly harm.
    And my question for you, Ms. Moy, is I like the idea of 
this, and I don't know if you can answer it in 25--28 seconds. 
Actually, I know you can't. But do we need to tighten this up a 
little better?
    Ms. Moy. I do think that--yes. I mean, I think that this 
carve-out is in a bunch of privacy laws, kind of like the idea 
that for the detection--or for the detection of fraud, or for 
the investigation of crimes, that there is an exception there. 
And I think in general that those exceptions should be 
tightened up, yes.
    Mr. Armstrong. Thank you.
    Mr. Griffith. The gentleman yields back to the gentlelady, 
and the gentlelady yields back to the Chair.
    Mrs. Cammack. That is right, I do.
    [Laughter.]
    Mr. Griffith. And I don't see any additional Members 
wishing to ask questions. Seeing there are no further Members--
who have time they haven't already used.
    [Laughter.]
    Mr. Griffith. Seeing there are no further Members wishing 
to ask questions, I would like to thank our witnesses again for 
being here today.
    I will tell you I think this has been a very important 
hearing. I hope that C-SPAN will run it, so the public is more 
aware of what is going on, particularly if they run it in prime 
time, but you never know what they are going to pick and choose 
to run. It might be a month from now it will pop up.
    That being said, in pursuance to committee rules, I remind 
Members that they have 10 business days to submit additional 
questions--that would be you, Mr. Armstrong--for the record, 
and I ask that witnesses submit their response within 10 
business days upon receipt of the questions.
    Without objection, the committee is adjourned.
    [Whereupon, at 4:00 p.m., the subcommittee was adjourned.]

                                 [all]
</pre></body></html>
