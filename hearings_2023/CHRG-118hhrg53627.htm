<html>
<title> - MAN AND MACHINE: ARTIFICIAL INTELLIGENCE ON THE BATTLEFIELD</title>
<body><pre>
[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]



                         [H.A.S.C. No. 118-37] 
                         
                         
                         
                         
                         

                      MAN AND MACHINE: ARTIFICIAL  
                    INTELLIGENCE ON THE BATTLEFIELD

                               __________

                                HEARING

                               BEFORE THE

                  SUBCOMMITTEE ON CYBER, INFORMATION  
                     TECHNOLOGIES, AND INNOVATION 

                                 OF THE

                      COMMITTEE ON ARMED SERVICES

                        HOUSE OF REPRESENTATIVES

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             FIRST SESSION

                               __________

                              HEARING HELD

                             JULY 18, 2023


                                     



              [GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]


                                     
  


                               ------- 
                               
                  U.S. GOVERNMENT PUBLISHING OFFICE 
                  
53-627                    WASHINGTON : 2024 













           SUBCOMMITTEE ON CYBER, INFORMATION TECHNOLOGIES,  
                            AND INNOVATION

                  MIKE GALLAGHER, Wisconsin, Chairman

MATT GAETZ, Florida                  RO KHANNA, California
LISA C. McCLAIN, Michigan            SETH MOULTON, Massachusetts
PAT FALLON, Texas                    WILLIAM R. KEATING, Massachusetts
DALE W. STRONG, Alabama              ANDY KIM, New Jersey
MORGAN LUTTRELL, Texas               ELISSA SLOTKIN, Michigan
JENNIFER A. KIGGANS, Virginia        JARED F. GOLDEN, Maine
NICK LaLOTA, New York                PATRICK RYAN, New York
RICHARD McCORMICK, Georgia           CHRISTOPHER R. DELUZIO, 
                                         Pennsylvania

                Sarah Moxley, Professional Staff Member
               Michael Hermann, Professional Staff Member
                    Brooke Alred, Research Assistant 
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
       
                    
                            C O N T E N T S

                              ----------                              
                                                                   Page

              STATEMENTS PRESENTED BY MEMBERS OF CONGRESS

Gallagher, Hon. Mike, a Representative from Wisconsin, Chairman, 
  Subcommittee on Cyber, Information Technologies, and Innovation     1
Khanna, Hon. Ro, a Representative from California, Ranking 
  Member, Subcommittee on Cyber, Information Technologies, and 
  Innovation.....................................................     2

                               WITNESSES

Kitchen, Klon, Nonresident Senior Fellow, American Enterprise 
  Institute......................................................     5
Mahmoudian, Haniyeh, Global AI Ethicist, DataRobot...............     6
Wang, Alexandr, Chief Executive Officer, Scale AI................     3

                                APPENDIX

Prepared Statements:

    Kitchen, Klon................................................    53
    Mahmoudian, Haniyeh..........................................    68
    Wang, Alexandr...............................................    37

Documents Submitted for the Record:

    ``The AI War and How to Win It,'' by Alexandr Wang...........    83
    ``Why AI Will Save the World,'' by Marc Andreessen...........    97

Witness Responses to Questions Asked During the Hearing:

    Mr. Gaetz....................................................   123
    Mr. Keating..................................................   123

Questions Submitted by Members Post Hearing:

    [There were no Questions submitted post hearing.]
 
               MAN AND MACHINE: ARTIFICIAL INTELLIGENCE ON 
                            THE BATTLEFIELD

                              ----------                              

                        House of Representatives,
                        Committee on Armed Services,  
                      Subcommittee on Cyber, Information  
                           Technologies, and Innovation,
                        Washington, DC, Tuesday, July 18, 2023.
    The subcommittee met, pursuant to call, at 9:00 a.m., in 
room 2118, Rayburn House Office Building, Hon. Mike Gallagher 
(chairman of the subcommittee) presiding.

OPENING STATEMENT OF HON. MIKE GALLAGHER, A REPRESENTATIVE FROM 
  WISCONSIN, CHAIRMAN, SUBCOMMITTEE ON CYBER, INFORMATION 
  TECHNOLOGIES, AND INNOVATION

    Mr. Gallagher. The subcommittee will come to order.
    I ask for unanimous general consent that the Chair be 
authorized to declare a recess at any time. Without objection, 
so ordered.
    I want to briefly review the three commandments of the CITI 
[Cyber, Information Technologies, and Innovation] Subcommittee.
    One is that we shall start on time, which we just did. So 
that is good.
    We are going to enforce the 5-minute rule, but if time 
allows, we will entertain a second round of questions, and it 
often does.
    But I bring this up, I want to stress the third 
commandment, which is ``Thou shalt not use acronyms or 
jargon,'' which I think is particularly important in this 
discussion because discussions about AI [artificial 
intelligence] can quickly degenerate into jargon-laden 
discussions.
    We have three true experts on this topic, but just don't 
assume your average Member of Congress--or let me just say, 
don't assume I understand what you are talking about when you 
get into the nuances of AI. So we want to have a discussion in 
the open that your average American can understand today. We 
are asking you to demystify a lot of the concepts surrounding 
AI.
    And in thinking about this topic that may sound 
counterintuitive, but I have been going back to the history of 
the early Cold War. In particular, I'm obsessed with the Korean 
war, which is the moment in which the Cold War first turned 
very hot, and at great cost to Americans, at even greater cost 
to the Korean people themselves.
    And I was reading this sort of obscure book about it and 
came across the words of a historian named David Rees, who 
said, ``At the heart of West military thought lies the belief 
that machines must be used to save its men's lives. Korea would 
progressively become a horrific illustration of the effects of 
a limited war where one side possessed the firepower and the 
other the manpower.''
    There's a lot of different ways to interpret this in the 
current context, and particularly in the context of this 
hearing.
    One is that AI could potentially increase the destructive 
power of modern warfare.
    The other is AI has the potential to decrease it, or at 
least decrease the exposure that our soldiers, sailors, airmen, 
and Marines take when they put themselves in a combat 
situation.
    Or the third--and what is unique, in contrast to the early 
Cold War--is that the machines themselves might somehow take 
power and go beyond our ability to control them.
    Today, we want to dig into all of these different 
hypotheses. The only thing, as I have dug into this topic, and 
I want to commend the ranking member, Mr. Khanna, for the way 
in which he has worked with me to really use the subcommittee 
to explore AI concepts.
    We had a very fascinating discussion with Elon Musk last 
week. I will say there were some sources of disagreement. Mr. 
Musk believes China is on ``Team Humanity.'' I'm not persuaded 
of that point. And the only thing I have become convinced is 
that the CCP [Chinese Communist Party], if they win this 
competition or win the sort of AI component of this 
competition, will likely use that technology for evil, as a way 
of perfecting a oppressive totalitarian surveillance state, as 
well as exporting that model around the world. Whereas, we in 
the West, we in the free world at least have the chance of 
using it for good.
    So to make sense of all these things, we are lucky to have 
three incredible witnesses.
    Mr. Alex Wang is the CEO [chief executive officer] of Scale 
AI. And I don't know, you might be the most successful MIT 
[Massachusetts Institute of Technology] dropout of all time at 
this point, but there's actually probably a unique subset of 
people that qualify there.
    Mr. Klon Kitchen is senior fellow at the American 
Enterprise Institute and someone many of us on Capitol Hill 
look for for advice when talking about the intersection of 
technology and warfare.
    And Dr. Haniyeh Mahmoudian of DataRobot is an absolute AI 
expert as well.
    So I have been looking forward to this hearing for a long 
time. I look forward to an open and honest discussion. Just 
remember, no acronyms, no jargon.
    And with that, I yield to the ranking member, Mr. Khanna.

STATEMENT OF HON. RO KHANNA, A REPRESENTATIVE FROM CALIFORNIA, 
  RANKING MEMBER, SUBCOMMITTEE ON CYBER, INFORMATION 
  TECHNOLOGIES, AND INNOVATION

    Mr. Khanna. Thank you, Mr. Chairman, and thank you for 
convening this panel and your interest in a bipartisan way in 
addressing AI and making sure that our military is leading with 
AI. I have appreciated how you have approached this throughout 
your chairmanship.
    I'm not going to be long because I know people want to hear 
from the witnesses. I would just say that my understanding is 
that China is spending almost 10 times as much as the U.S. as a 
percent of their military budget on AI, and we really need to 
think about the modern technologies that are going to be needed 
to have a most effective national security strategy.
    So I'm particularly curious from the witnesses about how 
they think America can maintain and have the lead in AI 
technology going forward, what are the investments we need to 
make, and what are the standards we need to have to ensure that 
our AI is used most effectively. I'm looking forward to this 
panel.
    Mr. Gallagher. Thank you.
    Mr. Wang, you are now recognized for 5 minutes.

        STATEMENT OF ALEXANDR WANG, CHIEF EXECUTIVE 
                      OFFICER, SCALE AI

    Mr. Wang. Chairman Gallagher, Ranking Member Khanna, and 
members of the subcommittee, my name is Alexandr Wang and I'm 
the founder and CEO of Scale AI.
    It is an honor to be here today to testify at the dawn of 
this new era of warfare--one that will be dominated by AI--and 
what the United States must do to win.
    In 2016, I founded Scale with a mission to accelerate the 
development of AI. From our earliest days of working with the 
leading autonomous vehicle programs at General Motors and 
Toyota; technology companies such as Meta, Microsoft, and Open 
AI; and partnerships with the U.S. Government, including the 
U.S. Department of Defense's CDAO [Chief Digital and Artificial 
Intelligence Office], the U.S. Army, and the U.S. Air Force, we 
have been at the forefront of AI development for more than 7 
years.
    The country that is able to most rapidly and effectively 
integrate new technology into warfighting wins. If we don't win 
on AI, we risk ceding global influence, technological 
leadership, and democracy to strategic adversaries like China.
    The national security mission is deeply personal for me. I 
grew up in the shadow of the Los Alamos National Lab. My 
parents were physicists and worked on the technology that 
defined the last era of warfare, the atomic bomb.
    The Chinese Communist Party deeply understands the 
potential for AI to disrupt warfare and is investing heavily to 
capitalize on the opportunity. I saw this firsthand 4 years ago 
when I went on an investor trip to China that was both 
enlightening and unsettling.
    China was making rapid progress developing AI technologies 
like facial recognition and computer vision and using these for 
domestic surveillance and repression. That same year, President 
Xi Jinping said, quote, ``We must ensure that our country 
marches in the front ranks where it comes to theoretical 
research in this important area of AI and occupy the high 
ground in critical and AI core technologies.'' End quote.
    China is investing the full power of its industrial base 
for AI. This year, they are on track to spend roughly three 
times the U.S. Government on AI. The PLA [People's Liberation 
Army] is also heavily investing in AI-enabled autonomous drone 
swarms, adaptive radar systems, autonomous vehicles, and China 
has launched over 79 large-language models since 2020. AI is 
China's Apollo Project.
    To lead the world in the development of AI, we must lead 
the world in the amount of high-quality data powering AI. Scale 
is firmly committed to doing our part to support the U.S. 
Government and ensure America maintains its strategic 
advantage. Today, we do so in three ways.
    One, Scale data engine. We annotate and prepare vast troves 
of data for the U.S. Government.
    Two, autonomous mission systems. We partnered with DIU 
[Defense Innovation Unit] to develop a data engine that will 
support the Army's Robotic Combat Vehicle program.
    Three, we developed Scale Donovan, our AI-powered 
decisionmaking platform that rapidly helps the U.S. Government 
make sense of real-world information.
    The DOD [Department of Defense] has also taken a number of 
steps in the right direction, most notably with the launch of 
the Chief Digital and Artificial Intelligence Office.
    While this progress is promising, more must be done to 
achieve AI overmatch. AI Overmatch is our five-pillar plan to 
maintain the United States' security and technological edge in 
this new era.
    First, investment in AI. It is critical to increase 
America's investment to maintain our leadership. Despite record 
AI investment in the fiscal year 2024 President's budget, the 
U.S. is still spending three times less than China.
    Second, data supremacy. AI systems are only as good as the 
data they are trained on. The DOD creates more than 22 
terabytes of data daily, most of which is wasted. AI warfare 
requires leading the world in developing AI-ready data.
    Scale fully supports the CDAO and its legislative mandate 
to establish a centralized data repository, which would enable 
the DOD to harness the power of data with AI.
    Third, testing and evaluation. It is one of the most 
important ways to ensure that AI models are accurate, reliable, 
and uphold the DOD's ethical AI principles.
    The administration has embraced this concept by 
highlighting Scale's role building an evaluation platform for 
frontier LLMs [large language models] at DEFCON [hacker 
conference].
    Fourth, pathfinder projects. Congress should authorize and 
fund new programs with the mission of developing innovative AI-
powered warfighting capabilities. Since Project Maven was 
started more than 6 years ago, no new AI pathfinder projects 
have begun.
    Fifth, upscaling the workforce. The U.S. should invest in 
rapidly training the DOD workforce for AI. Scale has already 
worked on this with the DOD to tackle this challenge head-on.
    In St. Louis, we established an AI center which has created 
more than 300 AI-focused jobs, ranging from entry-level 
labelers to machine learning engineers with advanced degrees.
    The race for global AI leadership is well underway, and I 
cannot be more excited to do everything in my power to ensure 
that the United States wins. It is in moments like this that 
Congress, the DOD, and the tech industry can either rise to the 
challenge together or stand idle.
    I have included my further remarks in a written statement 
to be submitted for the record.
    And thank you again for the opportunity to be here today. I 
look forward to your questions.
    Thank you.
    [The prepared statement of Mr. Wang can be found in the 
Appendix on page 37.]
    Mr. Gallagher. Thank you, Mr. Wang.
    Mr. Kitchen, you are recognized for 5 minutes.

       STATEMENT OF KLON KITCHEN, NONRESIDENT SENIOR 
           FELLOW, AMERICAN ENTERPRISE INSTITUTE

    Mr. Kitchen. Good morning, Chairman Gallagher, Ranking 
Member Khanna, and members of the committee. Thank you for the 
privilege of testifying.
    I would like to use my opening statement to make three 
points.
    First, I believe artificial intelligence, and particularly 
emerging capabilities like generative AI, are a national 
security lifeline for the United States. The national security 
community has discussed the potential of AI for years, but now 
it seems these technologies are finally maturing to where they 
can be applied at scale--with few doubting that they will soon 
reshape almost every aspect of our lives, including how we 
fight and win wars.
    The importance of AI is felt as acutely in Beijing as it is 
in Washington. But, until recently, I was not at all confident 
that the United States would hold the AI advantage. If you 
assume this advantage comes down to algorithms, data, and 
hardware, just 1 year ago I would have given the United States 
the advantage on algorithms, the Chinese the advantage on data, 
and I would have called hardware a jump ball.
    But this deserves another look. Large language models and 
other generative AIs may be moving the competition back to the 
American advantage. The U.S. dominates the underlying computer 
science giving birth to these advancements and we remain the 
home of choice for global talent.
    On hardware, a strong, bipartisan consensus is allowing us 
to meaningfully constrain China's access to cutting-edge 
capabilities, like advanced graphics processing units, and even 
more can and should be done. For example, limiting Chinese 
cloud services would be an excellent next step.
    Finally, on data, while the Chinese economy and people 
continue to generate a deluge of digitized data, and while the 
Chinese Communist Party continues to have unfettered access to 
these data, the promise of synthetic data and the fact that 
many of the new AI models are indexed on the open internet may 
blunt the CCP's advantage.
    It is my hope, for example, that the Chinese government's 
political fragility, strict content controls, and general 
oppression of its own people will compromise or bias much of 
the data that it collects, diluting its utility and ultimately 
limiting the development of Chinese AI. At the very least, I 
think that the United States has an opportunity to surge ahead 
of Beijing if we are aggressive and deliberate.
    But AI offers the U.S. more than bespoke capabilities. 
Large language models and other generative technologies, if 
properly realized, could provide an economic base for a new era 
of American prosperity and security.
    For years, we have known that the United States is not 
investing in its military sufficiently to meet the demands of 
the Nation. The truth of this has been laid bare, as our 
defense industrial base struggles to keep up with the demand of 
the conflict in Ukraine, for example.
    But according to one recent study, existing generative AI 
capabilities could add the equivalent of $2.6 trillion to $4.4 
trillion annually to the global economy, and that this estimate 
would double if we include the impact of embedding generative 
AI into existing software that is currently used.
    The bottom line is this: I believe AI is offering us an 
opportunity to get our economic house in order, to lay a 
foundation for our Nation's long-term prosperity, and to build 
a national security enterprise that is properly resourced.
    But finally, while AI offers all this promise and more, it 
is also has serious national security risks; most acutely, a 
flood of misinformation and the exponential growth of 
conventional and novel cyberattacks. By now, we have all seen 
the photos, videos, and other media generative AIs are 
creating, and these capabilities have already been 
democratized. Virtually anyone can create and distribute 
synthetic media that will undoubtedly be used to undermine 
American confidence in our democratic institutions.
    Similarly, generative AIs will offer hostile cyber actors 
potent tools for generating and automating traditional and new 
online attacks. In a world where we are already overwhelmed by 
online threats, generative AIs will soon pour gas on these 
fires.
    There is much more that I could say on these matters, but I 
trust we will cover them more fully on the course of this 
hearing.
    Thank you again for the opportunity to testify, and I look 
forward to your questions.
    [The prepared statement of Mr. Kitchen can be found in the 
Appendix on page 53.]
    Mr. Gallagher. Thank you, Mr. Kitchen.
    Dr. Mahmoudian, you are recognized for 5 minutes.

         STATEMENT OF HANIYEH MAHMOUDIAN, GLOBAL AI 
                    ETHICIST, DATAROBOT

    Dr. Mahmoudian. Thank you.
    Chairman Gallagher, Ranking Member Khanna, and the members 
of the Cyber, Information Technologies, and Innovation 
Subcommittee, thank you for the opportunity today to testify 
before the subcommittee on the critical issues of machine 
learning and human warfare: artificial intelligence on the 
battlefield.
    My name is Dr. Haniyeh Mahmoudian, and I am the global AI 
ethicist at DataRobot. In my personal capacity, I am an 
advisory member to the National AI Advisory Committee and co-
chair the AI Future Working Group. Today, I testify in my 
individual capacity.
    AI holds immense potential and is increasingly becoming an 
essential component of modern military strategies and 
operations with potential to profoundly impact operational 
efficiency and decision making.
    In the realm of cybersecurity, AI can help military protect 
its network and systems against increasingly sophisticated 
cyber threats and also assist them in offensive cyber 
operations.
    AI can also play a critical role in predicting and 
prevention of injuries among military personnel. AI can 
efficiently track real-time fatigue and injuries, which can aid 
prevention of MSK [musculoskeletal] and other bodily injuries, 
which, along with consequences, is a major reason for medical 
disability and consequent discharge from the service.
    Thus, it is imperative that the United States expedites the 
adoption of AI to sustain our strategic military leadership and 
advantage. While these benefits are significant, it is crucial 
to ensure that the use of AI in the military context adheres to 
law and ethical guidelines.
    In recent years, insufficient scrutiny of AI and evaluation 
of AI systems, coupled with a limited comprehension of AI's 
potential adverse effect, have led to numerous instances where 
AI, despite being developed with good intentions, ended up 
harming individuals and groups it was designed to help.
    This suggests that consideration of AI ethics have often 
been relegated to secondary thought when it comes to building 
and deploying AI systems. However, it is encouraging that the 
Department of Defense has taken initiatives to develop AI 
ethics principles that will apply to both combat and noncombat 
functions.
    As former Secretary Esper has remarked, ``AI technology 
will change much about the battlefield of the future, but 
nothing will change America's steadfast commitment to 
responsible and lawful behavior.''
    Incorporation of responsible AI frameworks and fostering 
trust in AI systems requires consideration of people, process, 
and technology. Investment in AI and AI ethics literacy for 
military personnel at all levels is a key step to ensuring 
responsible and appropriate use of AI.
    To successfully adopt AI and have it at scale at the 
Department of Defense requires that the Department implement AI 
governance frameworks and adopt risk-management processes to 
manage and mitigate risks associated with AI.
    One of the challenges in adoption of AI in the government, 
especially in the Department of Defense, is a slow procurement 
process. As mentioned earlier, AI is an evolving space. 
Therefore, it is paramount for us to make sure that we have a 
faster procurement cycle, but ensuring that we also have proper 
evaluation of AI tools by using robust governance processes.
    In conclusion, AI holds transformative potential. However, 
along with these benefits, it is vital to establish ethical 
frameworks and comprehensive governance processes that ensure 
effectiveness, reliability, and human oversight.
    Thank you.
    [The prepared statement of Dr. Mahmoudian can be found in 
the Appendix on page 68.]
    Mr. Gallagher. Thank you to all our witnesses for your 
thoughtful testimony.
    I now recognize myself for 5 minutes.
    Mr. Wang, I would like to begin by asking you to respond a 
bit to some of what Mr. Kitchen laid out in terms of our 
advantages and disadvantages relative to China in the AI race. 
How do you see those advantages--relative advantages and 
disadvantages?
    Mr. Wang. So I certainly agree that America is the place of 
choice for the most talented AI scientists in the world. So we 
certainly continue to have an advantage there. And the evidence 
is clear, if you look at ChatGPT, GPT-3, GPT-4, as well as the 
transformer model that underpins it, all of those were invented 
in the United States.
    When it comes to data, I actually also agree that we have a 
potential very powerful advantage here, specifically when it 
pertains to military implementations. So in America we have the 
largest fleet of military hardware in the world. This fleet 
generates 22 terabytes of data every day. And so if we can 
properly set up and instrument this data that is being 
generated into pools of AI-ready datasets, then we can create a 
pretty insurmountable data advantage when it comes to military 
use of artificial intelligence.
    Now, I think this is something that we need to work 
together and actually move towards as a country. Today, most of 
this data goes unused or is wasted in some manner. We need to 
fix that to create a longstanding and durable advantage in 
artificial intelligence data.
    And when it comes to computational power, Nvidia, which is 
the world's leader in chips for artificial intelligence, is an 
American company. These technologies are innovated and built in 
America. And so, again there, I think we have an advantage.
    Thank you.
    Mr. Gallagher. And, I mean, you have dealt a lot with the 
Pentagon. It is a customer of yours. Why is it at present--I 
know a lot of this is in your written testimony--that it is 
wasted? What is preventing us from harnessing that data? And I 
guess, more broadly, what is preventing us--why have we not had 
new pathfinder projects since Maven?
    Mr. Wang. So data is something that is significantly more 
valuable with the advent of these artificial intelligence 
algorithms. So, you know, a very simplistic way to look at AI 
is that you have these algorithms that analyze troves and 
troves of high-quality data, identify patterns in those data, 
and then can emulate those patterns going forward.
    So we see that with models like ChatGPT which are able to 
read troves and troves of language data, things that humans 
have written over years and years. Then, it can emulate how a 
human might speak in a lot of these instances.
    So these artificial intelligence algorithms have made data 
significantly more valuable than they have in the past. And so 
it is a new paradigm that the DOD needs to adapt towards. As we 
all know, the DOD is a fragmented organization. There's many 
different constituencies and organizations that each have their 
own approach to data.
    And like one of my witnesses mentioned, there's an 
education process and an upscaling process that needs to 
happen. Everyone within the DOD needs to understand that data 
is actually the ammunition in an AI war. And if we have that 
recognition as an entire Department, and as a country, I think 
it becomes very clear for us to take the right actions to 
actually collect all this data and move forward.
    Mr. Gallagher. It sounds as though you are suggesting that, 
with the right leadership and organization, DOD could actually 
be a leader in this space. I wonder if it could also be a 
leader in terms of the guardrails that a lot of our 
constituents are asking us about, right? I think your average 
American understands we need to win this competition, but is 
concerned about, you know, uncontrolled AI. And everyone has 
seen Terminator, et cetera, et cetera.
    What is your assessment of the DOD's ethical framework? Is 
that potentially a foundation that could be built upon, 
expanded, to ensure we are on the same page within the Five 
Eyes alliance, within the NATO [North Atlantic Treaty 
Organization] alliance, and then, gradually bring more and more 
people into that sort of free-world framework for AI?
    Mr. Wang. I definitely agree. I think it is really critical 
that the United States takes the lead on this topic, 
particularly as it pertains to ensuring that artificial 
intelligence is used in accordance with our values and our 
principles.
    The DOD has established ethical AI principles, which I 
believe are great, and those principles are ones that we should 
continue to adhere. And I think now it comes down to 
implementation. How are we going to actually make sure that 
these principles are followed?
    That is where I think a test and evaluation regime is 
incredibly important and critical to the increased deployment 
of these AI systems. You know, as the DOD looks to apply AI to 
every function within its operation, everywhere from 
warfighting to back-office functions and logistics, we need to 
have proper test and evaluation mechanisms that ensure that 
every instance of artificial intelligence deployed follows our 
ethical AI principles.
    So I think we need to set up the framework by which we can 
ensure all this deployment follows those principles and really 
lead the world in terms of thinking on how AI can be used in 
accordance with democratic principles.
    Mr. Gallagher. I have questions for the other witnesses 
that I will have to save for a second round.
    I recognize Mr. Khanna for 5 minutes.
    Mr. Khanna. Mr. Keating, would you like to go?
    Mr. Keating. Thank you, Mr. Chairman, since I have to do 
this. Let's see if I can do in 5 minutes here three quick 
questions, and quick answers, I hope.
    Mr. Kitchen mentioned global talent and we have an 
advantage. But we also have immigration issues here that is 
hindering that talent. Indeed, should we change some of the 
immigration barriers that exist to get that global talent here 
to the U.S., make sure we are not losing that talent to other 
countries?
    Mr. Kitchen. So immigration policy is outside of my area of 
expertise. What I would say is that maintaining our access and 
continuing to be the preferred home of global talent will be 
essential for national security.
    Mr. Keating. Okay. This question deals with the procurement 
issue that the doctor mentioned. If you could, it is 
fragmented, the Department of Defense. Could you give this 
committee, as a follow-up, some suggestions on procurement 
changes just within the area of AI? Is that something that 
could be carved out? Because this is an area of great 
significance. And you mentioned that, and I agree, is a major, 
major problem. It is a problem generally, but can we do 
something specifically with that that you could suggest to this 
committee?
    Dr. Mahmoudian. So one area that we can think about--and I 
have to emphasize that military is not my area of expertise--
but one area that I can bring from the business perspective, 
because on the business side you also go through--procurement 
side goes through proof of value or proof of concept.
    So one of the challenges that we also see over there is the 
long process of evaluation, which, if we have standard 
procedure in place, these type of processes, these type of 
evaluations, as long as they are standardized, it can go much 
faster.
    Mr. Keating. Thank you.
    Mr. Wang, you are familiar, though, on the military side. 
Can you follow up on that?
    Mr. Wang. Yes. I think there have been immense strides in 
building fast procurement methods for the Department of 
Defense. Notably, the CDAO, the Chief Digital and AI Office, 
has set up a Tradewinds program which is one of the fastest 
procurement methods for new technologies, new and innovative 
technologies in the DOD.
    DIU, as an organization, has also been actively partnering 
with many innovative tech companies in bringing their 
technologies into the DOD.
    And so there are current programs that I think we can 
double down on. Both of these instances that I mentioned at the 
CDAO and at DIU are working. And I think what we need to look 
towards in the next era of AI is doubling down on some of these 
fast procurement methods and ensure that we continue 
innovating.
    Mr. Keating. Is that something that you could follow up 
with the committee and provide that kind of information, how it 
could be tailored, or doubled down, as you said, more 
efficiently, something we could exchange with the military?
    Mr. Wang. Of course.
    [The information referred to can be found in the Appendix 
on page 123.]
    Mr. Keating. Okay. Thank you.
    Then, just an overview. I think Mr. Wang might be the 
proper person, but the others can comment in the 2 minutes I 
have left.
    Mr. Wang mentioned that we have a data advantage in the 
U.S., but we are not capturing all that data. But I think 
inherently in our democracy with privacy right protections, we 
are at a disadvantage in terms of how Chinese operate 
themselves.
    And, you know, it can't just be broken down into 
information, military and otherwise. All that information is 
valuable that they gathered.
    Is there an area where, because of our privacy 
protections--which is something we shouldn't change in our 
country--where we might be at an inherent disadvantage with 
China?
    Mr. Wang. So I actually look at our democratic values as an 
advantage when it comes to artificial intelligence. If you zoom 
in on the realm of large language models, this is an area where 
in the United States we have clearly raced ahead, and we have 
invented much of the technologies. And if you compare that to 
the current, what we know of how China views this technology, 
you know, they are likely going to squash a lot of the 
technology because it is impossible to censor.
    I mean, anyone can use ChatGPT and notice that, you know, 
ChatGPT can say all sorts of different things. In the United 
States, we have protection of free speech. And so we will 
continue innovating when it comes to large language models. In 
China, they view that as a risk to their socialist values. They 
recently came out with regulations that say that their AI 
technology has to adhere to socialist values.
    Mr. Keating. That is interesting, huh?
    Mr. Wang. Yes, it is very interesting.
    Mr. Keating. And I'm glad I asked that question, and I 
never looked at that aspect of the answer.
    Lastly, quickly, with 30 seconds to go, you know, Vladimir 
Putin has said whoever controls AI has a huge advantage, but 
look at Russia right now. Is it fair to say that they are way 
behind? Is it fair to say that their involvement in Ukraine and 
what it is doing to the economy and the sanctions are having an 
effect? Yes or no? Just in 14 seconds.
    [Laughter.]
    Mr. Kitchen. Yes, I think there is good reason to suspect 
that the Russian AI capability, while they may have some basic 
research, in terms of applied deployment is minimal.
    Mr. Keating. All right. I thank the ranking member for 
switching his time, so I could go to another hearing.
    Thank you. I yield back.
    Mr. Gallagher. Dr. McCormick is recognized for 5 minutes.
    Dr. McCormick. Thank you, Mr. Chair.
    And thank you to the witnesses. I wish I had time to talk 
to you all day because this is fascinating. You are all, 
obviously, experts. Unfortunately, we get time enough for about 
two questions and that is about it. So I will go with the most 
pertinent that you guys actually brought up in your opening 
statements that I thought was really interesting.
    Mr. Kitchen, you just discussed limiting Chinese access to 
our information, which totally makes sense. We see how they can 
develop very rapidly when they literally take our information 
and apply it.
    My concern is we have an enormous amount of foreign 
students at our universities right now in some of the leading 
technology areas, including AI development. Georgia Tech is 
right in my back yard. I went to Georgia Tech. I did my pre-med 
there. And we are literally educating them and sending them 
right back there. That is access to leading technology in 
America. Is that what you are discussing when you talk about 
access or are you talking about in the industry itself? Or the 
stuff that is out on the internet? Or is it everything?
    Mr. Kitchen. Thank you, Congressman. It is an important 
question.
    Certainly, there is undeniable--a level of risk associated 
with foreign, and particularly Chinese, student presence in the 
United States. However, the research that I have seen by 
organizations like Georgetown's Center for Security and 
Emerging Technology actually demonstrates that the vast 
majority of foreign research students, even Chinese students, 
actually stay in the United States or, more broadly, in the 
West, for the course of their career and amplify our 
capability.
    What I'm most concerned about, however, when I talk about 
Chinese access to data--again, not dismissing an inherent, 
built-in threat there--is, frankly, their acquisition through 
purchase of American data through large data stores, but then 
also things that we have all been talking about and staring at 
in the face for multiple years now--things like Chinese-owned 
and operated social media companies like TikTok, where every 
bit and byte of data that is generated via these applications 
on Americans' phones is, by law, made accessible to the Chinese 
Communist Party.
    And so while Chinese students and other foreign students 
may have some type of risk, it pales, in my view, in comparison 
to the type of data that we are just kind of giving away.
    Dr. McCormick. I appreciate that and I can totally 
understand where that is coming from. My other concern, though, 
in regards to that--and this is just a quick comment--is that 
the Chinese government is not stupid, and they, obviously, 
don't really care about their people more than they do about 
their government. So when they allow people to come here for 
education or jobs, I think it is with nefarious intent, and 
that is my worry. I'm not saying we don't need to educate 
people from other foreign lands, but I'm worried about it. And 
worried about anybody who is pushing their people over here, 
knowing they are not coming back for a reason.
    With that said, also, Mr. Wang, you made an interesting 
statement about investing in AI and how China has got three 
times more investment in their AI. Of course, the one thing we 
do have a huge advantage is we have a lot of private people 
that are investing in AI now, and China doesn't have that. They 
don't have the capacity to outperform our private industry 
because they don't have a private industry.
    How do we compare when we combine our synergistic efforts 
between government and private industry with China as far as--
and you mentioned, Mr. Kitchen, that in that effect that we 
allow this freedom of flow and it is not controlled. So it does 
have the potential to outpace, as long as we put the right 
guardrails on it when we are talking about our competition with 
China.
    Mr. Wang. Certainly, if you factor in the amount of private 
sector investment into AI in the United States, that is an 
incredible sum. You know, large technology companies, the 
venture capital industry, and now, the sort of global 
enterprise is investing billions and billions of dollars into 
AI. And so if you tally all that up, it is an incredible 
investment into artificial intelligence in the United States.
    That being said, I don't think we should rest easy on that, 
because military implementations of AI are going to be 
incredibly important. We need to ensure that in this next phase 
that the U.S. is both economically dominant, but also has 
military leadership as well when it comes to artificial 
intelligence.
    And so, you know, we need to consider what the overall 
investment into military implementations looks like, and that 
is where there is a large disparity. That is where China is 
investing 3X more. And if you compare as a percentage of their 
overall investment, the PLA is spending somewhere between 1 to 
2 percent of their overall budget into artificial intelligence; 
whereas, the DOD is spending somewhere between .1 and .2 
percent of our budget into AI.
    Dr. McCormick. That is a good point. And it is interesting 
to watch these private industries now in the United States 
pairing with the DOD to develop a lot of that stuff, which is 
very cool, including yourself.
    I will say, since I am out of time, just that we shouldn't 
sleep on Iran and Russia, who obviously want to be players. 
They have used technology in the past to disrupt other 
countries, and they, of course, love misinformation. So this is 
something we need to be aware of.
    Thank you. With that, I yield.
    Mr. Gallagher. Mr. Khanna is recognized for 5 minutes.
    Mr. Khanna. Thank you, Mr. Chairman.
    Mr. Kitchen, I thought it was interesting that you said 
that the advantage that China may have because of data is 
diminishing because things like ChatGPT are based on the entire 
universe of the internet, which has both good and bad data in 
it.
    And then, Mr. Wang, you said that DOD is really relying on 
sort of tagged, annotated data. I guess I'm trying to 
understand, what is the best data that is needed for AI to be 
effective in military applications? And does China have an 
advantage on that kind of data or not? And I would love both of 
your answers on that.
    Mr. Wang. So both data are important, both sort of open 
source data that is accessible on the internet--that is a key 
data source for large language models like ChatGPT--as well as 
high-quality, annotated datasets. ChatGPT and its precursor 
InstructGPT were trained on large quantities of high-quality, 
expert-generated data. And it is an important data source to 
ensure that these systems are more trustworthy, truthful, 
responsible, et cetera.
    So both matter, but when you look towards, again, military 
implementations of AI, the key is, what is the military data 
that these models are trained on. Right now, the models that 
are used by consumers and are present in the private sector are 
trained on, essentially, no military data. As a result, you 
know, if you would try to apply these without any additional 
data towards military problems, they would not perform 
particularly well.
    So as we look towards applying artificial intelligence to 
the military, we need to have military AI-ready datasets that 
are ready for this kind of deployment. When it comes to that 
kind of data, I think probably today you would say it is a jump 
ball. I think that PLA is looking deeply at this issue and that 
DOD is looking deeply at this issue.
    But we have all of the fundamentals to have an 
insurmountable advantage because the DOD generates 22 terabytes 
of data--far more data that the PLA generates--on a daily 
basis. So if you can instrument this data into one central 
repository, we can come out ahead.
    Mr. Khanna. So their being--and then I want Mr. Kitchen's 
comments.
    Their being a surveillance state of just getting data from 
all their citizens is not really going to be helpful for the 
military datasets that are needed to solve military problems. 
Correct?
    Mr. Wang. It would be of very limited help, and military 
data is, you know, orders of magnitude more valuable for 
military problem sets.
    Mr. Khanna. Mr. Kitchen.
    Mr. Kitchen. Yes, sir, I completely agree with what Alex is 
saying. I think the application matters. So in military 
applications, particularly anything that would be tactical or 
kinetic, military-generated, well-curated data is really going 
to be the key differential.
    The point that I was trying to raise when I mentioned the 
data advantage perhaps swinging back our way, it is in one 
sense aspirational. Part of the hope of generative AI is that 
over the course of time we will be able to generate what is 
called synthetic data. So instead of data that has been 
produced via normal economic activity or military activity, 
that GenAI, generative AIs, are able to then begin generating 
synthetic datasets that would be useful for training.
    I suspect that we are, number one, not there yet; and 
number two, that those datasets will be helpful for broad 
economic application, but not at all the type of--it will be 
supplemental to the type of military applications that Alex was 
discussing.
    Mr. Khanna. Thank you.
    Dr. Mahmoudian, thank you for your testimony.
    I know Secretary Esper had introduced an AI framework/
guidelines for DOD. I'm not sure if that has been updated now. 
Are there things you would want the DOD to do more in terms of 
the ethical guidelines/framework for the use of AI?
    Dr. Mahmoudian. So the DOD, as I mentioned, they already 
have AI ethics principles in place. So one comment that I would 
have about that is how we can make these frameworks from 
abstract to a practical form of view. And that comes with the 
education of the personnel--to make sure that personnel 
understand what these principles mean and how they can 
actually, in practice, apply to their use cases that they are 
working on. So that is a first step.
    The second step is the implementation of AI governance. So 
when you are talking about policies, processes that their AI 
governance would have, those measurements that would be part of 
this process would include the principles that they have.
    So it is all about people and the process, and obviously, 
the technology. How we are going to measure those risks that we 
may identify in a use case. These are all part of the 
technology aspect of it. Design the technology in a way that it 
would provide explanation of why the system made certain 
decision.
    And I'm out of time.
    Mr. Khanna. Thank you. Thank you.
    Mr. Gallagher. Mr. Gaetz, Esquire, is recognized for 5 
minutes.
    Mr. Gaetz. Mr. Wang, thank you for bringing into sharp 
relief the extent to which we have to think about all of these 
weapon systems that we have in contested environments as data 
collection platforms--almost primarily when it comes to 
integration with AI. And I took great interest in your call to 
the committee that, you know, we not waste that exquisite data 
that is being collected.
    What advice would you have for the committee about shaping 
some sort of access or utilization regime for the data that we 
are currently wasting?
    Mr. Wang. I think this is one of the most important things 
that we can do to set up America for decades and decades of 
leadership in military use of AI. Right now, a lot of this data 
goes onto hard drives, and what ends up happening are the hard 
drives are either overwritten with new information, so the old 
data gets deleted effectively and lost, or these hard drives go 
into sort of closets or places where they never see the light 
of day.
    So first is instrumenting the data to sort of flow into one 
central data repository. The CDAO has a legislative mandate to 
do so and set up a central data repository for the DOD. So I 
think that is of critical importance.
    And then, this is a whole-of-DOD issue. Every service, 
every group, every program needs to be thinking about how can 
they--all of the data that their programs are collecting and 
that are being generated within their purview, how can they 
ensure that all these datas flow through into one central data 
repository, and then, are prepared and tagged and labeled for 
AI-ready use down the line.
    Mr. Gaetz. And it would seem as though, under the normal 
construct of a mission set, someone might reasonably be 
stovepiped away from the broader utilization of some of that 
data. So it almost seems like something that is an appendage to 
a mission set. Very hard to weave it in because, as you are 
collecting data in contested environments, it could be for all 
kind of reasons and all kind of help.
    I wonder aloud, what will be commoditized first, the 
processing capability on some of these platforms or the data 
itself?
    Mr. Wang. Well, I think you are right that this is, you 
know, data is a new asset for this new regime of AI warfare. 
Data truly is the ammunition that will power our future efforts 
in the military. So it is a new paradigm to think about data as 
a key and central resource versus, as you mentioned, an 
appendage that sort of doesn't feel particularly critical to 
the future operation of our programs.
    Mr. Gaetz. Yes, you know, we do all kind of domestic 
policy/military policy around who can access rare earth 
minerals; who can access various forms of energy. And I wonder 
if in the future a nation-state's access to exquisite datasets 
that have been properly stored and collected are viewed just as 
precious.
    I also wanted to reflect on the smartest hour I ever spent. 
It was listening to Elon Musk with our chair and ranking member 
discuss some of these issues, and I would encourage anyone 
watching this who has an interest in the issue--hard to find a 
conversation on the internet with a higher average IQ 
[intelligence quotient] across the board than that one.
    But what Mr. Musk presented as an argument was that China 
understands that AI control of governance is equally a threat 
to them and to the United States. And so Mr. Musk's argument 
was, we really are ideal partners with China because we share a 
common goal to not have the AI robots ultimately take over our 
governance.
    And our chairman offered, I think, a pretty strident 
critique of that perspective saying that, while we view China 
as typically thinking long term in the short term, they are 
more ``Team Communistic Genocide'' than they are ``Team 
Humanity.''
    So I was just wondering if, because you had so much in your 
written testimony about your time in China, and how that shaped 
your perspective on the ethics of all this, do you think China 
sees an overlap of interests with the United States on this? Or 
do they see us as explicitly an arm's length competitor?
    Mr. Wang. I think it would be a stretch to say we are on 
the same team on this issue. I think that, if you look at the 
last generation of AI, computer vision technology, the way that 
China approached it was utilizing it--building an industrial 
base that was government-funded to immediately build advanced 
facial recognition technology for the suppression of their 
population and the suppression of Uyghurs--ultimately sort of 
tightening the grip of their totalitarian regime.
    I expect them to use modern AI technologies in the same way 
to the degree that they can. And that seems to be the immediate 
priority of the Chinese Communist Party when it comes to 
implementations of AI.
    Mr. Gaetz. We will count you on Team Gallagher, not Team 
Elon, on that.
    And just a question for the record. I would love to know 
everyone's perspective on what the most important alliances the 
United States is involved in when it comes to these AI regimes. 
Is it AUKUS? Is it Five Eyes? Does NATO have a role to play in 
the ethics around this? I would love to submit that for----
    Mr. Gallagher. Well, I will break the second commandment, 
which there is a corollary--if you say something nice about me 
or the ranking member, you get more time.
    I just quickly, what is the answer to Mr. Gaetz's question? 
That is an interesting question.
    Mr. Wang. I think they are all important. I would probably 
start with Five Eyes, given the strength of our partnerships 
within that group.
    But, you know, as we look towards artificial intelligence 
as a global technology that will shape much of the future of 
the world, I think we need to form as many key partnerships as 
possible to ensure that particularly the governance of this 
technology, both for--certainly for military use, for use in 
intelligence, and for use sort of in commercial purposes are 
adhering to the democratic values that we have as a country.
    Mr. Gallagher. Quickly, Mr. Kitchen.
    Mr. Kitchen. From a traditional security alliance, I would 
say Five Eyes and NATO will be critical. However, I would say 
that the broader economic partnership with our friends and 
allies in the European Union is going to be critical long term 
and is going in the wrong direction. Happy to talk about that 
more.
    Mr. Gallagher. Quickly, Dr. Mahmoudian.
    Dr. Mahmoudian. I'm echoing the sentiment that the other 
witnesses had. Later in the year, we are going to have our 
first AI summit that is happening in the U.K. [United Kingdom] 
So we need to expand these types of alliance, as mentioned 
earlier, with our allies on the area of AI.
    Mr. Gallagher. Great.
    Ms. Slotkin is recognized for 5 minutes.
    Ms. Slotkin. You know, I would just say, just following on 
that last question, with Five Eyes, we have had generations of 
learning how to share with each other and become interoperable. 
I don't actually know if we have data-sharing arrangements when 
we don't have a joint platform. And it is just fascinating to 
just think about, like, getting those arrangements in place and 
sharing data, given the value is going so precipitously up on 
it.
    So, you know, I would say what we are doing here up on the 
Hill, with the help of industry who is invested in AI, is like 
admiring the problem, right? We are all talking about the 
problem of, like, this new tool that we know has real 
potential, but also has potential real downsides. And so how do 
we govern it? And our constituents are asking us, like, what 
are the ground rules on this new technology because it sounds 
scary?
    And I would commend the Joint Artificial Intelligence 
Center at DOD for putting up some basic, really 40,000-foot 
guidelines on being responsible, and equitable, and traceable 
and reliable, and governable, but it is like it is real top-
level stuff.
    But we are up here, you know, the flip-phone generation, 
trying to figure out how to govern AI, and it is complicated. 
But could you give us a sense, sort of in colloquial English, 
of what keeps you up at night about the military use of AI? If 
China is investing at least 3 times, and in some cases 10 
times, the amount that we are, what is the number one thing 
that you feel like, you know, kind of worst-case scenario, if 
we go unchecked, we could see in the next decade?
    Mr. Kitchen, you are shaking your head.
    Mr. Kitchen. Thank you.
    While there are certain risks of what we would call kind of 
bespoke threats, I think the most acute challenge that we are 
likely to encounter in the near term is a simply more effective 
and efficient enemy.
    So the chairman referenced a quote from the Korean war. I 
will raise him with another one from General Pershing who said, 
``Infantry wins battles, but logistics wins wars.''
    And I think supply chain and military logistics, and a lot 
of what we call kind of back-office military capacity, is what 
is likely to be reshaped by AI in the near term, which can 
sound innocuous and not so scary----
    Ms. Slotkin. Not after Ukraine. I mean, not after watching 
Russia in Ukraine. I will be happy to invest in more improved 
logistics, given what we have just seen, the buffoonery in the 
Russian military.
    But I just want to make sure Mr. Wang has an opportunity. 
That is a good one and it is not a scary thing. It is just a 
more capable and competent adversary, whoever they are.
    Mr. Wang.
    Mr. Wang. I would certainly agree that the application of 
AI to back-office functions, logistics, and just overall 
optimization is really critical. If you look towards, you know, 
the areas where the PLA is investing into artificial 
intelligence, it is for autonomous drone swarms, whether that 
be aerial, subsurface, or ground. They are investing across all 
fronts. They are investing into adaptive radar systems which 
jam and blind U.S. sensors and information networks. So they 
are investing across the whole spectrum in artificial 
intelligence to sort of set the new tone of warfare with this 
technology. And so we need to be investing across the slate.
    That being said, I worry as well about the risks in 
deploying these AI systems without proper guardrails. And for 
me, it really comes down to implementation, which is test and 
evaluation.
    So how do we know that, for all of the artificial 
intelligence systems that the DOD is likely to deploy over the 
next few years and the next decade, how do we ensure that each 
of these AI systems adhere to the DOD ethical AI principles, as 
stated.
    So I think it needs to be a standard part of the 
procurement process, is a test and evaluation mechanism to 
ensure that every instance where a program within the DOD is 
looking to use artificial intelligence, that we have the right 
testing and evaluation to ensure that it adheres to our 
guardrails.
    Ms. Slotkin. And I know that the Department is working hard 
on this data-labeling problem and trying to--it is an enormous 
task to ask what tends to be a stovepiped organization to share 
data, make it available, label it, make it usable.
    If you were king or queen for the day and could get them to 
do one thing on reliability of data and availability, what 
would it be?
    Mr. Wang. I would say, first, establishing the central data 
repository, and then creating a plan by which as much of the 22 
terabytes of data generated a day goes into that central data 
repository. And then creating a plan by which as much of that 
data is processed and labeled and annotated to be AI-ready as 
possible.
    You know, these are all multiyear efforts that are not 
going to be solved tomorrow at the snap of a finger. They need 
to be solved through long-term planning and long-term 
coordination.
    Ms. Slotkin. Great.
    Thank you very much. Yield back.
    Mr. Gallagher. Mr. LaLota is recognized for 5 minutes.
    Mr. LaLota. Thank you, Chairman. Thank you, Chairman 
Gallagher, for your leadership on this issue and to our 
witnesses for helping to inform Congress on these important 
issues. Along with my colleagues from both sides of the aisle, 
I am concerned with the rapid advances in artificial 
intelligence and machine learning, specifically with our 
adversaries like China.
    What concerns me most is the Chinese Communist Party has 
been making great strides and intends to be the world's leader 
by 2030. And while we here in the United States have made 
significant improvements in recent years and we continue to 
advance, thankfully, we still have much work to do when it 
comes to ensuring the DOD is adopting and deploying these 
capabilities properly.
    With that, I wanted to give a shameless plug for one piece 
of legislation that I have for the AI space. My legislation 
would require the Office of Management and Budget to issue 
guidance to Federal agencies to implement transparency 
practices relating to the use of AI and machine learning, 
specifically when AI is being used to supplant a human's 
decision making impacting American citizens.
    While my legislation focuses more broadly, I wanted to ask 
for your thoughts on where the DOD currently stands when it 
comes to AI and machine learning. Where is the U.S. compared to 
our adversaries such as Russia and China with respect to fully 
implementing the latest capabilities? Are we years ahead? Are 
we on par? Are we years behind? And what are some ways you 
would plan for the DOD to speed up the adoption and 
implementation of AI effectively at the Department?
    Mr. Wang.
    Mr. Wang. So when we look at the new technologies like 
large language models, like ChatGPT, that have sort of really 
come to light over the past year, I think that is a jump ball. 
This is a new technology that we need to implement as quickly 
as possible, they are trying to implement as quickly as 
possible, and we will see how that develops.
    If you look towards the last generation of AI technologies, 
which is computer vision and AI for things like facial 
recognition, this is an area where the original techniques were 
invented in the United States, but then China quickly raced 
ahead. So they built an industrial base within their country, 
funded it with government money to build facial recognition 
technology, which they deployed throughout their country to 
suppress Uyghurs and overall, you know, tighten the grip of 
their socialist regime.
    If you look today at the leaderboards for computer vision 
AI competitions globally, Chinese companies, Chinese 
universities, dominate compared to American institutions. So if 
you look at that as a case study, the Chinese system clearly 
has an ability and a will to race forward when it comes to 
artificial intelligence deployments.
    Now, as we look towards this next field of large language 
models, we have reasons to be optimistic. You know, China is 
going to be more reticent to invest into large language models 
because they are difficult to censor. They released recent 
regulation on--that said that AI needed to adapt to their 
socialist principles, which I think is a clear limitation if 
you have an AI that can, you know, sometimes misspeak, like 
ChatGPT.
    So we have reasons for optimism. And again, the DOD 
produces more data than the PLA, by orders of magnitude; we 
generate 22 terabytes of data every single day. And so if we 
can properly build an advantage here, it will be quite durable.
    Mr. LaLota. Mr. Kitchen, would you add something to that? 
Where is your scorecard at? Are we behind? Are we ahead? Are we 
on par?
    Mr. Kitchen. Well, I would say that the two global powers 
where the competition matters most, historically, is between 
the United States and China. As I mentioned at the beginning of 
my testimony, a year ago, I had very real concerns as to how 
the United States was going to be able to maintain its AI 
advantage.
    But precisely because so much of the conversation around 
AI--legitimately so--the public conversation focuses on the 
risks and the kind of unknown, again, meaningful conversations. 
I do think--just analytically, I do believe that we have a 
moment to reassert American dominance in a way that really 
matters, that some of the things that I would have called a 
drag on our development and deployment from a national security 
perspective are actually lessening, and that if we realize this 
technology deliberately, then we can seize the advantage, and 
not just seize the advantage now, but actually build an 
advantage that will be meaningful over the long term.
    And I think that we should do everything we can to do that.
    Mr. LaLota. Thanks.
    And with 30 seconds to go, Doctor, I will ask you the last 
question. What are the risks that this committee, and the 
Department, should be aware of? And how do we address those 
risks as we leap forward?
    Dr. Mahmoudian. So, when it comes to risk there is 
obviously a fallback if the United States falls behind with 
regards to the advancement of AI in military. So the main area 
that we need to focus on is to make sure that we do have the 
advantage in the research, investing in the research, 
especially in the military side, and making sure that we are 
still a leader in the area of R&D [research and development] in 
AI.
    Mr. LaLota. Thanks.
    Chairman, my time has expired.
    Mr. Gallagher. Mr. Kim is recognized for 5 minutes.
    Mr. Kim. Thank you, Mr. Chair.
    Thank you so much for coming on out and talking to us 
today. We spent a lot of time today talking so far about who 
has got the development edge and where we are kind of building 
that direction, certainly about competition with China. So I 
don't want to go over those right now, as they were very well 
talked through.
    Mr. Wang, you talked about in your opening statement 
talking about how the--some of the main technology of the past 
being about nuclear development and whatnot sort of shaping 
that era, and this very well likely shaping our era.
    So I wanted to kind of get a sense from you all about what 
you think proliferation of this technology and possible 
weaponry would look like. You know, when we were in the nuclear 
era, which, you know, we still are--you know, we have a 
situation here where only a very few set of countries have been 
able to reach that threshold of technology, and proliferation 
has been, in many ways, kind of tried--effort to be kind of 
contained in that capacity.
    So I guess I wanted to ask you--for me, that doesn't 
necessarily seem like the kind of setup that we are likely to 
see over the coming decade or two. What does it look like to 
you? Are we going to have a situation where the U.S. and China, 
a handful of countries, are the major developers and 
gatekeepers to this technology, but the actual weapon systems 
and technology will be potentially mass deployed and able for 
purchase by pretty much any nation that is out there?
    Just give us a sense of what that proliferation and 
topography and landscape looks like.
    Mr. Wang. I think this is a really good question. You know, 
I think in terms of impact, artificial intelligence is going to 
be similar to nuclear weaponry. But as you mentioned, it is a 
technology that is likely to be ubiquitous.
    A, artificial intelligence can be used across every single 
domain, every single function, every single activity that the 
military has today, so it is not sort of contained as one 
individual weapon. And it is a technology that is increasingly 
becoming a global technology.
    A few months ago, the UAE [United Arab Emirates] announced 
their own large language model that they had built called 
Falcon 40B. They actually open-sourced that model to the world 
so that anybody on the internet can go and download that model, 
that large language model, for use. We are seeing with the 
open-source community when it comes to large language models 
that this technology is likely to be accessible in some way, 
shape, or form to nearly everyone in the world.
    That being said, I think that is not a reason to, you know, 
give up hope because of one of the things I mentioned before, 
which is, for military use cases and military applications, you 
need algorithms that are trained on military data. And----
    Mr. Kim. I mean, Mr. Kitchen, if you don't mind, I would 
like to bring you in. But would we find a situation where, yes, 
you know, some country or entity or company is doing that but 
then able to then sell that type of technology and weaponry to 
a country or to a group?
    You know, Mr. Kitchen, I would like to also get your 
thoughts on potential for rogue actors, non-state actors, to be 
able to get this type of technology, to be able to utilize it. 
So, if you don't mind, give us some of your thoughts.
    Mr. Kitchen. So I agree with Alex in the sense of this 
technology having the same strategic impact of something like 
nuclear weapons. But one of the peculiarities of it is that 
this technology is overwhelmingly being developed in the 
private sector for commercial applications, unlike nukes.
    And so one of the implications of that is that, because of 
that and the fact that so much is done via the open-source 
model, it is instant proliferation. It is available, in terms 
of the underlying technology and capacity.
    But it is going to be the applications, the particular 
applications, that really make the difference when it comes to 
capability distinctions. And that is where Alex's points about 
the United States having a potential advantage on military 
data--right? How we apply the underlying capability is really, 
really going to matter. And that is where the advantage comes 
to us.
    Now, when we think about non-state actors or kind of rogue 
actors, I think it is--I think where the most acute challenge 
there is probably on novel and traditional cyber exploitations 
of these capabilities. So the ability to generate malicious 
code and automate it and deploy it is now going to be 
democratized to a level and at a scale that is going to be 
difficult.
    Mr. Kim. I want to just get one last question. Doctor, to 
bring you in on this, you know, when we talk about this 
proliferation, seeing the potential for non-state actors and 
others, I guess, you know, we talked about some of these 
frameworks. The U.S. needs to lead the way. But should we be 
thinking about an actual international agreement here, an 
international treaty? What kind of structure should we be 
building towards to give our ability to try to structure that 
as a whole?
    Dr. Mahmoudian. I completely agree. We need to think about 
both the domestic side--so within the United States, we need to 
think about how we should be governing these type of 
technologies, understanding its risk and having mitigation 
process in place. But we do need to work with allies as an 
international--at the international level.
    Mr. Kim. Okay. Thank you.
    I yield back.
    Mr. Gallagher. Mr. Fallon is recognized for 5 minutes.
    Mr. Fallon. Thank you, Mr. Chairman.
    I just want to follow up real quickly with Mr. Kitchen. 
Yeah, I think ransomware is an issue that--it is a huge problem 
already, and it is one that largely goes under the radar 
unless, you know, Colonial Pipeline is hit or something, JBS. 
And that is--everybody talked about it for a week and then 
forgot about it and acted as if it is not a real problem, which 
it is when you have friends in industry, small companies--100, 
200 people--that are getting hit.
    Half-a-million-dollar ransoms now are being asked, or 
million-dollar ransoms, when a lot of the times, it was 50 
grand a few years back. Do you think that with AI, are we going 
to face, as you just mentioned--but I want you to expand on 
it--an explosion in ransomware when you say it is democratized?
    Mr. Kitchen. I think that is certainly one of the potential 
implications. Honestly, I think one of the key developments 
over the last 2 years that has constrained ransomware to the 
degree that it has been constrained is the war in Ukraine, that 
many of those cyber syndicates that were prosecuting those 
attacks have been repurposed by the Russian government for 
attacks in Ukraine and elsewhere.
    I think, if and when that ever slows down, we are going to 
feel the surge again. And I think that that surge will 
absolutely be enabled by generative AI because one of the key 
areas--there is a study that says that there are kind of four 
key areas that will constitute approximately 75 percent of the 
economic increase coming with GenAI. One of those is in R&D, 
and in software development being the other.
    And so I think that applies, unfortunately, equally to the 
bad guys as it does the good guys.
    Mr. Fallon. Yeah. Nobody has ever accused the DOD of being 
highly efficient. They are large. But when you have 
inefficiencies, you are talking about wasting billions of 
taxpayer dollars. Particularly when we are in a competition 
with China, that is even more troubling, and we need to address 
it.
    We might envision AI with future wars being fought by 
robots and such, but within the walls itself, these walls, Mr. 
Wang, in your opinion, can the Department of Defense use AI to 
extract efficiencies in programming and budgetary activities?
    Mr. Wang. For sure. One of the areas that we have already 
worked with some of our DOD customers on is using artificial 
intelligence and large language models to help digest 
requirements that are given by the DOD.
    There are so many groups within Department of Defense that 
are generating requirements, and matching those requirements up 
with capabilities in the private sector or new capabilities 
that the DOD develops is an incredible efficiency--potential 
efficiency gain.
    There is hundreds, if not thousands, of applications like 
that of artificial intelligence towards making the DOD a more 
efficient organization. So I am incredibly optimistic about the 
ability to use AI, whether it is in logistics, back-office, you 
know, in personnel-related matters, to build a more efficient 
force that wastes fewer resources and ultimately is able to 
have more force projection capability.
    Mr. Fallon. Think that the same thing holds for, you know, 
increased accountability with DOD contracting and spending?
    Mr. Wang. I think that there is--you know, if you think 
about what the limitations are or what the challenges are, it 
is in processing huge amounts of information and data that is 
being generated by the DOD to, you know, understand not only 
how funds are being used but also understand what the 
capabilities that are being generated are.
    And so if you think about that problem set, it is one that 
is naturally suited for artificial intelligence and for the use 
of these large language models.
    Mr. Fallon. Doctor, you know, when you talk about AI, my 
mind starts to bend and hurt and break a little bit because it 
is just so intriguing. But when we just talk about basic 
concepts of some of the technology we have grown accustomed to, 
like with social media, some folks, believe it or not, in this 
building, on the other side of the building, don't grasp even 
those--I mean, I remember a major State's governor saying that 
we should use Tweeter more, didn't even get the name right.
    And one of the Senators I think I remember saying, like, 
``How can they post a picture on the line?'' Things like that. 
So while that is funny, it is also troubling that if they are 
not grasping basic concepts, and you talk about AI, which is 
this stuff on, you know, hyper-steroids, how do we go about 
best educating our colleagues and the American public on AI and 
assuage some of the fears associated with it?
    Dr. Mahmoudian. So when we are thinking about the education 
side of it, we need to understand that this education needs to 
be tailored towards people's needs. So depending on their 
roles, depending on their responsibilities, we need to tailor 
that education for them.
    To give you an example, for senior leaders who may not be 
technical, we need to come up with an education that lets them 
know what AI is, exactly to your point, what it is capable of, 
what its limitations are, versus someone who is technical. 
Let's say a data scientist. For them, that would be a different 
story. We can have a more technical education for them, but 
also having this tech education in a continual form as AI 
evolves.
    Mr. Fallon. So almost like how it can help them 
specifically and make their lives a little bit better.
    Dr. Mahmoudian. Exactly.
    Mr. Fallon. Yeah.
    Thank you, Mr. Chairman. I yield back.
    Mr. Gallagher. Mr. Ryan is recognized for 5 minutes.
    Mr. Ryan. Thank you, Mr. Chair.
    Good morning. Thank you all for being here and for your 
insights. I wanted to build on some of your--to start building 
on some of your written testimony, Mr. Wang. You talked about 
data as the ammunition in AI warfare. You talked about what 
some of our adversaries, particularly China, are doing.
    And then you were--and I appreciate it--candid about areas 
where we need to improve. Can you talk about, based on your 
specific experience and your companies working with DOD, who is 
doing relatively better? What are the lessons we can learn in 
terms of--and also, if you could talk a little bit about CDAO 
and how you see that intersecting here so that we can recognize 
the imperative around wrapping our arms around our data better.
    Mr. Wang. Certainly. So the groups that we work with, by 
nature of, you know, us generally working with the more 
forward-leaning groups within the DOD, are forward-looking. 
They are extremely innovative, and they have incredible--in 
terms of taking on this technology as a key part of their go-
forward strategy and building impressive capabilities.
    So, you know, we have worked with many of the early 
programs in the DOD for use of AI. And by and large, we have 
been--I have been incredibly impressed. That being said, I 
think now is an opportunity for us to build on those successes 
and really take this moment in the technology and speed up our 
deployment.
    It is incredibly important that we build on our past 
successes, that we are able to more scalably deploy this 
technology across the entire DOD rather than being limited to, 
you know, a few innovative cells within the DOD.
    As I mentioned a bit ago, the DIU and the CDAO have been 
some of these areas, some of the groups within the DOD that 
have been able to have fast procurement cycles and generally 
innovate when it comes to use of artificial intelligence. But 
that needs to happen across the entire Department of Defense.
    Lastly, just on the CDAO, I think they have done--you know, 
it is a recently established organization, but they have done a 
good job of pushing forward in building, you know, the right--
pushing forward the topic of data labeling and the central data 
repository for the DOD. And now I think we need to ensure that 
that actually happens in terms of collecting this 22 terabytes 
of data that are being generated every day.
    Mr. Ryan. Thank you.
    And just to build on that and bring in anyone else who 
wants to add here, is it even possible to do that from the top 
down? I mean, I understand the importance of setting the right 
tone and direction. But if we think that creating a new office 
is--it is necessary, but I would argue not sufficient, to 
really--if we are serious about wrapping our arms around this, 
it should be emphasized and trained and reinforced that--much 
more broadly.
    Do you agree with that? Any ideas from anybody on how to do 
that, particularly looking at how others, adversaries or 
allies, are doing it?
    Mr. Wang. A combination of top-down and bottoms-up is 
necessary here because the individuals who are making the 
decisions of, you know, when they get a new hard drive off of a 
military platform and they need to make the decision on what 
they are going to do with that hard drive, we need all the way 
down to that individual to understand that hard drive is full 
of data that will fuel the future of American military 
leadership.
    And so they need to understand that as viscerally as we do 
from a tops-down perspective within the CDAO or the--you know, 
within this conversation. So it requires a whole-of-DOD 
approach to be able to properly achieve this outcome.
    Mr. Kitchen. Congressman, the one thing I would add is that 
as we tackle these difficult challenges--and they are legion--
that just from a mentality standpoint, I would encourage 
Congress and the U.S. Government to approach these as 
challenges that have to be managed, not solved.
    If we make the perfect the enemy of the good, if we try to 
find the exquisite solution, we will so delay ourselves as that 
we will miss the opportunity. And that's one of the kind of key 
narratives I am really trying to emphasize, is that we really 
do have a meaningful strategic opportunity. And these 
guardrails and everything, they matter. They really do.
    But as we approach these things, seizing the opportunity, I 
think, is probably one. And then doing it well and carefully is 
a part of that, but it cannot be the goal by which we have to 
leap over before we begin.
    Mr. Ryan. I appreciate and agree.
    Just very briefly, Dr. Mahmoudian and anyone else, 
particularly talking--you hit on it all a little bit, but--we 
are talking about DOD, but how--your sense of, in the research 
realm, academic realm, how are we doing there? What can we do 
better? I think I could guess, but----
    Dr. Mahmoudian. So we can definitely--when you are 
investing in the research side of it, it opens the door for us 
on the innovation side to also invest in research on the safety 
aspect of it, on these guardrails that was mentioned.
    So we need to--when we are investing in the research, we 
need to consider both in parallel in order to make sure that we 
are always ahead of it.
    Mr. Ryan. Thank you.
    I yield back, Mr. Chair.
    Mr. Gallagher. We will now move to a second round of 
questions. I will begin by recognizing myself for 5 minutes.
    I want to return to Mr. Gaetz's question about key allies 
in the AI competition. You all mentioned, you know, our most 
obvious allies. I mean, I think you are right. I am not 
detracting from that answer--Five Eyes, NATO, EU [European 
Union].
    I would like to invoke Jared Cohen's concept of sort of 
geopolitical swing states, perhaps countries that may not fit 
neatly within the free world paradigm. What are the emerging AI 
superpowers that we may not be thinking about, or let's just 
say states that punch above their weight when it comes to AI, 
that we need to be cultivating and ensuring they are not 
Finlandizing in the Chinese Communist Party direction?
    I will start with you, Mr. Wang.
    Mr. Wang. I do think it is really important, you know, as 
we--as AI sort of promises to be one of the most important 
technologies both economically and militarily, there are a 
myriad of countries that are all getting involved.
    Kind of as I mentioned, the UAE has a very dedicated effort 
towards artificial intelligence. They have open-source models. 
You know, they are continuing that series of developments 
towards building bigger and more powerful AI models. We don't 
know if they are going to open-source them, but we will see. I 
think it is important that, you know, as they develop those, 
that we try as hard as we can to make sure those follow our 
principles and our governance regimes.
    India is another key country, obviously, you know, very 
critical when we think about geopolitical allies. But also as 
you think about their developments in AI, they have an 
incredibly active tech sector, and they have stated efforts to 
develop large language models within their country.
    So, you know, these are some of the countries I would say 
that, from an AI perspective, seem to be racing ahead and ones 
that we want to ensure are thinking about artificial 
intelligence and its impacts in the same ways that we are as a 
country.
    Mr. Gallagher. Mr. Kitchen.
    Mr. Kitchen. I would agree completely. I think this affects 
the way we think about our relationships. So right now our 
technology supply chain is distributed in such a way as to 
where there are critical vulnerabilities. Many of the key nodes 
are deep within Chinese sphere of influence.
    And where I think we are going to be going is we are going 
to try to build trusted technology ecosystems amongst trusted 
partners and allies; that the idea is that we identify 
particularly Western democracies as being the type of 
organizations that we can partner with so that we have mutually 
beneficial trade and technology relationships that are the core 
of future national security partnerships.
    That requires, however, a common purpose and common 
understanding of the opportunities and the challenges. One of 
the things I am most concerned about is where many of our 
friends and allies are in the European Union particularly on 
this issue. So my point there being that when we think about 
military interoperability in these types of alliances, we also 
need to understand that military interoperability is going to 
be predicated on regulatory interoperability.
    And that is where we have a real gap between us and some of 
our key friends. The European Union seems to have concluded 
that to build their own domestic technology base, they have to 
deliberately constrain, and at times even decouple, from the 
American technology base. And that will not work for our shared 
purposes and is going to be a real problem going forward.
    Mr. Gallagher. Good point.
    Dr. Mahmoudian.
    Dr. Mahmoudian. So I completely agree with other witnesses 
with regards to alliance. One of the things that we need to 
understand, also, that for those type of swing states that was 
mentioned, we need to also think about how we can align 
ourselves to them to make sure that their advancement in AI is 
also aligned to the United States so we would have that 
alliance with them, rather, while we are ensuring that we are 
still the leader in this space.
    Mr. Gallagher. Mr. Kitchen, you mentioned in written and 
oral testimony that we--on hardware, we have a strong 
bipartisan consensus allowing us to constrain China's 
advancement.
    There has been some suggestion--and maybe put on the Select 
Committee on China hat here--as we engage with Silicon Valley 
leaders, that while we admire the GPU [graphics processing 
unit] export controls--in fact, we're able to bring Japan and 
the Dutch along with us was great, and I give the Biden 
administration credit for that--there is loopholes whereby they 
are still able to access a tranche of these sort of second-
most-advanced chips right now.
    I am curious for your comments on that and, Mr. Wang, yours 
as well. And I recognize I have run out of time here.
    Mr. Kitchen. Yeah. So this goes to my previous point about 
an iterative process. I think that you were referencing the 
October 7 rules, the export control on integrated chips. That 
was the first tranche, and now we are beginning to kind of 
optimize and tighten those controls.
    It is not a surprise that government and industry are doing 
a bit of back and forth on this. I think there is a growing 
recognition between both stakeholders that action is necessary, 
and now we are trying to find the right way forward. I have 
high confidence that we will do that.
    Mr. Gallagher. Quickly, Mr. Wang.
    Mr. Wang. It is true. You can see reports that ByteDance 
and other Chinese companies have bought billions of dollars of 
GPUs in the past, you know--in this year so far. So it is 
something that we need to be extremely careful and vigilant 
about.
    Mr. Gallagher. Mr. Khanna.
    Mr. Khanna. Thank you.
    When Chairman Gallagher and I had that conversation with 
Elon Musk, he said that AGI [artificial general intelligence] 
was 5 to 6 years away. I was surprised by that timeline. What 
is your sense of how long we are from AGI?
    Mr. Wang. AGI is an ill-defined concept. And, you know, I 
think many----
    Mr. Gallagher. Could you define it, since we are not doing 
acronyms? You are the guy. Sorry.
    Mr. Wang. AGI stands for artificial general intelligence, 
you know, the idea that we would build an AI that is sort of 
generally intelligent in the way that humans are. It is not a 
super well-defined concept because, you know, even in using the 
current AI systems, you will notice clear limitations and 
issues and challenges that they have with doing even things 
like basic math.
    AGI as a concept is an enticing one that we in Silicon 
Valley talk about a lot, but I don't think it is very well 
defined and not something, certainly, that should meaningfully 
affect how we think about, you know, putting one foot in front 
of the other for not only economic leadership as well as 
military leadership.
    The reality is that the technologies today--large language 
models, computer vision technology, and other AI systems that 
are being developed and deployed today--have immense bearing on 
the future of our world, whether that is from an economic 
perspective or from a military perspective. And that is why I 
think it is important that we set the foundations today of 
investing into data, investing in testing and evaluation, to 
set up the foundations for long-term success.
    My last comment as it comes to AGI prediction timelines--I 
think this is often a way to sort of distract from the current 
conversation, which is, in my mind, very important.
    Mr. Khanna. Mr. Kitchen or Dr. Mahmoudian?
    Mr. Kitchen. Yeah. I think Alex is exactly right. The idea 
of artificial general intelligence--I think what we will be 
seeing is increasingly agile and capable foundation models, or 
these types of generative AI capabilities, that are going to be 
more broadly applicable.
    So one of the features of these foundational models is 
something that is called emergent capabilities. It is the idea 
that we created this algorithm or this foundation model to be 
able to do a particular task, and lo and behold, it actually 
can do this other thing without having been trained to do so. 
So we are going to see that. That is a common feature.
    But I would say that the timeline that was given to you 
about artificial general intelligence in the next 5 years is 
aspirational.
    Mr. Khanna. If it is good.
    Dr. Mahmoudian. Similar to the previous comments, it is 
aspirational. But what I would add to that is we are headed to 
that direction. We see, as mentioned, with regard to foundation 
models, these type of models that can provide tasks that they 
were not necessarily trained on, but they can generalize to 
some extent.
    However, while we are heading into that direction--
obviously, not in 5 years--but we need to also invest--while we 
are investing on the research side of it, we also need to 
invest in the guardrails, the safety aspects of it, to make 
sure that we are able to mitigate the risks that we are 
anticipating with regards to artificial general intelligence.
    Mr. Khanna. Maybe I will quickly ask my last question, 
which is, do you think we need any DOD clearance for any types 
of AI like we have for nuclear technology? There are 
safeguards. There is only so many people who can get access to 
it.
    Mr. Wang, is there anything analogous in the AI space?
    Mr. Wang. So as we think towards military AI systems, so 
much of the next generation of capabilities are going to need 
to be built and trained on top of already classified data. So 
there is already an existing sort of structure and regime to 
protect any models that are trained on classified data, whether 
it is at the secret or top secret or even beyond level, to 
ensure that those capabilities sort of stay limited to certain 
audiences and state controlled.
    I don't know if we need to build even more on that, but I 
think that it is certainly true that most of the exquisite 
capabilities that the DOD looks to build are likely to be 
developed at the secret or top secret level.
    Mr. Khanna. Thank you.
    Mr. Gallagher. Mr. Gaetz.
    Mr. Gaetz. I am interested in the integration of AI and 
human performance. We always are very touched whenever there 
is--we have casualties that are in training or otherwise that 
are preventable.
    What have any of you learned about where some of the 
potential lies in utilizing AI in integration with sensor 
technology and other types of human performance capabilities?
    Mr. Wang. You know, one of the areas where artificial 
intelligence, I think, has some of the most greatest promise is 
in--as Mr. Kitchen mentioned before, is actually in logistics.
    So if you look at one of the largest causes of casualties, 
it actually was in, you know, transporting fuel and other 
resources for the military. This is an area where autonomous 
vehicles or even leader-follower setups are able to greatly 
improve the efficiency as well as reduce casualties for the 
military and is one of the goals of the Army's Robot Combat 
Vehicle program that we are collaborating with them on.
    As we look further, these AI systems are assistive 
technologies in--with our Scale Donovan platform, we are able 
to assist in key decision-making. This is being utilized right 
now in military planning exercises to help ensure that all of 
the data and information that the DOD has access to is being 
integrated into the correct military decisions.
    So there is an incredibly bright future, I think, for 
assistive use of artificial intelligence to make the DOD more 
effective.
    Mr. Kitchen. This is one of the most exciting things about 
AI, in my view, is its ability to help expand human thriving. 
So, many will have seen a commercial with one technology 
provider whose--their phone could help users who have speech 
pathologies or difficulties communicate more effectively. The 
OpenAI--their ChatGPT has a function for vision-impaired 
individuals where it describes images for them so they can 
participate in knowledge gain and application.
    And then, when we think about in the military context, I 
mean, it is going to be the AI underlying technology and 
capability that enables everything from allowing paraplegics to 
walk again to bring injury prevention and recovery. I mean, the 
things that this technology--again, I am not an idealist on 
this, but the promise is real, and what it means for our 
society just in general, I think, is very promising.
    Mr. Gaetz. As the son of a paraplegic mother, that is an 
inspiring concept.
    Doctor, I wanted to ask a little different twist on that 
question to you. I have talked with my colleague Mr. Khanna to 
some degree about how we ought to measure the soft-power 
capabilities of some of these AI platforms. How is it that 
ethicists are thinking about what it would mean for the United 
States, as opposed to China, to be the leader in deploying 
100,000 AI robot doctors into Africa or Latin America or 
somewhere else in the Global South?
    Dr. Mahmoudian. It is all about how we want to have our 
values embedded into these AI systems. When we are thinking 
about these principles, one area that especially the DOD has is 
these system to be governable. So depending on the level of 
risk that these systems pose, we want to have oversight.
    In some cases, the risk is low, so we may want to let the 
AI make the decision. Imagine a benign example being 
recommending a movie that might be bad. But in specific cases, 
especially the ones that are lethal, we do not want the AI to 
make the decision. We want human oversight.
    We want AI to be used to provide us information, patterns 
that we may have not seen. So we would use those information, 
and us humans would be able to make the judgment. So these are 
elements that we need to consider when we are thinking about 
these----
    [Simultaneous speaking.]
    Mr. Gaetz. That will substantially impact scalability and 
just the scale of being able to deploy the tech, I would think.
    Dr. Mahmoudian. If we have comprehensive governance 
processes, actually, this does not necessarily be viewed as an 
obstacle with regards to scalability. A robust and 
comprehensive governance process actually enables us to have 
standards and policies in place that can easily apply to any AI 
use case that we have.
    So with that foundation of AI governance, we would be able 
to replicate the process for any AI use case that we have.
    Mr. Gaetz. Thank you.
    And I haven't given you enough time to answer this 
question, Mr. Wang, but one of the things that I am sure we 
would like to explore with you further is, when we get into 
this test and evaluation paradigm that you keep coming back to 
in your testimony, that it is important for us to get a concept 
of what the core principles of that test and evaluation regime 
would look like. And I hope you will continue to work with the 
subcommittee on that.
    Yield back.
    [The information referred to can be found in the Appendix 
on page 123.]
    Mr. Gallagher. I am sorry. I am going to do a third round, 
but it will go very quick. Trust me. And I am going to apply 
the--what I call the justice test, which is a reference to my 
96-year-old grandmother, Virginia Justice. She is very smart 
but is not even a member of the flip-phone generation, let 
alone the AI generation.
    So I want you to imagine you are sitting across from my 
grandma. Each have an old fashioned in hand. Her late husband 
is a World War II vet. You need to explain to her why a--what 
she needs to know about AI, why this conversation matters both 
for the future of warfare as well as her life and the lives of 
her children and grandchildren. What do you say to the great 
and beautiful Virginia Justice?
    Mr. Wang. If we look towards World War II and the last era 
of conflict, new technologies like the atomic bomb were 
critical in ensuring that we both had American leadership and 
that the values that America upholds were able to continue to 
prosper and set the tone for the development of the world.
    We are now embarking on a new era of the world, one in 
which a new technology, artificial intelligence, is likely to 
set the stage for, you know, the future of ideologies, the 
balance of global power, and the future of the relative peace 
of our world.
    Artificial intelligence is an incredibly powerful 
technology that underpins nearly everything that we do from an 
economic and military standpoint, and therefore, it is critical 
that we as a Nation think about how we not only protect our 
citizens from the risks of artificial intelligence but also 
protect our ideologies and democracy by ensuring we continue to 
be leaders.
    Mr. Gallagher. Mr. Kitchen.
    Mr. Kitchen. Ma'am, there is a new technology that, under 
the right circumstances, could protect your grandchildren and 
this Nation, that could make this Nation economically and 
militarily strong enough to defend its people and its 
interests, and a technology that in the wrong hands could 
imperil those same things. And it is really important that your 
government and industry work together to realize those promises 
and to mitigate those threats.
    Mr. Gallagher. Great.
    Dr. Mahmoudian.
    Dr. Mahmoudian. It is a technology that is pretty much 
embedded in our day-to-day lives. We are living with it. We are 
breathing with it. So we want to make sure that this technology 
that is part of our life has its--our values, the values that 
we fought for, is incorporated into this technology so we still 
would have our civil liberties and civil rights as well as 
using this technology and leveraging it to have a better 
quality of life.
    Mr. Gallagher. Great.
    By the way, it just occurred to me, though I love being a 
Gallagher, if I had my mother's maiden name, Justice, I mean, I 
would probably be President at this point. That is such a 
better----
    Mr. Khanna. And a progressive.
    Mr. Gallagher. Well played.
    Any other questions? Okay. A bit of housekeeping before we 
adjourn. I want to enter three things into the record quickly. 
The first is the article I referenced before by Jared Cohen on 
geopolitical--the rise of geopolitical swing states, published 
on May 15, 2023.
    [The article referred to is retained in the committee files 
and can be viewed upon request.]
    Mr. Gallagher. The second is something that you, Mr. Wang, 
wrote in November of last year on the AI war and how to win it, 
in which you say, ``We must recognize that our current 
operating model will result in ruin. Continuing on our 
trajectory for the next 10 years could result in us falling 
irrevocably far behind. Why do large organizations often 
continue on the path to their demise, even if the future is 
painfully obvious? The reason is inertia. Bureaucracies will 
continue to glide deep into the abyss for an eternity.''
    [The information referred to can be found in the Appendix 
on page 83.]
    Mr. Gallagher. And then the third is a recent article by 
Marc Andreessen, which articulates the optimistic case for AI, 
entitled ``Why AI Will Save the World,'' in which he says, 
``The single greatest risk of AI is that China wins global AI 
dominance and we, the United States and the West, do not. I 
propose a simple strategy for what we do about this, in fact, 
the same strategy President Ronald Reagan used to win the first 
Cold War with the Soviet Union, which is we win and they 
lose.''
    [The information referred to can be found in the Appendix 
on page 97.]
    Mr. Gallagher. So I ask unanimous consent to enter all 
three of those into the record.
    Without objection, so ordered.
    I ask unanimous consent that members have 5 days to submit 
statements for the record.
    And the hearing stands adjourned.
    [Whereupon, at 10:31 a.m., the subcommittee was adjourned.]



      
=======================================================================



                            A P P E N D I X

                             July 18, 2023

=======================================================================

      



      
=======================================================================


              PREPARED STATEMENTS SUBMITTED FOR THE RECORD

                             July 18, 2023

=======================================================================

      

      
    [GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT] 
    
    
      
=======================================================================


                   DOCUMENTS SUBMITTED FOR THE RECORD

                             July 18, 2023

=======================================================================

      

      
    [GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]  

      
=======================================================================


              WITNESS RESPONSES TO QUESTIONS ASKED DURING

                              THE HEARING

                             July 18, 2023

=======================================================================

      

             RESPONSE TO QUESTION SUBMITTED BY MR. KEATING

    Mr. Wang. Scale is committed to working with your office, and the 
Committee to address this critical topic.   [See page 10.]
                                 ______
                                 
              RESPONSE TO QUESTION SUBMITTED BY MR. GAETZ
    Mr. Wang. Thank you for that question, and I look forward to 
working with the Subcommittee and DOD to put in place a comprehensive, 
risk-based, test and evaluation framework to ensure that AI is safe to 
deploy.   [See page 30.]

                                  [all]
</pre></body></html>
