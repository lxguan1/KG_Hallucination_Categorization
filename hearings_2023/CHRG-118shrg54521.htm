<html>
<title></title>
<body><pre>
[Senate Hearing 118-208]
[From the U.S. Government Publishing Office]


                                                        S. Hrg. 118-208

                       AI AND THE FUTURE OF WORK:
                        MOVING FORWARD TOGETHER

=======================================================================

                                HEARING

                               BEFORE THE

                     SUBCOMMITTEE ON EMPLOYMENT AND WORKPLACE 
                                  SAFETY

                                 OF THE

                    COMMITTEE ON HEALTH, EDUCATION,
                          LABOR, AND PENSIONS

                          UNITED STATES SENATE

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             FIRST SESSION

                                   ON

                  EXAMINING AI AND THE FUTURE OF WORK

                               __________

                            OCTOBER 31, 2023

                               __________

 Printed for the use of the Committee on Health, Education, Labor, and 
                                Pensions
                                
[GRAPHIC NOT AVAILABLE IN TIFF FORMAT]                                


        Available via the World Wide Web: http://www.govinfo.gov
        
                             __________

                   U.S. GOVERNMENT PUBLISHING OFFICE                    
54-521 PDF                  WASHINGTON : 2024                    
          
-----------------------------------------------------------------------------------             
       
          COMMITTEE ON HEALTH, EDUCATION, LABOR, AND PENSIONS

                 BERNIE SANDERS (I), Vermont, Chairman
PATTY MURRAY, Washington             BILL CASSIDY, M.D., Louisiana, 
ROBERT P. CASEY, JR., Pennsylvania       Ranking Member
TAMMY BALDWIN, Wisconsin             RAND PAUL, Kentucky
CHRISTOPHER S. MURPHY, Connecticut   SUSAN M. COLLINS, Maine
TIM KAINE, Virginia                  LISA MURKOWSKI, Alaska
MAGGIE HASSAN, New Hampshire         MIKE BRAUN, Indiana
TINA SMITH, Minnesota                ROGER MARSHALL, M.D., Kansas
BEN RAY LUJAN, New Mexico            MITT ROMNEY, Utah
JOHN HICKENLOOPER, Colorado          TOMMY TUBERVILLE, Alabama
ED MARKEY, Massachusetts             MARKWAYNE MULLIN, Oklahoma
                                     TED BUDD, North Carolina

                Warren Gunnels, Majority Staff Director
              Bill Dauster, Majority Deputy Staff Director
                Amanda Lincoln, Minority Staff Director
           Danielle Janowski, Minority Deputy Staff Director
                                 ------                                

            SUBCOMMITTEE ON EMPLOYMENT AND WORKPLACE SAFETY

                 JOHN HICKENLOOPER, Colorado, Chairman
ROBERT P. CASEY, JR., Pennsylvania   MIKE BRAUN, Indiana
TAMMY BALDWIN, Wisconsin             ROGER MARSHALL, M.D., Kansas
TIM KAINE, Virginia                  MITT ROMNEY, Utah
BEN RAY LUJAN, New Mexico            TOMMY TUBERVILLE, Alabama
ED MARKEY, Massachusetts             TED BUDD, North Carolina
BERNIE SANDERS (I), Vermont, (ex     BILL CASSIDY, M.D., Louisiana, (ex 
    officio)                             officio)
                            
                            
                            C O N T E N T S

                              ----------                              

                               STATEMENTS

                       TUESDAY, OCTOBER 31, 2023

                                                                   Page

                           Committee Members

Hickenlooper, Hon. John, Chairman, Subcommittee on Employment and 
  Workplace Safety, Opening statement............................     1
Braun, Hon. Mike, Ranking Member, U.S. Senator from the State of 
  Indiana, Opening statement.....................................     3

                               Witnesses

Billingsley, Tyrance, Founder and Executive Director, Black Tech 
  Street, Tulsa, OK..............................................     5
    Prepared statement...........................................     7
Lannin, Josh, VP of Productivity Technologies, Workday, Boulder, 
  CO.............................................................    12
    Prepared statement...........................................    13
Morley Ryan Mary Kate, Managing Director of Talent and 
  Organization, Accenture, St. Louis, MO.........................    19
    Prepared statement...........................................    20
Newman, Bradford, Partner/Leader of the AI Practice, Baker & 
  McKenzie LLP, Co-Chairman, The AI Subcommittee for the American 
  Bar Association, Palo Alto, CA.................................    24
    Prepared statement...........................................    26

                          ADDITIONAL MATERIAL

Statements, articles, publications, letters, etc.
Hickenlooper, Hon. John:
    IBM, Statement for the Record................................    47
    NSC, Statement for the Record................................    49
Casey, Hon. Robert:
    The Promise and the Peril of AI in the Workplace by Matthew 
      Shearer....................................................    54

                        QUESTIONS FOR THE RECORD

Response by Tyrance Billingsley to questions of:
    Senator Lujan................................................   125
Response by Josh Lannin to questions of:
    Senator Lujan................................................   127
Response by Mary Kate Morley Ryan to questions of:
    Senator Lujan................................................   128

.                     
                       AI AND THE FUTURE OF WORK:
                        MOVING FORWARD TOGETHER

                              ----------                              


                       Tuesday, October 31, 2023

                                       U.S. Senate,
           Subcommittee on Employment and Workplace Safety,
       Committee on Health, Education, Labor, and Pensions,
                                                    Washington, DC.
    The Subcommittee met, pursuant to notice, at 10 a.m., in 
room 430, Dirksen Senate Office Building, Hon. John 
Hickenlooper, Chairman of the Subcommittee, presiding.

    Present: Senators Hickenlooper [presiding], Casey, Kaine, 
Braun, and Budd.

               OPENING STATEMENT OF SENATOR HICKENLOOPER

    Senator Hickenlooper. [Technical problems]--let's try that 
again. The Committee on Employment and Workplace Safety will 
come to order.

    Today we are discussing the future of AI and its impact on 
the workforce. One of our expectations is to show that there 
will--that there is nothing to be afraid of in this future. 
Ranking Member Braun and I will each give an opening statement. 
Then we will introduce the witnesses.

     After the witnesses give their testimony, Senators will 
have 5 minutes for a round of questions. Now, it is no secret 
that artificial intelligence is having a moment in all of our 
lives in myriad ways, and the workplace is certainly no 
exception.

    Just yesterday, President Biden signed an Executive Order 
focused on AI governance, a critical step in our Nation's 
overall approach to how we integrate AI into a larger and 
larger parts of our life.

    This is just the beginning. To make sure our workforce is 
positioned for success, we want to know how AI is being adopted 
and how AI is being used in the workplace. This is going to 
help us understand how we can ensure that workers are trained, 
that they have sufficient training, and that they are empowered 
to maximize the potential of this rapidly evolving technology.

    According to a recent Pew study, nearly 6 in 10 workers, 
when they were contacted, had interacted with an AI system or 
application in their workplace just in the last year, and we 
know that is just the beginning. This number will continue to 
rise. AI technology has been a part of our daily lives for 
years, from my phone's text suggestion functions, to search 
engines' ability to recommend top results.

    But now generative AI systems like ChatGPT are coming to 
the stage where they can assist us with writing our emails, 
making travel plans, quickly analyzing large datasets, even 
increasing the artwork we surround ourselves with.

    This technology has the potential to positively alter the 
way that literally all of us work, but I think we have an 
imperative to do it right, to make sure we are not making 
missteps as we move so rapidly in this direction. I think 
working together and including workers in that conversation is 
essential.

    Maybe that is the most important point we can make today. 
Many people think of movies where AI replaces humanity. I think 
the reality in many cases will be that AI will work hand in 
hand with the workforce, the people that are actually doing the 
work.

    Just look at some of the most popular AI applications we 
are seeing, how they are being used. I mean, ChatGPT is great, 
but it requires input from a worker who has a combination of 
subject matter expertise and a decent level of AI literacy.

    He has got to be able to give the system clear and direct 
prompts--make sure that it is being directed properly. Got to 
monitor the output for inaccuracies that are not as rare as 
they hopefully will become.

    This is all part of why it makes it so important that we 
make sure that our workers across all industries are active 
partners in this transition. We should make sure that we help 
our workers to gain the relevant and essential skills, to gain 
the training that they are going to need to be able to succeed 
in this transition. In some ways, it is a tale as old as time. 
We don't call plumbers just because a wrench is hard to use.

    We call them because they have mastered how to use that 
wrench to solve all manner of problems, and they have learned 
how to recognize the essential elements of each specific 
problem. Now, Bob Dylan and I both play the banjo, but even if 
we pluck the same notes, I think you would recognize that you 
would be missing the magic.

    If you were listening to Bob he and any great musician 
bring a certain order and magic to what they do. No different 
than what a plumber does when he walks in and can unravel the 
most complex issues in your house. So, whatever the tools are, 
it is still workers that are using them and creating the magic.

    Their skills, their training is what is going to make the 
difference. And that is why we have got to find smart workforce 
development opportunities around AI that are inclusive, that 
lift up the skills of all our workers to make sure that 
everyone thrives, everyone has the opportunity to create their 
own better future, their own career.

    Today's hearing is going to provide an opportunity for us 
to hear from some terrific experts who have been considering AI 
implementation in a variety of contexts and have direct 
experience of how these efforts to train and upskill our 
workers are succeeding at some of the challenges we face.

    Our goal today is to walk away with a better understanding 
of what AI integration looks like in work workplaces around 
different industries, the role both public and private sector 
leaders in fostering literacy and making sure that the training 
of the workforce of tomorrow continues unimpeded, what more 
needs to be done at a Federal level to make sure we all get it 
right.

    I think this Subcommittee is uniquely positioned to help 
identify how employers and workers can best understand, and 
maybe more importantly, leverage the AI tools that are at our 
disposal. After all, I think every Member in this room wants to 
make sure that AI technology remains a treat, not a trick.

    [Laughter.]

    Senator Hickenlooper. Before I introduce our panel of 
witnesses, I would also like unanimous consent--to ask for 
unanimous consent to enter two letters into the record. One 
from IBM and one from the National Security Council. No 
objections. Without objection.

    [The following information can be found on page 47 in 
Additional Material:]

    Senator Hickenlooper. With that, I would like to welcome 
each of our witnesses who are joining us today. Tyrance 
Billingsley is the Founder and Executive Director for Black 
Tech Street based in Tulsa, Oklahoma. There, he is leading the 
initiatives, community based approach to tech innovation and 
the economic development that leads to feet on the ground, real 
life experiences.

    Josh Lannin is the Vice President of Productivity 
Technologies at Workday, from my home State of Colorado. There, 
he leads Workforce's team through production of tech products, 
including AI technology systems. Workday has been a leader in 
adapting AI--from before people were even talking about AI.

    Mary Kate Morley Ryan serves as the Managing Director of 
talent organization Accenture, one of the leaders in the 
country in terms of facilitating the acquisition of the skills 
necessary to deal successfully with AI.

    At Accenture, she is focused on researching workforce 
transformation and inclusion in the future of work. Now, I 
recognize Ranking Member Braun to make his opening remarks, and 
then to introduce our final witness.

                   OPENING STATEMENT OF SENATOR BRAUN

    Senator Braun. Thank you, Mr. Chairman, all of you for 
being here, and I look forward to introducing you in a moment. 
Senator Hickenlooper and I come from a unique background, 
unusual for most individuals in the U.S. Senate.

    We actually spent a lot of time in the real world before we 
got here. We ran businesses. We were entrepreneurs by trade. 
And I look at the 37 years that I spent with a little, little 
business. I mean, it was so hardscrabble. It was 17 years with 
15 employees.

    But when I knew I had a tiger by the tail, that is when I 
had to start confronting technology, and the always extreme 
cost of it. And I am talking about dollar spent to get the 
latest and greatest, because in year 17, we were on RadioShack. 
I can tell you now that we employ a lot of custom coders.

    That little business grew from a regional one, then a 
national one with locations in most states. You learn a lot 
there. I learned to generally always say to my chief technology 
officer, which is my older son, my younger son runs the 
business as the CEO and CFO--we just quit saying no to that 
latest and greatest technology because we have leveraged it so 
well to differentiate ourselves from the competition.

    We are looking at AI. Would you do the same? Well, being an 
entrepreneur, when I watch to see whatever is hitting the 
market across the spectrum of our economy, and I have heard it 
forewarned by the people that put it out there more than 
anything I have ever observed in my time, being someone looking 
for that leading edge, what is that next best way to do 
something.

    It brings us to an interesting crossroads with something 
that looks like it can do so much, that can be so beneficial, 
but also looks like the malfeasance that could come from it 
forewarned by the people that know the most about it should 
give you pause. I am very concerned that we don't smother it. I 
think that we could do that easily.

    Generally, we overregulate here, and we get bureaucrats and 
folks that don't know how to get from here to there in the real 
world, making all the rules. So, we have got to be careful 
about that. What we see it can do and what we are being warned 
about that it may be used for the wrong purpose to me is the 
essence of the journey that we are on.

    All I can tell you is we are a lot more productive now in 
my own business, now that we have got the greatest and latest 
technology. I remember back when we were doing orders by hand 
on a RadioShack system.

    That is why I think in weighing how we get through this, we 
have got to err on the side of letting it breathe, letting it 
show what it can do, but also take into consideration what the 
people that know the most about it are giving us as an 
admonition to be careful with it. So, I think that is where we 
are today.

    As we apply it to how we can use it in the workforce, our 
economy grows by how much productivity we can leverage on the 
people that are in it itself. And over time, we always come 
into confrontations to where we are worried about what it is 
going to do to the economy because it will displace jobs.

    This is a little different because it can get into areas of 
creativity. You already see things like patent trolling. You 
see things that are trying to rob people of their--what they 
have created in other arenas in our economy.

    I think there is a lot there to be worried about. I do 
believe that hearings like this, and they are going to have 
many more in the Congress, are key to putting some type of 
framework of common sense regulation around it, keeping full in 
mind that we don't want to smother something that could be so 
beneficial to all of us. I will yield back.

    Senator Hickenlooper. Thank you, Senator Braun, and Ranking 
Member. I appreciate that perspective. And it is unusual in the 
Senate to have a chair and a co-chair of--that are both 
entrepreneurs. They are not as many entrepreneurs in the--in 
our Congress as there used to be, for whatever reason.

    Senator Braun. Need to be more, don't you think?

    [Laughter.]

    Senator Hickenlooper. Well, that is a bias we shouldn't be 
ashamed of. All right, now for our opening remarks, I will go 
from order from left to right.

    Senator Braun. Introduce the next witness. Are you going to 
do that?

    Senator Hickenlooper. Oh, yes. I am sorry. No, no, you do 
it now.

    Senator Braun. Okay. Yes. My pleasure to introduce Bradford 
Newman. Mr. Newman is a Litigate Partner, Resident in Baker 
McKenzie's Palo Alto Office, and Chair of the North American 
Trade Secrets Practice.

    Mr. Newman routinely advises and represents the world's 
leading technology, banking, professional service, 
manufacturing, and commerce companies in connection with their 
most significant data protection and trade secret matters. That 
is a lot. Among other subjects, Mr. Newman specializes in 
matters related to AI.

    He is the Chair of the AI Subcommittee of the American Bar 
Association and has been instrumental in proposing Federal AI 
workforce legislation, as well as developing AI oversight and 
corporate governance, best practices designed to ensure 
algorithmic fairness.

    Mr. Newman was also recognized as one of the top 20 AI 
attorneys in California in 2019. We welcome his expertise to 
the conversation today.

    Senator Hickenlooper. Welcome to you all. Appreciate that. 
I apologize, Mr. Newman, for slipping--moving too--I hit fast 
forward accidentally. So, we will start with Mr. Billingsley to 
give his opening remarks, and then go down the line.

    STATEMENT OF TYRANCE BILLINGSLEY, FOUNDER AND EXECUTIVE 
             DIRECTOR, BLACK TECH STREET, TULSA, OK

    Mr. Billingsley. Thank you, Mr. Chairman. I am appreciative 
to the Subcommittee on Employment and Workplace Safety for this 
opportunity to testify here.

    My name is Tyrance Billingsley II, and I am the Founder and 
Executive Director of Black Tech Street, an initiative to 
rebirth historic Black Wall Street as a Black innovation 
economy and catalyze a movement that sees Black Americans 
embrace technology as a wealth building and global impact 
mechanism.

    Black Tech Street was founded when I asked myself the 
question, what could Black Wall Street have been had it been 
supported and not destroyed? When I thought about the level of 
tenacity that it took for these Black entrepreneurs to build 
successful businesses during Jim Crow in my hometown of Tulsa, 
Oklahoma, I immediately saw parallels with the tech industry, 
and not long after, I came to a three pronged epiphany.

    One, tech is one of the only industries in which 
intergenerational wealth is generated in 7 to 10 years via a 
successful company exit. Two, tech is the core medium through 
which all global innovation takes place.

    Three, by the year 2030, there were projected to be as many 
as 4.3 million vacant, high paying tech jobs due to a tech 
talent shortage. After considering these three things, I not 
only saw an incredible wealth building opportunity for Black 
Americans, but I also saw the Black Wall Street vision pushed 
to a new horizon.

    I surmised that had Black Wall Street been supported and 
not destroyed, it would have been nothing other than the 
nation's premier Black innovation economy. Focusing on the 
three verticals of cybersecurity, business, intelligence, data 
analytics, and responsible artificial intelligence, Black Tech 
Street was founded on the premise that technology presents 
unparalleled economic opportunity.

    The key word here is responsible AI, and back in Oklahoma, 
we are taking a community first approach and not just relying 
on big tech to address how AI can be a responsible tool for the 
benefit of communities and entrepreneurs.

    To that end, our organization has brokered a holistic 
alliance with Microsoft to support the creation of 1,000 Black 
cyber and cyber adjacent professionals in Tulsa by the year 
2030. We facilitated the participation of over 70 Black Tulsans 
in the largest public AI red teaming exercise alongside CDI at 
DEF CON 31, and we co-led the Tulsa Hub for Equitable and 
Trustworthy Autonomy Consortium that recently received a U.S. 
Economic Development Agency's regional tech hubs designation 
alongside Tulsa Innovation Labs and the George Kaiser Family 
Foundation.

    While we believe that all of our work is critical, the 
conversation around AI is on an entirely different level of 
urgency and importance. Artificial intelligence will not just 
disrupt lives, it will remake the world. Perhaps most urgently, 
AI will fundamentally transform the workforce, which is the 
lifeblood of any well-functioning society and economy.

    In truth, the workforce will be the first area where we 
truly see the power--the transformative power of AI at scale, 
whether this be in the innovation economy, the creative 
economy, or one of the many other facets.

    Whether or not we ensure AI secures a beneficial 
arrangement for people in the future of work will set a 
precedent for how AI is administered in all facets of life. If 
the systems for AI in the workforce are designed in a human 
centered way, AI could be a tool to fundamentally alter the 
socioeconomic position of marginalized communities in this 
country, or it could exacerbate preexisting inequities in a way 
that are almost irreparable.

    To that end, I believe there are four critical guidelines 
that can help us ensure that the future of work built by AI is 
safe, equitable, and beneficial for the American worker and 
economy. One, approach the regulation of AI and the issues that 
surround it in the workforce and more broadly as a socio-
technical issue.

    Complex or wicked socio-technical issues are problems that 
resist solution despite repeated attempts, are difficult to 
describe or predict, are not addressable by single individuals 
or organizations, are not addressable in a single intervention 
and require multiple coordinated interventions, and the most 
critical question in them is discerning where to focus, 
followed by what to do, when, and how.

    Two, develop a worker centered AI social contract for the 
workforce that defines the rules of use and engagement as they 
relate to AI for both employees and employers, is rooted and 
framing and incentivizing AI as a copilot to enhance human 
creativity, productivity, and output.

    Sets the precedent for policies and systems that define how 
AI can and should be used in relation to workers as the most 
critical aspect of the future of work instead of just what the 
technology can do. And finally displays a stable framework for 
using AI to unleash human potential in a way that also leads to 
better profit and performance for companies.

    Three, over-index and incentivize training and education 
programs that target people of color and communities that have 
been historically left out of the technological revolution. 
Four, develop the framework for AI and the future of work in a 
way that strengthens the intersection between workforce and 
high growth, as well as small business entrepreneurship.

    I believe that these four guiding principles and the 
inclusion of communities like Tulsa in these conversations will 
be the keys to ensuring that we utilize AI to build a future of 
work that unleashes the true potential of the labor force, 
empowers the American economy of the 21st century. Thank you 
very much.

    [The prepared statement of Mr. Billingsley follows.]
               prepared statement of tyrance billingsley
    I am appreciative of the privilege to testify here today. My name 
is Tyrance Billingsley II and I am the Founder and Executive Director 
of Black Tech Street, an initiative to rebirth historic Black Wall 
Street as a Black Innovation Economy and catalyze a movement that sees 
Black Americans embrace technology as a wealth-building and global 
impact mechanism. Black Tech Street was founded when I asked myself, 
``What could Black Wall Street have been if it had been supported and 
not destroyed?''

    When I thought about the level of tenacity that it took for these 
Black entrepreneurs to build successful businesses during Jim Crow in 
my hometown of Tulsa, Oklahoma, I immediately saw parallels with the 
tech industry and not long after, I came to a three-pronged epiphany:

        1. Tech is one of the only industries in which 
        intergenerational wealth is generated in 7-10 years via 
        successful company exit.

        2. Tech is the core medium through which all global innovation 
        takes place.

        3. By the year 2030, there are projected to be as many as 4.3 
        million vacant high-paying jobs due to a tech talent shortage.

    After considering these three things, I not only saw the perfect 
wealth-building opportunity for Black Americans, but I also saw the 
Black Wall Street vision pushed to a new horizon. I surmised that if 
Black Wall Street were supported and not destroyed, it would be nothing 
other than the Nation's premiere Black Innovation Economy. Focusing on 
the three verticals of cybersecurity, business intelligence/data 
analytics and responsible artificial intelligence, Black Tech Street 
was founded on the premise that technology presents unparalleled 
economic opportunity.

    A key word here is responsible AI. And back in Oklahoma, we are 
taking a community-first approach and not just relying on Big Tech to 
address how AI can be a responsible tool for the benefit of our 
communities and entrepreneurs.

    To that end, this organization has brokered a holistic alliance 
with Microsoft to support the creation of 1000 Black Cyber and Cyber 
adjacent professionals in Tulsa by the year 2030, facilitate the 
participation of over 70 Black Tulsans in the largest public AI Red 
Teaming exercise at DEF CON 31, and co-lead the Tulsa Hub for Equitable 
and Trustworthy Autonomy consortium that recently received a U.S. 
Economic Development Agency Regional tech hubs designation alongside 
Tulsa Innovation Labs and the George Kaiser Family Foundation.

    While we believe that all of our work is critical, the conversation 
around AI is on an entirely different level of urgency and importance. 
Artificial intelligence will not just disrupt lives; it will remake the 
world. Perhaps most urgently, AI will fundamentally transform the 
workforce, which is the lifeblood of any well functioning society and 
economy. In truth, the workforce will be the first area where we truly 
see the power transformation of AI at scale, whether this be in the 
innovation economy, the creative economy or one of the many other 
facets.

    Whether or not we ensure AI secures a beneficial arrangement for 
people in the future of work will set a precedent for how AI is 
administered in all facets of life. If the systems for AI in the 
workforce are designed in a human centered way, AI could be a tool to 
fundamentally alter the socioeconomic position of marginalized 
communities in this country, or it could exacerbate pre-existing 
inequities in a way that is almost irreparable.

    To that end, I believe there are four critical guidelines that can 
help us ensure that the future of work built by AI is safe, equitable 
and beneficial for the American worker and economy.

        1. Approach the regulation of AI and the issues that surround 
        it in the workforce (and more broadly) as a sociotechnical 
        issue. Complex or ``wicked'' sociotechnical issues are 
        problems:

                <bullet>  That resist resolution despite repeated 
                attempts

                <bullet>  Are difficult to describe or predict

                <bullet>  Are not addressable by single individuals or 
                organizations

                <bullet>  Are not addressable in a single intervention 
                and require multiple co-ordinated interventions

                <bullet>  The most critical question is discerning 
                ``Where to focus?'' followed by what to do, when and 
                how.

        2. Develop a worker centered AI social contract for the 
        workforce that:

                <bullet>  Defines the rules of use and engagement as 
                they relate to AI for both employees and employers.

                <bullet>  Is rooted in framing and incentivizing AI as 
                a co-pilot to enhance human creativity, productivity 
                and output.

                <bullet>  Sets the precedent for the policies and 
                systems that define how AI can/should be used in 
                relation to workers as most critical to the future of 
                work vs what the technology can do or is capable of.

                <bullet>  Displays a stable framework for using AI to 
                unleash human potential in a way that also leads to 
                better profit and performance for companies.

        3. Overindex and incentivize training and education programs 
        that target POC and marginalized communities that have been 
        historically left out of technological revolutions.

        4. Develop the framework for AI and the future of work in a way 
        that strengthens the intersection between workforce and high 
        growth, as well as small business entrepreneurship.

    I believe that these four guiding principles and the inclusion of 
communities like Tulsa in these conversations will be the keys to 
ensuring that we utilize AI to build a future of work that unleashes 
the true potential of the labor force and powers the American economy 
of the 21st century.
          AI and the Future of Work: A Sociotechnical Approach
    With complex sociotechnical problems, the first issue at hand is 
often to discern ``where to focus''. The entirety of the questions 
around AI and how it will remake our world could be defined and, in my 
opinion, should be approached like a complex sociotechnical problem. 
However, ``AI and the Future of Work'' presents a specific subset of 
the issues that can be focused on, as it is the most imminent of the AI 
issues that will have a visible and tangible effect at scale.

    I believe that ``AI and the Future of Work '' is a sociotechnical 
problem in and of itself that needs to be addressed and can then 
provide a framework for addressing AI issues more broadly as it relates 
to ensuring the future we build is equitable, safe, trustworthy and 
beneficial.

    Albert Einstein said, ``If I had 20 days to solve a problem, I 
would take 19 to define it.'' Identifying a true problem can be 
difficult, especially in a complex sociotechnical problem, because 
there is rarely just one. In cases like these, we have to think in 
terms of two questions:

        1. ``Which problems are most urgent for me to solve?''

        2. ``Which problems are the ones that, if I solve or make 
        progress on, will have a domino effect on solving for the 
        greatest number of other problems due to the multifaceted and 
        interconnected nature of the issue I am tackling?''

    To answer these questions, one can use a method called ``catalytic 
factor analysis''. Catalytic Factor Analysis is based on a method 
designed to identify which keystone species in an ecosystem are 
critical to success, i.e., if a certain species were to flourish or 
flounder, would the overarching effect on the ecosystem be positive or 
negative in relation to the health of the ecosystem.

    It starts with a 5 step process of:

        1. Identify a ``North Star'' for AI and the Future of Work.

        2. Gather a room of key experts in AI and the workforce from 
        FOW thought leaders, policy experts, labor lawyers, human 
        rights activists and technologists to identify the root factors 
        relating to AI and workforce/the future of work.

        3. Have the experts collectively rank the problems in a survey 
        based on their ``catalytic'' nature and their urgency as it 
        relates to securing the ``North Star'' as it relates to AI and 
        the Future of Work.

        4. Conduct an exercise using a tool that utilizes catalytic 
        factor analysis to identify which factors in the system are 
        catalytic.

        5. Prioritize research, funding and public private sector 
        efforts to mobilize and solve (or take steps to solve) the 
        factors that were deemed catalytic.

    The thesis is that, with the opinion of the blended participants of 
experts from various fields touching AI and workforce, the outcome will 
be an accurate network map of catalytic factors that can be actioned 
against in various ways and from various players in the public and 
private sectors. This will allow the Federal Government and other 
stakeholders to know what to prioritize and where to pour funding and 
efforts in terms of solving the issues that are most urgent, as well as 
maximizing efficiency by tackling issues that will go the longest way 
in tackling others related to AI and the workforce overall.
                Workers Social Contract in The Age of AI
    Whether it be the SAG-AFTRA strike in Hollywood or the nuance 
around AI's use in the workplace of different industries, it is clear 
that there needs to be a workers social contract for AI that governs 
its use, both by the employee and the employer. The need for this is 
something that would likely be identified as a result of the study 
above if it were to be done; it is the baseline of the entire AI and 
the Future of Work conversation. At some point, there will need to be a 
new social contract for everyone as it relates to AI more broadly, but 
once again, the workforce will likely be the first example of how this 
plays out (and thus set the pace for the broader conversation).

    This contract has to not only govern AI in the workforce but also 
create a culture where AI is viewed as a copilot to enhance creativity 
and productivity, set the precedent in the public and private sectors 
of prioritizing how AI is used in relation to workers and work as most 
important vs just what the tech is capable of, and maximize both human 
potential and profitability for the companies.
  Overindexing Investment in Education and Training in POC Communities

    POC communities have historically been left out of technological 
revolutions that result in massive wealth and other socioeconomic 
disparities. The opportunity and dangers presented by AI could 
fundamentally alter the socioeconomic position of POC in America 
forever, and this can either be good or bad. If the funding and 
infrastructure are not sufficient to ensure that POC are educated, 
trained and proficient in AI prior to widespread adoption and further 
technological innovation, the economic effect could be catastrophic 
nationwide. Conversely, if the right care is taken, AI could be the 
catalyst that goes toward remedying many of the socioeconomic 
disparities that resist solution.
         AI Workforce and The Intersection of Entrepreneurship

    If sufficient care is taken to truly ensure AI is well applied to 
the future of work and the efforts are successful, the workplace will 
be the perfect place to build proficiency with AI in a way that will 
poise participants in the labor market to take up the entrepreneurial 
spirit and use their learned proficiency in AI to start small or high 
growth businesses based on their experiences. The higher the level at 
which we succeed as it relates to a framework for AI and the Future of 
Work, the better the backbone of the other parts of the American 
economy that depend on the labor force, such as entrepreneurship and 
academic research.
     Support for Fiscal Year 2024 Appropriations to Spur Innovation

    Last, none of these efforts will succeed without adequate 
government funding and support.

    In the immediate future, I urge Congress to support the following 
fiscal year 2024 appropriations to support organizations like Black 
Tech Street and Tulsa Innovation Labs back home in Oklahoma in their 
efforts to innovate:

        <bullet>  President Biden's fiscal year 2024 Budget Proposal 
        showed the administration's investment in science and 
        innovation through his proposed fiscal year 2024 budget 
        requests. As Congress seeks to finalize its NSF and CJS 
        budgets; as such please, consider fully funding the following 
        programs which provide Federal resources to support key 
        programs that aid Black Tech Street in transforming Oklahoma.

        <bullet>  The Department of Commerce, Justice and Science 
        Appropriations (``CJS''): The Senate Appropriations Committee's 
        CJS bill would provide $71.7B, $10.3B below the fiscal year 
        2023 enacted level, and $19.5B less than President Biden's 
        fiscal year 2024 budget request. While the House Appropriations 
        Committee has not passed a bill, the House subcommittee 
        approved the CJS bill for a total of $58.4B, which is $24.9B 
        below the current level, and $34.2B below President Biden's 
        fiscal year 2024 budget request.

    Within the CSJ, there are key programs that are vital to Black Tech 
Street and its partners.

    These include but are not limited to the following:


 
------------------------------------------------------------------------
                                                                 Black
    CJS        FY23        FY24        FY24 House      FY24       Wall
  Program     Final      President    Subcommittee    Senate     Street
                                                                Request
------------------------------------------------------------------------
Dept. of    $11.1B     $12.4B        $9.6B           $11.1B    $11.1B
 Commerce
------------------------------------------------------------------------
EDA         $1.6B      $804M         $255M           $466M     $804M
                       *$4B for
                        Regional
                       Tech Hubs
------------------------------------------------------------------------
Regional    $500M*     $4B                           $41M      $4B
 Technolog  *Funds to
 y and       jumpstar
Innovation   t
 Hub        program
 Program     in
             suppleme
             ntal
------------------------------------------------------------------------
Regional    $170M*     $300M                         $200M     $300M
 Innovatio  *Directed
 n           at least
Engines      $170M
 Program
------------------------------------------------------------------------
Minority    $68M       $110M         $55M            $70M      $110M
 Business
Developmen
 t Agency
------------------------------------------------------------------------
STEM        $1.2B      $1.4B         $2.5M           $2.5M     $2.5M
------------------------------------------------------------------------


        <bullet>  The Black Tech Street supports President Biden's 
        request of $4B to build on the one-time $500 million provided 
        in the Consolidated Appropriations Act, 2023. This funding 
        would enable EDA to establish cutting-edge and strategic 
        regional technology hubs that foster the geographic diversity 
        of innovation and create quality jobs in underserved and 
        vulnerable communities across the Nation--including our 
        communities in the northern region of Tulsa.

        <bullet>  Within the Small Business Administration, the Black 
        Tech Street supports President Biden's request and asks that 
        $30M for SBA's Growth Accelerator Fund Competition, Regional 
        Innovation Clusters, and the Federal and State Technology 
        Partnership Program; $30M for the Community Navigator Pilot 
        Program; and increasing the authorized lending level for the 
        SBIC program by 20 percent to $6B is honored by Congress.

    The National Science Foundation (``NSF''): Additionally, as part of 
the CSJ bill, President Biden's requested a total of requests $11.3 
billion in discretionary budget authority for 2024, a $1.8 billion or 
18.6-percent increase from the 2023 enacted level.

    Within the NSF portion of the CSJ, there are key programs that are 
vital to Black Tech Street and its partners. These include but are not 
limited to the following:


 
------------------------------------------------------------------------
                                                              Black Wall
NSF Program  FY23 Final       FY24         FY24       FY24      Street
                           President      House      Senate     Request
------------------------------------------------------------------------
STEM         $1.2B       $1.4B          $2.5M      $2.5M      ----
 Workforce
------------------------------------------------------------------------
Scientific   ----        $2B            ----       ----       ----
 &
Technologic
 al
 Advances
------------------------------------------------------------------------
U.S.         ----        $1.2B          $300M      ----       ----
 Leadership
 in
 Emerging
Technologie
 s
------------------------------------------------------------------------
Research     $9.87B      $11.3B         $9.6B      $9.5B      $11.3B
 Activities
 for
 CHIPS and
Science Act
------------------------------------------------------------------------


        <bullet>  Black Tech Street supports President Biden's request 
        of $1.4B in funding to STEM workforce development which is 
        vitally important for the advancements in innovation by 
        American workers.

        <bullet>  Black Tech Street supports the President's request of 
        $1.2B in advancing U.S. leadership in emerging technologies--as 
        a network of partners located in Oklahoma, our challenges to 
        recruit and retain talented innovators faces both domestic and 
        global competition. We support policy that supports keeping 
        American jobs in America and applaud the President's request 
        for this funding as part of NSF.

        <bullet>  Black Tech Street also supports the $7.6B for NSF's 
        research and related activities and the $11B allocated by the 
        Senate to implement the CHIPS and Science Act.

    We are hopeful with the passage of the CJS bill and its NSF 
funding, Congress can continue to support innovation and advancements 
in commerce, science, innovation, and technologies that community 
partners like Black Tech Street work on each day for all Americans.

    We are confident the above recommendations are a step in the right 
direction for our Nation's future.
                                 ______
                                 

    Senator Hickenlooper. Thank you very much. Mr. Lannin.

   STATEMENT OF JOSH LANNIN, VP, PRODUCTIVITY TECHNOLOGIES, 
                      WORKDAY, BOULDER, CO

    Mr. Lannin. Good morning, Chairman Hickenlooper, Ranking 
Member Braun, and Members of the Subcommittee. My name is Josh 
Lannin. I am Vice President of Productivity Technology at 
Workday.

    Workday is a leading provider of cloud applications for 
finance and human resources. Our software is used by more than 
10,000 organizations, including half of the Fortune 500, 
servicing over 65 million users. In April of this year, nearly 
one in four of all U.S. job openings were processed on the 
Workday platform, a responsibility we take very seriously.

    At the same time, our business gives us a unique vantage 
point and opportunity to shape the future of work. For more 
than 25 years, I have led teams of developers, product 
managers, and researchers that build software, which has 
transformed how teams run their business.

    AI clearly holds great potential in this area, which is why 
I commend the Subcommittee for its timely bipartisan focus on 
how AI will impact the American workforce. It is clear that 
advancing technology will change the skills the workforce of 
the future requires.

    As a father of two teenage daughters, it is an incredibly 
challenging time to give them career advice. At the same time, 
when I see how new technologies are helping them in ways, in 
their schooling, I couldn't have imagined when I was in school.

    At Workday, we believe that I can enable U.S. workers and 
employers to better navigate future changes by focusing on a 
skills based approach to talent. Today, an employee can use 
Workday's AI to identify opportunities for career development.

    For example, employees can ask Workday specific questions 
about their company's learning and development policies and get 
a clear answer without having to read page after page of 
documentation, all thanks to AI.

    As our Workday product teams integrate AI, we strive to put 
people at the center and enable them to apply their judgment. 
This requires careful crafting of the Workday product 
experience, so users understand always how and when AI is 
augmenting their work. It is also why Workday provides tools 
that enrich but don't replace human judgment. It is an approach 
that builds trust with our customers and our users.

    Recently, Workday surveyed 1,000 senior business leaders 
about AI and learned there is overwhelming agreement the AI is 
needed to help their employees work more efficiently and make 
better decisions.

    Yet leaders also told us that people lack the skills to 
adapt to the coming changes in the workplace. How do we address 
the skills gap, while also equipping workers and employers to 
navigate the coming changes? It is a significant challenge to 
identify and invest in skills that are relevant today, or 
recognizing those skills will change in the future.

    Workday's view, a skills based approach to talent, an 
approach that emphasizes what a person can do or learn, rather 
than their credentials is the best way forward. The Governors 
of 10 states are embracing such an approach because it provides 
for more nimble reskilling and expands applicant pools.

    We are pleased to see the President's new AI Executive 
Order acknowledge the importance of skills in a changing 
workplace. And I have seen firsthand in my organization how 
shifting to a skills based approach has impacted our 
organization, faster hiring and the opportunity to bring on 
qualified candidates we might have overlooked in the past.

    To make a shift to a skills based approach, you need both 
the right mindset and technology. Workday skills cloud, for 
example, uses AI to align skills to a common vocabulary and map 
how different skills relate to each other.

    With that in place, our customers provide online talent 
marketplaces for their employees to find new internal 
opportunities to get the skills they need. For example, a 
retail associate who is interested in a management position can 
discover a leadership role at another store and take suggested 
online learning classes to give them the skills they need to 
apply for that opportunity.

    In other words, AI can take the guesswork out of workforce 
development and elevate people skills. Finally, I would like to 
mention that Workday believes there are steps the Subcommittee 
can take to support the transition to a data driven, skills 
based approach to talent at a national scale.

    There is growing awareness, including with the National AI 
Advisory Committee, about the need to modernize the Department 
of Labor's workforce and labor market information reporting. 
High quality and timely Federal data is essential to be able to 
leverage AI and to provide workers and employers with 
actionable insights and what skills are needed.

    Workday has partnered with industry stakeholders to craft 
model legislation that Congress can take to support these 
efforts. In conclusion, while AI will continue to drive change, 
we at Workday are all in on its ability to unlock human 
potential and support a skills based approach to talent.

    We seek to play a constructive role in AI with workforce 
issues and practices. We hope the Subcommittee will see us as a 
resource as you consider a path forward. Thank you.

    [The prepared statement of Mr. Lannin follows.]
                   prepared statement of josh lannin
    Good morning, Chairman Hickenlooper, Ranking Member Braun, and 
Members of the Subcommittee. My name is Josh Lannin, and I'm Vice 
President of Productivity Technology at Workday. I'm grateful for the 
opportunity to appear before you today.

    For more than twenty-five years, I've worked on emerging 
technologies such as artificial intelligence (AI) that enhance how 
workers collaborate, amplify their team's performance, and succeed in 
the rapidly changing workplace. I've called Colorado home for more than 
thirty years, and I'm a proud graduate of the University of Colorado 
Boulder where my oldest daughter, Sydney, recently started.
                               Background
    For those who don't know us, Workday is a leading provider of 
enterprise cloud applications for finance and human resources, helping 
customers keep pace with a changing world. Our applications for 
financial management, human resources, planning, spend management, and 
student management are built with AI and machine learning at the core 
to help organizations embrace the future of work. Headquartered in 
Pleasanton, California, Workday has more than 18,000 employees with 
offices in Boulder, Boston, McLean, and Salt Lake City.

    Workday was founded in 2005 and today is used by more than 10,000 
organizations around the world and across industries--from medium-sized 
businesses to more than 50 percent of the Fortune 500. The Workday 
customer community has 65 million users, and in April of this year, 
nearly one in four of all U.S. job openings was processed on the 
Workday platform. \1\ We are deeply committed to providing consistent, 
reliable, and secure software services to our customers and their 
employees. We also believe we have a unique opportunity to improve 
employee experiences and empower people to do their best work.
---------------------------------------------------------------------------
    \1\  Landman, Inna. ``First Half 2023 Hiring Trends: Slowdown and 
Stagnation,'' Workday Blog, September 20, 2023, https://
blog.workday.com/en-us/2023/first-half-2023-hiring-trends-slowdown-
stagnation.html.

    Our customers include state, local, and county governments and 
institutions of higher education, including the cities of Denver and 
Boulder; Hamilton County, Indiana; the Colorado School of Mines; and 
DePauw University. Last year, Workday entered the Federal marketplace. 
\2\, \3\ We did so after recognizing that Federal agencies like the 
Department of Energy needed enterprise software that helps them address 
their workforce development and financial management challenges and can 
keep pace with rapid change.
---------------------------------------------------------------------------
    \2\  ``Workday Achieves Fedramp Authorized Designation.'' Workday 
Newsroom. https://newsroom.workday.com/2022-07-13-Workday-Achieves-
FedRAMP-Authorized-Designation.

    \3\  Robinson, Doug. ``Tipping Point--Modernizing the Federal 
Workforce.'' POLITICO, July 11, 2022. https://www.politico.com/sponsor-
content/2022/07/11/tipping-point-modernizing-the-Federal-workforce.

    I commend the Subcommittee for convening this hearing and for its 
bipartisan focus on how AI will impact the American workforce and on 
the skills needed to succeed in the changing workplace. These issues 
are a high priority for Workday and our customers, and we view them as 
central to the question of how to make the most of AI's potential. As 
with earlier advancements in technology, AI will impact how people work 
and the skills their jobs require. Notable developments around 
generative AI are also accelerating the pace and depth of 
transformation that we will likely see in the next two to 3 years. At 
the same time, we are confident that AI can empower U.S. workers and 
employers to navigate these changes by fostering a skills-based 
---------------------------------------------------------------------------
approach to talent.

    My testimony will highlight how Workday and our customers are 
thinking about AI, how trustworthy AI can drive a skills-based approach 
to talent at scale, and the steps we recommend the Subcommittee 
consider so that workers and employers have the data to better adapt to 
the changing workplace.
      Employers are Optimistic about AI and Navigating Skills Gaps
    At Workday, we believe AI can positively transform how people and 
organizations work. The AI tools we deliver to our customers help 
people to make more informed decisions by surfacing new insights, 
identifying opportunities for career development, and improving 
workers' day-to-day by simplifying labor-intensive tasks. \4\ Our 
guiding principle is that AI should be used in ways that augment, 
rather than displace people. As such, Workday provides tools that 
enrich--but don't automate--human decisions. Our product teams work 
hard so that users can understand how and when AI is being used so that 
a human is always the ultimate decision-maker. We've found that this is 
an approach that builds trust with our customers and end users. \5\

    \4\  Chakraborty, Sayan. ``Workday's Vision for AI.'' Workday Blog, 
March 10, 2023. https://blog.workday.com/en-us/2022/workdays-vision-
for-ai.html.

    \5\  Chakraborty, Sayan. ``How AI and ML Are Powering the Future of 
Work.'' Workday Blog, July 6, 2023. https://blog.workday.com/en-us/
2023/how-ai-and-ml-are-powering-future-work.html.

    Earlier this year, Workday surveyed 1,000 senior decision-makers in 
human resources, finance, and technology for their perspectives on AI. 
\6\ As decisions about the future of work are being made today, the 
results illustrate how employers are thinking about AI and the 
workplace. Senior decision-makers overwhelmingly agreed (80 percent) 
that AI is needed to keep their business competitive and help their 
employees work more efficiently and make better decisions. Of the 
technology leaders surveyed, 94 percent indicated they are investing in 
AI and a similar number (83 percent) expect to invest the same amount 
or more over the next 3 years.
---------------------------------------------------------------------------
    \6\  Krist, Josh. ``Workday Research: `AI IQ' Study Reveals 
Artificial Intelligence Adoption Barriers for Business Leaders,'' 
Workday Blog, October 2, 2023, https://blog.workday.com/en-us/2023/
workday-research-ai-iq-study-reveals-artificial-intelligence-adoption-
barriers-business-leaders.html.

    Yet alongside the optimism about AI's potential is anxiety. A 
majority of senior decision-makers (72 percent) voiced concern that 
their organization lacks the skills to fully implement AI. Nearly all 
(93 percent) said it was important to keep a ``human in the loop'' when 
---------------------------------------------------------------------------
making significant decisions.

    Although we're in the early days of AI adoption, the opportunities 
and challenges ahead of us are coming into view. Employers understand 
the benefits of using AI to address both labor-intensive and time-
intensive work, but wrestle with growing skills gaps in AI, AI-
adjacent, and more traditional roles. How do we address this skills gap 
while also equipping workers and employers to navigate the coming 
changes to the workplace? By one estimate, 85 percent of the jobs in 
2030 have not been created yet. \7\ While this number may be bullish, 
it speaks to the challenge of identifying and investing in skills that 
are not only in-demand today, but will also be relevant tomorrow.

    \7\  Realizing 2030: A divided vision of the future--Dell USA, 
https://www.delltechnologies.com/content/dam/delltechnologies/assets/
perspectives/2030/pdf/Realizing-2030-A-Divided-Vision-of-the-Future-
Summary.pdf.
---------------------------------------------------------------------------
         Skills: the Right Lens to View the Changing Workplace

    We believe a shift to a skills-based approach to talent--rather 
than trying to forecast the skills of the future--is the best way 
forward. \8\, \9\, \10\ By a skills-based approach to talent, we mean 
an emphasis on what a person can do or learn, rather than solely on 
their credentials.

    \8\  Schlampp, Pete. ``A.I. Is a Must for Skills-Based 
Organizations That Want to Move at the Speed of Future Business,'' 
Fortune, February 17, 2023, https://fortune.com/2023/02/17/workday-
future-business-skills/.

    \9\  Somers, David. ``How Workday Is Delivering Next-Generation 
Skills Technology at Scale,'' Workday Blog, September 28, 2022, https:/
/blog.workday.com/en-us/2022/how-workday-delivering-next-generation-
skills-technology-scale.html.

    \10\  Bryan Hancock et al., ``Taking a Skills-Based Approach to 
Building the Future Workforce,'' McKinsey & Company, November 15, 2022, 
https://www.mckinsey.com/capabilities/people-and-organizational-
performance/our-insights/taking-a-skills-based-approach-to-building-
the-future-workforce.

    Awareness of the benefits of a skills-based approach to hiring, 
learning, and career development is growing. \11\ Alongside the private 
sector, Governors of at least ten states, including Colorado, North 
Carolina, Pennsylvania, Utah, and Virginia, are taking steps to remove 
degree requirements for most state opportunities. \12\ In hiring 
guidance issued by the Office of Personnel Management last year, the 
Nation's largest employer--the Federal Government--recognized the 
---------------------------------------------------------------------------
importance of a skills-based approach to recruiting its workforce. \13\

    \11\  Ferguson, Stephanie. ``Understanding America's Labor 
Shortage,'' U.S. Chamber of Commerce, October 23, 2023, https://
www.uschamber.com/workforce/understanding-americas-labor-shortage.

    \12\  ``States Consider Elimination of Degree Requirements.'' 
National Conference of State Legislatures. https://www.ncsl.org/
education/states-consider-elimination-of-degree-requirements.

    \13\  ``OPM Releases Skills Based Hiring Guidance.'' U.S. Office of 
Personnel Management. https://www.opm.gov/news/releases/2022/05/
release-opm-releases-skills-based-hiring-guidance/.

    Why focus on skills? First, it helps workers more nimbly upskill 
and reskill for new roles, including through on-the-job experience. 
\14\ Second, employers can expand their applicant pools and shine a 
spotlight on talented individuals who are equipped to excel in a job 
but may not fit a traditional candidate profile on paper. \15\, \16\ 
Approaches that over-rely on college degrees can also screen out 
otherwise qualified candidates, such as applicants from 
underrepresented and rural communities. \17\ Third, the data supports a 
skills-based approach to talent. Hiring for skills has been found to be 
five times more predictive of job performance than hiring for 
educational qualifications. \18\ Organizations that use skills-based 
practices are also twice as likely to place talent effectively and 98 
percent more likely to retain high performers. \19\
---------------------------------------------------------------------------
    \14\  Coolberth, Nicky Lauricella. ``118 Businesses and 
Organizations Call on Congress to Support Investments in Workforce and 
Skills Training as Part of Economic Recovery Legislation,'' National 
Skills Coalition. https://nationalskillscoalition.org/news/press-
releases/118-businesses-and-organizations-call-on-congress-to-support-
investments-in-workforce-and-skills-training-as-part-of-economic-
recovery-legislation/.
    \15\  Schlampp.
    \16\  ``STARs.'' Opportunity@Work. ``https://opportunityatwork.org/
stars/.''
    \17\  The Editorial Board. ``See Workers as Workers, Not as a 
College Credential.'' The New York Times, January 28, 2023. https://
www.nytimes.com/2023/01/28/opinion/jobs-college-degree-
requirement.html.
    \18\  Hancock et al.
    \19\  Griffiths, Michael, and Robin Jones. ``Skills-Based 
Organizations: Deloitte Global.'' Deloitte, November 2, 2022. https://
www.deloitte.com/global/en/issues/work/skills-based-organizations.html.

    As a manager, I've seen the benefits of these practices firsthand. 
Workday's approach to talent is skills-based. As a result, I'm able to 
find qualified candidates for our product organization faster, and 
opportunities have opened up for individuals who might have been 
overlooked in the past.
        AI Can Drive a Skills-Based Approach to Talent at Scale
    At Workday, we've found that successfully implementing a skills-
based approach to talent can be difficult to scale without the right 
technology. \20\ People use different words to describe a skill, and 
very different skills can be described with the same word. Workers 
often struggle to identify which skills they should develop to advance 
their careers, and the lack of consistency makes it difficult for 
employers to identify workers who can fill an open role.
---------------------------------------------------------------------------
    \20\  ``Skills credentials and Workforce of the Future.'' Workday. 
https://www.workday.com/content/dam/web/en-us/documents/whitepapers/
skills-credentials-and-workforce-of-the-future.pdf.

    Fortunately, AI is unique in that it will drive change in the 
workplace and power the tools that workers and employers need to 
successfully navigate those changes. AI can process large amounts of 
data associated with occupational roles and responsibilities and 
develop so-called ``ontologies'' or vocabularies that make skills data 
actionable. Workday's Skills Cloud, for example, aligns skills to a 
common vocabulary by using machine learning to map how different skills 
relate to each other and evolve over time. \21\ Skills Cloud has been 
used over 40 million times, including by hiring managers for new job 
postings and by incumbent workers and candidates to communicate the 
skills they have. Over 25 percent of Fortune 500 companies are now live 
on Skills Cloud and workers have entered over 200 million skills into 
their profiles.
---------------------------------------------------------------------------
    \21\  Stratton, Jim, David Somers, Rowan Miranda, et al. ``The 
Foundation of the Workday Skills Cloud.'' Workday Blog, 2020. https://
blog.workday.com/en-us/2020/foundation-workday-skills-cloud.html.

    Incumbent workers can also use Career Hub, a one-stop-shop on the 
Workday platform where employees can find AI-enabled personalized 
recommendations, such as learning content and short-term projects on 
other teams where they can pick up new skills. For example, a retail 
associate who is starting a new family and is interested in management 
can discover a leadership role at another store and take suggested 
learning courses to prepare them for that opportunity. \22\ The result 
is a win-win for workers and employers: the retail associate can pursue 
growth opportunities that align with their career goals, and employers 
can benefit from and support their incumbent talent. This is one 
example of how AI and skills can take the guesswork out of workforce 
development and facilitate data-driven reskilling.
---------------------------------------------------------------------------
    \22\  Ernst, Chris. ``Making the Shift to a Skills-First People 
Strategy.'' SHRM, August 23, 2022. https://www.shrm.org/executive/
resources/people-strategy-journal/summer2022/pages/chris-ernst-workday-
skills-first-people-strategy.aspx.

    AI can also give workers the tools to succeed in their current 
roles. In the coming months, finance professionals using Workday will 
be able to use a generative AI tool to analyze contracts for any 
anomalies or discrepancies. This saves time, enhances accuracy, and 
frees up those workers to focus on negotiating contracts and building 
partnerships--all while keeping the human as the final decision-maker. 
\23\ When thoughtfully and responsibly applied, these AI tools can 
elevate the work people do, and give them time back to focus on what 
matters most to them and their roles. \24\
---------------------------------------------------------------------------
    \23\  Workday Staff Writers. ``Workday elevates human performance 
with generative AI capabilities.'' Workday Blog, September 27, 2023. 
https://blog.workday.com/en-us/2023/workday-elevates-human-performance-
innovative-generative-ai-capabilities.html.

    \24\  Luke, Shane. ``The requirements for seizing generative AI 
advantages. Fortune, September 27, 2023. https://fortune.com/2023/09/
27/workday-generative-ai/.
---------------------------------------------------------------------------
                 Responsible AI Governance Builds Trust
    While we see incredible opportunities for AI to unlock human 
potential, we also recognize that the risk of unintended consequences 
is real. One thing we are certain of is that people won't use 
technology they don't trust. \25\ As a cloud-native enterprise software 
company, we learned early on that rigorous investments in technology 
governance are critical to earning and retaining our customers' trust. 
This is why Workday put in place a robust responsible AI program that 
includes:
---------------------------------------------------------------------------
    \25\  Cosgrove, Barbara. ``Safeguarding Privacy while Innovating 
with AI.'' Workday Blog, May 24, 2023. https://blog.workday.com/en-us/
2023/safeguarding-privacy-while-innovating-ai-workday.html.

        <bullet>  Leadership Commitment from a Responsible AI Advisory 
        Board that is led by our General Counsel and counts our Chief 
        Compliance Officer, Chief Technology Officer, and Chief 
---------------------------------------------------------------------------
        Diversity Officer among its members.

        <bullet>  Dedicated Resources that include a team of social and 
        data scientists and technology experts that report to our Board 
        of Directors through our Chief Compliance Officer and that 
        develops and maintains Workday's responsible AI governance 
        framework. The team receives cross-company support, including 
        from responsible AI champions who provide subject matter 
        expertise so that AI products are developed in accordance with 
        Workday's AI principles. \26\
---------------------------------------------------------------------------
    \26\  Trindel, Kelly. ``Workday's Continued Diligence to Ethical AI 
and ML Trust.'' Workday Blog, September 19, 2023. https://
blog.workday.com/en-us/2022/workdays-continued-diligence-ethical-ai-
and-ml-trust.html.

        <bullet>  Responsible AI Guidelines and Review Processes that 
        operationalize our principles through AI development 
        guardrails, turning them into documented practices and 
        assessments. \27\ Our product development teams use tools to 
        evaluate a potential AI feature's risk profile before we write 
        any code. AI tools intended for use in consequential decisions, 
        such as hiring or promotion, are treated as high-risk.
---------------------------------------------------------------------------
    \27\  Srihari, Dileep and Meghan Chilappa, ``Impact Assessments: 
Supporting AI Accountability and Trust,'' Access Partnership. https://
accesspartnership.com/impact-assessments-supporting-ai-accountability/; 
``Impact Assessments: A Key Part of AI Accountability,'' BSA. https://
www.bsa.org/files/policy-filings/08012023impactassess.pdf.

        <bullet>  Disclosure to equip our customers with a clear 
        understanding of how our AI tools are developed and assessed, 
---------------------------------------------------------------------------
        as well as transparency and choice in how their data is used.

    Although Workday has taken these steps to develop AI in a 
responsible manner, we recognize that the lack of public trust in AI 
must be addressed across the industry. \28\ Workday strongly supports 
new regulations on AI developed and used for consequential decisions, 
including hiring, promotion, and termination. \29\, \30\ We were also 
early champions for the creation of the National Institute of Standards 
& Technology's AI Risk Management Framework because we recognized the 
need for a commonly accepted benchmark for AI governance. \31\, \32\ 
Workday participated in every stage of the Framework's development, 
alongside contributors from academia, the business community, and civil 
society groups. Last month, NIST published a case study featuring 
Workday's use of the AI Risk Management Framework, the first of any 
organization. \33\
---------------------------------------------------------------------------
    \28\  Tyson, Alec. ``Growing Public Concern about the Role of 
Artificial Intelligence in Daily Life.'' Pew Research Center, August 
28, 2023. https://www.pewresearch.org/short-reads/2023/08/28/growing-
public-concern-about-the-role-of-artificial-intelligence-in-daily-life/

    \29\  ``Toward Trusted Innovation: Our Vision for U.S. AI Policy.'' 
Workday. https://www.workday.com/content/dam/web/en-us/documents/
public-policy/Workday-US-AI-Policy-Paper-Released-
June2023.pdf?trk=public-post-comment-text.
    \30\  ``Building Trust in AI and ML Through Principles, Practice, 
and Policy.'' Workday. https://www.workday.com/content/dam/web/en-us/
documents/whitepapers/building-trust-in-ai-ml-principles-practice-
policy.pdf.
    \31\  ``A Timely Bipartisan Push for Trust in AI: Congress and the 
NIST Trustworthy AI Framework.'' Morning Consult, January 12, 2021. 
https://morningconsult.com/opinions/congress-and-the-nist-trustworthy-
ai-framework/.
    \32\  Morse, Chandler C., ``The New NIST AI Framework: Accelerating 
Trustworthy AI.'' Workday Blog, February 16, 2023. https://
blog.workday.com/en-us/2023/the-new-nist-ai-framework-accelerating-
trustworthy-ai.html.
    \33\  ``Using the AI Risk Management Framework.'' National 
Institute of Standards and Technology. https://www.nist.gov/system/
files/documents/2023/09/14/workday-success-story-final-for-release.pdf.

    We also recognize the need for a practical roadmap that developers 
and deployers of AI in the workplace can use. This is why Workday 
joined the Future of Privacy Forum and other leading technology 
companies to co-develop the Best Practices for AI and Workplace 
Assessment Technologies. \34\ The Best Practices are a roadmap for 
responsible AI in the workplace that accounts for the shared 
responsibility of AI developers and deployers. \35\ They leverage 
Workday's experience in developing trustworthy enterprise AI 
capabilities, as well as the NIST AI Risk Management Framework and 
guidance from U.S. regulators, including the Equal Employment 
Opportunity Commission. \36\ We were proud to endorse the Best 
Practices and have called on other organizations to join us in putting 
them to use.
---------------------------------------------------------------------------
    \34\  ``Future of Privacy Forum and Leading Companies Release Best 
Practices for AI in Employment Relationships.'' Future of Privacy 
Forum. https://fpf.org/blog/future-of-privacy-forum-and-leading-
companies-release-best-practices-for-ai-in-employment-relationships/.
    \35\  ``AI Developers and Deployers: An Important Distinction.'' 
BSA. https://www.bsa.org/policy-filings/ai-developers-and-deployers-an-
important-distinction.
    \36\  Morse, Chandler C. ``Advancing Responsible AI in the 
Workplace: The Future of Privacy Forum's Best Practices.'' Workday 
Blog, October 16, 2023. https://blog.workday.com/en-us/2023/advancing-
responsible-ai-workplace-future-privacy-forums-best-practices.html.
---------------------------------------------------------------------------
                  Modernize Federal Labor Market Data
    As the Subcommittee weighs AI's impact on the future of work, we 
recommend that it consider taking steps to modernize Federal labor 
market data. \37\ Federal labor market data that is granular, high 
quality, and timely could fuel the AI technologies needed to bring a 
skills-based approach to talent to a national scale. When equipped with 
this kind of information, workers, employers, and educators can better 
navigate the coming changes to the workplace. \38\
---------------------------------------------------------------------------
    \37\  Robinson.
    \38\  ``Real-time labor data could be the answer to workforce 
woes.'' Axios. https://www.axios.com/sponsored/content-item/workday-
real-time-labor-data-could-be-the-answer-to-workforce-woes.

    Although the Department of Labor (DOL) produces important Federal 
macroeconomic information, the current reporting system provides 
limited insight into employment patterns and skills that are in demand 
in the job market. \39\, \40\, \41\ Awareness about the importance of 
better Federal labor market data, however, is growing. \42\
---------------------------------------------------------------------------
    \39\  Goger, Annelies, and Janie McDermott. ``Digital 
Transformation in Labor and Education Systems.'' Brookings, November 9, 
2021. https://www.brookings.edu/essay/digital-transformation-in-labor-
and-education-systems/.
    \40\  ``Workforce Policy.'' Business Roundtable. https://
www.businessroundtable.org/workforcepolicy.
    \41\  ``What is JEDx? Why Now? What Does It Do? Who Benefits?'' The 
U.S. Chamber Foundation. https://www.uschamberfoundation.org/sites/
default/files/JEDx%20One-Pager-May2022.pdf.
    \42\  ``Unemployment Insurance: DOL Needs to Further Help States 
Overcome IT Modernization Challenges.'' Government Accountability 
Office, July 10, 2023. https://www.gao.gov/products/gao-23-
105478#summary-recommend.

    In the wake of the economic disruption caused by the pandemic, the 
Workforce Information Advisory Committee recommended that the DOL take 
steps to improve data on the changing nature of work, improve the 
accuracy of local-level data, and adequately fund state reporting 
infrastructure. \43\ The White House's National Cyber Workforce & 
Education Strategy, in recognizing the importance of a skills-based 
approach to talent, also highlighted the need to improve labor market 
data and resources. \44\ Moreover, in its Year 1 Report, the National 
AI Advisory Committee (NAIAC) recommended that DOL prioritize and 
request adequate funding for ongoing efforts to modernize the Workforce 
and Labor Market Information system. \45\ The NAIAC concluded that 
``with the appropriate investments and privacy safeguards in place, AI-
driven tools coupled with real-time labor market data can enable 
workers to not only adapt to a changing workplace, but also thrive.'' 
\46\
---------------------------------------------------------------------------
    \43\  Workday's Principal Product Strategist Chris Kim was recently 
appointed to the Federal Workforce Information Advisory Committee.
    \44\  ``National Cyber Workforce and Education Strategy.'' The 
White House, July 2023. https://www.whitehouse.gov/wp-content/uploads/
2023/07/NCWES-2023.07.31.pdf.
    \45\  Workday Co-President Sayan Chakraborty serves on the National 
AI Advisory Committee in his personal capacity.
    \46\  ``National Artificial Intelligence Advisory Committee Year 1 
Report.'' NAIAC. May 2023. https://ai.gov/wp-content/uploads/2023/05/
NAIAC-Report-Year1.pdf.

    To advance the modernization of Federal labor market data, Workday 
has collaborated with stakeholders on model legislation. Our proposal 
---------------------------------------------------------------------------
would:

        1. Establish a workforce and labor market data pilot program 
        that would focus on supporting ongoing efforts and existing 
        public-private partnerships with technical resources for 
        states.

        2. Create a rapid response initiative that would encourage 
        Federal agencies to identify labor shortages and workforce gaps 
        across the country and provide Congress insight on labor data 
        standardization.

        3. Establish a congressional Commission to provide 
        recommendations on how to further improve the collection, 
        security, maintenance, and dissemination of labor market data.

                               Conclusion

    At Workday, we are all in on trustworthy AI's ability to unlock 
human potential and support a skills-based approach to talent. As 
workplaces and work transform, it's increasingly clear that 
technologies like AI are necessary to help workers and employers 
navigate change. Workday seeks to be a partner. As you chart a way 
forward on responsible AI and the future of work, we hope the 
Subcommittee will consider us a resource. Thank you and I look forward 
to your questions.
                                 ______
                                 

    Senator Hickenlooper. Thank you very much, Mr. Lannin.

    Ms. Morley Ryan.

STATEMENT OF MARY KATE MORLEY RYAN, MANAGING DIRECTOR OF TALENT 
           AND ORGANIZATION, ACCENTURE, ST. LOUIS, MO

    Ms. Morley Ryan. Chairman Hickenlooper, and Ranking Member 
Senator Braun, and Members of the Subcommittee, it is my 
pleasure to speak to you this morning on behalf of Accenture.

    My name is Mary Kate Morley Ryan. I focus on technology and 
workforce transformation, social innovation, and inclusion in 
the future of work. Accenture is a global professional services 
organization that helps the world's leading businesses, 
governments, and other organizations build their digital core, 
transform their operations, and accelerate their growth.

    We have approximately 733,000 people serving clients in 
more than 120 countries. We are the largest independent 
technology services firm globally, and the top partner of most 
leading technology and AI companies.

    Our unique position in the market allows us to identify 
cross-cutting trends and concerns in the use of AI and 
generative AI, including how they will affect the future of 
work and business.

    We recently issued a report with the World Economic Forum 
that provides a structured analysis of the potential impacts of 
the integration of large language models on jobs. Our research 
analyzed over 19,000 individual tasks across 867 occupations, 
assessing the potential exposure of each task to large language 
model adoption.

    We were able to identify occupations with a greater 
proportion of time spent in tasks with the potential for 
automation, including credit authorizers, telemarketers, and 
others. We also identified occupations that are more likely to 
be augmentable, those that will be unaffected, and a number of 
new roles that will be created, such as AI developers, data 
curators, and AI content creators.

    AI will transform the way we work. We estimate that 40 
percent of all working hours across industries will be impacted 
by large language models like the ones driving the generative 
AI applications such as ChatGPT. That does not mean that 
generative AI will replace 40 percent of all working hours. On 
the contrary, jobs will not be done either by humans or by 
robots, but by humans enhanced by AI.

    As AI transforms the workplace, in addition to aligning on 
responsible AI frameworks and governance, organizations will 
need to consider its workforce impact in three key ways. First, 
how it will impact existing jobs. Second, how can we develop a 
pipeline of talent to create the AI powered technologies of the 
future.

    Third, what kind of skilling needs it will create. The 
reality is we don't currently have the workforce we need to 
fill the jobs of the future. That is why we advise our clients 
to establish a skills foundation tailored to their 
organization, to deconstruct the work to support human and 
machine collaboration, and re-architect strategic and 
operational talent practices.

    At Accenture, we put this advice into practice. We recently 
announced a $3 billion investment that will double our data and 
AI practice from 40,000 to 80,000 people over the next 3 years 
through a combination of acquisitions, new hires, and 
retraining our current workforce.

    Additionally, we view skilling and apprenticeship programs 
as critical to our success and adaptability. That is why we 
invest $1 billion a year in upskilling our own people and 
invest heavily in structured, earn and learn apprenticeships.

    We have also put our skill based hiring commitment into 
action by opening nearly half of our entry level positions to 
people who do not have a 4-year college degree. The workforce 
commitments and programs we drive internally are echoed in the 
way that we serve our clients.

    Client conversations around the workforce, including skills 
based practices, responsible AI, technology and AI fluency are 
happening every day, if not every minute--every minute of every 
day. All too often, AI and the workforce debate turns into a 
binary one with the machine--will machines take our jobs?

    But the answer is not binary. AI cannot--can help us do our 
jobs better if deployed effectively and responsibly. We believe 
the focus must be on evolving how we work and unleashing the 
potential of people, as much as we are focusing on the 
technology.

    I appreciate the opportunity to speak with you this morning 
and look forward to answering your questions.

    [The prepared statement of Ms. Morley Ryan follows.]
              prepared statement of mary kate morley ryan
    Chairman Hickenlooper, Ranking Member Braun and Members of the 
Subcommittee, it is my pleasure to speak with you this morning on 
behalf of Accenture. My name is Mary Kate Morley Ryan. I focus on 
workforce transformation, social innovation, and inclusion in the 
future of work at Accenture. I am responsible for the firm's U.S. 
Innovating for Society strategy which pilots, implements, and amplifies 
solutions to pressing workforce-related challenges faced by people and 
organizations.

    Accenture is a global professional services company that helps the 
world's leading businesses, governments and other organizations build 
their digital core, transform their operations, accelerate their growth 
and enhance citizen services, creating tangible value at speed and 
scale. We are a talent and innovation-led company with approximately 
733,000 people serving clients in more than 120 countries. We combine 
our strength in technology and leadership in cloud, data and artificial 
intelligence (AI) with unmatched industry experience, functional 
expertise and global delivery capability.

    Accenture has deep experience both in AI as a technology and its 
application across nearly every industry. We are the largest 
independent technology services firm globally and the top partner of 
most of the leading technology and AI companies. Our unique position in 
the market as well as our use of AI internally allow us to identify 
cross-cutting trends and concerns in the use of AI and Generative AI 
(Gen AI), including how they will affect the future of work and 
business at both a micro and macro level.
                            The AI Awakening
    It is exceedingly rare for a single advancement in technology to 
unleash big changes in human behavior and business dynamics, demanding 
a government response at an accelerated pace, but that is the reality 
of what is happening with AI today. This means that government and 
private sector leaders are presented with incredible opportunities to 
be more efficient and drive more growth. In a recent survey Accenture 
conducted of C-suite executives, 97 percent said that they believe Gen 
AI will be a transformative game-changer worth long-term investment. 
\1\
---------------------------------------------------------------------------
    \1\  Pulse of Change, C-suite perceptions on generative AI, https:/
/newsroom.accenture.com/content/1101/files/PulseOfChange.pdf.

    The rapid growth of AI also requires government and private sector 
leaders to navigate a world of increasingly hard choices. Public and 
private organizations will need to deploy enterprise-wide responsible 
AI through a deep interrogation of every AI use case, application, and 
---------------------------------------------------------------------------
process, with complete and persistent monitoring.

    At Accenture, for example, we use a rigorous risk-based approach 
for each use case to navigate through over 50,000 AI use cases integral 
to our daily operations--highlighting the enormity of our task. As we 
chase the rapid growth offered by AI, it's crucial to simultaneously 
commit to the time-intensive diligence essential for responsible AI. 
Collaborating with numerous global organizations, we've been pioneering 
organizational frameworks, aligning them in significance with anti-
corruption, security, and data privacy initiatives, thereby seamlessly 
connecting growth with responsibility.
                    AI Will Transform the Workplace

    AI presents a significant value creation opportunity; if 
organizations fully embrace the integration of AI, the U.S. economy 
could add $8 trillion in economic activity and increase productivity by 
as much as 40 percent. \2\ We know that AI will transform the way we 
work, and this is a good thing.
---------------------------------------------------------------------------
    \2\  Why Artificial Intelligence is the Future of Growth, https://
newsroom.accenture.com/news/artificial-intelligence-poised-to-double-
annual-economic-growth-rate-in-12-developed-economies-and-boost-labor-
productivity-by-up-to-40-percent-by-2035-according-to-new-research-by-
accenture.htm.

    We believe about 40 percent of all working hours across industries 
will be impacted by large language models (LLMs) like the ones driving 
the Gen AI applications such as ChatGPT. That does not mean that Gen AI 
will replace 40 percent of all working hours. On the contrary, we view 
this as a ``both/and'' proposition; not an ``either/or.'' Jobs will not 
---------------------------------------------------------------------------
be done either by robots or by humans, but by humans enhanced by AI.

    The integration of LLMs in various industries presents a paradigm 
shift in how we interact with information and, by extension, how we 
work. Every role in every enterprise has the potential to be 
reinvented. In any given job, some tasks will be automated, some will 
be augmented or assisted--freeing people to do things that matter 
more--and some will be unaffected by the technology. There will also be 
new tasks for humans to perform, such as ensuring the accurate and 
responsible use of new AI-powered systems.

    Accenture recently issued a report in partnership with the World 
Economic Forum that provides a structured analysis of the potential 
impacts of LLMs on jobs. \3\ Our research analyzed over 19,000 
individual tasks across 867 occupations, assessing the potential 
exposure of each task to LLM adoption, classifying them as tasks that 
have high potential for automation, high potential for augmentation, 
low potential for either or are unaffected (non-language tasks). It 
also explores the new roles that are emerging due to the adoption of 
LLMs.
---------------------------------------------------------------------------
    \3\  Jobs of Tomorrow: Large Language Models and Jobs (Sept. 2023), 
https://www..weforum.org/docs/WEF-Jobs-of-Tomorrow-Generative-AI-
2023.pdf.

    About 62 percent of total work time across occupations involves 
language-based tasks, meaning the widespread adoption of LLMs, such as 
those behind ChatGPT, could significantly impact a broad spectrum of 
job roles. The jobs with the highest time spent on tasks that could 
potentially be automated through LLMs include various types of office 
clerks, especially those dealing with record keeping and other forms of 
information management, including Credit Authorizers, Checkers and 
Clerks (81 percent of work time could be automated), Management 
Analysts (70 percent), Telemarketers (68 percent), Statistical 
---------------------------------------------------------------------------
Assistants (61 percent), and Tellers (60 percent).

    Jobs with the highest potential for task augmentation emphasize 
mathematical and scientific analysis as well as critical thinking and 
complex problem solving, including roles such as Insurance Underwriters 
(100 percent of work time potentially augmented), Bioengineers and 
Biomedical Engineers (84 percent), Mathematicians (80 percent), and 
Editors (72 percent). \4\
---------------------------------------------------------------------------
    \4\  Id.

    In addition to reshaping existing jobs, the adoption of LLMs is 
likely to create new roles within the categories of AI Developers, 
Interface and Interaction Designers, AI Content Creators, Data 
Curators, and AI Ethics and Governance Specialists. \5\
---------------------------------------------------------------------------
    \5\  Id.

    An industry analysis was done by aggregating potential exposure 
levels of LLM adoption of the jobs to the industry level, noting that 
jobs may exist in more than one industry. The industries with the 
highest estimates of total potential exposure (automation plus 
augmentation measures) are both segments of financial services: 
financial services and capital markets, and insurance and pension 
management. This is followed by information technology and digital 
communications, and then media, entertainment, and sports. Similarly, a 
function group analysis reveals that the two thematic areas with the 
greatest total potential exposure to LLMs are information technology, 
with 73 percent of working hours exposed to automation and 
augmentation, and finance, with 70 percent of working hours exposed. 
\6\
---------------------------------------------------------------------------
    \6\  Id.

    To illustrate the research approach and how specific jobs will be 
reinvented with AI, the report broke down one customer service job in 
---------------------------------------------------------------------------
13 component tasks. Our research found that:

        <bullet>  4 tasks would continue to be performed primarily by 
        humans with low potential for automation;

        <bullet>  4 tasks could be fully automated; and

        <bullet>  5 tasks could be augmented to help humans work more 
        effectively, such as using an AI-generated summary to help 
        provide a rapid solution with a human touch. \7\
---------------------------------------------------------------------------
    \7\  Id.

    The potential for transformation is enormous across all kinds of 
industries, occupations and roles. We expect to see five core ways that 
---------------------------------------------------------------------------
Gen AI will commonly work with people:

        1. As an always-on advisor, putting new kinds of intelligence 
        into human hands in areas ranging from sales enablement and 
        human resources to medical and scientific research and 
        corporate strategy.

        2. As a creative partner, offering new ways to reach and appeal 
        to audiences, bringing unprecedented speed and innovation to 
        production design, design research, visual identity and naming, 
        copy generation and testing and real-time, personalized 
        customer relationship marketing.

        3. As a software developer, boosting productivity in areas 
        ranging from automating code writing to predicting and pre-
        empting problems.

        4. As an automation driver, especially those tasks that provide 
        historic context, present the next best actions, or summarize 
        or make intelligent predictions.

        5. As an enterprise protector, as companies learn to use Gen AI 
        to their advantage in governance and information security, 
        including in Security Operations Centers to mitigate threats 
        and identify vulnerabilities faster.

             So how do we Skill for the Jobs of the Future?
    Given the transformative potential that AI has, government and 
private sector organizations will need to consider AI impacts on their 
workforce in three ways: how it will impact existing jobs; how to 
develop a pipeline of talent to create the AI-powered technologies of 
the future; and what kind of workforce/skilling needs it will create. 
Organizations will need their employees to be capable of developing, 
deploying, monitoring and working with AI and AI-enabled technologies 
in the future.

    Unfortunately, we simply don't have the pipeline of students or the 
existing workforce we need to fill the jobs of the future and 
competition for jobs in these areas is fierce. We tell clients to take 
a skills-driven approach to address this issue, including:

        <bullet>  Establishing a skills foundation through data models, 
        infrastructure, policies, processes and platforms;

        <bullet>  Deconstructing work into tasks, skills, and models to 
        support human and machine collaboration; and

        <bullet>  Rearchitecting both strategic and operational talent 
        practices, including workforce planning, learning, talent 
        acquisition, internal mobility, and performance and rewards. 
        \8\
---------------------------------------------------------------------------
    \8\  Becoming a Skills-Driven Organization, Accenture, https://
www.accenture.com/content/dam/accenture/final/accenture-com/document/
Accenture-Becoming-a-Skills-Driven-Organization-Report.pdf.

    Using our own programs as an example, Accenture recently announced 
a $3 billion investment in our Data & AI practice that includes plans 
to double our data and AI workforce from 40,000 to 80,000 over the next 
3 years through a combination of acquisitions, new hires and 
reskilling/retraining of our existing workforce. \9\ Our reskilling, 
upskilling, retraining and apprenticeship programs are critical to our 
success and adaptability.
---------------------------------------------------------------------------
    \9\  Accenture to Invest $3 Billion in AI to Accelerate Clients' 
Reinvention (June 13, 2023), https://newsroom.accenture.com/news/
accenture-to-invest-3-billion-in-ai-to-accelerate-clients-
reinvention.htm.

    On the upskilling front, we invest $1 billion a year in training, 
reskilling and leadership development of our people. We have set up 
multi-stage training programs. The first stage is to ensure that all 
our employees have the training needed to be technology conversant. 
Everyone at Accenture participates in our technology quotient (TQ) 
training program, designed as a simple and effective way to learn about 
a technology, how it's applied, why it matters, and how it works with 
other technologies \10\ TQ has enabled our 700k+ workforce to be 
conversant across technology areas enabling our people to perform at 
their best and most innovative for our clients. AI has always been one 
of the hottest topics, and now we're leveraging the platform for Gen AI 
learning.
---------------------------------------------------------------------------
    \10\  Raise your cloud technology IQ, Accenture Blog, July 2021, 
https://www.accenture.com/us-en/blogs/blogs-careers/raise-your-cloud-
technology-iq.

    We also have skill and role-based learning as organizations look to 
pivot AI skills for a generative AI era. In some instances, this 
includes partnerships with top academic institutions. For example, 
Accenture partnered with Stanford University to create a Foundation 
Model Scholar Program last July. We are now sending our practitioners 
---------------------------------------------------------------------------
to this multi-day training to learn from the best.

    As a skills-driven organization, we believe in expanding our talent 
sourcing pools by focusing primarily on talent and skills, not degrees. 
We do that through re-thinking our recruiting process--things like 
asking strengths-based questions like: ``How do you feel about working 
in an environment that is often challenging?'' to get a sense of the 
person's approach and experiences. We ask candidates to pick any topic 
they want related to technology and allow them to present to their 
interviewer as they feel best equipped to better understand their 
critical thinking skills in action.

    Additionally, we reduced the number of entry-level positions that 
require a 4-year college degree. As of fiscal year (FY) 2023, nearly 
half of Accenture's entry-level positions in the U.S. are open to 
individuals who do not have a 4-year college degree.

    We heavily invest in structured, ``earn and learn'' apprenticeship 
programs. Since launching the Accenture North America apprenticeship 
program in 2016, we have onboarded more than 2,000 apprentices and met 
our fiscal year 2022 and fiscal year 2023 goals of filling 20 percent 
of our entry level roles in North America through our apprenticeship 
program. Apprentices come from diverse backgrounds and ethnicities, 
typically with a minimum of a high school diploma or equivalent.

    We continue to add a variety of new partnerships with community-
based organizations and across the business world to source 
apprentices, who specialize in one of many unique, in-demand digital 
career paths ranging from cybersecurity, application development and 
data science serving clients in more than 40 cities.

    We are also helping other employers--including our clients--create 
professional apprenticeship programs based on the best practices we've 
established in our own successful model. We have launched 9 local 
Apprentice Networks convening over 175 employers with talent and other 
key partners and published a national professional apprenticeship 
resource guide to help companies jumpstart their own programs. \11\ The 
10th Network is set to launch in November in Southern California.
---------------------------------------------------------------------------
    \11\  Apprenticeship Program Resource Guide, https://
accenture.pagetiger.com/accentureapprentice.

    In addition to the work we're doing to skill our own people, we're 
also creating digital skilling programs for our clients. In one 
example, we worked with a global critical infrastructure company to 
implement an enterprise-wide digital skilling program, enabling them to 
identify skills gaps across the business in more than 100 job families. 
Within the first 12 months, more than 20,000 employees enrolled in 
personalized skilling at scale; over 1,200 employees have spent more 
than 5 hours in training. In total, their employees have spent about 
18,000 hours and completed 112,000 courses.
                               Conclusion
    All too often the AI and workforce debate turns into a binary one--
will the machines take all of our jobs? The answer, we think, is a 
resounding no. But it can help us do our jobs better if deployed 
effectively and responsibly. We know that government and private sector 
organizations will need to radically rethink how work gets done. 
Reauthorization of the Workforce Innovation and Opportunity Act (WIOA), 
offers one opportunity to provide the public workforce development 
system the ability to scale training opportunities with a focus on Gen 
AI upskilling. We believe the focus must be on evolving our operations 
and training our people as much as on the technology itself.

    I look forward to answering your questions today.
                                 ______
                                 

    Senator Hickenlooper. Thank you very much, Ms. Morley Ryan.

    Mr. Newman.

    STATEMENT OF BRADFORD NEWMAN, PARTNER/LEADER OF THE AI 
      PRACTICE, BAKER & MCKENZIE LLP, CO-CHAIRMAN, THE AI 
  SUBCOMMITTEE FOR THE AMERICAN BAR ASSOCIATION, PALO ALTO, CA

    Mr. Newman. Chairman Hickenlooper, Ranking Member Braun, 
and the honorable Members of the Employment and Workplace 
Subcommittee, my name is Brad Newman. I am a partner with the 
law firm of Baker & McKenzie, where I am a leader of their AI 
practice.

    I serve as the chair--I have served as a Chair and now Co-
Chair of the AI Subcommittee of the American Bar Association. 
Today, I am here as a concerned citizen and a parent.

    For many years, I have had the privilege to represent the 
world's leading developers of AI, tend to get a behind the 
scenes look at the technology, including the incredible promise 
it presents to improve so many of our lives, and in particular 
the workforce, as well as the very serious social downside.

    I have published extensively on the need for legislative 
safeguards on the use of AI. I have spoken with the world's 
leading data scientists and ethicists, as well as the EEOC, and 
I am familiar with all sides of the AI regulatory debate.

    I passionately believe that AI in the employment context is 
one area where the Federal Government should act cautiously, 
prudently, and once fully informed, on a bipartisan basis, to 
enact legislation designed to promote innovation and protect 
the health, welfare, and safety of society.

    My long held belief is that the existing laws do not 
adequately provide for the potentially harmful downside of AI 
in the employment context. Without additional funding and 
training, existing agencies are not fully prepared to oversee 
and regulate this complex technology.

    In 2015, I published an article in TechCrunch entitled, The 
Artificial Intelligence Poses a Greater Risk to IP Than Humans 
Do. In 2018, I published a follow-up piece entitled, Society 
Needs the Artificial Intelligence Data Protection Act Now. In 
these articles, I proposed a comprehensive Federal AI 
legislative framework, including addressing AI's impact on the 
workforce.

    My articles and demands for regulation piqued the interest 
of the House of Representatives, affording me the great 
privilege of working on a draft bill of the AI Data Protection 
Act. I urge this Committee to conclude, as I have, that we need 
new AI legislation. Because of the significant civil rights 
implication of workplace technologies, AI legislation in the 
employment context is a prudent place to begin this journey.

    Eventual Federal legislation should not regulate AI 
technology generally, but rather delineate specific prohibited 
use cases and guardrails. Future legislation must not create 
overly burdensome compliance obligations. It should not create 
rules and regulations that are so onerous that only the very 
largest developers and users of this technology can afford to 
comply, thus creating a de facto monopoly for the largest 
industry players.

    A rational, risk based approach would ensure that all AI 
developers have the resources to comply and participate in the 
opportunities presented by the AI workforce ecosystem. The 
developers of this technology want to do the right thing and 
are eager to work with a bipartisan group of Federal 
legislators to get this right.

    Carefully regulating the use of AI in the employment 
context is as important as regulating the securities markets 
for which we have the SEC, our food and drug safety for which 
we have the FDA, and so forth.

    However, just as the Federal Government does not regulate 
against securities and new drugs per se, so should the Federal 
Government narrow its regulation of AI to known risk factors 
rather than the technology as a whole. No existing law 
adequately protects the workforce from the potential downside 
risks of AI employment tools, while ensuring that they promote 
innovation.

    Developers and users of this technology face an increasing 
patchwork of state and local legislation which creates onerous, 
vague, and expensive compliance obligations depending on the 
jurisdiction.

    Regulations like those enacted in New York City, for 
instance, come with convoluted and unclear rules that will 
likely prove too expensive for many segments of the user 
community to comply with, thus incentivizing them to abandon 
the benefits of AI tools in this use case.

    The New York City law codifies a misguided, one size fits 
all approach to AI regulation that prioritizes limiting the 
technology rather than minimizing or eliminating risk factors 
the technology poses.

    That is not a desirable outcome. Companies that develop AI 
and deploy AI technology in the workforce and the workforce 
itself deserve a rational solution that delivers clarity and 
consistency on a national level. The guardrails should be 
plainly spelled out in bipartisan Federal legislation.

    Again, Chair Hickenlooper, Ranking Member Braun, and the 
Members of the Subcommittee, it is truly an honor to share my 
perspective on these important issues, and I welcome the 
opportunity to answer any questions. Thank you.

    [The prepared statement of Mr. Newman follows.]
                 prepared statement of bradford newman
    Honorable Members of this Subcommittee, My name is Brad Newman. I 
am an attorney based in Silicon Valley for the last nearly 30 years. I 
am a partner with the law firm of Baker McKenzie, where I serve as a 
leader of our Firm's AI practice. For the last several years, I served 
as the Chair and now the Co-Chair of the AI Subcommittee of the 
American Bar Association, Business and Commercial Litigation Section. 
In 2018, I was recognized by the Daily Journal as one of the Top 20 AI 
attorneys in California. I frequently teach lawyers, judges and clients 
accredited Legal Education courses in AI and particularly, ethical uses 
of AI, oversight and governance. I have been an invited speaker on AI 
at several of the Nation's top law and graduate business schools, 
including MIT Sloan. For many years I have had the privilege to 
represent the world's leading developers of AI, and to get a behind the 
scenes look at the technology--including the incredible promise it 
presents to improve so many aspects of our lives, and in particular the 
workforce, as well as the very serious societal downside. I have 
published extensively on the need for legislative safeguards on the use 
of AI, including in the employment domain. I have spoken with many of 
the world's leading data scientists and AI ethicists, as well as with 
the EEOC, and believe that I am familiar with all sides of the AI 
regulatory debate, and the many differing perspectives about how to 
approach this important topic in the employment domain.

    I am not part of any lobbying, special interest or industry group. 
I am here as a concerned citizen and father. I am anti-regulation, but 
passionately believe that the AI employment context is one area where 
the Federal Government should act--cautiously, prudently and once fully 
informed--on a bipartisan basis to enact legislation designed both to 
promote innovation and protect the health, welfare and safety of 
society. I want to stress that while I am here today as a private 
citizen, my views are informed by what I have personally witnessed and 
experienced since at least 2010. I also want to be clear from the onset 
that my long held belief is that existing laws do not adequately 
provide for the potential downside impact of AI, including in the 
varied and growing employment use cases context. Nor are any existing 
agencies fully prepared to oversee, regulate and enforce an omnibus AI 
Bill.

    For the benefit of society, I urge this Committee to ultimately 
conclude, as I have, that we need new omnibus Federal legislation. 
Eventual Federal legislation should not regulate AI technology 
generally, but rather, delineate specific prohibited use cases and 
guardrails for AI use in the employment context. That is an important 
distinction. Future legislation must promote and encourage continued AI 
innovation and protect the workforce, without creating overly 
burdensome compliance obligations that will fuel inefficiency and 
discourage future AI advancements in places like Silicon Valley and 
other tech hubs around the country where very smart minds are working 
around the clock to create new and better AI algorithms. The optimal 
outcome for Federal AI legislation would be one that successfully 
avoids creating the scenario where rules and regulations are so onerous 
that only the very largest developers and users could afford to comply 
and thus have a de-facto monopoly over the industry and innovation. 
Rather, a rational, risk-based approach would ensure that AI developers 
both large and small have the resources to comply and thus participate 
in the vast opportunities presented by the AI workforce ecosystem. From 
my vantage point, industry--and particularly the developers of this 
technology, want to do the right thing and are eager to work with a 
bipartisan group of Federal legislators to get this right--especially 
in the employment context.

    Back on December 31, 2015, I published an article in Tech Crunch 
entitled ``Artificial Intelligence Poses A Greater Risk To IP Than 
Humans Do.'' In this initial article which focused predominantly on IP 
risks arising from AI proliferation, I noted that AI will displace 
human workers. While I candidly noted that I am no fan of over-
regulation, I stressed that AI is one area where there needs to be 
Federal regulation and I proposed omnibus Federal legislation called 
the Artificial Data Protection Act. In this initial article, I laid out 
some of the general requirements I thought important for any Federal 
legislation. This includes the requirement that companies of a certain 
size designate a Chief AI Officer charged with internal corporate 
oversight and monitoring of AI usage in the workplace. This was one of, 
if not the earliest proposal to create a C-suite position called the 
Chief AI Officer designated with overall corporate responsibility and 
governance of AI. I also proposed the creation of a Federal agency 
staffed with legal and technical experts to address issues arising 
under the AI Data Protection Act.

    It is worth noting that the photo Tech Crunch ran with the 2015 
article was a picture of the Terminator--a science fiction AI war 
machine. I knew at the time that my call to arms was premature, and 
that society at large which did not have my Silicon Valley based 
vantage point of this technology, was not yet ready to act. But I 
persisted. In the years that followed, based on what I saw in the AI 
field and knew was on the horizon, I continued to speak out about the 
needs for rational and well-designed Federal AI regulation.

    On May 15, 2018, I published a follow-up piece in Tech Crunch 
entitled: ``Society Needs the Artificial Data Protection Act Now.'' In 
this article, I included further details about what I thought prudent 
Federal AI legislation should include. Now, in addition to addressing 
unique IP considerations, I proposed Federal AI legislation should 
address AI's impact on the workforce. My 2018 article begins:

        On December 31, 2015, I published my original call to arms for 
        society's rational regulation of artificial intelligence before 
        it is too late. I explained certain reasons why someone who is 
        against solving problems through regulation would propose 
        precisely that mechanism to help hedge the threats created by 
        AI, and announced my proposed legislation: The Artificial 
        Intelligence Data Protection Act (AIDPA).

        Since 2015, we have witnessed AI's rapidly evolving national 
        and international growth and adoption that will soon impact 
        every phase of mankind's life, from birth to death, sex to 
        religion, politics to war, education to emotion, jobs to 
        unemployment.

        Three of many recent developments confirm why now is the time 
        for the AIDPA: (1) a McKinsey study from late 2017 determined 
        that up to 800 million workers worldwide may lose their jobs to 
        AI by 2030, half of contemporary work functions could be 
        automated by 2055 and other recent studies suggest as many as 
        47 percent of U.S. jobs could be threatened by automation or AI 
        over the next few decades . . .

        Now--and not later--society must address AI's legal, economic 
        and social implications with regard to IP and employment. 
        Current legislation does not adequately account for the new 
        challenges, threats and needs presented by the impact of AI.

        This article addresses the AIDPA's twin focuses (AI's threats 
        to intellectual property rights and the labor force) and 
        presents a proposed framework to address them. The AIDPA is 
        intended to provide industry with a voice in regulating AI 
        while promoting its safe, secure and ethical use. The United 
        States must lead the way in regulating AI, and leaders in 
        industry, technology and ethics should join together to 
        finalize and enact the AIDPA--the first and most important 
        legislation of its kind.

    I believed that then and I believe that now. The week my 2018 
article was published, I received a call from Congressman Nolan (D) of 
Minnesota's office. I was informed they read the article and agreed 
with it. They asked if I wanted to assist their office in turning the 
proposal into a draft discussion bill. I spent the latter part of 2018 
working with their office and House Legislative Counsel to prepare a 
draft of the AI Data Protection Act. The intent was to complete the 
draft by the end of 2018 so that Congressman Nolan, who was not running 
for re-election, could read it into the record and it could be assigned 
a Bill number. However, as so often happens, events on the ground 
overtook us. The Federal Government shut down at the end of 2018, and 
Congressman Nolan returned to his home without having the opportunity 
to formally enter the Discussion Draft into the record.

    The Discussion Draft of the AI Data Protection Act has several key 
features that I think are important for this Subcommittee to be aware 
of, pieces of which have now been included in subsequent legislative 
proposals floating around both Chambers of Congress.

        1. Section 101 of the AI Data Protection Act provides for:

                (a) the establishment of an Article II Federal AI Board 
                and

                (b) its makeup, authority and powers that include 5 
                Senate confirmed Board members who must at all times 
                include members from each of these fields: industry, 
                labor, data science and law.

        2. Section 102 establishes certain statutory Unlawful Uses of 
        AI that includes a prohibition on:

                (1) Sole reliance on artificial intelligence--

                        (A) by an employer to make a decision regarding 
                        the employment of an individual, including an 
                        Adverse Employment Action

        3. Section 201 establishes the requirement that covered 
        entities appoint a Chief AI Officer with certain roles and 
        responsibilities.

        4. Section 202 creates a Federal Worker Realignment Program to 
        ``aid covered individuals [displaced by AI] by training such 
        individuals for alternative careers and by helping such 
        individuals find employment opportunities; and

        5. Section 204 requires 60 day advance notice to workers who 
        will be displaced by AI.

    Any future AI workplace legislation enacted by Congress ought to 
have, at minimum, these components. It will go a long way to building 
trust between management and the workforce when it comes to AI 
employment tools, and minimize the current challenges faced by those 
who seek to utilize AI in responsible fashion to improve the employment 
relationship for both management and workers.

    I want to conclude by contrasting a proposed omnibus Federal 
legislative approach to AI in the employment context with the existing 
status quo, which is a patchwork of vexing state and local regulation. 
In my opinion, carefully regulating the fair and lawful use of AI in 
the employment context is as important as regulating the fairness of 
the securities markets (for which we have the SEC), our food and drug 
safety (for which we have the FDA), management-labor relations (for 
which we have the NLRB), employment discrimination (for which we have 
EEOC), and so forth.

    No existing law, in my opinion, adequately protects the workforce 
from the potential and serious risks of AI employment tools while 
ensuring the we promote innovation and have individuals with the right 
skill set presiding over these technical issues. Instead, the 
developers and users of this AI tecnhology face an increasing patchwork 
of state and local legislation, which creates onerous--and at times 
vague--compliance obligations depending on jurisdiction. Whether its 
employee biometrics like Illinois, employee personal information and 
the new Executive Order in California, employment bias in NY City, or 
many other areas that AI impacts in the employment domain, there is 
confusion and inconsistency. Regulations like those enacted by NYC come 
with incredibly complex and unclear regulations that will likely prove 
too expensive for many segments of the user community to comply with, 
thus incentivizing them to abandon the benefits of AI tools in this use 
case. That is not a desirable outcome, and one the Federal Government 
should seek to avoid. Both companies that develop and deploy AI 
technology as well as the workforce deserve a rational solution that 
delivers clarity and consistency on a national level. The guardrails 
should be plainly spelled out in bipartisan Federal legislation.

    I want to again thank this Subcommittee for inviting someone like 
me--a complete outsider to Washington DC--and listening to my 
viewpoints on these important issues. I am encouraged to see this 
Subcommittee approaching this topic by hearing from a range of 
perspectives.
                                 ______
                                 

    Senator Hickenlooper. Thank you, Mr. Newman.

    I feel comfortable saying I have been to a lot of Senate 
hearings, although at this I am a first termer, so that limits 
how sweeping this statement might sound, but I don't think I 
can remember being on a panel where I have four--any one of you 
I could spend an entire day with and want to hear, a, how you 
grew up, how you ever got to this position in your life, and 
you all are representing essential, important, key factors as 
we make this incredible transition.

    I already am recognizing that we are not going to have 
enough time, so I am going to just warn the witnesses that they 
will be badgered at some time in the future for additional 
questions, I am sure. Let me start around Workday. Obviously 
creating many of the AI tools that--across America that America 
is using. Mr. Lannin, in your testimony, you note that the 
Workday really strives, it makes every effort to develop 
products that are going to enrich, and not automate, human 
decisions.

    In your view, how should employers work with employees as 
they think about different types of automated decision-making? 
Well, let's start with that.

    Mr. Lannin. Thank you, Senator. It starts with that point 
of view that, as we say, puts the person at the center of the 
experience.

    When we think about developing an experience, we think 
first about the employee and how they are using AI. And we have 
several principles I want to kind of unpack in terms of like 
how we apply that principle in our product experience.

    When you are using a product of AI in an area where you are 
applying judgment for something that is important, bringing 
someone on board into your organization, promoting them, it 
needs to be very clear to the user that they are engaging with 
AI, and that is very critical.

    Second, they need to know how they are passing data into 
the AI to make a decision. What is the basis for the 
information that is coming back from that AI system that they 
are evaluating and looking at.

    We have learned from talking to employees and sort of 
looking at how they use our products, that if they have those 
two things in place, they have a better sense of what is 
happening and they can then apply their judgment to any 
resulting decisions or content that is being created for them, 
to apply that into their work environment.

    That is what gives them the confidence in using the AI 
systems. It is also what gives the employers the confidence in 
using the AI system. So, from the perspective of the employers, 
they want to know what types of AI is powering the systems.

    They want to know that we have evaluated those risks. They 
want to know that we have really continued to invest in 
understanding when AI is used, and we treat AI as something 
that customers can opt into, not opt out of.

    Now, it is the case that over 80 percent of our customers 
at work, they have opted into using our AI solutions, but that 
is a conscious choice, and we have to provide them a lot of 
information to substantiate that work.

    Senator Hickenlooper. Great. Thank you. And I have more 
questions, but I am going to go around the horn first. So, we 
are in the beginning stages of what I always think of is the 
great transition.

    It is not just to clean energy, but it is our worlds are 
changing simultaneously. But as we are doing that, we are 
building the careers of the 21st century. Mr. Billingsley, in 
your testimony, you allude to how Tulsa, and I know Oklahoma 
City better than I know Tulsa just because there is a band 
there called The Flaming Lips that I have listened to 
occasionally.

    But you allude to how Tulsa, specifically the community 
Greenwood, was left out of the last technological revolution. 
What lessons can we learn to effectively incorporate AI 
literacy training into our workforce development in smaller, 
rural communities, and particularly from my point of view, 
small businesses?

    Mr. Billingsley. Thank you, Chairman. I would actually 
speak about Greenwood kind of being a microcosm for 
marginalized communities across the country.

    We know communities of color, and typically underserved 
ones are often left out of these kinds of technological 
revolutions, which leads me to why I made my third point. I 
think it is critical for, when it comes to making policy and 
advising in terms of how we are going to build the 
infrastructure, to ensure AI is something that everyone has 
access to.

    We have to over-index in the communities that have 
historically been left out because we know that AI already has 
the potential to cause a lot of disruption. But if that is 
layered on top of a community that already didn't have some of 
the basic resources, whether it be from broadband or computer 
literacy from a previous technological jump, we could see a 
worse effect.

    But that is not to speak of the negative aspects. It is to 
speak of the positive aspects. Think about some of the 
unleashed creativity potential that could happen if systems 
were developed specifically around ensuring that people in 
these communities were able to have on ramps to be trained in 
them and also get jobs in the field.

    When I say the field, I don't mean AI as its own vertical 
just specifically, but I also mean many of the high growth 
industries that we know will last in the--for the foreseeable 
future.

    Senator Hickenlooper. Absolutely. No, I get that, that the 
overlapping nature of some of our previous technological 
revolutions or disruptions did leave--they left whole 
communities behind. And now, we could--we run the risk of 
compounding that--those gaps. I will turn it over now. We are 
out of time. I will get back to you guys later. But for now, I 
will turn it over to Ranking Member Braun.

    Senator Braun. Thank you, Mr. Chairman. Mr. Newman, I was 
listening. My first question was going to be about, how do we 
do this between the Federal Government, and state and local 
Government.

    You cited that already some of the lower levels of 
Government have gotten out there. I think you made it clear 
that you think we need some template here that will be the 
general framework. Is that in a nutshell what you said earlier?

    Mr. Newman. It is Ranking Member Braun. The companies that 
want to use this are being faced with a vexing and increasing 
patchwork of state and local laws, some of which are 
promulgated by folks who are less than informed on the 
technology, the upside risks and the downside risks.

    This is creating a lot of headwinds for those who want to 
innovate, those who want to responsibly deploy, and those who 
want to make sure, as my fellow folks here testifying, want to 
make sure this is done responsibly.

    I am anti-regulation by DNA, but this is an area where I 
think the Federal Government ought to act responsibly and 
prudently, and occupy the field, so there is a uniform set of 
rules to do this responsibly that large and small companies 
alike can draw from and make sure they are on the right side of 
the compliance line while innovating.

    Senator Braun. You referenced something that is in the 
House currently. How long has that been there? Was it in the 
last Congress, or did it originate in this Congress?

    Mr. Newman. It made it to a discussion draft bill, not a 
formal numbered bill, and it was in the 2018 Congress. I think 
that was a 118th Congress.

    Senator Braun. You mean the last Congress?

    Mr. Newman. Yes.

    Senator Braun. That was 117th.

    Mr. Newman. 117th. Yes, sir.

    Senator Braun. Okay. So, it made it to that point. Any 
other formality on legislation that you are aware of?

    Mr. Newman. There is a bunch kicking around, but no.

    Senator Braun. I think Senator Hickenlooper and I will take 
a look at that. You talk about the downside risks. I am going 
to call it the nefarious use of AI. Could you give me your top 
three biggest concerns, both domestically and internationally, 
in terms of what that might be in the time you have been 
looking at this?

    Mr. Newman. In the employment context or generally?

    Senator Braun. I am talking more broadly here now.

    Mr. Newman. Yes, I think AI could be use nefariously and 
will be by state actors to influence domestic issues. I think 
there will be a lot of fakes, voice and image. I think AI will 
be used to interfere with our elections and promulgate cyber-
attacks. Those are the most national security points of 
concern, in my view, ex the workplace.

    Senator Braun. I am glad you got it on record because we 
hear a lot about it and a lot of times it is just referred to 
generally. Thank you. Ms. Morley Ryan intrigued me. You work 
for Accenture. In fact, you mentioned--and workforce is such a 
big deal in a place like Indiana. We have got inherently low 
unemployment rates.

    We have half our counties that are trying to find their 
next act. That idea of getting better skills while you are in 
the place where everyone goes to school K through 12. How do 
you see that?

    I thought you mentioned that you are going to have entry 
level positions in your own company that don't require a 4-year 
degree. Is that true, and would you elaborate on that?

    Ms. Morley Ryan. Yes. Thank you, Senator Braun. Yes, we 
have multiple ways to come into Accenture. To your point, half 
of our entry level positions, or almost half of our entry level 
positions, do not require a 4-year degree.

    Senator Braun. Currently?

    Ms. Morley Ryan. Currently. Yes. And we hire 20 percent of 
our entry level positions through our apprentice program across 
North America. We have had 2,000 apprentices since 2016. We 
also do a bunch around apprentice networks across the country.

    We don't have one in Indiana yet, but Chicago was our 
founding apprentice network where we encouraged other employers 
to join us in building apprentice work and learn programs.

    Additionally, from an access and onramp perspective, we 
work with nonprofits and other organizations to provide our 
perspective on technology and AI fluency to inform how they are 
developing their learning and training programs.

    Senator Braun. You mentioned, too, that you were going to 
increase--how many employees does Accenture have currently?

    Ms. Morley Ryan. We have 733,000 employees globally.

    Senator Braun. Okay. And you mentioned going from 40,000 to 
80,000.

    Ms. Morley Ryan. Yes, sir.

    Senator Braun. Particularly aimed at an AI focus.

    Ms. Morley Ryan. Yes, sir. Data and AI.

    Senator Braun. You are going to bump it 5 to 10 percent of 
total employment on that. And again, a large percentage of 
those will be you, if you come out of high school with the 
right aptitude, you could come and apply for a job and get one.

    Ms. Morley Ryan. Yes. Assuming that there are openings and 
all that sort of thing----

    Senator Braun. Sure.

    Ms. Morley Ryan. But yes, and I think----

    Senator Braun. I think that is an amazing statistic from a 
company like Accenture that I would have just assumed it would 
have taken a 4-year degree. My daughter actually worked there 
for four or 5 years----

    Ms. Morley Ryan. Oh, Okay.

    Senator Braun. Now, in the company that I built. She and 
her two brothers are running it, but I think that is something 
we need to shout out more.

    Ms. Morley Ryan. Yes.

    Senator Braun. College educations are getting so expensive. 
The stuff that I see is only 35 percent of the jobs actually 
require it. It is generally in technical or professional 
training. I think it is neat that you are doing that in a way 
that to me then emphasizes how important that K through 12 
education is and teaching real life skills for a multitude of 
uses once you graduate from high school. I will yield back.

    Senator Hickenlooper. All right.

    Senator Casey.

    Senator Casey. Mr. Chairman, thanks very much. Before I 
start my questions, I wanted to ask unanimous consent that a 
statement be entered to the record. It is from Matthew Shearer 
entitled, The Promise and the Peril of AI in the Workplace. It 
is dated today. I would ask consent to make that part of the 
record.

    Senator Hickenlooper. Without objection.

    [The following information can be found on page 54 in 
Additional Material:]

    Senator Casey. Thanks very much. As Congress considers 
artificial intelligence and the future of work, it is critical 
that we focus on workers' voices and then ensure that workers 
have a seat at the table when policies are made and decisions 
are made--being made that impact workplaces, excuse me, in such 
a significant way.

    As the power imbalance in workplaces continues to grow, 
employers are increasingly willing to use workplace 
technologies like AI, as well as invasive surveillance 
technologies that will allow them to track workers like--almost 
like pieces of equipment.

    Decisions are being made solely by employers without 
consultation or input from workers, and that is why I have 
introduced several bills aimed at creating a much needed set of 
rules, standards, protections, and oversight to counter the 
risks of workplace technologies that are spreading unchecked.

    This July, I introduced the No Robot Bosses Act in Senate 
Bill 2419, which aims to regulate the potential risks and use 
of AI in the workplace. This bill would add protections for job 
applicants and employees related to automated decision systems 
and would require employers to disclose when and how these 
systems are being used.

    It will also create guardrails around how AI can manage 
workers. A second bill, by way of example, is the Stop Spying 
Bosses Act. This is Senate Bill 262 that I introduced in 
February to require disclosures and prohibitions for employers 
engaging in surveillance of workers.

    American workers are the backbone of our Country, and they 
deserve to be treated with basic dignity at work. I am hopeful 
that these bills and other actions that we take will help 
empower and protect workers, and I will continue to fight for 
those protections and rights. Mr. Newman, I just have a 
question for you.

    Do you agree that the rise of AI has created both novel and 
unaddressed issues in the American workforce, and particularly 
with respect to both the autonomy of and the dignity of the 
American worker, and that it requires both study and 
appropriate rules of the road?

    Mr. Newman. I agree with you 100 percent, Senator.

    Senator Casey. Thank you. And I hope we can work together 
on legislation and other policies that relate to workers. Mr. 
Chairman, that is all I have. I will give back all my time.

    Senator Hickenlooper. Great. Thank you.

    Senator Budd.

    Senator Budd. Chairman, thank you. And I thank the panel 
for being here today. Mr. Lannin, whether businesses are aware 
of it or not, many of these existing services that they use--I 
mean it has had AI integrated into it for years, whether they 
knew that or not.

    But as this technology further develops and the public has 
greater access to tools like generative AI, how can businesses 
of all sizes best leverage this technology?

    Mr. Lannin. Thank you, Senator. And it is true that there 
has been a breakthrough around the use of artificial 
intelligence in the last year and a sort of a greater awareness 
among people from all walks of life about what it means.

    That is pervasive from the employers and workers that we 
talk to. I think it is paramount that businesses are very 
transparent with their efforts in this area. It is one of the 
reasons that we believe not only in putting in place risk based 
frameworks, but sharing what we are doing as an industry is so 
important.

    We hear more and more an interest from people who are both 
workers at companies and employers in understanding exactly how 
we are employing AI and for what ends. And when we provide that 
level of transparency, and the more we can do that in a 
standardized way, to Mr. Newman's point, I think we will get 
more confidence and trust built around the use of AI. And I 
think fundamentally that is what this is about.

    It is something new and it is going to take time for people 
to build trust and confidence in these systems. And if you are 
not transparent with the ways that you are leveraging AI, you 
are not going to be successful in sort of getting people 
comfortable and getting the most out of this technology.

    Senator Budd. Workday is a very well-known company, but it 
is most thought of as more of an enterprise level. What would 
you suggest for small businesses to more quickly adopt some of 
the AI?

    Mr. Lannin. Yes. Thank you, Senator. In my experience, it 
is taking an open mind toward experimentation or having an eye 
toward risk. There are a lot of great resources.

    There are emerging skill sets around AI that are coming up. 
And as we have talked about so far in the testimony, availing 
yourself of about the online resources around prompt 
engineering, responsible use of large language models are all 
really valuable frameworks.

    Just within our organization, we do a lot of pretty 
informal training on how best to use AI technologies to make 
decisions and just driving a conversation around that, 
technology in the workplace, really elevates the discussion and 
allows us to sort of embrace the technology. And we also sort 
of encourage like a skeptical attitude.

    Try things, try to break it, see if it really works, and in 
a practical sense, see if it has bias. And when you get comfort 
level with people using this technology, it is pretty amazing. 
And finally, I will just say, like watching my daughter go to 
school and come back using these tools in her classes, it is 
really interesting seeing in the last year professors switching 
to a mindset of like, we expect you to use these tools, just 
disclose that you are using them.

    Explain how you are working with them. Don't just write the 
essay and pretend it is yours. Like really use this in a 
meaningful way. And I think that principle holds for small 
businesses and large businesses as well.

    Senator Budd. That is helpful. Thank you. So, in the coming 
years, AI regulation will present a difficult challenge to both 
Congress and Federal agencies.

    Already, the European Union has proposed regulations that 
would classify AI technology, according to a four tier risk 
based system, and California's Governor has directed state 
agencies to examine and report on so-called high risk 
applications of AI, including those that would cause workforce 
displacement.

    I think that the Federal Government should really tread 
carefully when considering new regulations in any form. And I 
appreciate your sentiment and your DNA, Mr. Newman. And I think 
that is particularly true in such a cutting edge industry.

    But, Mr. Newman, what impacts could these early attempts at 
regulation, could they have on the very development of AI 
technology?

    Mr. Newman. Well, I think we are seeing it in the state and 
local level in a patchwork of various approaches. It can be 
viewed as anti-innovative. It can raise the cost. It can fuel 
litigation. It can create barriers to responsible adoption.

    A lot of the developers are scratching their heads saying, 
what do I have to do in California? What do I have to do in New 
York City? Should we be in New York City if that is what we 
have to do? That is the opposite of what we want as a society.

    We want clarity. We want efficiency. We want fairness. We 
want rational regulation. And we are creating a hodgepodge of 
anti-competitive, anti-innovation catch or catch can all over 
the country, and that isn't desirable to fuel innovation.

    Senator Budd. Thank you all again for being here. Thank 
you, Chairman. I yield back.

    Senator Hickenlooper. Thank you.

    All right, Senator Kaine.

    Senator Kaine. Thank you, Mr. Chairman. And thanks to our 
witnesses for being here. At least three of you, Mr. 
Billingsley, Mr. Lannin, and Ms. Morley. Ryan, your testimony 
is really focused on workforce issues. Mr. Newman, you really 
get into how to conceive of the regulatory challenge, not that 
you ignore the workforce issues, but I really want to focus on 
the workforce side.

    Maybe I will use, Mr. Lannin, your written testimony. ``We 
believe a shift to a skills based approach to talent is the 
best way forward. By a skills based approach to talent we mean 
an emphasis on what a person can do or learn rather than solely 
on their credentials.''

    I kind of read Mr. Billingsley testimony about the need to 
over-index investment in education and training and communities 
representing people of color. Ms. Morley Ryan, you are talking 
about Accenture's apprenticeship programs and some of the 
things you are doing.

    Okay, how do we deal with the workforce and how do we look 
at what it is to be educated and ready to succeed in an AI 
dominant economy? We are woefully behind in a number of the 
policies we have at the Federal level. Senator Braun and I are 
co-sponsors of a bill that has now been pending before the 
Senate for 9 years.

    The bill would do something really radical. It would allow 
Pell Grants to be used for career and technical training and 
not just college. It has virtually zero cost. It has--it has 
had about 60 Members of the Senate currently serving as co-
sponsors at one time or another. It has gotten close to being 
passed, but there always seems to be something in the way.

    Most recently, we had it on the list for a markup in 
Committee, but there were two other bills being markup that day 
that were controversial, and so the entire markup was pulled 
down, and what we expected was going to be essentially a voice 
unanimous vote from the Committee never happened. It has not 
yet been scheduled for another markup.

    Meanwhile, all of my employers are telling me they are 
having a hard time hiring people. We just did a manufacturing 
bill. Who is going to make it? We just did an infrastructure 
bill. Who is going to build it?

    You have testified that significant percentages of your 
employees don't need college degrees, and yet we offer to 
families whose kids want to go to college or whose parents want 
their kids to go to college a significant financial 
entitlement, an incentive they can count on in the Pell Grant.

    But for a family that wants to have a youngster in Tulsa, 
for example, master skills to be an AI professional decades 
forward that doesn't require a college degree, we don't 
necessarily provide easily accessible financial aid for that 
family or for that student. Just seems to me to be a no 
brainer, a no brainer.

    I agree with you, Mr. Lannin, we really are moving to sort 
of skills rather than credentials. Now, sometimes the best 
credentials are a validator of skills. So, somebody who can 
pass the American Welding Society certification exam, they can 
take that anywhere in the country, and they may not know what 
the name of the high school you attended or what college you 
went to, but they know an AWS certification is.

    A credential can often be a validation of the skills or the 
validation of your ability to succeed in this area. But I just 
would like to throw it open to you we are the HELP Committee. 
We set Federal education policy, including--how we incentivize 
students and their families to learn.

    I think we ought to incentivize college attendance, but I 
don't think we should suggest that college is the only way for 
somebody to successfully learn and be productive in this 
economy, and I would just love any of your comments on that.

    Mr. Lannin. Yes. Thank you, Senator. I couldn't agree more. 
And I hope that with the looming transformation of AI, could be 
used as impetus for taking action now at a congressional level.

    I would just say, like Accenture we have had a lot of 
success with our opportunity onramp program at Workday, where 
20 percent of our hires this year in early and mid-stage 
careers will come from a program that works with nonprofits to 
provide skill based training for people at Workday. 4 to 6 
month internships that are paid, transitioning to full time 
hires at our company.

    People don't have to come from a background where they have 
had the opportunity to get a college degree, or maybe they are 
a midlife and they are a veteran, or they are coming as a 
caregiver and just having that skills based orientation and 
mindset is so beneficial to us as an organization, and I do 
think we share that with my other panelists.

    Senator Kaine. Mr. Billingsley.

    Mr. Billingsley. Absolutely. So, I would draw a parallel 
between something that we are actually doing in Tulsa.

    We are trying to tackle a similar issue as it relates to 
the cybersecurity industry, and we have taken--we have some 
nontraditional programs like the Cyber Skills Center that 
offers a 6-month boot camp that we then use to connect people 
to apprenticeships within companies so that they can grow and 
be groomed and then get full time employment.

    We should see something similar as it relates to the 
infrastructure around education and certification with 
artificial intelligence. But another thing we should consider 
is community wide use case training.

    One of the best ways for people to understand the power of 
artificial intelligence, specifically in different areas of the 
workforce, is for them to get hands on experience, seeing how 
effective it can be as a copilot for them.

    One of the things that we have worked on designing in 
partnership CDI how do you go into a community and take some 
critical areas, workforce areas, and get the community to use 
whether they be not just chat bots but other forms of AI as 
copilots, whether it be in creative expression grant writing, 
community development, social and criminal justice.

    We can provide real world examples of how people can use AI 
to enhance and improve their output in their career. That is a 
perfect way to get initial exposure before you plug them into 
an actual preset infrastructure.

    Senator Kaine. [Technical problems.]

    Ms. Morley Ryan. Yes. I echo again my fellow panelists 
here. I think what you are speaking to, Mr. Billingsley, is 
also just this overall technology and AI fluency that we need 
to be driving at the broadest level.

    I think that starts at the K-12, sort of exposing people 
not only to the careers, which I think has been discussed quite 
a bit, but the technology in the context that it is a treat, to 
your point, Senator Hickenlooper, at the beginning, and not a 
trick, right.

    We want people to see what the value is for them within 
their own context, within their own sort of incentives and 
environment. And that comes back, I think, to what everybody 
has said so far today, which is--centering the human or the 
person as a part of this conversation.

    To your question on sort of workforce preparedness, 
Accenture is very much in the same--in line with you around 
providing opportunities, whether it is not a degree program, or 
even a credential, but really driving technology and add 
fluency in a variety of ways, which could be through work based 
learning, it could be through a credential program or a two or 
4 year degree, or it could candidly continue to just be on the 
job, or within their K to12 education. Thank you for the 
question.

    Senator Kaine. Thank you so much. I yield back.

    Senator Hickenlooper. That was a great question. They are 
all great questions. And I agree that the making sure 
everything is human centered is key. It is our prerogative to 
continue the questioning. So, this--when you saw no other 
centers coming in, perhaps you breathed a sigh of release, but 
you should hold that sigh.

    Ms.Morley Ryan and I think what we have seen with a lot of 
the questions and responses is that the balance between risk 
and opportunity that AI poses, and I think, I feel that we have 
an alliance of people that are more excited by the opportunity. 
Not that we don't have to be aware of the risks, but the 
opportunity is so exciting. And Senator Braun talked a little 
bit about small businesses.

    Ms.Morley Ryan, I want to make sure that small businesses 
see the excitement of opportunity here. Having ways to train 
workforce. Again, I was so impressed that almost half your 
entry level work slots don't require college degrees.

    When I was Governor of Colorado, we went--we spent a couple 
of years going through almost every work, every job in the 
State Government, and we found that almost half of them, we 
could not justify the college degree that was being required. 
We got rid of it. But boy, was there a lot of pushback on that.

    I think--well, I think that allowing small businesses to be 
able to see what you guys have clearly seen, and it is really 
about skills and the ability to acquire these skills. So, how 
can we ensure that the AI education, this fluency you describe, 
and that the workforce development opportunities are tailored 
so that businesses of all sizes can get excited about it.

    Ms. Morley Ryan. Thank you for the question. I think it 
starts again in this sort of K to 12 exposure, because people 
are using this technology. I think one of the things that we 
have learned from small, medium, large sized businesses that 
Accenture serves right now is that the youngest people are 
often having two computers up, right.

    The computer that is their work computer and the computer 
that they have their generative AI applications running on. So, 
they are--young people in general, I would say, are already 
using these applications. And for a small business, I think the 
presumption should be, they are going to be bringing this 
knowledge.

    Now, whether it is to my fellow panelists' point, inform 
around how this technology works or not, I think the importance 
for small businesses is that they are, to your point, driving 
fluency, but leveraging what is available from what I would say 
trusted organizations in this space, from a learning 
perspective.

    Accenture developed our responsibly AI framework even 
before NIST responsibly framework. But there is organizations 
like NIST that I think small businesses can look to, say, Okay, 
what should our governance or our policy for our organization 
be? And it is not over-burdensome because you have something 
that you can reference, right.

    I think the second piece is looking at what is publicly 
available, again from a trusted organizations. And I would have 
to come back to you with some--a written statement around that. 
That they can use to drive fluency. There is tons of 
democratized learning in this, in the world now, right. 
Learning is essentially free if you can go find the right 
places for it.

    I think it is kind of twofold, right, leveraging some of 
the existing frameworks and existing work that NIST and other 
organizations have done, but then also leveraging public 
learning in this space, would be a start.

    Senator Hickenlooper. Yes, no, I think you are exactly 
right with the democratization of learning and education.

    At various times the CEOs of Walmart, Target, Starbucks 
have said, we will share our, all of our IP in terms of around 
training and skills acquisition, if you could find a way to do 
that efficiently and fairly and have a system where you had a 
lifetime of apprenticeship opportunities.

    Kids of all ages could get stackable credentials. It would 
reflect their skills, acquisitions, and sort through that. I 
think AI really helps us get there. I actually, as an 
individual, I own the rights to the domain name myshot.com, 
which I bought about 7 years ago right when Hamilton had just 
come out.

    I don't think Lin-Manuel Miranda is going to actually ever 
let me use the song, but I did think that image of a country 
looking at this as myshot.com, people of all ages seeing that 
is something that you guys are working on.

    Let me say, Mr. Newman, we look, and we see the research 
this--that AI technologies can create all these positive 
opportunities, jobs across. And that AI will impact each 
workplace differently.

    It will be important to make sure that workers can access 
the trainings that meet a variety of skills and skill 
requirements. As this all happened so fast--these transitions 
are going so quickly, the potential that I think you lay out 
there that, that AI can be a tool to take intellectual property 
and violate the cost and the creation of that capital.

    What are some of--what do you imagine as some of the 
solutions that would protect companies to--in that situation?

    Mr. Newman. Yes. Well, coming from Silicon Valley, I think 
we place a premium on IP protection, and I think AI is a tool 
in the threat actors' arsenal to try through cyber or other 
means to implicate and compromise intellectual property, which 
is the bedrock of our Nation's innovation.

    I think that there does need to be a hard look at the IP 
protections afforded around AI. I think on the domestic side 
and non-national security side, there is now a large debate in 
the courts about whether copyright holders should be given 
compensation if their copyrighted work is used in data training 
set for an algorithm.

    I think that cries out for an as cap type model where there 
is a marking of copyrighted works and some statutory 
compensation to copyright holders. I mean, we are going to 
field of employment, but that is an AI generated issue with 
intellectual property.

    This really gets me to the point where, again, DNA wise I 
am against regulation, but what worries me is state and local 
regulators who don't have the time and resources to delve into 
this area and understand the technology, understand the legal 
issues, understand the worker versus managements, all of these 
considerations are important.

    That is why I think AI cries out for a Federal uniform 
solution in most, if not all, domains, national security and 
civil side as well, because it is the Federal Government that 
is uniquely positioned with its resources and the folks who are 
serving in the Federal Government to take the time to 
understand the issues we are just exploring today.

    I think we are going to have a better bipartisan resolution 
that meets all of the varying constituents' legitimate needs if 
the Federal Government acts versus the state and local 
patchwork we are getting in every aspect of AI. I think it is 
detrimental to both sides of the debate.

    Senator Hickenlooper. Great. Thank you.

    Senator Braun.

    Senator Braun. Mr. Lannin, Workday has only been a company 
for 18 years, it looks like. It started in 2005, financial 
planning, HR. A lot of companies started then. When did you 
start incorporating AI into what you do as a company and the 
consulting you give to others?

    Mr. Lannin. Thank you, Senator. Yes, it has been an amazing 
18 year ride for the company. And it was interesting for us 
because we were one of the first companies to move to the 
cloud.

    At the time that was very new for the type of work that we 
were doing, and there were a lot of incumbent questions upon us 
from customers about is the data is secure, cannot be trusted.

    Some of those bedrock principles that we founded at the 
start of the company hold very much true as we have started to 
make forays into AI over the last number of years, few years, 
especially in 2019. We had----

    Senator Braun. On the timeline, the cloud, I think we all 
understand now. When did you actually formalize the use of AI 
into your own company and what you advise to others?

    Mr. Lannin. Yes, I want to follow-up with making sure it 
doesn't pre-date the data I am going to give you. But 2018, 
2019 was a time when we started developing machine learning 
based algorithms to deliver capabilities.

    That is also when we started working on what would become a 
lot of the NIST based AI risk management frameworks to go along 
with that work. And so----

    Senator Braun. You are on the leading edge of it. So that 
is three to four, maybe 5 years. And the distance we have 
traveled, that is amazing.

    Begs the question, since you are on the leading edge of it 
and we generally always hear about what good comes from it, are 
there any examples of where even in your own company or with 
businesses that have incorporated it, have gotten ahead of 
their skis and had issues with it?

    Mr. Lannin. None of significance, but I think we are so 
leaning into a prevailing concern with our experience that we 
could introduce risk, especially in terms of bias and 
discrimination into the workplace.

    I think that is most pronounced for us as we start to 
evaluate some of these generative AI technologies. One of the 
things that a lot of our first generation AI was good at was 
like predicting financial numbers, doing math. Does your 
payroll add up.

    Senator Braun. The low hanging fruit.

    Mr. Lannin. The low hanging fruit. And now we are talking 
about AI systems that can write business documents, evaluate 
contracts, really do a lot----

    Senator Braun. Fair to say we are on the cusp of all the 
potential that might be good ahead of us, but a lot of the 
potential issues, which would beg the kind of a general 
regulatory framework, are just coming to the surface.

    Mr. Lannin. I think that is true. And I agree that we are a 
company that is very accustomed to working in regulated 
environments with a lot of different compliance regimes, cyber 
security, FedRAMP, many of these things.

    We are comfortable with that, but what--it really hurts 
when you have a mishmash of different approaches. And having 
something uniform at a national level and allowing the U.S. to 
take leadership in this area is really important.

    A lot of our businesses operate at a global level, and so, 
the more we can have a simplified, smart set of regulations, 
the more benefit we will have. And I think those benefits will 
accrue to all nature of businesses.

    Senator Braun. Mr. Billingsley, when you take what we just 
talked about there and then you related to entrepreneurs 
wanting to capitalize on it, we have seen cryptocurrency being 
something a little bit amorphous recently in terms of the 
volatility of it, No. 1.

    What is your concern about everything we have discussed 
here in terms of entrepreneurs who generally are a little less 
risk averse, plowing into a field where they want to build a 
company when there are so many inherent uncertainties around 
it.

    Mr. Billingsley. Thank you for the question. I actually 
think this is why the conversation around workforce is 
critical, because when we talk about how you are going to use 
AI, if it is going to be the bedrock of the new economy, that 
is both in terms of workforce and entrepreneurship, in a lot of 
ways some of the best entrepreneurs are people who spent a long 
time in a field learning a specific skill and then they branch 
out and start their own companies.

    When you talk about risk averse entrepreneurs, yes, some 
will jump up and start companies without any background. But if 
we create the correct framework for people to learn and be 
trained with AI in the workforce, we are actually training up 
some more responsible people who have more fluent skills in 
terms of AI.

    When they start, perhaps AI enabled businesses and 
companies, they can use them more responsibly. They can use 
them more effectively because they will have the reference 
point of what they learned and how they saw it administrated 
when they were in the workforce.

    Senator Braun. I look back to the dot com craze as an 
analog, based upon just technology in general, and look at the 
number of companies that flamed out in a short period of time 
back then, and look now how important that has been in terms of 
woven into almost every aspect.

    I think that was a lot less concerning then. But when you 
do get a hot new technology, entrepreneurs generally not being 
risk averse, this to me almost looks like it is more full of 
potential pitfalls than what we would have had back two decades 
ago.

    Mr. Billingsley. Absolutely. I think that is the inherent 
nature of how AI should be approached.

    When you have got a tool, I always use the analogy two kids 
hitting each other with pillows is one thing. But if they ended 
up having an actual weapon, the amount of times you have to get 
it wrong is one.

    When we think about specifically high growth companies who 
are going to integrate AI and using it for solutions that are 
critical for whether it be loan applications and critical 
decisions, you don't have very many times to get it right 
before it becomes a serious problem.

    The reference and initial framework is more critical than 
it has ever been.

    Senator Braun. Thank you.

    Senator Hickenlooper. Senator Kaine.

    Senator Kaine. Thank you, Mr. Chair. And now, Mr. Newman, I 
might get to you, since I dealt with my other three witnesses 
in the first round. First, I was intrigued with one aspect of 
your testimony that was cryptic and unexplained.

    I think I know what you mean, but I wanted to ask you about 
it. I am not part of any lobbying special interest or industry 
group. I am here as a concerned citizen and father. Why did you 
throw father into your testimony?

    Mr. Newman. I have five children, and the world they are 
coming into is going to be impacted from a 24 hour cycle, a 
sleep, awake, all the way back to a sleep by AI, and I am 
concerned. I know firsthand the tremendous upside AI offers in 
every use case, including the workforce.

    Again, by DNA, I am anti-regulation, but AI from what I 
have seen behind the scenes, from those developing it and 
innovating it, they mean well, they are doing the best they 
can, but this is an area for the health, welfare, and safety of 
society, I believe the Federal Government ought to provide 
rules of the road.

    Senator Kaine. It sounds like from listening to your 
testimony, reading it, but also listening to you in the Q&A 
that your belief in Federal regulation sort of is justified by 
two pillars.

    One is there would be a danger of differing state level 
regulatory schemes that could choke off innovation, that could 
create huge problems for the development of this industry, that 
could put us at a strategic disadvantage with other nations.

    The one justification for a Federal framework is to avoid 
needless complexity and contradictory state level regulation. 
But then the second level is sort of on the more affirmative 
side, you think that there are aspects where we could advance 
good and put up guardrails against bad by doing the Federal 
level regulation.

    One item in your, the third page of your testimony, where 
you go over the sort of five--your five points about the 
different sections intrigued me. Section 202 creates a Federal 
worker realignment program to aid covered individuals displaced 
by AI, by training such individuals for alternative careers, 
and by helping such individuals find employment opportunities.

    We have an analog to that in trade adjustment assistance. 
So, for a long while we have had Federal programs to focus 
resources on individuals and communities if trade has disrupted 
something that they have counted on as a pillar of the economy.

    Until I read your testimony, I had not heard someone 
suggest the same thing from those displaced by AI or other 
technological advancements. My experience as a Mayor and 
Governor before I got here is that more people lose jobs to 
technology changes than to trade. But with trade, there is 
somebody you can blame.

    You can blame the person who negotiated the trade deal. It 
is a job has gone overseas. There might be a plant with a lock 
on it. It is easy to blame. Whereas we don't really want to 
blame technology because we all like carrying around the latest 
version of these.

    We tend not to focus so much upon the dislocations in the 
workforce caused by technology. But I thought that was an 
interesting proposal and thinking about it kind of connected to 
trade adjustment assistance. I found it to be a creative one. 
You want to expand on that?

    Mr. Newman. Yes, I have had this debate with many of folk, 
is AI the cotton gin. And are we luddites. And will there be 
more jobs created?

    Yes, there will be some jobs created. But let me take my 
profession as an example, and maybe it is a good thing, but 
there are going to be less lawyers, Okay. There is tremendous 
private equity and venture capital being deployed to create AI 
solutions in the law, and they are going to be amazingly 
effective in doing things better than the human can do in the 
law.

    Now, with our rule of law system, we always need humans. 
And there is going to be, in my view, you don't want AI judges, 
AI juries. But in the day to day practice of law, they are 
going to be less lawyers, less paralegals, less admin, and 
there isn't going to be a reentry into the workforce for a lot 
of these folks with their skill set.

    I do come out on the side that AI is fundamentally 
different than all that has come before, and the impact on the 
workforce will be different, and there will ultimately, in my 
view, be dislocation on a different level than we have seen 
before.

    I do think one aspect, if the Federal Government is 
eventually going to legislate this, is not only providing for 
something like a chief AI officer and the necessity for one, 
and having an AI board like we have, the FCC, the FDA, 
etcetera, or the NLRB, or the EEOC, but I think we are going to 
need a worker retraining program that is federally funded, that 
allows workers of various skill sets to have a way to reenter 
the workforce in some way if they are displaced by AI.

    Senator Kaine. Let the record show Mr. Billingsley was 
emphatically nodding his head yes on that last point. So, I 
think that is an important thing for us to hear. I appreciate 
it.

    Senator Hickenlooper. Great. Great question, and I 
appreciate the answer. I have got quick questions. I know that 
I am standing between you and freedom, and perhaps your lunch. 
So, let me see the first question I want.

    Ms. Morley Ryan. your recent, or Accenture's recent life 
trends report states that technology today feels like it is 
happening to people, not for them. What does your research 
indicate about the skills that workers are seeking out to help 
them understand and leverage AI, and how can adequate skills 
training help workers to regain and restore their sense of 
trust in the workplace?

    Then, Mr. Billingsley, I am going to ask you to comment on 
this as well.

    Ms. Morley Ryan. I think the question--thank you for that 
question, Senator. I think the question that has sort of two--
or my answer will have two parts. One is, we focus a lot on the 
hard skills, sort of what is AI, what does this technology do, 
how can I use it.

    What Accenture has found through our extensive work with 
our own people and the $1 billion a year that we invest in our 
own learning, as well as our client conversations and 
engagement in the community, is that it is just as important to 
have what I would call sort of the support to build a culture 
of learning, right. Growth mindset, self-efficacy, agency for 
that learner to have choice as to say what job is going to be 
their next job and giving them an opportunity to make that 
choice.

    I think there is a component of sort of the hard skills 
piece, if that makes sense, from an availability, but then also 
recognizing what we know about human behavior, cognitive 
science, and neuroscience, about how people learn, so that we 
provide opportunities that--and training programs and learning 
programs that allow and are based on that knowledge. Yes.

    Senator Hickenlooper. Okay. Mr. Billingsley.

    Mr. Billingsley. Absolutely. I would echo those sentiments. 
In my community we have a saying called what you do for me 
without me, you do to me. And I think that is often the entire 
approach of these technological revolutions, or to be frank, 
even sometimes when regulation is handed down.

    I think that this new age of AI that we are in is also an 
opportunity for us to take a far more community focused 
approach when it comes to not only figuring out what are the 
right decisions to make, but how are things actually going to 
affect people in real time, engaging workers, engaging 
community members in exposing them to this technology, to go 
back to that point. Exposing them to this technology in two 
different tracks.

    One that is more framed in terms of how they might apply it 
in the workforce. But another that is more general, that helps 
people specifically in communities of color, many of whom have 
a really terrifying view of AI, that gets them to develop a 
culture that they are more comfortable with it, they can adopt 
it, but also they can see using it as a remedy to so many of 
the stumbling blocks that they have often faced, both in the 
workforce or in everyday life.

    The culture and the social systems we build around AI are 
equally as important as the technology. For most people, it is 
more important because most people aren't on the fringes to be 
able to influence how the technology actually works, 
fundamentally.

    But for most of us, it is these systems we develop. So that 
is where most of the energy needs to go, and it needs to be 
human, and people focused.

    Senator Hickenlooper. Right. Got that. And then on that 
same similar slant, Mr. Newman, I thought--I mean, we all have 
a vested interest in protecting the rights of workers, 
especially their civil rights. But, and you were talking about 
that this universal opportunity for retraining workers that I 
think really makes a lot of sense. All of you have said a 
version of that along here.

    Mr. Newman, in your experience, what are some of the 
factors that should weigh--that employers should weigh, should 
be thinking about when considering AI implementation to really 
help make sure that workers are included and at the same time 
protected, but really included as well? Just, I think sort of 
what Mr. Billingsley was saying.

    Mr. Newman. Yes, Thank you for the question, Chairman. The 
framework that all companies should aspire to who deploy AI, 
whether large or small, is to have either by name or the 
equivalent a chief AI officer.

    One of their responsibilities will be to educate and 
disclose transparently to the workforce what AI systems are 
being used in the workplace that can affect your hire, your 
fire, your promotion, your identification for promotion, job 
selection, etcetera.

    By being transparent in that way as one facet of the chief 
AI's officer's job, it takes a lot of the fear and uncertainty 
away, and the workforce can see that they are not being treated 
unfairly by AI because they understand what is happening. It is 
the black box approach.

    It is the, we are using it in ways we are not showing you 
to spy and harm you, versus very responsible ways to use AI in 
the employment context that ought to be disclosed and workers 
should understand what is happening.

    Senator Hickenlooper. Right. No, excellent points made. My 
last question for Mr. Lannin, although you could all--I mean, 
every one of you could have answered every one of these 
questions. It is so--such a great panel. There are a number of 
ways that AI obviously can enhance workplace processes.

    You have all described this. Promote efficiencies, make 
workers more productive, make their lives easier in many cases. 
This could go too far, and we run the risk of relying too much 
on AI, I think at--potentially at the expense of human 
decision-making. Imagine decision-making being a muscle that 
atrophies.

    Mr. Lannin, how are developers thinking about the need to 
balance advances in AI without losing sight of the critical 
analytic decision-making capability?

    Mr. Lannin. When we think about developing AI into our 
products, we need to think about what outcomes we are going to 
achieve as part of that process. Is it going to have an impact 
on the hiring we are doing? Is it going to have an impact on 
another part of the workforce?

    If we understand the outcomes, then we can understand where 
human judgment comes to play most. And we can think about AI as 
that copilot that allows someone to be more informed in their 
judgment.

    I think it starts with really assessing like, what are the 
key parts of any piece of work that matter the most, where we 
rely on that fundamental ability to make good decisions, and we 
can augment them, as sort of that foundation point.

    Yes, AI will show up in lots of simple, nondescript ways 
across the products. It will recommend a song that is pretty 
innocuous. But there are many places in the work that we do 
where human decision-making matters. It was a great point 
around the legal profession. For sure, we want our judges and 
our jurors to be human beings that are applying their judgment.

    I think that analogy holds for all kinds of different 
professions, and that is how I think about it, is what is the 
outcome we are driving. And if you think holistically about 
that, it is easy to arrive at the places. We need to keep 
people at the center.

    Senator Hickenlooper. Great. And that is, I think, where 
you started, was keeping people at the center. More questions?

    Senator Braun. I am good.

    Senator Hickenlooper. All right. I think, not that I am out 
of questions, but I think that I will back off at the moment. 
But I really, I can't thank you all enough for taking the time 
to be here. I think this has been so illuminating in so many 
ways and I feel so optimistic. Not that there aren't serious 
risks that you guys have all laid out, but that it is--and I am 
an optimist.

    Entrepreneurs, you can't be in small business--these days 
you can't be in Government if you are not somewhat of a small, 
of an optimist. And I think we--I come away from this feeling 
more hopeful than fearful.

    Anyway, that will end our hearing today. I would like to 
thank the colleagues who are here and watching on the Zoom, the 
internet. I want to thank each of our witnesses Mr. 
Billingsley, Mr. Lannin, Ms. Mobley Ryan, Mr. Newman--Morley 
Ryan, sorry. Mobley--Morley Ryan, and Mr. Newman.

    Again, words can't express how much I appreciate having 
such a wide arc of experience to help us work through this 
stuff. For any Senators that wish to ask additional questions 
or have questions that weren't asked today, questions for the 
record will be due within 10 business days. So, on Tuesday, 
November 15th at 5.00 p.m. So ordered. The Committee now stands 
adjourned.
                                ------                                


                          ADDITIONAL MATERIAL

             statement for the record from ibm corporation
    Chairman Hickenlooper and Ranking Member Braun.

    On behalf of IBM, thank you to the Senate Health, Education, Labor, 
and Pensions (HELP) Committee for convening a hearing on artificial 
intelligence (AI) and the future of work. This is an important and 
timely discussion, and IBM is pleased to share our perspective on the 
role of AI in shaping the future of the workforce.

    The future of work is here, and it redefines what work gets done, 
who does it, how they do it, and will require people working with 
technology. We--the private sector, government, educators, and 
workforce stakeholders--must collectively act now to ensure every 
American is prepared to work alongside digital tools, take on higher-
level and more meaningful work, and thrive in lifelong careers.

    When harnessed and deployed responsibly, with ethics at its core, 
AI has a tremendous opportunity to enrich and advance human ingenuity 
to help solve the most challenging and pressing problems of our time. 
IBM shares the following experiences and considerations as Congress 
deliberates AI-related legislation in the context of workforce and 
urges the United States to take a risk-based approach to AI.
                  Responsible Deployment of Technology
    The recent rise of generative AI catapulted this technology into 
the mainstream with dialog about the impact on society and the world of 
work, but AI innovation has been going on for decades. AI is not new 
for IBM, a leader in AI research and development since the 1950's.

    In recent years, IBM has been applying AI in our business 
processes, and today, support clients' digital transformation and 
deployments of generative AI tools. IBM recognizes AI is a powerful 
technology that must be deployed responsibly. We prioritize AI ethics 
and governance by adhering to long-held principles of trust and 
transparency. And IBM is clear that the role of AI is to augment and 
not replace human expertise and judgment.

    IBM believes the future of work is hybrid and flexible, based on a 
partnership between humans and digital tools. To advance this vision, 
IBM has advocated for regulating the use of technology, not the 
algorithms themselves, since 2020. Legislation based on end uses and 
in-context risks to consumers is the only way regulation can keep pace 
with the rapid evolution of technology. Our full perspective on the 
``precision regulation'' of AI can be read here.
               Preparing Workers for Jobs Augmented by AI
    IBM has long asserted that technology and automation will change 
today's jobs in some manner--new jobs will be created, many jobs will 
be transformed, and some tasks will transition away. And we are 
optimistic about the impact of AI on jobs.

    The World Economic Forum's (WEF) 2023 Future of Jobs report found 
that 50 percent of companies expect AI to create job growth, while 25 
percent expect it to create job losses. WEF's study also estimates AI 
will disrupt 85 million jobs globally through 2025--and create 97 
million new job roles. The IBM Institute for Business Value's recent 
survey of executives, ``Augmented work for an automated, AI-driven 
world,'' paints the same picture--87 percent of executives surveyed 
expect job roles to be augmented, rather than replaced, by generative 
AI. To further the point, the International Labor Organization also 
found that, ``the most important impact of the technology is likely to 
be of augmenting work--automating some tasks within an occupation while 
leaving time for other duties--as opposed to fully automating 
occupations.''

    As AI applications continue to infuse into our daily lives, 
Americans are becoming more familiar with the technology and starting 
to understand AI is a tool that can be used in many ways to support 
human decision-making. As our economy begins to transition to leverage 
AI across industries, new roles will be created, and many roles will be 
transformed by AI tools that help free human professionals to focus on 
higher-value and more meaningful responsibilities. This new dynamic 
will create opportunities for employers across industries to create 
environments where employees shift their focus to more rewarding work 
while letting technology do the more repetitive, administrative tasks.

    We, collectively, as industry leaders have a responsibility to help 
prepare the American workforce on how to capitalize on the benefits of 
AI. We also encourage policymakers to ensure that our public education 
and workforce systems are aligned to help individuals attain the skills 
needed to work with AI technologies.

    In 2021, IBM made a global commitment to help skill 30 million 
people by 2030. And recently, we committed to train two million 
learners in AI by the end of 2026--with a focus on underrepresented 
communities--through collaborations with global universities and new 
generative AI coursework through IBM SkillsBuild.
    Upskilling, Reskilling, and Lifelong Learning are key to Success

    As new technologies like generative AI begin to transform 
industries, critical skills and competencies will continue to play a 
crucial role in meeting the talent needs of employers. The WEF predicts 
that 44 percent of workers' skills will be disrupted between 2023 and 
2028--up 9 percentage points from its last 5-year projection. 
Similarly, research conducted by the IBM Institute of Business Value 
shows C-suite executives estimate that 40 percent of their workforce 
will need to reskill for AI and automation over the next 3 years.

    However, a new skills paradigm is emerging. As the IBM study points 
out, ``STEM skills are plummeting in importance, dropping from the top 
spot in 2016 to 12th place in 2023.'' It's not because STEM skills are 
no longer needed. Instead, executives surveyed for the study expect a 
basic level of technical acumen to work alongside AI and digital labor. 
Their top priorities now are people skills needed for higher-value jobs 
because the half-life of technical skills is less than 3 years. 
Technology's ubiquity and ease of use essentially democratizes basic 
STEM skills, making it possible for today's high-demand technical skill 
to be tomorrow's commodity.

    That's why IBM places talent and skills at the center of our people 
strategy. For instance, IBM requires employees to complete at least 40 
hours of learning annually and provides the tools for learning. IBM's 
integrated digital career experience platform--YourLearning--helps 
IBMers reflect on their skills, develop in their role, grow mentoring 
relationships, and advance in their career. Last year, each IBMer 
completed an average of 88 hours which is 22 million learning hours 
collectively. Furthermore, employees with the highest learning hours 
(at least 200) are 20 percent more likely to move to a new role and 44 
percent more likely to get a promotion. By providing continuous 
learning opportunities, including on topics like generative AI, IBMers 
can stay ahead of market demands and learn valuable technology career 
skills.

    Earlier this summer, over 160,000 IBMers participated in a company-
wide, global challenge to experiment with watsonx, a data and AI 
platform powered by IBM's foundation models. The challenge provided 
IBMers the opportunity to get hands-on experience with watsonx while 
helping us enhance the platform for clients and partners.
                          IBM H.R. Case Study

    IBM's Human Resources function was an early deployer of AI in 2016, 
adopting a model of employee-driven innovation. IBM trained H.R. 
specialists in AI topics like data analysis, behavioral psychology, 
prompt engineering, and ethics. Now, almost 70 percent of the ideas for 
new applications of AI in H.R. come from those employees. Before, most 
projects were driven top-down by management. As a result, we saw 
tangible outcomes of their efforts including:

        <bullet>  Saving 50,000 hours of work in one business unit's 
        promotions process, and saving 40 percent of their time overall 
        during the process

        <bullet>  Automating over 100 standard H.R. processes, and

        <bullet>  Saving our recruiters 6.5 hours of administrative 
        work per week.

    On average, our employees in Compensation, Payroll, and the H.R. 
Help Desk are now at least one job band higher, reflecting their higher 
value skills and work. We redefined their jobs around higher value-
added tasks while letting AI do the repetitive work.

                      Recommendations to Congress

    As generative AI transforms industries and the workplace, more 
Americans are looking to obtain in-demand skills and career 
opportunities. Congress must work to improve alignment between our 
education and workforce systems, ensure critical public workforce 
programs are rooted in quality and outcomes, and establish responsive 
data systems. This can be accomplished by modernizing several Federal 
laws, including the Workforce Innovation and Opportunity Act, expanding 
Pell Grants for short-term and high-quality skilling programs, and 
scaling successful earn-while-you-learn opportunities by updating the 
National Apprenticeship Act of 1937. IBM recently shared best practices 
for employers and Federal policy recommendations in its Workforce 
Technology Playbook.

    Thank you, again, for holding this important hearing on the impact 
of AI on employers and workers. IBM looks forward to continuing to work 
with the HELP Committee to align America's education and workforce 
systems with in-demand skills--for now and for the future.

    For any questions or follow-up information, please contact Yelena 
Vaynberg, IBM's Government and Regulatory Affairs Executive.
                                 ______
                                 
                           National Safety Council,

                                                  October 31, 2023.
Hon. John Hickenlooper Chair,
Hon. Mike Braun Ranking Member,
U.S. Senate Committee on Health, Education, Labor, and Pensions,
Subcommittee on Employment and Workplace Safety,
Washington, DC.

    Dear Chair Hickenlooper and Ranking Member Braun:

    The COVID-19 pandemic changed the way we work in many ways and sped 
up technology and other transitions across workplaces. The National 
Safety Council (NSC) has been engaged in these transitions from the 
perspective of how technology impacts workplace safety and health. 
Through the NSC SAFER and Work to Zero initiatives, we have captured 
thoughts and reactions of workplaces and workers across the country on 
these changes and would like to share these findings with the Health, 
Education, Labor, and Pensions (HELP) Committee, Employment and 
Workplace Safety Subcommittee for the hearing ``AI and the Future of 
Work: Moving Forward Together.'' NSC believes the impacts of the 
pandemic that slingshot advances in technology, like AI, are only part 
of the makeup of the ``Future of Work,'' and we believe that work 
changes brought by the pandemic and technology implementation are more 
related to influence the success or failure of each other. We would 
like to offer an overview on the topics being considered with links to 
the full reports for the Subcommittee's consideration.

    NSC is America's leading nonprofit safety advocate and has been for 
110 years. As a mission-based organization, we work to eliminate the 
leading causes of preventable death and injury, focusing our efforts on 
the workplace and roadways. We create a culture of safety to keep 
people safer at work and beyond so they can live their fullest lives. 
Our more than 13,000 member companies represent nearly 41,000 U.S. 
worksites.

    Before sharing our report findings, there are a few key points to 
raise for your consideration.

        1. Many cases of bias in technology and especially ``learning'' 
        technology like AI have been found. \1\ Technologists, 
        employers, policymakers and others should take every step to 
        ensure bias is not part of machine learning.
---------------------------------------------------------------------------
    \1\  https://www.nist.gov/news-events/news/2022/03/theres-more-ai-
bias-biased-data-nist-report-highlights.

        2. Incorrect information and data are always present online. 
        For workplace safety and health programs, incorrect information 
        can be the difference between life and death. People will be 
---------------------------------------------------------------------------
        necessary for the foreseeable future to validate AI data.

    Our first report, ``State of the Response, The Future World of 
Work,'' recognized that not all workers experienced the pandemic in the 
same way. Front line workers, construction workers, healthcare workers 
and other employee groups continued to go into workplace settings to 
ensure seamless operations. Likewise, new technologies and other 
innovations have impacted workplaces differently depending on the 
sector. This report also highlights how new technology was more quickly 
integrated into workplace situations because of the pandemic. Cameras, 
healthcare screening devices and augmented reality replaced some of the 
interactions that had previously been done between people.

    This report highlights the following topics:

        <bullet>  Operations--Moved to remote work arrangements for as 
        many employees as possible

        <bullet>  Human Resources--Provided flexible work arrangements 
        (e.g., hours, days, scheduling)

        <bullet>  Stress, Mental Health and Well-being--Promoted or 
        increased employee assistance plans (EAP) benefit offerings

        <bullet>  Communications--Provided regular communication via 
        multiple channels

        <bullet>  Organizational Culture--Increased focus on safety and 
        health using COVID-19 as a catalyst

        <bullet>  Technology--Increased use of mobile app software

        <bullet>  Sustainability--Rethought need for physical space and 
        travel

    NSC issued ``SAFER Recommendations for Moving Past the Pandemic'' 
earlier this year on moving past the pandemic with a section on the 
future of work. This report built upon the way work changed during the 
pandemic to be more remote and with a greater use of technology. The 
report provides recommendations for how employers can proceed in a way 
that keeps workers engaged, safe and healthy. NSC recommends employers 
can prepare their organization and workforce for continued change from 
automation and AI by doing the following:

        1. Invest in Training and Upskilling: Provide opportunities for 
        workers to learn new skills that align with emerging 
        technologies and trends. Offer training programs that help them 
        adapt to changing roles and responsibilities, enabling them to 
        stay relevant and valuable.

        2. Foster a Learning Culture: Create an environment where 
        continuous learning is encouraged and celebrated. This could 
        include providing resources for self-paced learning, hosting 
        workshops and offering incentives for workers to gain new 
        skills.

        3. Promote Critical Thinking and Problem-Solving: Emphasize the 
        importance of critical thinking and creative problem-solving. 
        Encourage workers to think outside the box and come up with 
        innovative solutions, which are skills less likely to be 
        automated.

        4. Facilitate Collaboration: Develop team-based projects 
        encouraging collaboration and diverse skill sets. Cross-
        functional teams can work together to tackle complex challenges 
        requiring both human expertise and technological support.

        5. Flexible Work Arrangements: Allow for flexible work 
        arrangements, including remote work and flexible hours, to 
        accommodate different employee needs and enhance work-life 
        balance.

        6. Provide Clear Communication: Keep employees informed about 
        the organization's strategies and plans related to technology 
        adoption. Openly discuss the potential impacts on jobs and 
        responsibilities and provide a clear vision of how the changes 
        will benefit both the company and the workforce.

        7. Support Well-being: Acknowledge the potential stress 
        technological changes can bring and offer resources to support 
        workers' mental and emotional well-being. This can include 
        stress management programs and access to counseling services.

        8. Redesign Job Roles: Analyze current job roles to identify 
        tasks that can be automated and determine how human skills can 
        complement automation. This can lead to the creation of new 
        hybrid job roles leveraging the strengths of both humans and 
        machines.

        9. Empower Individual Autonomy: Give workers the autonomy to 
        explore new technologies and suggest ways to implement them for 
        improved efficiency. Empower them to be proactive in adopting 
        new tools and methods.

        10. Leadership and Vision: Leadership plays a crucial role in 
        guiding the organization through change. Leaders should set a 
        clear vision for the future, communicate it effectively and 
        demonstrate their commitment to supporting workers throughout 
        the transition.

        11. Monitor and Adapt: Regularly assess the impact of 
        technological changes on the workforce and adjust strategies 
        accordingly. Flexibility and adaptability are key in navigating 
        the evolving landscape.

    For companies that are ready to implement more advanced technology, 
NSC issued guidance to help implement AI systems to improve workplace 
safety outcomes. ``Using Data and AI to Gain Insights into Your Safety 
Program'' examines how these technologies may be used by organizations 
of all sizes and identifies both potential benefits and drawbacks. 
Findings in this report include the following:

        1. Data collected across an industrial enterprise in various 
        forms (i.e., written reports, forms, images, video and audio) 
        can all be used by modern data analytics and AI systems to 
        derive powerful insights and deliver actionable risk 
        predictions.

        2. AI-assisted computer vision offers automated object 
        recognition from images and videos for uses including spills, 
        fires, personal protective equipment (PPE) adherence and site 
        inspections. The technology can be further combined with EHS 
        software and other safety workflows.

        3. Natural language processing can rapidly summarize written 
        reports and extract quantitative insights and sentiments to 
        help EHS personnel perform incident analysis and make quicker 
        decisions.

        4. Predictive and prescriptive analytics engines can use large 
        datasets to review permit-to-work requests, predict the risk 
        for future incidents and deliver suggested solutions based on 
        best-practice guidelines and historical data.

        5. Drawbacks include high costs for building models from the 
        ground up, bias exacerbation due to learning from world-scale 
        datasets, data privacy issues, lack of general intelligence and 
        tough tradeoffs between effectiveness, cost and complexity.

    People must be the center of any conversation surrounding the 
future of work. Workers should be part of any effort to integrate 
technology into workplaces. They should be brought in early as a normal 
part of the process to gain additional perspectives and share potential 
concerns about a technology's use. In this process, technology 
developers should be forthright about what technology can and cannot 
due, thus maintaining safety as a priority for both the worker, 
organization and wider community. Included is an overview of NSC 
recommendations for implementing workplace technology.

    I am available to discuss this topic more as it is central to work 
NSC is doing to prevent injury and deaths in workplaces--a goal I know 
Members of the Employment and Workplace Safety Subcommittee share. 
Thank you for the opportunity to share the work of NSC with the 
Subcommittee.
            Sincerely,
                                        Lorraine M. Martin,
                                                 President and CEO.
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]

                                 __
                                 
                 prepared statement of matthew scherer
[GRAPHIC NOT AVAILABLE IN TIFF FORMAT]

   response by mr. tyrance billingsley to questions of senator lujan
                             Senator Lujan
    Topic (1): Mr. Billingsley, I appreciate the important work you're 
doing to ensure that the tech sector is inclusive. New Mexico is filled 
with smart young people who have a lot to say about how technology and 
AI should affect them. Many of these young people attend Tribal 
Colleges and Universities, and other MSIs such as Hispanic-Serving 
Institutions, which are often left out of conversations on emerging 
tech.

    Question 1. Why is it important to involve TCUs (Tribal Colleges 
and Universities), HBCUs (Historically Black Colleges and Universities) 
and MSIs (Minority-Serving Institutions) like HSIs (Hispanic-Serving 
Institutions) in research and development for responsible AI?

    Answer 1. There are two key aspects of how and why TCU's, HBCU's 
and HSI's should not only be included but heavily leaned on as it 
relates to the development of, education around and adoption of 
artificial intelligence:

    1. Research and development impact

    2. Sociocultural systems and infrastructure related to AI
                        Research and Development
    Artificial intelligence will remake the world as we know it, and 
the most obvious danger or implication of minority communities being 
left out of the conversation on AI's research and development is the 
outcome of bias in AI. AI is trained by data, and at this point, most 
of the lay AI world is familiar with the concept of ``garbage in, 
garbage out'' as a way to say that if the data that is used to train 
these models is subpar in terms of its inclusion of different and 
informed perspectives, the models will be biased in a way that only 
exacerbates existing inequities by baking them into the model's 
decision-making process, whose negative impact will then scale more 
quickly and totally to wider society.

    Whether this be the criminal justice system, healthcare, financial 
institutions or beyond, biased AI could exponentially poison the well 
of some of the most critical areas of life whose broken systems are 
already core to the reasons that marginalized communities find 
themselves behind socioeconomic 8-ball. By having institutions heavily 
involved in the research and development of AI, we can ensure more 
diverse perspectives are being imputed as it relates to the training 
and development of AI models. As a result, we will see less bias and 
crippling effects from the algorithms.

           Sociocultural Systems and Infrastructure Around AI

    Equally (if not more) important as the conversation regarding 
diverse involvement in research and development is the sociocultural 
systems and infrastructure around AI in marginalized communities. 
Adoption of any new trend or resource starts with a narrative and 
culture being built around said thing being for and beneficial to a 
group of people. This holds especially true for marginalized 
communities and it is even more so as it relates to new technology 
within marginalized communities.

    If we are to create a new sociocultural paradigm for marginalized 
communities that sees them embrace AI and the opportunities that it 
presents, such a shift will start with the education institutions in 
said communities. AI pathways at HBCU's and other institutions leading 
to high earning and high impact opportunities in AI will serve as a 
real world model for people in these communities to display why the 
technology should be embraced. This will in turn spark excitement and 
curiosity amongst community members, which will lead to a culture 
developing around wanting to succeed and innovate in/with AI, which 
will help ensure that communities of color are aggressive in securing 
their position in the AI revolution.

    Additionally, these institutions often have strong ties to their 
respective communities, enabling them to facilitate a two-way flow of 
information and insights between AI researchers and the communities 
they serve. This engagement ensures that the development of AI is 
grounded in real-world contexts and addresses the actual needs and 
concerns of diverse populations.

    Question 2. What should Congress and companies be doing to help 
drive more investments and resources for AI research and development at 
these Institutions?

    Answer 2. For Congress and companies to effectively drive more 
investments and resources for AI research and development at tribal 
colleges and universities, historically Black colleges and 
universities, and Minority-Serving institutions like Hispanic-serving 
institutions:

        <bullet>  Direct Funding and Grants: Congress should allocate 
        specific funds for AI research and development at these 
        institutions. This could be in the form of grants, 
        scholarships, or endowments designated for AI-related projects. 
        Similarly, companies can establish partnerships with these 
        institutions to provide direct funding for research 
        initiatives, labs, and technology upgrades. Most critically, 
        perhaps, efforts should be put into developing one or two of 
        the existing institutions in each category into an R1 research 
        institution around AI.

        <bullet>  Legislation Encouraging Private Investment: Congress 
        can pass legislation that incentivizes private companies to 
        invest in AI research at TCUs, HBCUs, and MSIs. These 
        incentives could include tax breaks, public recognition, or 
        other benefits for companies that partner with these 
        institutions.

        <bullet>  Collaborative Research Opportunities: Encourage and 
        facilitate partnerships between these institutions and major 
        tech companies or research organizations aimed at applying AI 
        to issues most critical to their respective communities. These 
        collaborations can provide students and faculty with access to 
        cutting-edge technology, mentorship, and real-world AI project 
        experience.

        <bullet>  Infrastructure Development: Beyond just funding, 
        there's a need to develop the physical and digital 
        infrastructure necessary for cutting-edge AI research. This 
        includes state-of-the-art laboratories, high-speed internet 
        access, and access to advanced computing resources (returning 
        to the R1 institution conversation).

        <bullet>  Curriculum Development and Faculty Training: Support 
        the development of AI-focused curricula and provide resources 
        for faculty training and development in AI and related fields. 
        This ensures that students are receiving education that is 
        current and relevant to the industry's needs.

        <bullet>  Internship and Job Placement Programs: Companies can 
        establish internship and job placement programs specifically 
        for students from these institutions. This not only provides 
        students with invaluable industry experience but also helps 
        diversify the AI workforce.

        <bullet>  Policy Advocacy and Awareness: Both Congress and 
        companies can play a role in raising awareness about the 
        importance of including TCUs, HBCUs, and MSIs in AI research 
        and development. Congress and the private sector could partner 
        to spearhead public campaigns, forums, and discussions that 
        highlight the importance of over indexing the involvement of 
        these institutions in the development of AI.

    By implementing these strategies, Congress and companies can build 
the correct infrastructure to ensure that these institutions become the 
backbone of the AI revolution in marginalized communities and are 
avenues for economic prosperity for decades to come.

    Topic (2): The emergence of artificial intelligence is not the 
first time our workforce has had to catch up to the pace of evolving 
technologies.

    Congress can help provide opportunities for our workforce to learn 
the skills they need to be prepared for the jobs of tomorrow. This body 
recognized this need when we included the Digital Equity Act in the 
Infrastructure Investment and Jobs Act 2 years ago. Private companies 
also have a responsibility to create workforce development and training 
programs to support the workforce through technological transitions. 
This public and private investment is vital to close gaps in digital 
literacy and give historically underrepresented communities a chance to 
compete for good-paying jobs in tech--especially as artificial 
intelligence increasingly becomes a part of our day-to-day life.

    Question 3. How can increased training and education in AI help our 
workforce to meet the needs of tomorrow?

    Answer 3. Once again, the infrastructure and training framework 
designed to ensure that America's economy maximizes on the AI 
revolution will make all the difference. In terms of ensuring that our 
workforce is capable for the new world that this technology will help 
develop, there are 5 key areas and ways that I see training and 
education benefiting the American economy via a diverse and AI fluent 
workforce:

        1. Economic Empowerment and Job Creation: AI and related 
        technologies are creating new job categories and transforming 
        existing ones. By focusing on AI training for communities of 
        color, we ensure they are not only consumers of AI technology 
        but also creators, leaders, and decision makers within this 
        field. This empowerment leads to better job opportunities, 
        economic growth, and a more equitable distribution of the 
        wealth generated by AI innovations.

        2. Diversity in AI Development: A workforce trained in AI that 
        is diverse in terms of race, ethnicity, and cultural background 
        brings a multitude of perspectives to AI development. This 
        diversity is crucial for creating AI systems that are fair, 
        unbiased, and representative of the broader population. It also 
        ensures that AI solutions are designed with a deep 
        understanding of different cultural contexts and needs.

        3. Innovation and Creativity: Diverse teams are known to be 
        more innovative and creative. Training people of color in AI 
        taps into a vast pool of untapped talent, fostering innovation 
        that can lead to breakthroughs in AI technology. This is not 
        just beneficial for these communities but enriches the AI field 
        as a whole.

        4. Social Impact and Community Engagement: Educating 
        communities of color in AI can lead to the development of AI 
        solutions that address specific challenges faced by these 
        communities. This grassroots approach ensures that AI 
        technology is used to make a positive social impact, from 
        improving healthcare and education to addressing economic 
        disparities.

        5. Policy Influence and Advocacy: A well-informed and AI-
        literate workforce can better advocate for policies that ensure 
        the ethical use of AI. By understanding the technology, 
        communities of color can more effectively push for regulations 
        that protect against biases, privacy breaches, and other 
        potential harms of AI.

    These 5 points represent the key areas we will see the overall 
Future of Work benefit from a diverse and educated AI workforce. They 
also serve as the foundation for how we can ensure that workforce will 
be adaptable to unforeseen challenges that may arise as it relates to 
AI in the workforce or its effects on communities.
                                 ______
                                 
       response by mr. josh lannin to questions of senator lujan
                             Senator Lujan
    Topic (1): Mr. Lannin, I know Workday is committed to responsible 
AI, as am I. I introduced the TEST AI Act, which creates testbeds for 
the U.S. government to test and evaluate AI systems. And I was happy to 
see this idea was included in the White House Executive Order on AI as 
well. Companies must integrate AI workplace tools in a responsible way 
that protects workers from privacy violations, bias, discrimination, 
and other harms.

    Question 1. What types of evaluations and assessments does Workday 
conduct to safeguard workers before integrating AI productivity tools 
in the workplace?

    Answer 1. Workday invests in rigorous technology governance so that 
our solutions are in line with our values and can earn and retain the 
trust of our enterprise customers. This is why Workday put in place a 
robust responsible AI program that includes: (1) an advisory board of 
senior company leaders led by our General Counsel; (2) a responsible AI 
team with dedicated resources and cross-company support; (3) guidelines 
and review processes that turn Workday's AI ethics principles into 
documented practices and assessments; and (4) disclosure that equips 
our customers with a clear understanding of how our AI tools are 
developed and assessed.

    Workday's AI tools are assessed from the earliest stages of 
development. If a tool may implicate a consequential decision, such as 
a decision about hiring or promotion, it is flagged as high-risk and 
evaluated for impermissible bias in accordance with existing and 
emerging legal requirements. High-risk tools are required to conform to 
responsible AI guidelines that ensure documentation for fairness and 
bias mitigation, explainability and interpretability, and disclosure. 
Workday's lifecycle review for impermissible bias helps improve product 
quality and supports our commitment to ethical AI. In keeping with our 
unwavering commitment to privacy, Workday integrates privacy-by-design 
principles into our product development and governance framework.

    Workday views AI governance as a partnership between developers, or 
organizations that produce or design AI tools, and deployers, which use 
AI tools and interact with end users. We provide our customers, who are 
deployers, with clear documentation that describes how our AI tools are 
built, how they work, how they are trained and tested, and how they are 
monitored through our ongoing testing and evaluation practices. We also 
provide our customers with the means to access their data for bias 
testing and the choice of whether to use an AI tool at all.

    Workday is an active contributor to the emerging field of AI 
governance. We were an early champion and adopter of the National 
Institute for Standards and Technology's AI Risk Management Framework. 
To advance the responsible development and use of AI in the workplace, 
we partnered with the Future of Privacy Forum to co-develop the Best 
Practices for AI and Workplace Assessment Technologies. These practices 
leverage Workday's experience with responsible AI and technology 
governance, as well as the guidance from U.S. regulators, such as the 
Equal Employment Opportunity Commission.

    Topic (2): A just and gradual transition is critical to protecting 
workers as AI becomes a valuable workplace productivity tool. Part of 
that transition must include worker training and skills development.

    Question 2. Mr. Lannin, as you and your customers roll out AI tools 
for use by workers, what skills gaps are you seeing in workers' ability 
to use and adapt to these new productivity tools? What training and 
upskilling programs are you or your customers creating to reach workers 
who need them most?

    Answer 2. Workday sees problem solving and strategic planning high 
on the list of in-demand skills, which suggests that core soft skills 
will be an enduring need despite changes driven by AI. We also see hard 
skills like computer and AI literacy high on the list of skills needed 
for today's jobs, which we expect to grow in the future. These trends 
validate our approach of focusing on AI tools that augment, rather than 
replace human decision-makers. While technical skills will need to grow 
in order for the U.S. workforce to effectively leverage AI, we expect 
core judgment and analytical skills to remain vitally important for 
workers.

    Workday's approach to training and upskilling programs internally 
is twofold: First, to fully leverage our employees' existing skills, 
identify and grow what they do best, and give them the ability to 
advance their careers using newly learned skills. Second, we're aiming 
to create a more agile and dynamic workforce; one that is resilient in 
the face of changing labor markets, and can be redeployed to tackle 
shifting organizational priorities. Our initial phase focused on laying 
a skills foundation for the company. Now we are actively building 
skills into our talent practices that employees and people leaders 
engage with the most, including mobility and advancement, hiring, and 
upskilling and reskilling.

    With more than 2,000 Workday customers using AI, including more 
than 25 percent of Fortune 500 companies, we believe Skills Cloud 
allows employers and employees to understand the skills and 
capabilities of an entire workforce, create targeted talent strategies, 
drive upskilling and reskilling, plan for skills, flex around skills 
and much, much more. This includes suggestions for employee growth 
plans for career development based on data to identify in-demand roles 
and skills.
                                 ______
                                 
    response by mary kate morley ryan to questions of senator lujan
                             Senator Lujan

    Topic (1): AI has the potential to help people work faster and more 
efficiently. It can also relieve workers of simpler tasks and help them 
work smarter. But workers must be engaged early on to ensure that AI 
rollouts are not leaving workers behind.

    We are already seeing the harmful effects of not engaging workers 
in the AI transition in the entertainment sector. The Writers Guild of 
America negotiated a contract with the AMPTP where the use of AI was 
one of the main sticking points. The WGA contract says that AI is not a 
writer, but writers can use AI to help their writing process.

    As the actors' strike continued, I sent a letter with Senator 
Heinrich and Chair Hickenlooper to AMPTP urging the producers to come 
to a fair resolution with SAG-AFTRA as well. SAG-AFTRA won critical 
concessions on AI as well, requiring consent and compensation when 
studios use digital likenesses of actors. As technology evolves, worker 
protections must evolve with it.

    Question 1. Ms. Morley Ryan, how are employers ensuring workers are 
engaged in companies' integration of AI into workflows?

    Answer 1. Integrating workers in the design of workflows that 
incorporate AI is not only the ethical thing to do, it's also the most 
valuable way to deploy this technology. Thoughtfully investing in 
people alongside data and technology, yields a top-line productivity 
premium of up to 11 percent that creates a better output for the 
company, for people, and for the use of the technology. \1\
---------------------------------------------------------------------------
    \1\  https://hbr.org/2023/03/generative-ai-will-enhance-not-erase-
customer-service-jobs.

    When employees fully understand how AI applies to their role, the 
adoption of the technology is two times more likely to be successful. 
\2\ Part of the strategy to increase transparency is with responsible 
AI frameworks that involve employees throughout. The framework should 
for example detail how a participative decision culture should guide 
the design, development, and deployment of AI. However, just 6 percent 
of organizations have built a responsible AI foundation and put its 
principles into practice. \3\
---------------------------------------------------------------------------
    \2\  https://www.accenture.com/content/dam/accenture/final/a-com-
migration/thought-leadership-assets/accenture-built-to-scale-pdf-
report.pdf.
    \3\  https://www.accenture.com/us-en/insights/applied-intelligence/
professionalization-ai?src=SOMS.

    That said, at this time most employers are at the starting line of 
integrating their workforce into AI workflows; \4\ however, most firms 
don't yet have the prerequisites to deploy AI right now. For instance, 
you can't deploy AI without good data, data-based processes (including 
decision-making), or infrastructure. A company that's exclusively run 
by paper and excel will struggle to integrate most of the benefits from 
AI tools.
---------------------------------------------------------------------------
    \4\  The recently signed Executive Order on Safe, Secure, and 
Trustworthy Artificial Intelligence urges companies to include workers 
in the development phase, an important part of responsible AI.

    Part of Accenture's $3 billion AI investment announced earlier this 
year includes plans to add 80,000 workers in part to help support 
companies' initial efforts to get their arms around their data so they 
---------------------------------------------------------------------------
can scale AI and do it responsibly.

    Roughly 60 percent of organizations are optimistic about the impact 
that generative AI will have on their people, including the overall 
work experience. Approaches include improving job satisfaction by 
reducing time spent on routine tasks and enabling individuals to engage 
in more meaningful and innovative tasks. \5\
---------------------------------------------------------------------------
    \5\  https://www.accenture.com/us-en/about/company/pulse-of-change.

    Companies should focus on how to train the workforce of the future 
to optimally interact with AI tools. In fact, according to Stanford 
University's Erik Brynjolfsson, for every dollar spent on new 
technology, companies should invest an additional nine dollars in 
talent and related processes, such as helping people develop the right 
skills. Distinctively people-centered tasks and higher-order cognitive 
work like moral reasoning and innovative thinking, gain a premium in a 
world of AI. New tasks also emerge, like adjusting system design 
outputs with feedback, monitoring data privacy and bias, or optimizing 
AI tool inputs. With continuous learning, employees can embrace new 
ways of working, ultimately helping organizations diversify skills 
across the workforce and ensure their people--and their business--not 
---------------------------------------------------------------------------
only stay relevant, but also grow through change.

    Topic (2): A just and gradual transition is critical to protecting 
workers as AI becomes a valuable workplace productivity tool. Part of 
that transition must include worker training and skills development.

    Question 2. What kinds of workforce development programs is 
Accenture creating to ease the transition to using AI tools in the 
workplace, and how is it ensuring all workers can access these 
opportunities?

    Answer 2. We invest heavily, $1 billion annually, in reskilling, 
training and leadership development for our people to ensure that our 
workforce is best positioned to work with AI tools now and in the 
future. At the foundational level, we start by providing our employees 
with grassroots-level training. Everyone at Accenture is required to 
take our Technology Quotient (TQ) training, a technology learning 
program that we have been using for the last few years. We continuously 
update the platform, content, and infrastructure, to include adding a 
generative AI course, so that our workforce stays current with 
technology trends.

    We also leverage our partnerships with top academic institutions. 
For example, we partnered with Stanford University to create a 
Foundation Model Scholar Program. We completed our inaugural program 
this past July.

    To expand our talent pipeline from non-traditional recruiting 
sources, Accenture launched its own apprenticeship program in 2016, 
alongside the launch of our Apprentice Network, which has since 
expanded to 10 locations with 195 unique employers across North 
America. Accenture has set a goal for apprentices to make up 20 percent 
of North America entry level hiring from apprenticeship applicants. 
Accenture has hired over 2,000 apprentices to date in over 40 cities. 
Our apprenticeship program applicants are only required to have a high 
school degree. To further emphasize our skills-based hiring approach, 
we made the decision to reduce the number of entry-level positions that 
require a 4-year college degree. As of fiscal year (FY) 2023, nearly 
half of Accenture's entry-level positions in the U.S. are open to 
individuals who do not have a 4-year college degree.

    Externally, Accenture is a proud partner with Code.org to support 
Hour of Code, aiming to empower every student to succeed in a digital 
world. \6\ Hour of Code is a free introduction to computer science 
through fun activities and videos for learners of all skill levels. 
This year's events will take place from December 4-8, 2023, in K-12 
schools across 10 cities.
---------------------------------------------------------------------------
    \6\  https://hourofcode.com/us.

    Over 700 high school and post-high school students participated in 
our Skills to Succeed internship and Learning to Lead program in 2022. 
Both programs work with organizations to break down barriers to 
employment and expand job opportunities to motivated, high-potential 
underrepresented talent who have traditionally lacked access to the 
---------------------------------------------------------------------------
digital economy.

    We also offer the Skills to Succeed Academy, a free highly 
interactive online training program that helps learners build the 
skills and confidence they need to make smart career choices and find 
and succeed in employment. \7\ In addition to soft skills, the Academy 
includes over 40 technology-related modules ranging from internet 
navigation to coding and data interpretation.
---------------------------------------------------------------------------
    \7\  https://s2sacademy.org/.

    Question 3. How can Congress incentivize companies to provide 
equitable upskilling as AI is integrated into the private and public 
---------------------------------------------------------------------------
sectors?

    Answer 3. As the digital economy transforms the way we live and 
work, Congress can help incentivize better collaboration between the 
public and private sectors to ensure upskilling is accessible to 
everyone.

    Building a strong educational foundation for continuous learning 
and upskilling is critical. We can start that process by:

        <bullet>  Creating a stronger dialog between businesses and 
        institutions to establish a workforce where people are prepared 
        for their careers.

        <bullet>  Providing options for micro-credentials, badges, 
        programs, and certificates as interest is rising among American 
        students.

        <bullet>  Helping students identify and more easily demonstrate 
        to employers what job-ready skills they've developed as part of 
        their education and training, rather than focusing on the two-
        or 4-year degree or credential as the output.

    As students make the transition into the workforce, we can 
reinforce continuous learning and upskilling by:

        <bullet>  Expanding access to the tools and skills needed to 
        succeed in future-proof jobs, including through expanded career 
        and technical education (CTE), apprenticeships, and 
        partnerships between educational institutions and the private-
        sector.

        <bullet>  Providing sufficient resources to support the demand 
        for sector-based workforce training and reskilling programs 
        that help bridge skills mismatch, including workers' digital 
        skill needs, while promoting more equitable economic mobility.

        <bullet>  Expanding workforce training capacity by providing 
        incentives for training programs led by industry, educators, 
        and non-profit organizations and embracing flexible short-term 
        and online training in key digital and emerging, in-demand 
        skills.

        <bullet>  Driving informed training by growing real-time labor 
        force data identifying economywide trends focused on emerging 
        roles and the skills needed for in-demand jobs and high-demand 
        sectors and measure the equitable impact of public investments.

                Y  The real time labor market data for in-demand and 
                high-demand sectors should be developed at not just the 
                local level but the global, national, regional, state 
                and local level to have a better understanding of the 
                true labor market supply and demand.

        <bullet>  Creating a culture of lifelong learning and making it 
        easier for workers to invest in their futures, including by 
        providing incentives and tools for upskilling, and modernizing 
        our Federal workforce development and worker displacement 
        programs. Specifically, the Workforce Innovation and 
        Opportunity Act (WIOA) can incentivize employer upskilling in 
        the workforce development system by:

                Y  Enhancing WIOA's definitions related to ``basic 
                skills deficient,'' ``training,'' and ``individual with 
                a barrier to employment'' to include digital literacy.

                Y  Incentivizing states to offer reciprocity to high-
                quality training providers to streamline the Eligible 
                Training Provider List (ETPL) application process for 
                multi-state providers and prioritize those programs 
                that have a strong return on investment, with an 
                emphasis on providers that have a robust upskilling 
                curriculum.

                Y  Providing the established infrastructure (2,200 
                American Job Centers) to upskill at scale jobseekers 
                and employers, particularly on AI and digital skills.
                                 ______
                                 

    [Whereupon, at 11:34 a.m., the hearing was adjourned.]

                                   [all]
</pre></body></html>
