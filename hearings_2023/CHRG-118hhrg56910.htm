<html>
<title> - CENSORSHIP LAUNDERING PART II: PREVENTING THE DEPARTMENT OF HOMELAND SECURITY'S SILENCING OF DISSENT</title>
<body><pre>
[House Hearing, 118 Congress]
[From the U.S. Government Publishing Office]


 CENSORSHIP LAUNDERING PART II: PREVENTING THE DEPARTMENT OF HOMELAND 
                    SECURITY'S SILENCING OF DISSENT

=======================================================================

                                HEARING

                               BEFORE THE

                            SUBCOMMITTEE ON
                       OVERSIGHT, INVESTIGATIONS,
                           AND ACCOUNTABILITY

                                 OF THE

                     COMMITTEE ON HOMELAND SECURITY
                        HOUSE OF REPRESENTATIVES

                    ONE HUNDRED EIGHTEENTH CONGRESS

                             FIRST SESSION
                               __________

                           DECEMBER 13, 2023
                               __________

                           Serial No. 118-46
                               __________

       Printed for the use of the Committee on Homeland Security
                                     

                  [GRAPHIC NOT AVAILABLE IN TIFF FORMAT]


                                     
        Available via the World Wide Web: http://www.govinfo.gov
                               __________

                    U.S. GOVERNMENT PUBLISHING OFFICE
                    
56-910 PDF                 WASHINGTON : 2024   


                     COMMITTEE ON HOMELAND SECURITY

                 Mark E. Green, MD, Tennessee, Chairman
Michael T. McCaul, Texas             Bennie G. Thompson, Mississippi, 
Clay Higgins, Louisiana                  Ranking Member
Michael Guest, Mississippi           Sheila Jackson Lee, Texas
Dan Bishop, North Carolina           Donald M. Payne, Jr., New Jersey
Carlos A. Gimenez, Florida           Eric Swalwell, California
August Pfluger, Texas                J. Luis Correa, California
Andrew R. Garbarino, New York        Troy A. Carter, Louisiana
Marjorie Taylor Greene, Georgia      Shri Thanedar, Michigan
Tony Gonzales, Texas                 Seth Magaziner, Rhode Island
Nick LaLota, New York                Glenn Ivey, Maryland
Mike Ezell, Mississippi              Daniel S. Goldman, New York
Anthony D'Esposito, New York         Robert Garcia, California
Laurel M. Lee, Florida               Delia C. Ramirez, Illinois
Morgan Luttrell, Texas               Robert Menendez, New Jersey
Dale W. Strong, Alabama              Yvette D. Clarke, New York
Josh Brecheen, Oklahoma              Dina Titus, Nevada
Elijah Crane, Arizona
                      Stephen Siao, Staff Director
                  Hope Goins, Minority Staff Director
                       Sean Corcoran, Chief Clerk
                                 ------                                

     SUBCOMMITTEE ON OVERSIGHT, INVESTIGATIONS, AND ACCOUNTABILITY

                  Dan Bishop, North Carolina, Chairman
Marjorie Taylor Greene, Georgia      Glenn Ivey, Maryland, Ranking 
Mike Ezell, Mississippi                  Member
Dale W. Strong, Alabama              Shri Thanedar, Michigan
Elijah Crane, Arizona                Delia C. Ramirez, Illinois
Mark E. Green, MD, Tennessee (ex     Yvette D. Clarke, New York
    officio)                         Bennie G. Thompson, Mississippi 
                                         (ex officio)
                  Sang Yi, Subcommittee Staff Director
           Lisa Canini, Minority Subcommittee Staff Director

                            C O N T E N T S

                              ----------                              
                                                                   Page

                               STATEMENTS

The Honorable Dan Bishop, a Representative in Congress From the 
  State of North Carolina, and Chairman, Subcommittee on 
  Oversight, Investigations, and Accountability:
  Oral Statement.................................................     1
  Prepared Statement.............................................     4
The Honorable Glenn Ivey, a Representative in Congress From the 
  State of Maryland, and Ranking Member, Subcommittee on 
  Oversight, Investigations, and Accountability..................     6
The Honorable Bennie G. Thompson, a Representative in Congress 
  From the State of Mississippi, and Ranking Member, Committee on 
  Homeland Security:
  Prepared Statement.............................................    12

                               WITNESSES
                                Panel I

Mr. Michael Shellenberger, Founder, Public, A Substack 
  Publication:
  Oral Statement.................................................    14
  Prepared Statement.............................................    16
Mr. Mark Chenoweth, President and General Counsel, New Civil 
  Liberties Alliance:
  Oral Statement.................................................    88
  Prepared Statement.............................................    90
Mr. Alex Abdo, Litigation Director, Knight First Amendment 
  Institute, Columbia University:
  Oral Statement.................................................    98
  Prepared Statement.............................................   100
Mr. Gary M. Lawkowski, Senior Fellow, The Council to Modernize 
  Governance:
  Oral Statement.................................................   101
  Prepared Statement.............................................   103

                                Panel II

Mr. Iranga Kahangama, Assistant Secretary, Cyber, Infrastructure, 
  Risk, and Resilience, Office of Strategy, Policy, and Plans, 
  U.S. Department of Homeland Security:
  Oral Statement.................................................   138
  Joint Prepared Statement.......................................   140
Ms. Mona Harrington, Assistant Director, National Risk Management 
  Center, Cybersecurity and Infrastructure Security Agency, U.S. 
  Department of Homeland Security:
  Oral Statement.................................................   142
  Joint Prepared Statement.......................................   140

                             FOR THE RECORD

The Honorable Glenn Ivey, a Representative in Congress From the 
  State of Maryland, and Ranking Member, Subcommittee on 
  Oversight, Investigations, and Accountability:
  Article, The Washington Post, November 16, 2023................     8
  Statement of Yoel Roth, PhD, Former Head of Trust & Safety, 
    Twitter, Inc.................................................   113
  Statement of Dr. Kate Starbird, Associate Professor and 
    Director of the Center for an Informed Public, University of 
    Washington...................................................   116
  Statement of Marc Rogers, Co-founder, Cyber Threat Intelligence 
    League.......................................................   119
The Honorable Yvette D. Clarke, a Representative in Congress From 
  the State of New York:
  Article, November 10, 2021, The Hill...........................   133

 
 CENSORSHIP LAUNDERING PART II: PREVENTING THE DEPARTMENT OF HOMELAND 
                    SECURITY'S SILENCING OF DISSENT

                              ----------                              


                      Wednesday, December 13, 2023

             U.S. House of Representatives,
                    Committee on Homeland Security,
                Subcommittee on Oversight, Investigations, 
                                        and Accountability,
                                                    Washington, DC.
    The subcommittee met, pursuant to notice, at 2 p.m., at 
Room 310, Cannon House Office Building, Hon. Dan Bishop 
[Chairman of the subcommittee] presiding.
    Present: Representatives Bishop, Greene, Ezell, Strong, 
Crane, Thanedar, Ivey, Ramirez, and Clarke.
    Also present: Representative Thompson.
    Chairman Bishop. The Committee on Homeland Security, 
Subcommittee on Oversight, Investigations, and Accountability 
will come to order.
    The purpose of this hearing is to understand the scope and 
scale of the Department of Homeland securities and CISA's 
counter- 
mis-, dis-, and mal-information efforts and why Government 
censorship continues to present a threat to the free discourse 
essential to a constitutional republic.
    I now recognize myself for an opening statement.
    Good afternoon, and welcome to this hearing of the 
subcommittee titled ``Censorship Laundering, Part Two: 
Preventing the U.S. Department of Homeland Security's Silencing 
of Dissent.'' In May this subcommittee held our first hearing 
to examine the Department of Homeland Security's role as the 
nerve center for the Federal Government's scheme to censor the 
on-line voices of millions of Americans. What we learned during 
that hearing was deeply concerning. As Americans, we are 
committed to the idea that freedom of speech and open debate 
are essential features of a free society. Make no mistake, the 
efforts to censor public discourse under the guise of so-called 
mis-, dis- and mal-information--MDM--threatened this essential 
freedom and the very core of our republic.
    Now, through our own investigation and the incredible work 
of a small group of individuals dedicated to protecting 
Americans' fundamental rights to discourse and debate, 
including our witnesses today, we have a far more complete 
picture of the censorship-laundering complex and how it 
operates. While we recognize the Cybersecurity and 
Infrastructure Security Agency's mission of protecting our 
institutions from legitimate cybersecurity threats, we cannot 
allow a component of the Department of Homeland Security to 
anchor a censorship-laundering enterprise. Silencing the voices 
of the American people is never acceptable by Government and we 
must return the agency to its core mission.
    Two major developments have been enormously helpful to our 
investigations into the true extent of DHS and CISA's role in 
Government censorship efforts. First, several lawsuits, most 
notably Missouri v. Biden--although the assistant attorney 
general for the Division of Civil Rights doesn't know about 
that litigation, I hope she will take note of it--that lawsuit 
has made public vital evidence, uncovering the scope and scale 
of Government efforts to censor on-line speech. Second, Elon 
Musk released the second edition of the Twitter files, exposing 
the breadth of the Government's efforts to censor American 
speech on-line. In addition, we have learned that despite the 
Federal Government's continued denials of having any role in 
the creation of the so-called election integrity project, EIP, 
that DHS and CISA were involved from the beginning.
    Look at the words of Graham Brookie, senior director of the 
Atlantic Council's digital Forensic Research Lab, DFR Lab, one 
of the four founding EIP partners who wrote this to his 
colleagues on July 21, 2020, ``We just set up an election 
integrity partnership at the request of DHS/CISA and are in 
weekly comms to debrief about disinformation, disinfo, IO, et 
cetera''. As an active participant with EIP partners, CISA was, 
``switchboarding'', which is the term CISA used to describe 
flagging what they called misinformation and notifying social 
media platforms who could, ``independently'' decide whether to 
remove or modify the content. CISA director Jen Easterly 
claimed earlier this year during a DHS appropriations 
subcommittee hearing that ``we don't flag anything to social 
media organizations'', but that is exactly what CISA was doing.
    Moreover, while EIP and its stakeholders claimed that EIP 
was just conducting research--that is the terminology, 
conducting research--the words of a senior EIP official during 
a transcribed interview with our committee say otherwise. 
``Flagging content for social media companies was part and 
parcel with the EIP's creation''. There is, unfortunately, far 
more evidence than I have time to describe.
    After CISA's hands were caught in the censorship cookie jar 
some of my colleagues on the other side of the aisle have come 
to the defense of its censorship-laundering enterprise, its 
censorship by proxy. They claim that there were no funding 
links between CISA and these outside organizations, no 
censorship. At the same time, they take pains to reaffirm their 
commitment to fighting ``misinformation''. Just last week, the 
Ranking Member of the full committee issued a press release 
denying that CISA created, funded, or directed the work of the 
election integrity partnership. Now, you can believe the press 
release, or you can believe the individuals in the private 
sector who were most intimately involved with this work who 
talk about how the Government gave them the ability to stomp 
out misinformation. Listen, for example, to Alex Stamos.
    [Video played.]
    Chairman Bishop. As a reminder, the impact of this 
censorship effort was massive, 859 million tweets collected for 
``misinformation analysis'', 22 million tweets and retweets 
categorized as misinformation subject to censorship, 21 Twitter 
users, Americans, identified and stigmatized as ``the most 
prominent repeat spreaders of disinformation''. Every one of 
whom were on the political right. It was not just for 
elections. The same network used the same tools to censor 
dozens of purportedly false COVID-19 narratives, of which some 
were later proved true, but all of which were within the sphere 
of free speech that the Constitution protects from Government 
interference.
    Let's turn to where things might be headed. We know that 
DHS and CISA have continued to explore ways to build on their 
counter-MDM efforts. Some of their publicly-acknowledged or 
directed efforts have been pretty Orwellian, like DHS's ill-
conceived effort to establish a disinformation governance board 
last year, or CISA director Jen Easterly's bizarre comment 
about controlling citizens' thoughts through regulating 
``cognitive infrastructure'' as critical infrastructure reposed 
to CISA's care. Other evidence is more bureaucratic but no less 
alarming. Look, for example, at CISA's cybersecurity advisory 
committee's MDM subcommittee, which continues to exist and to 
recommend that CISA should expand efforts into new areas, such 
as the courts, financial systems, and public health. The MDM 
subcommittee also recommended CISA view its counter-MDM work 
across a much wider range of media. Other DHS documents suggest 
CISA wants also to broaden the target issues of public concern 
to include racial justice, immigration, the U.S. withdrawal 
from Afghanistan, and support to Ukraine.
    What is stopping DHS from overreaching its jurisdiction 
beyond elections to censor more Americans, to ``protect'' 
whatever Government-deployed orthodox notions it deems critical 
infrastructure? Right now, the answer is nothing. While CISA 
has made a public pretense of pulling back from some of its 
more aggressive censorship efforts, that change was driven by 
public scrutiny and not from all that appears to a fundamental 
change of heart. This is unacceptable and dangerous. Every 
American, even those serving in the vast Federal bureaucracy, 
should be committed to upholding Americans' fundamental rights.
    At this point, it appears the courts may provide part of 
the solution. Indeed, the District of Louisiana and the Fifth 
Circuit in particular ruled in an affirmative this October that 
CISA probably violated the First Amendment through its 
censorship activities. This is to be now decided by the U.S. 
Supreme Court. But the issue of DHS and CISA's censorship 
efforts goes beyond a ruling on the precise contours of the 
First Amendment. The Government's power to censor speech, 
including on-line speech, must be strictly limited to content 
that is not Constitutionally-protected, such as inciting 
imminent lawless action. At DHS censorship became ordinary and 
banal, an everyday activity carried out by anonymous and 
unaccountable bureaucrats using censorship by proxy to 
accomplish indirectly and in secret what it would not have the 
power to do openly.
    Congress cannot wait or hope for a court decision to stop 
DHS and CISA's overreach. Congress has a duty to rein in out of 
control agencies and protect the rights of the American people. 
To that end, this subcommittee will be drafting legislation 
that stops DHS and CISA's censorious MDM efforts and prevent 
DHS and CISA from working with social media platforms to 
suppress free speech on-line. The Government cannot simply 
sidestep the Constitution by outsourcing censorship under the 
guise of protecting critical infrastructure.
    Thank you all for joining. I look forward to hearing 
testimony from our witnesses.
    [The statement of Chairman Bishop follows:]
                    Statement of Chairman Dan Bishop
                           December 13, 2023
    Good afternoon, and welcome to this hearing of the Subcommittee on 
Oversight, Investigations, and Accountability titled, ``Censorship 
Laundering Part II: Preventing the U.S. Department of Homeland 
Security's Silencing of Dissent.''
    In May, this subcommittee held our first hearing to examine the 
Department of Homeland Security's role as the nerve center for the 
Federal Government's scheme to censor the on-line voices of millions of 
Americans. What we learned during that hearing was deeply concerning. 
As Americans, we are committed to the idea that freedom of speech and 
open debate are essential features of a free society. Make no mistake: 
the efforts to censor public discourse under the guise of so-called 
mis-, 
dis-, and mal-information (MDM) threaten this essential freedom and the 
very core of our republic.
    Now, through our own investigation and the incredible work of a 
small group of individuals dedicated to protecting Americans' 
fundamental rights to discourse and debate--including several of our 
witnesses today--we have a far more complete picture of the censorship 
laundering complex and how it operates.
    While we recognize the Cybersecurity and Infrastructure Security 
Agency's mission of protecting our institutions from legitimate 
cybersecurity threats, we cannot allow a component of the Department of 
Homeland Security to anchor a censorship laundering enterprise. 
Silencing the voices of the American people is never acceptable, and we 
must return the agency to its original mission.
  uncovering and validating the scope and scale of censorship efforts
  <bullet> Two major developments have been enormously helpful to our 
        investigations into the true extent of DHS and CISA's role in 
        Government censorship efforts.
    <bullet> First, several lawsuits, most notably Missouri v. Biden, 
            have made public vital evidence uncovering the scope and 
            scale of Government efforts to censor on-line speech.
  <bullet> Second, Elon Musk released the second edition of the Twitter 
        files, exposing the breadth of the Government's efforts to 
        censor Americans' speech on-line.
  <bullet> In addition, we have learned that despite the Federal 
        Government's continued denials of having any role in the 
        creation of the Election Integrity Project (EIP),\1\ that DHS 
        and CISA were involved from the beginning.
---------------------------------------------------------------------------
    \1\ For example of denials, see: https://www.cip.uw.edu/2023/03/16/
uw-cip-election-integrity-partnership-research-claims/.

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

  <bullet> Look at the words of Graham Brookie, senior director of the 
        Atlantic Council's Digital Forensic Research Lab (DFRLab)--one 
        of the four founding EIP partners--who wrote this to his 
        colleagues on July 21, 2020--``We just set up an election 
        integrity partnership at the request of DHS/CISA and are in 
        weekly comms to debrief about disinfo, IO, etc.''.
  <bullet> As an active participant with EIP partners, CISA was 
        ``switchboarding'', which is the term CISA used to describing 
        flagging what they called misinformation and notifying social 
        media platforms who could ``independently'' decide whether to 
        remove or modify the content. CISA director Jen Easterly 
        claimed earlier this year during a DHS Appropriations 
        subcommittee hearing that ``We don't flag anything to social 
        media organizations,''\2\ but that is exactly what CISA was 
        doing.
---------------------------------------------------------------------------
    \2\ See https://www.washingtontimes.com/news/2023/jun/27/
cybersecurity-and-infrastructure-security-agency-a/.

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

  <bullet> Moreover, while EIP and its stakeholders claim the EIP was 
        just conducting research, the words of a senior EIP official 
        during a transcribed interview with our committee, say 
        otherwise. ``Flagging content for social media companies was 
        part and parcel with the EIP's creation''.
  <bullet> There is unfortunately far more evidence than I have time to 
        describe.
  <bullet> After CISA's hands were caught in the censorship cookie jar, 
        some of my colleagues on the other side of the aisle have come 
        to the defense of its censorship laundering enterprise. They 
        claim that there were no funding links between CISA and these 
        outside organizations, no censorship. At the same time, they 
        take pains to reaffirm their commitment to fighting 
        ``misinformation.''
  <bullet> Just last week, the Ranking Member of the full committee 
        issued a press release denying that CISA created, funded, or 
        directed the work of the Election Integrity Partnership. Now 
        you can believe the press release, or you can believe the 
        individuals in the private sector who were most intimately 
        involved with this work, who talk about how the Government gave 
        them the ability to stomp out ``misinformation.''
  <bullet> As a reminder, the impact of this censorship effort was 
        massive:
    <bullet> 859 million tweets collected for ``misinformation'' 
            analysis;
    <bullet> 22 million tweets and retweets categorized as 
            ``misinformation'' subject to censorship;
    <bullet> 21 Twitter users--Americans--identified and stigmatized as 
            ``the most prominent repeat spreaders [of disinformation]'' 
            every one of whom were on the political right.
  <bullet> And it was not just for elections. The same network used the 
        same tools to censor dozens of purportedly false COVID-19 
        narratives, of which some were later proven true, but all of 
        which were within the sphere of free speech that the 
        Constitution protects from Government interference.
              the continuing risk of government censorship
  <bullet> Let's turn to where things might be headed.
  <bullet> We know that DHS and CISA have continued to explore ways to 
        build on their counter-MDM efforts.
  <bullet> Some of their publicly-acknowledged or directed efforts have 
        been pretty Orwellian, like DHS's ill-conceived effort to 
        establish a Disinformation Governance Board last year or CISA 
        Director Jen Easterly's bizarre comments on controlling 
        citizens' thoughts through regulating ``cognitive 
        infrastructure'' as critical infrastructure.

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]
        
  <bullet> Other evidence is more bureaucratic but no less alarming. 
        Look for example at CISA's Cybersecurity Advisory Committee's 
        MDM Subcommittee which continues to exist and recommended that 
        CISA should expand efforts into new areas such as the courts, 
        financial systems, and public health. The MDM Subcommittee also 
        recommended CISA view its counter-MDM work across a much wider 
        range of media.
  <bullet> Other DHS documents suggest CISA wants also to broaden the 
        target issues of public concern, to include racial justice, 
        immigration, the U.S. withdrawal from Afghanistan, and support 
        to Ukraine.\3\
---------------------------------------------------------------------------
    \3\ See https://theintercept.com/2022/10/31/social-media-
disinformation-dhs/.
---------------------------------------------------------------------------
  <bullet> What is stopping DHS from overreaching its jurisdiction 
        beyond elections to censor more Americans to ``protect'' 
        whatever Government-deployed orthodox notions it deems 
        ``critical infrastructure?''
  <bullet> Right now, the answer is nothing. While CISA has made a 
        public pretense of pulling from some of its more aggressive 
        censorship efforts, that change was driven by public scrutiny 
        and not, from all that appears, to a fundamental change of 
        heart. This is shameful and dangerous. Every American--even 
        those serving in the vast Federal bureaucracy--should be 
        committed to upholding Americans' fundamental rights.
  <bullet> At this point, it appears the courts may provide part of the 
        solution. Indeed, the Fifth Circuit ruled this October that 
        CISA probably violated the First Amendment through its 
        censorship activities. Ultimately, this will be decided by the 
        Supreme Court.
  <bullet> But the issue of DHS and CISA's censorship efforts goes 
        beyond a ruling on the precise contours of the First Amendment. 
        The Government's power to censor speech, including on-line 
        speech, must be strictly limited to content that is not 
        Constitutionally-protected, such as inciting imminent lawless 
        action.
  <bullet> At DHS, censorship became ordinary and banal--an everyday 
        activity carried out by anonymous and unaccountable bureaucrats 
        using censorship by proxy to accomplish indirectly and in 
        secret what it would not have the power to do openly.
  <bullet> Congress cannot wait or hope for a court decision to stop 
        DHS and CISA's overreach. Congress has a duty to rein in out-
        of-control agencies and protect the rights of the American 
        people. To that end, this subcommittee will be drafting 
        legislation that stops DHS and CISA's censorious MDM efforts 
        and prevent DHS and CISA from working with social media 
        platforms to suppress free speech on-line. The Government 
        cannot simply sidestep the Constitution by outsourcing 
        censorship under the guise of protecting critical 
        infrastructure.
    Thank you all for joining, and I look forward to hearing testimony 
from our witnesses.

    Chairman Bishop. I now recognize the Ranking Member, the 
gentleman from Maryland, Mr. Ivey, for his opening statement.
    Mr. Ivey. Thank you, Mr. Chairman.
    I have to say I have a slightly different take on this than 
my friend from North Carolina in a variety of ways. I think 
that the claims about CISA being a giant censorship entity 
completely misses the mark, based on the transcripts that I 
have seen of testimony that has been given by this committee 
and to this committee and other committees here in the House. 
For example, this is a statement from Brandon Wales, he is the 
CISA executive director: CISA does not and has never censored 
speech or facilitated censorship. Any such claims are patently 
false. We can go through a few of these others, and we will, 
including the testimony that I had mentioned a moment ago.
    For example, Mr. Masterson. Now Masterson was an 
interesting individual who came up through the Republican Party 
in the Ohio State election boards. He now works for Microsoft. 
But he made a couple of statements with respect to this issue. 
One, they were never compelled, they never compelled the 
platforms to take positions or take down information. In other 
words, they never forced censorship to happen of any kind. No, 
I don't recall that happening in my experience, no.
    There are a couple other quotes from him that I would like 
to share on this front, too. At any point in your experience 
working at CISA, were you advised that you had the authority to 
compel a social media company to take any particular action 
related to any particular content on social media? No, I don't 
recall that happening in my experience, no. Did you ever try to 
exercise that authority? No, I don't recall ever perceiving 
that I had that authority.
    Mr. Stamos, who was just mentioned a moment ago, also has 
testified here in the House. To be clear, at no time did the 
EIP censor speech or have access to back-end platform systems 
or data outside of public content. The EIP did not take down 
posts or apply labels and had no power to do so. The EIP did 
not create targeting lists or blacklists of accounts, and the 
list of accounts included in our reports as the top spreaders 
of false information were generated by our own analysis, which 
importantly occurred after the election. Mr. Stamos was the 
person who was--the tape was played a moment ago by the 
Chairman.
    We have got more of those, but I need to move forward 
because I think on a couple of fronts here, we have to address 
the reality of what is going on I think behind some of this. 
There are a lot of conspiracy theories that persist that are, 
in my view, dangerously weakening America's ability to defend 
itself against foreign attacks from Russia, China, and Iran. 
Some of these attacks focus on America's election and our 
election apparatus, especially since we haven't fully responded 
in the wake of the 2016 and 2020 attacks with respect to those 
elections.
    In 2017, the Trump administration's national security 
strategy included a section on information statecraft, naming 
Russia and China among the adversaries seeking to ``weaponize 
information'' for strategic gain and control. Adversaries of 
the United States leverage influence operations and 
disinformation campaigns to degrade confidence in key 
institutions, sow civil discord, and undermine U.S. pillars of 
power. For example, Russian interference in the 2016 
Presidential election, I think, is a powerful example. I know 
there has been a lot of political debate about collusion and 
other issues, but the Senate Intelligence Committee found that 
Putin ordered the Russian effort to hack Democratic Party 
networks and accounts to leak information damaging to Hillary 
Clinton. There is also information with respect to Iranians 
trying to do the same thing on the opposite side, posing as 
Proud Boys to intimidate voters in the 2020 election. That is 
based on an indictment. The Department of Justice is 
prosecuting individuals involved in that case. But that is on 
the other side of this. From my perspective, this isn't a 
partisan issue. That was an attempt, apparently, in their view, 
help the Biden campaign.
    But I also think we have to focus on this because we face 
internal dangers that can come from the internet and some of 
the information that is being abused on that front. The January 
6 attack against the Capitol was aimed at preventing the lawful 
and peaceful transfer of power. The internet was used, the 
social media platforms were used essentially as the principal 
means of communications from any of those activities. Also some 
of the, in my view, false conspiracy theories that have grown 
out of that, like the ghost buses issue that was raised here in 
this committee a few weeks ago, I think is disinformation that 
we need to address. The recent Osama bin Laden letter, which 
got viral on the internet and ended up--I think it had over 2 
million views--but essentially was espousing bin Laden's view 
that the United States was an evil country, that 9/11 was an 
appropriate attack on the United States. I am concerned about 
the impact it could have, for example, on lone-wolf individuals 
in the United States. There are other kinds of efforts like 
that that are aimed at reaching out directly to people in the 
United States to encourage them to engage in terrorist 
activities.
    This is an article from the Washington Post, ``How Osama 
bin Laden's Letter to America Reached Millions Online.'' Video 
citing the document had been viewed far less than many TikTok 
posts. Then a journalist made a compilation and posted it on X, 
causing attention to the manifesto to explode. That was dated 
November 16, 2023, and I offer it for the record.
    Chairman Bishop. Ordered to be submitted.
    [The information follows:]

  How Osama Bin Laden's ``Letter To America'' Reached Millions Online
By Drew Harwell and Victoria Bisset, Updated November 16, 2023 at 5:32 
        p.m. EST/Published November 16, 2023 at 12:23 p.m. EST, The 
        Washington Post.
Videos citing the document had been viewed far less than many TikTok 
        posts. Then a journalist made a compilation and posted it to X, 
        causing attention to the manifesto to explode.
    On Monday, a TikTok user with 371 followers, using the screen name 
``_monix2,'' posted a video where she read parts of Osama bin Laden's 
``Letter to America,'' in which the late terrorist leader said his 
killings of nearly 3,000 Americans in the Sept. 11, 2001, attacks had 
been justified by the United States' support of Israel's ``occupation'' 
of the Palestinian territories.
    By Wednesday night, the letter had become a point of discussion 
among left-wing creators on the video app, with some saying its 
critiques of American foreign policy had opened their eyes to a history 
they'd never learned.
    But the letter didn't rank among TikTok's top trends. Videos with 
the #lettertoamerica hashtag had been seen about 2 million times--a 
relatively low count on a wildly popular app with 150 million accounts 
in the United States alone.
    Then that evening, the journalist Yashar Ali shared a compilation 
he'd made of the TikTok videos in a post on X, formerly Twitter. That 
post has been viewed more than 38 million times. By Thursday afternoon, 
when TikTok announced it had banned the hashtag and dozens of similar 
variations, TikTok videos tagged #lettertoamerica had gained more than 
15 million views.
    The letter's spread sparked a deluge of commentary, with some 
worrying that TikTok's users were being radicalized by a terrorist 
manifesto, and TikTok's critics arguing it was evidence that the app, 
owned by the Chinese tech giant ByteDance, had been secretly boosting 
propaganda to a captive audience of American youth.
    But the letter's spread also reflected the bedeviling realities of 
modern social media, where young people--many of whom were born after 
9/11--share and receive information on fast-paced smartphone apps 
designed to make videos go viral, regardless of their content.
    It also showed how efforts to suppress such information can 
backfire. Many of the videos on TikTok were posted after the British 
newspaper the Guardian, which had hosted a copy of bin Laden's letter, 
removed it. Some TikTokers said the removal was proof of the letter's 
wisdom and importance, leading them to further amplify it as a result.
    ``Don't turn the long-public ravings of a terrorist into forbidden 
knowledge, something people feel excited to go rediscover,'' Renee 
DiResta, a research manager at the Stanford Internet Observatory who 
has advised Congress on online disinformation, wrote Thursday in a post 
on Threads. ``Let people read the murderer's demands--this is the man 
some TikTok fools chose to glorify. Add more context.''
    TikTok spokesman Alex Haurek said Thursday that the company was 
``proactively and aggressively'' removing videos promoting the letter 
for violating the company's rules on ``supporting any form of 
terrorism'' and said it was ``investigating'' how the videos got onto 
its platform.
    Haurek said that the #lettertoamerica hashtag had been attached to 
274 videos that had garnered 1.8 million views on Tuesday and 
Wednesday, before ``the tweets and media coverage drove people to the 
hashtag.'' Other hashtags, for comparison, dwarfed discussion of the 
letter on the platform: During a recent 24-hour period, #travel videos 
had 137 million views, #skincare videos had 252 million views and 
#anime videos had 611 million views, Haurek said.
    Ali said he made the compilation video Wednesday after seeing 
``thousands'' of the videos and intentionally left out the ``most 
incendiary examples'' because he didn't want the compilation to be 
removed from Instagram, where he also posted it.
    He agreed the hashtag had never trended on TikTok but disputed the 
idea that the number of videos posted there had been ``small,'' saying, 
``Sure, in the context of a global platform. But not small enough to be 
minuscule or not important.''
    Most of the videos have since been removed by TikTok, making it 
difficult to get a full tally. But a search for the letter Thursday 
morning by a Washington Post reporter revealed around 700 TikTok 
videos, only a few of which got more than 1 million views.
    Such high view counts are common on TikTok, where videos are served 
up in rapid fashion and the average U.S. user watches for more than an 
hour a day. One viral video last month, in which a young woman 
discussed the pain of a 9-to-5 job, has more than 3 million views and 
280,000 likes.
    The videos featured many people saying they'd known little about 
bin Laden and were questioning what they'd been taught about American 
involvement around the world. Some said they were ``trying to go back 
to life as normal'' after reading it; in one video, a user scrolled 
through the full letter and said, ``We've been lied to our entire 
lives.''
    But while many pointed to bin Laden's comments on the Palestinian 
issue, few highlighted the letter's more extreme criticism of Western 
``immorality and debauchery,'' including ``acts of fornication, 
homosexuality, intoxicants, gambling and trading with interest.''
    Many commenters also criticized giving the letter attention or 
worked to remind people that bin Laden had preached an antisemitic, 
sexist ideology that led to thousands of deaths. On the ``_monix2'' 
video, one commenter said, ``You guys Bin Laden wrote this. Do y'all 
know what he did. What is wrong with y'all [oh my God. I guess] we're 
supporting terrorism these days.'' (Attempts to reach the @_monix2 
account were unsuccessful.)
    Charlie Winter, a specialist in Islamist militant affairs and 
director of research at the intelligence platform ExTrac, said in an 
interview Thursday that he was ``frankly really quite surprised at the 
response'' to the letter, which he described as ``a kind of core 
doctrinal text'' for both al-Qaeda and the Islamic State terrorist 
group.
    In addition to long-standing grievances, the letter contains 
``blatant language that is clearly calling for acts of genocide . . . 
[and] for killing noncombatants in any nation that is democratic and is 
fighting against a Muslim-majority state,'' he said.
    ``It's not the letter that is going viral. It's a selective reading 
of parts of the letter that's going viral,'' he said. ``And I don't 
know whether it's because people aren't actually reading it or, when 
they're reading it, they're reading the bits that they want to see.''
    The letter's spread online was celebrated Thursday by users on al-
Qaeda forums, according to SITE Intelligence Group, which tracks online 
extremism. One user Thursday wrote that Islamist militants should 
capitalize on the opportunity, saying, ``I hope you all are seeing 
ongoing storm on Social Media . . . We should post more and more 
content.''
    Some of the TikTok creators who shared the letter posted follow-up 
videos saying they did not support terrorism or violence. One of the 
first TikTok creators to share it, and who spoke to The Post on the 
condition that her name not be included in the story, said she had 
encouraged people to read it for ``educational purposes.''
    She said she did not ``condone nor justify'' bin Laden's actions 
and was ``distancing [herself] from this entire situation.'' ``It's a 
sad world if we cannot even read a public document, simply to educate 
ourselves, without being smeared online,'' she said.
    TikTok has faced criticism and calls for a nationwide ban due to 
the popularity of pro-Palestinian videos on the app compared with pro-
Israel content, even though Facebook and Instagram show a similar gap. 
In a video call organized by TikTok on Wednesday, first reported by the 
New York Times, some Hollywood actors and TikTok creators pushed 
company executives to do more to crack down on antisemitic content.
    But the idea that the ``Letter to America'' discussion solely began 
on TikTok is challenged by Google data, which show that search interest 
in the ``bin Laden letter'' began gathering last week, days before it 
became a topic of TikTok conversation.
    And TikTok is far from the only place where the letter has been 
discussed. Though instagram blocked searches for some hashtags, some 
videos related to the letter--including those critical of it--remained 
publicly viewable Thursday on the Meta-owned app.
    On Thursday afternoon, searches for ``letter to America'' on 
Instagram were still being given a ``Popular'' tag. One post, a series 
of screenshots of the letter, had more than 10,000 likes as of Thursday 
afternoon.
    On Thursday, the letter and bin Laden's name were also ``trending 
topics'' on X, the social network owned by Elon Musk. One tweet there 
from Wednesday--in which the writer said reading the letter was like 
feeling a ``glass wall shatter,'' and asks, ``Is this what ex cult 
members feel like when they become self aware''--remained online 
Thursday, with nearly 3 million views.
    The letter--a nearly 4,000-word translation of the al-Qaeda 
leader's comments--had been originally posted in Arabic on a Saudi 
Arabian website used to disseminate al-Qaeda messages. The Guardian 
originally published an English translation in 2002 alongside a news 
article that offered more detail on how it had begun circulating among 
``British Islamic extremists.''
    Though the Guardian removed the letter on Wednesday, its 
replacement, a page called ``Removed: document,'' had by Thursday 
become one of the most-viewed stories on the newspaper's website. Some 
TikTokers voiced anger at the newspaper for, in the words of one, 
``actively censoring'' information.
    A spokesperson for the Guardian said in a statement that the letter 
had been removed after it was ``widely shared on social media without 
the full context.''
    The editors of the Guardian faced a ``no-win scenario'' once 
interest in bin Laden's letter began to grow, Marco Bastos, a senior 
lecturer in media and communication at City University of London, said 
in a phone interview.
    ``If they don't take down the content, the content will be 
leveraged and it will be discussed, potentially shared and is going to 
go viral--if not out of context, then certainly outside of the scope of 
the original piece,'' Bastos said. ``If they take it down, they're 
going to be accused, as they are right now, of censorship.''
    At the time of publication, the editors ``expected that this letter 
would be read critically, you know, adversarially . . . that you would 
process this within the view--or the bias, if you prefer--of the 
Western side of the events,'' Bastos added. ``And now it's being 
consumed, distributed and shared to push an agenda that's precisely the 
opposite of the one that it was originally intended for.''
    Winter, the Islamist militant affairs specialist, said he found it 
``kind of ironic'' that the letter was being shared uncritically around 
the web.
    ``People who consider themselves to be critical consumers of 
mainstream media are consuming this very uncritically and not thinking 
about the context around it,'' he said. ``Not thinking about everything 
that happened just over a year before it was published as well, in any 
meaningful way.''
    Bisset reported from London.

    Mr. Ivey. I think it is important for CISA to continue to 
not only exist, but continue to operate at full capacity. I 
know there have been some efforts to reduce its capabilities, 
but the 2018 and 2020 cycles, the censorship issues, CISA 
connected election stakeholders to social media platforms in a 
nonpartisan manner by forwarding election disinformation, 
reporting from election officials to both parties to the 
relevant platforms. I believe we have got an email here from 
the RNC that was sent to CISA. This is, again, in an effort to 
be bipartisan on this front, the RNC detected misinformation 
that was being circulated in Philadelphia during that campaign 
cycle, that election workers were going to be paid, and that 
was incorrect. It worked its way up the chain. I didn't put all 
of the emails on this board here, but at the end of it, they 
sent it to CISA seeking help into taking down the information 
so the disinformation wouldn't spread. I don't know if that 
kind of funding is illegal in Pennsylvania, but I think the 
main point is that the RNC, at least in that election cycle, 
didn't view this as some sort of censorship effort, this was 
just an effort to make sure that they got correct information 
out to the public. That is true in other scenarios, too. One of 
the issues that we have seen pop up, false information with 
respect to elections. The election is going to happen on 
Wednesday instead of Tuesday. The Government needs to be able 
to correct that kind of misinformation.
    Also, there is a point I wanted to make too, about this. I 
think the argument seems to be that CISA was essentially 
compelling people, these platforms, to remove or edit 
information that was available on that platform. But all the 
emails that we have seen had a disclaimer that was displayed on 
the screen. This is attached and you can see down at the bottom 
of it there basically it says ``CISA affirms that it neither 
has nor seeks the ability to remove or edit what information is 
made available on social media platforms. CISA makes no 
recommendation about how the information that is sharing should 
be handled or used by social media companies.'' Social media 
platforms make their own decisions regarding the content on 
their platforms, and each have their own rules regarding the 
labeling and removal of mis- and disinformation. Of the posts 
flagged by the EIP, platforms took action on 35 percent, 21 
percent were labeled, 13 percent were removed, 1 percent were 
soft-blocked. No action was taken on 65 percent of those. This 
is not Government censorship or censorship by proxy. Social 
media companies are privately-owned and make content decisions 
based on their terms of service.
    I also want to raise this issue with respect to the 
elections that are coming up. State and local officials in 
these elections are seeking the assistance of not only the 
Federal Government, but of each other because a lot of these 
challenges that arise have Nation-wide impact and affect their 
different States, even if the misinformation or false 
information arises somewhere else. So State and local officials 
from 21 different States requested CISA's assistance leading up 
to the 2020 election, including Republican officials, to 
address foreign influence operations and disinformation. 
Kentucky State officials flagged tweets that falsely indicated 
Democratic votes were being under-counted in favor of 
Republican votes during a contentious Senate race, a county in 
Florida for the supervisor of elections shared threats emailed 
to Democratic voters. The Donald Trump campaign and the RNC 
flagged the misinformation about an RNC volunteer stipend 
program. We showed that already. According to an April 2023 
survey, 85 percent of local election officials responded that 
it is beneficial ``for CISA to dispel false information about 
elections by promoting accurate information on election 
administration and technology''.
    I will wind this up. I do want to get to the testimony of 
both panels. But I did want to raise these points about the 
Missouri v. Biden case. I think it is important to note that 
the Fifth Circuit put a stay on the rulings that the District 
Court had issued, particularly with respect to the limitations 
on the Government from having interactions with social media 
platforms. I guess the District Court had imposed essentially a 
total restriction on it. The Fifth Circuit rolled that back. I 
think it is fair. I have read some versions of this, and I have 
read the opinion myself. That some of the opinions, the 
District Court's opinions information is based on false 
information or misinformation as well. So I am hoping that as 
this case works its way through the courts--and I wouldn't be 
shocked if the Supreme Court remanded it for additional 
findings of fact--that a lot of this will be addressed.
    But the main point I want to make before I wrap up is that 
I am concerned that there has been a chilling effect with 
respect to CISA, the social media platforms, people who are 
doing research. They are concerned about if they raise their 
head up they get in trouble, they get subpoenas, they get 
doxed. We have got a couple of statements with respect to that. 
But I think it is important for us to make sure that we want to 
make sure there is no censorship going on. I think that my 
colleagues on the other side have significantly overstated that 
based on the transcripts I have seen. But importantly, I think 
we have to keep in mind that not only do we have to worry about 
making sure we have the apparatus in place, for example, to 
deal with child sexual exploitation and terrorism on-line, but 
also that we are able to address election issues, other types 
of foreign attacks that might be encouraging people to engage 
in terrorism or the like. We have to make sure that we have 
that capability up and ready to go, that people feel that they 
can do the work and reach their own conclusions. We might 
disagree about those conclusions, whether a particular social 
media platform takes information down or not. I don't know 
there is going to be universal agreement on all of that, but I 
think we need to make sure that people feel they can operate in 
a safe environment, and that includes exercising their First 
Amendment right.
    So, Mr. Chairman, we may draw the line in different places, 
clearly we do, but I think our ultimate goal is the same.
    So with that, I yield back.
    Chairman Bishop. Thank you, Ranking Member Ivey.
    Other Members of the committee are reminded that opening 
statements may be submitted for the record.
    [The statement of Ranking Member Thompson follows:]
             Statement of Ranking Member Bennie G. Thompson
                           December 13, 2023
    Today, I am pleased to be here to set the record straight on a 
dangerous and unfounded conspiracy theory that my Republican colleagues 
continue to promote: the notion that the Department of Homeland 
Security (DHS) engaged in Government censorship.
    In 2016, Russian information operations targeting our elections 
caught the United States flatfooted and caused alarm across the 
intelligence community and among State and local election officials. 
During both the 2018 and 2020 election cycles, foreign adversaries 
continued to disseminate false claims to undermine U.S. elections and 
stoke division between political parties.
    In response to requests for assistance from election officials, 
then-President Trump's Cybersecurity and Infrastructure Security Agency 
(CISA) forwarded messages from election officials--both Republicans and 
Democrats--to alert social media platforms to election related mis- and 
disinformation that was spreading widely on social media. During the 
2020 election cycle, State and local election officials increasingly 
began to flag posts that would mislead voters on where, when, or how to 
vote, as well as threats to intimidate or interfere with voters.
    CISA served as an intermediary between election officials and the 
social media platforms, each of which had their own rules regarding the 
labeling and removal of mis- and disinformation. To be clear, every 
message CISA forwarded from election officials to social media 
companies included a disclaimer at the end that read, in part:

``CISA affirms that it neither has nor seeks the ability to remove or 
edit what information is made available on social media platforms. CISA 
makes no recommendation about how the information it is sharing should 
be handled or used by social media companies. Additionally, CISA will 
not take any action, favorable or unfavorable, toward social media 
companies based on decisions about how or whether to use this 
information.''

    A small number of posts flagged by election officials and forwarded 
by CISA were removed by the platforms, and others were labeled as false 
information. The vast majority, however, went unabated. Ultimately, 
decisions regarding flagged content were made by private companies 
unbeholden to CISA or any other Government entity. I cannot emphasize 
enough that these efforts to protect America's elections, and CISA's 
involvement, were hardly a secret. Representatives from CISA sat before 
this very committee in 2019 and told Members in public hearings exactly 
what CISA was doing.
    At an October 2019 field hearing, CISA's then-Senior Cybersecurity 
Advisor stated, ``We don't recommend any actions to take on the 
activity, but we are able to pass it on and say, `Here is activity 
that's been reported to us. Here is the contact for the State or local 
election official reporting.' ''
    Mr. Chairman, I ask unanimous consent to submit the hearing 
transcript from October 2019 into the record.*
---------------------------------------------------------------------------
    * The document has been retained in committee files and is 
available at https://www.congress.gov/event/116th-congress/house-event/
LC65098/text?s=5&r=90.
---------------------------------------------------------------------------
    It was not until Donald Trump lost the 2020 election and refused to 
uphold our country's tradition of peaceful transitions of power, that 
Republican Members of Congress took issue with CISA's well-known 
activities. As soon as CISA officials refused to go along with the 
``Big Lie'', Republican Members of Congress began to slander the agency 
and initiate baseless investigations.
    Despite CISA's transparency about its activities, Republicans have 
used a twisted version of the facts, promoted by a fringe alt-right 
conspiracy theorist, to justify these allegations. This conspiracy uses 
out-of-context quotes and blatant lies to promote the idea that CISA 
engaged in censorship, or censorship by proxy, directed at conservative 
posters. Yet, the countless pages of documents and witness testimony 
provided to this committee over the last year do not show anything more 
than what the agency told us back in 2019.
    While CISA may have shared information with various social media 
platforms, those companies were not working at the direction of any 
Government agency. Any decisions made to remove social media posts were 
made by the companies themselves, according to their terms of service. 
My Republican colleagues, and the conspiracy theorists who feed them 
this false narrative, have not once been able to show that CISA engaged 
in censorship against Americans. But that has not stopped Members of 
this committee from spreading disinformation about CISA's activities.
    In the subcommittee's May hearing on this topic, Republicans 
continued to spread this false narrative by inviting a witness who 
claimed that the U.S. Government censored his posts on social media. 
However, when pressed by a Member, the witness admitted that he had no 
idea why the social media companies removed his posts, and had 
absolutely no proof that the Federal Government, let alone CISA or DHS 
in particular, was involved in any way. Meanwhile, as my Republican 
colleagues waste time trying to prove something that didn't happen, the 
threat that the rampant spread of mis- and disinformation poses 
persists.
    Following the devastating wildfires in Maui earlier this year, 
researchers found what they believe to be a Chinese-directed campaign 
to spread disinformation that the fire was caused by the U.S. 
Government itself. These kinds of rumors make FEMA's job to assist 
communities with resources following disasters more difficult.
    In another example, Customs and Border Protection contends with the 
results of lies spread by cartels and human smugglers everyday, as 
migrants are fed false information to encourage them to cross the 
Southwest Border.
    And as we look ahead to the 2024 election, the Federal Government's 
efforts to counter dangerous election-related disinformation will be 
severely hobbled by Republicans spreading this dangerous conspiracy 
theory about CISA. Already, these attacks have had a chilling effect on 
those who were previously studying ways to combat mis- and 
disinformation. Unchecked mis- and disinformation will affect all 
American citizens, regardless of political party.
    I hope that today, with the opportunity to hear from CISA and DHS 
officials directly, we can finally put these baseless allegations to 
rest once and for all.

    Chairman Bishop. I am pleased to have a distinguished panel 
of witnesses before us today on this very important topic. I 
ask that our witnesses please rise and raise your right hands.
    [Witnesses sworn.]
    Chairman Bishop. Thank you. You may be seated.
    Let the record reflect that the witnesses have answered in 
the affirmative.
    I would now like to formally introduce our witnesses. Mr. 
Michael Shellenberger is an investigative journalist and 
founder of Public. Mr. Mark Chenoweth is the president and 
general counsel of New Civil Liberties Alliance. Mr. Alex Abdo 
is the litigation director of the Knight First Amendment 
Institute at Columbia University. Mr. Gary Lawkowski is a 
senior fellow at the Council to Modernize Governance. I thank 
you all for being here today.
    The Chair will now recognize each witness for oral 
statements. Each oral statement will be limited to 5 minutes, 
but submitted written statements by witnesses will appear in 
the hearing record in their entirety.
    I now recognize Mr. Shellenberger for 5 minutes for his 
opening statement.

STATEMENT OF MICHAEL SHELLENBERGER, FOUNDER, PUBLIC, A SUBSTACK 
                          PUBLICATION

    Mr. Shellenberger. Thank you, Chairman Bishop, Ranking 
Member Ivey, and Members of the subcommittee for inviting my 
testimony.
    Researchers asked by the U.S. Department of Homeland 
Security to flag election and COVID misinformation to social 
media platforms in 2020 and 2021 say that they didn't break the 
law. According to the leaders of the Stanford Internet 
Observatory and the other groups involved, they simply alerted 
social media platforms to potential violations of their terms 
of service. What the platforms chose to do after that was up to 
them. But during the 2 years the DHS-empowered researchers were 
asking social media platforms to take down, throttle, or 
otherwise censor social media posts, the President of the 
United States was accusing big tech of killing people. His 
then-press secretary said publicly that the administration was 
``flagging violative posts for Facebook''. Members of Congress 
threatened to strip social media platforms of their legal right 
to operate because they said the platforms weren't censoring 
enough. Many supposedly disinterested researchers were 
aggressively demanding that the platforms change their terms of 
service. It's true that the social media platforms are private 
companies, technically free to censor content as they see fit 
and are under no clearly stated obligation to obey demands by 
the U.S. Government or its authorized researchers at Stanford 
or elsewhere. But the First Amendment of the U.S. Constitution 
states clearly that the Government should take no action that 
would limit free speech. The record shows that the U.S. 
Government in general, and DHS in particular, did just that.
    DHS supported, created, and participated in the 2020 Cyber 
Threat Intelligence League, the 2020 Election Integrity 
Partnership, or EIP, and the 2021 Virality Project, or VP. In 
the case of the EIP and VP, four think tanks led by Stanford 
Internet Observatory and reporting to CISA demanded and 
achieved mass censorship of the American people in direct 
violation of the First Amendment. A long-time U.S. Navy officer 
and U.K. military contractor created this so-called anti-
disinformation wing of the CTIL, Cyber Threat Intelligence 
League, in 2020. In doing so, they pioneered the misdescription 
of censorship laundering as cybersecurity. They used CTIL as a 
front group to demand censorship and demanded that cognitive 
security be viewed as their responsibility in addition to 
physical security and cybersecurity. DHS publicly blessed this 
project and its staff helped create CTL's anti-disinformation 
efforts and participated actively in its internal Slack 
messaging program.
    The explanations and justifications by the creators and 
leaders of the EIP and VP have shifted over the last 9 months. 
At first, an SIO executive, Renee DiResta, claimed in a video 
for DHS that the idea for EIP came from SIO's interns, who 
happened to be working at DHS at the time. More recently, 
another SIO executive, Alex Stamos, claimed that the idea was 
his. Then last month, this committee released documents 
establishing that DHS authorized groups believed that the idea 
had come from DHS. ``We just set up an election integrity 
partnership at the request of DHS, CISA'' said Atlantic Council 
senior executive Graham Brookie. After Matt Taibi and I 
testified before Congress in March, a Stanford Observatory 
spokesperson said, ``It did not censor or ask social media 
platforms to remove any social media content regarding 
coronavirus vaccine side effects.'' That turned out not to be 
true, as internal messages from its operation released publicly 
by the committee last month proved. Consider the language that 
was used--Hi Facebook, Reddit, and Twitter, we recommend it be 
removed from your platforms. We repeat our recommendation that 
this account be suspended. We recommend labeling. We recommend 
that you flag as false or remove the post below.
    Under the guise of a research project, EIP was enmeshed 
with the Federal Government leading up to the 2020 election. 
Four students involved in EIP were even employed by CISA. One 
Stanford student, for example, worked as a DHS intern inside 
the EIP network. These internal emails show that CISA and its 
nonprofit partners reported political speech to social media 
platforms, including jokes, hyperbole, and the types of 
viewpoints and nonspecific statements that CIS once claimed it 
would not censor.
    In 2020, Department of Homeland Security officials and 
personnel from EIP were often on emails together and CISA's 
personnel had access to EIP's tickets through an internal 
messaging system known as Jira. Anyone who doubts that DHS 
authorized organizations, SIO chief among them, need only look 
at the internal workflow graphic in a VIP proposal obtained 
earlier this week through a FOIA request by my colleague Matt 
Taibbi. It shows how disinformation ``incidents are routed to 
platform partners for takedowns''. Everybody understood exactly 
what was going on. These were demands for censorship. I should 
just add here that I absolutely support counterspeech. I agree 
that if there's false information out there about elections, 
the point is to respond publicly to it. That's not what was 
happening here. They were demanding that information be 
censored. It wasn't just around the date of the election or the 
security of mail-in ballots, it was on a whole range of social 
and political issues, which the Supreme Court has historically 
protected more than any other form of speech.
    I would just close by saying, if you set aside for a moment 
the Orwellian aspects of CISA's efforts at mind control, what 
do we think the consequences could be of CISA taking its eye 
off the cybersecurity ball so it can crusade with Stanford 
interns against wrongthink? Should we be able to sleep soundly 
at night knowing that CISA is focused on the problem of people 
being wrong on the internet, rather than on China, Russia, 
Iran, and other malicious actors seeking to harm American 
businesses, Government agencies, and our citizens? What's at 
stake here is our fundamental freedom to express our views on 
controversial social and political issues without fear of 
Government censorship.
    Thank you very much.
    [The prepared statement of Mr. Shellenberger follows:]
              Prepared Statement of Michael Shellenberger
                           December 13, 2023
    Chairman Green, Chairman Bishop, Chairman Ivey, and Members of the 
subcommittee, thank you for inviting my testimony.
    Researchers asked by the U.S. Department of Homeland Security (DHS) 
to flag election and Covid misinformation to social media platforms in 
2020 and 2021 say that they didn't break the law. According to the 
leaders of the Stanford Internet Observatory, and the other groups, 
they simply alerted social media platforms to potential violations of 
their Terms of Service. What the platforms chose to do after that was 
up to them.
    But during the 2 years that these DHS-empowered researchers were 
asking social media platforms to take down, throttle, or otherwise 
censor social media posts, the President of the United States was 
accusing Big Tech of ``killing people,'' his then-press secretary said 
publicly that the administration was ``flagging violative posts for 
Facebook,'' Members of Congress threatened to strip social media 
platforms of their legal right to operate because, they said, the 
platforms weren't censoring enough, and many supposedly disinterested 
researchers were aggressively demanding that the platforms change their 
Terms of Service.
    It's true that social media platforms are private companies 
technically free to censor content as they see fit and are under no 
clearly-stated obligation to obey demands by the U.S. Government or its 
authorized ``researchers'' at Stanford or anywhere else.
    But the First Amendment of the U.S. Constitution states clearly 
that the Government should take no action that would limit free speech, 
and the record shows that the U.S. Government, in general, and the DHS 
in particular, did just that.
    DHS supported, created, and participated in the 2020 Cyber Threat 
Intelligence League, or CTIL; the 2020 Election Integrity Partnership, 
or EIP; and the 2021 Virality Project, or VP. In the case of the EIP 
and VP, four think tanks led by Stanford Internet Observatory, or SIO, 
and reporting to CISA, demanded and achieved mass censorship of the 
American people in direct violation of the First Amendment and the 
prohibition on Government agencies from interfering in an election.
    A long-time U.S. Navy officer and a U.K. military contractor 
created the so-called anti-disinformation wing of the CTIL in 2020. In 
so doing, they pioneered the misdescription of censorship laundering as 
``cybersecurity.'' They used CTIL as a front group to demand censorship 
and demanded that ``cognitive security'' be viewed as their 
responsibility, in addition to physical security and cybersecurity.
    CTIL created a handbook full of tactics, including demanding social 
media platforms change their terms of service. Another explains that 
while such activities overseas are ``typically'' done by ``the CIA and 
NSA and the Department of Defense,'' censorship efforts ``against 
Americans'' have to be done using private partners because the 
Government doesn't have the ``legal authority.''
    DHS publicly blessed this project, and its staff helped create 
CTIL's ``anti-disinformation'' efforts.
    The CTI League aimed to implement something called ``AMITT,'' which 
stood for ``Adversarial Misinformation and Influence Tactics and 
Techniques.'' AMITT was a disinformation framework that included many 
offensive actions, including working to influence government policy, 
discrediting alternative media, using bots and sock puppets, pre-
bunking, and pushing counter-messaging. The specific ``counters'' to 
``disinformation'' in AMITT and its successor framework, DISARM, 
included the following:
  <bullet> ``Create policy that makes social media police 
        disinformation''
  <bullet> ``Strong dialog between the Federal Government and private 
        sector to encourage better reporting''
  <bullet> ``Marginalize and discredit extremists''
  <bullet> ``Name and shame influencers''
  <bullet> ``Simulate misinformation and disinformation campaigns, and 
        responses to them, before campaigns happen''
  <bullet> ``Use banking to cutoff access''
  <bullet> ``Inoculate populations through media literacy training''.
    The explanations and justifications by the creators and leaders of 
the EIP and VP have shifted over the last 9 months. At first, an SIO 
executive claimed in a video for DHS that the idea for EIP came from 
SIO's interns, who happened to be working at DHS. More recently, 
another SIO executive claimed that the idea was his.
    Then, last month, this committee released documents establishing 
that the DHS-authorized groups believed the idea had come from DHS. 
``We just set up an election integrity partnership at the request of 
DHS/CISA,'' said an Atlantic Council senior executive, Graham Brookie, 
in an email sent on July 21, 2020.
    After Matt Taibbi and I testified before Congress in March, an SIO 
spokesperson says it ``did not censor or ask social media platforms to 
remove any social media content regarding coronavirus vaccine side 
effects.''
    That turned out not to be true, as internal messages from its 
operation, released publicly by this committee last month, proved.
  <bullet> Consider the language that these DHS-authorized individuals 
        used:
  <bullet> ``Hi Facebook, Reddit, and Twitter . . . we recommend it be 
        removed from your platforms.''
  <bullet> ``We repeat our recommendation that this account be 
        suspended . . . ''
  <bullet> ``We recommend labeling . . . ''
  <bullet> ``We recommend that you all flag as false, or remove the 
        posts below.''
    Under the guise of a research project, EIP was enmeshed with the 
Federal Government leading up to the 2020 election. Four students 
involved with EIP were even employed by CISA. One Stanford student, for 
example, worked as a DHS intern ``inside the EIP network.''
    It is clear from the emails released by this committee that the 
supposedly independent Election Integrity Partnership (EIP) and CISA 
were working together and interacted. One email from a Colorado 
official was addressed to ``EI-ISAC, CISA, and Stanford partners,'' 
directly referring to EIP. The CISA-funded non-profit, Center for 
Internet Security (CIS), also sent alleged misinformation to social 
media companies.
    CIS had previously claimed that its definition of election mis- and 
disinformation did not include ``content that is polarizing, biased, 
partisan or contains viewpoints expressed about elections or 
politics,'' ``inaccurate statements about an elected or appointed 
official, candidate, or political party,'' or ``broad, non-specific 
statements about the integrity of elections or civic processes that do 
not reference a specific current election administration activity.''
    But the DHS emails reveal that CISA and CIS did, in fact, consider 
such content to be subject to censorship. The emails show that CISA and 
its non-profit partners reported political speech to social media 
companies, including jokes, hyperbole, and the types of ``viewpoints'' 
and ``non-specific statements'' that CIS once claimed it would not 
censor. Using the pretext of ``election security,'' DHS sought to 
censor politically-inconvenient speech about election legitimacy.
    Messages 1 year later also showed VP researchers urging censorship 
of ``general anti-vaccination'' posts, of the CDC's own data, of 
accurate claims of natural immunity, of accurate information from the 
journal Lancet, of anti-lockdown protests, and even of someone's entire 
Google Drive.
    In 2020, Department of Homeland officials and personnel from EIP 
were often on emails together, and CISA's personnel had access to EIP's 
tickets through an internal messaging system, Jira, which EIP used to 
flag and report social media posts to Twitter, Facebook, and other 
platforms. And CISA included a threatening disclaimer in its email. It 
stated that ``information may also be shared with law enforcement or 
intelligence agencies.''
    CISA was not supposed to have involvement in EIP's flagging 
activities, but, notes the House Judiciary, numerous Jira tickets 
mention CISA, and CISA referenced EIP Jira codes when switchboarding. 
Stanford's legal counsel insisted that EIP and SIO ``did not provide 
any Government agency . . . access to the Jira database,'' but in one 
November 2020 email, SIO Director Alex Stamos told a Reddit employee, 
``It would be great if we could get somebody from Reddit on JIRA, just 
like Facebook, Google, Twitter, TikTok, Instagram, CISA, EI-ISAC . . . 
'' Stamos's statement indicated that CISA had access to EIP's Jira 
system.
    In communications with social media platforms, the House report 
states, Stamos made it clear ``that the EIP's true purpose was to act 
as a censorship conduit for the Federal Government.'' In an email to 
Nextdoor, Stamos wrote that EIP would ``provide a one-stop shop for 
local election officials, DHS, and voter protection organizations to 
report potential disinformation for us to investigate and to refer to 
the appropriate platforms if necessary.''
    Anyone who doubts that the DHS-authorized organizations, SIO chief 
among them, need only look at the ``Internal Workflow'' graphic in a VP 
proposal obtained earlier this week through a FOIA request by Taibbi. 
It shows how disinformation ``Incidents are routed to platform partners 
. . . for . . . takedowns.''
    ``Psychological and influence operations have long been used to 
secure military objectives,'' noted my colleague. ``We now have clear 
evidence that, with the creation of CTIL and its partnership with CISA, 
[the censorship leaders] pioneered the use of psychological strategies 
to combat populism at home by censoring information and narratives 
associated with populist discontent.'' Today, the Defense Department 
and its contractors openly discuss the importance of ``cognitive 
warfare,'' not just ``security,'' aimed at the American people.
    While I believe all of the above is transparently unconstitutional, 
there is the possibility that The Supreme Court will not rule against 
it after it hears the Missouri v Biden censorship lawsuit next year. 
Some justices may conclude that somehow the First Amendment does not 
cover the internet, or that governments outsourcing censorship to 
third-party ``cut-outs'' or front groups is justified even though the 
Supreme Court has called it ``axiomatic'' that the Government cannot 
facilitate private parties violating the Constitution on its behalf. 
Still other justices may claim that the First Amendment requires a very 
high bar for Government coercion of private actors, even though the 
First Amendment prohibits Government limitations on freedom of speech 
broadly, not just through coercion.
    As such, the importance of this DHS oversight committee in 
protecting our freedom of speech is essential.
    Setting aside the clear and present threat that DHS poses to our 
first and most fundamental freedom, there is another problem related to 
DHS's censorship activities, and that's the ways in which it distracts 
from and thus undermines our Nation's cybersecurity.
    As this committee knows well, the internet is more essential than 
any other piece of America's infrastructure because every major aspect 
of civilization depends upon it, including our electrical grids, our 
transportation networks, and our policing and security systems. If 
cyber attacks take down or undermine the internet, the consequences 
could be catastrophic.
    Given that, does this committee believe it makes sense for the head 
of the DHS's so-called ``Cybersecurity and Information Security 
Agency,'' CISA, to be involved in policing what people say, hear, and 
think?
    Set aside for a moment the Orwellian aspects of CISA's efforts at 
mind control. What do we think the consequences could be of CISA taking 
its eye off the cybersecurity ball so that it can crusade with Stanford 
interns against wrongthink? Should we be able to sleep soundly at night 
knowing that CISA is focused on the problem of people being wrong on 
the internet rather than on China, Russia, Iran, and other malicious 
actors seeking to harm American businesses, Government agencies, and 
our citizens?
    Over the last 100 years, the Supreme Court created a tiny number of 
exceptions to the radical commitment to freedom of speech enshrined in 
our Constitution. Nobody questions the need for governments to fight 
fraud, child exploitation, and the immediate incitement of violence.
    What's at stake here is our fundamental freedom to express our 
views on controversial social and political issues without fear of 
Government censorship. CISA drifted so far from its mission that it 
slid down the slipperiest slope in American political life.
    I believe this dramatic situation requires the abolition of CISA. 
If it is doing good cybersecurity work, then it should be placed under 
the supervision of different leadership at a different agency free from 
the awful and unlawful behaviors of the last 3 years.
    However, I am also a realist and recognize that guardrails may be 
all that can be imposed. If that is the direction in which this 
committee chooses to go, then I would encourage very bright lines 
between cybersecurity and ``cognitive security.'' While censorship 
advocates have tried to blur that line, it is, in reality, quite clear 
to everyone what constitutes security and what constitutes censorship.
    Nonetheless, something must be done to make clear, in DHS-CISA's 
mandate, that the agency recognizes the distinction and will never 
again transgress its mandate in violation of our Constitution.
    The turning against the American people of counterterrorism tactics 
once reserved for foreign enemies should terrify all of us and inspire 
a clear statement that never again shall our military, intelligence, 
and law enforcement guardians engage in such a recklessly ideological 
and partisan ``warfare'' against civilians.

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]

    Chairman Bishop. Thank you, Mr. Shellenberger.
    I now recognize Mr. Chenoweth for his 5 minutes for his 
opening statements.

STATEMENT OF MARK CHENOWETH, PRESIDENT AND GENERAL COUNSEL, NEW 
                    CIVIL LIBERTIES ALLIANCE

    Mr. Chenoweth. Good afternoon, Chairman Bishop, Ranking 
Member Ivey, Members, and guests.
    My name is Mark Chenoweth, and I'm the president of the New 
Civil Liberties Alliance, a nonpartisan, nonprofit civil rights 
group founded by Professor Philip Hamburger of Columbia Law 
School to fight unlawful administrative power. NCLA fills the 
void left by legacy civil liberties groups that no longer care 
about Government-directed censorship. NCLA's motto is, let 
judges judge, let legislators legislate, and don't let 
bureaucrats do either. We champion the people's right to be 
governed by representatives they pick, and Congress' job to 
write the laws.
    Congress never authorized the administrative state 
censorship we are discussing today. My written testimony 
explains NCLA's public interest litigation combating social 
media censorship on behalf of four individuals in the Murthy v. 
Missouri Supreme Court case. But I'm here today to sound the 
alarm on four legal principles Congress must uphold to stop the 
rampant censorship by DHS, CISA, and multiple other Federal 
agencies.
    First, the Government is not the arbiter of truth. As 
Justice Robert Jackson observed, the very purpose of the First 
Amendment is to foreclose public authority from assuming a 
guardianship of the public mind. Every person must be his own 
watchman for truth, because the forefathers did not trust any 
government to separate true from the false. During the COVID-19 
pandemic, the Government proved unable to uphold truth. It 
peddled falsehoods that natural immunity does not exist to 
COVID-19, that vaccine immunity is superior to natural 
immunity, and that vaccines would stop the transmission of the 
virus. The Government then suppressed dissenting voices on 
Twitter, Facebook, and elsewhere who dared to express rational, 
scientifically accurate views on COVID-19 and the vaccines.
    Second, the First Amendment protects even false speech. 
Much of the suppressed COVID speech was true, but in U.S. v. 
Alvarez the Supreme Court held: False statements as a general 
rule are not beyond Constitutional protection. Were the court 
to hold that the interest in truthful discourse alone is 
sufficient to sustain a ban on speech, it would give Government 
a broad sensorial power unprecedented in this court's cases or 
in our Constitutional tradition. This means labeling disfavored 
speech as misinformation, disinformation, or malformation does 
not strip it of First Amendment protection.
    Third, the Government may not do indirectly what the First 
Amendment forbids it from doing directly. It is axiomatic, 
according to the Supreme Court, Norwood v. Harrison, 1973, that 
the Government may not induce, encourage, or promote private 
persons to accomplish what it is Constitutionally forbidden to 
accomplish. The bully pulpit does not include the power to 
harangue social media platforms to remove the lawful speech of 
third parties. When the Government coerces or pressures a 
company with threats, and the company responds by censoring 
private individuals, that is unlawful state action. But if the 
Government writes and tests software to effectively monitor and 
shut down disfavored speech, and then turns that over to 
private actors to run the software that censors the speech, 
that is also forbidden state action. It doesn't matter that 
it's indirect. The First Amendment bar is much lower.
    Fourth, the First Amendment term abridging supplies the 
test to determine when the Government has violated the right to 
free speech. The only question for the courts is whether the 
Government's conduct has led to the abridging, that is the 
diminishing of speech. The test is not coercion, it is not 
whether something was compelled, it's not pressure, it's not 
entanglement, it's abridging. The First Amendment prohibits 
Government from abridging speech, which contrasts with the 
narrower term prohibiting in the free exercise clause, as my 
written testimony, citing Professor Hamburger, explains.
    I will close with three examples that illustrate the scope 
of the problem with Government-led censorship through CISA 
switchboarding, and other practices. First, the Virality 
Project flagged Harvard Medical School epidemiologist Martin 
Kulldorff's tweet, which stated ``thinking that everyone must 
be vaccinated is as scientifically flawed as thinking that 
nobody should. Covid vaccines are important for older, high-
risk people and their caretakers. Those with prior natural 
infection do not need it, nor children.'' This tweet was 
censored and his account flagged.
    Second, the Virality Project wrote a report in which 
another NCLA client, Bri Dressen, was identified as a purveyor 
of misinformation for discussing the adverse, devastating 
effects she personally suffered from the AstraZeneca vaccine 
after she volunteered for a vaccine trial, even though NIH 
itself had diagnosed her as vaccine-injured. In NCLA's Dressen 
v. Flaherty case, we are suing the Government for shutting down 
Bri's support groups for vaccine-injured individuals. These are 
private on-line groups where vaccine-injured people can turn 
for emotional support. When their support groups were deleted, 
group members failed to get assistance they could have gotten 
that would have led to better treatments for them. At least one 
committed suicide. This is private speech we're talking about 
among already-vaccinated people who want to converse with each 
other and share their stories. They will not promote vaccine 
hesitancy to the general public because the speech occurs in 
private forums. And yet the Government is still suppressing 
that speech as we sit here. This is insanity.
    Third, White House pressure led the lab leak theory to be 
censored on social media. When Meta head of global affairs, 
Nick Clegg, asked a colleague why the story had been censored 
on Facebook, the colleague replied, ``because we were under 
pressure from the administration and others to do more'', and 
that ``we shouldn't have done it''. Meta also acknowledged 
changing its policies regarding content discussing adverse 
vaccine events to avoid retaliation from this White House.
    In some, these responses to dissenting COVID-19 views show 
the dangers of Government censorship. The Government's conduct 
violated censored Americans First Amendment rights, as well as 
the rights of other Americans to listen and learn from those 
perspectives and to draw their own conclusions about their 
health, their vote, and the truth.
    This committee must force the Executive branch to correct 
course before it completely obliterates the First Amendment.
    Thank you.
    [The prepared statement of Mr. Chenoweth follows:]
                  Prepared Statement of Mark Chenoweth
                           December 13, 2023
    Chairman Bishop, Ranking Member Ivey, and Members of the 
subcommittee, thank you for inviting my testimony.
                              introduction
    The New Civil Liberties Alliance is a nonpartisan, nonprofit civil 
rights organization founded by prominent legal scholar Philip 
Hamburger, the Maurice and Hilda Friedman Professor of Law at Columbia 
Law School in New York City, to protect Constitutional freedoms from 
violations by the administrative state. Professor Hamburger is among 
the Nation's foremost First Amendment scholars, and his brilliant 
scholarship informs the cases that NCLA pursues and the arguments that 
NCLA makes in those cases on behalf of our clients. NCLA's public-
interest litigation and other pro bono advocacy strive to tame the 
unlawful power of State and Federal agencies and to foster a new civil 
liberties movement that will help restore Americans' fundamental 
rights. NCLA views the administrative state as an especially serious 
threat to Constitutional freedoms. No other development in contemporary 
American law denies more rights to more Americans.
    The ``civil liberties'' of the organization's name include rights 
at least as old as the U.S. Constitution itself, such as freedom of 
speech, jury trial, due process of law, the right to be tried in front 
of an impartial and independent judge, and the right to live under laws 
made by the Nation's elected lawmakers through Constitutionally-
prescribed channels. Yet these selfsame rights are also very 
contemporary--and in dire need of renewed vindication--precisely 
because Congress, Federal administrative agencies, and even sometimes 
the courts have neglected them for so long. NCLA aims to defend civil 
liberties--primarily by asserting Constitutional constraints on the 
administrative state. Although Americans still enjoy the shell of their 
Republic, there has developed within it a very different sort of 
government--a type, in fact, that the Constitution was designed to 
prevent. This un-Constitutional administrative state within the 
Constitution's United States is the focus of NCLA's concern. NCLA urges 
Americans to recognize the administrative threat and join our civil 
liberties movement against it.
    From the outset of the COVID-19 pandemic, the New Civil Liberties 
Alliance has been dismayed at the widespread and brazen violation of 
Americans' civil liberties by all levels of government in the United 
States. It's as though officials think the U.S. Constitution does not 
apply in times of emergency when, in fact, it is during such times of 
crisis that the Constitution's protections for individual rights are of 
paramount importance. NCLA's litigators have been at the forefront of 
the battles against illegal lockdowns, the unlawful Nation-wide 
eviction moratorium, and unconscionable vaccine mandates for university 
employees and students, Federal employees, Federal contractors, and 
others. Particularly with reference to vaccine mandates, NCLA adopted 
the position that natural immunity to COVID-19 is a real phenomenon and 
that vaccines are not necessarily appropriate--and certainly should not 
be mandated--for individuals who have recovered from COVID-19 and have 
antibodies against the virus, which can be measured through antibody 
testing. NCLA has also argued that Federal law prohibits forcing anyone 
outside the military (and then only when ordered by the Commander-in-
Chief) to take a vaccine that has only been approved under Emergency 
Use Authorization. We have also argued that it is a fundamental 
violation of personal liberty to be forced to accept an experimental 
vaccine as a condition of maintaining employment, especially public 
employment by a State or Federal agency or State university.
    In contrast, the Federal Government peddled the falsehoods that 
natural immunity does not exist to COVID-19, that vaccine immunity is 
superior to natural immunity, that lockdowns were an effective 
mitigation strategy, that everyone needs the vaccine, that the COVID-19 
vaccines would stop transmission of the virus, that masks are effective 
in preventing transmission of the virus, that people hospitalized with 
COVID-19 need to be intubated, that EUA vaccines can be mandated for 
Federal employees, that the Wuhan lab was not the origin of the COVID-
19 virus, and so forth. Eventually, the Federal Government came to its 
collective senses and backed away from propagating most of these 
falsehoods. It was forced to abandon some of them after courts ruled 
against the Government. Some of them persist today. However, thanks in 
part to NCLA's efforts, at least the Government now admits that natural 
immunity to COVID-19 exists for some period of time among those who 
have recovered from the virus.
    To make matters worse, not only did the Federal Government peddle 
falsehoods during the pandemic, but it also suppressed dissenting 
voices in the public square on Twitter, Facebook, and elsewhere, who 
dared to express rational and scientifically accurate views about the 
COVID-19 virus and the vaccines authorized for emergency use in 
response to it. And it did so in blatant violation of the First 
Amendment. That is how NCLA first became aware of the vast and shocking 
censorship problem infecting the Federal Government today: our clients 
were censored for their views about COVID-19 and related issues.
    We can come back to that, but first let's explore the legal 
principles at stake here and the scope of the problem as it pertains to 
the Department of Homeland Security.
                            legal principles
    NCLA's most prominent role to date in fighting against unlawful 
Federal censorship has been through our participation representing the 
individual plaintiffs in the Missouri v. Biden case, now pending at the 
U.S. Supreme Court under the name Murthy v. Missouri. The U.S. District 
Court for the Western District of Louisiana, which had the opportunity 
to look at all of the (admittedly still limited) discovery in this case 
before ruling, pronounced on the Fourth of July this year that ``the 
present case arguably involves the most massive attack against free 
speech in United States' history.'' ``Although this case is still 
relatively young, and at this stage the Court is only examining it in 
terms of Plaintiffs' likelihood of success on the merits, the evidence 
produced thus far depicts an almost dystopian scenario. During the 
COVID-19 pandemic, a period perhaps best characterized by widespread 
doubt and uncertainty, the U.S. Government seems to have assumed a role 
similar to an Orwellian `Ministry of Truth.' ''
    On expedited appeal of that decision, the U.S. Court of Appeals for 
the Fifth Circuit, after noting that the U.S. Supreme Court has been 
reluctant to expand state-action doctrine, said: ``[W]e do not take our 
decision today lightly. But, the Supreme Court has rarely been faced 
with a coordinated campaign of this magnitude orchestrated by Federal 
officials that jeopardized a fundamental aspect of American life. 
Therefore, the district court was correct in its assessment--
``unrelenting pressure'' from certain Government officials likely ``had 
the intended result of suppressing millions of protected free speech 
postings by American citizens.''
    As a reminder to this body, the First Amendment says, that 
``Congress shall make no law respecting an establishment of religion, 
or prohibiting the free exercise thereof; or abridging the freedom of 
speech, or of the press; or the right of the people peaceably to 
assemble, and to petition the Government for a redress of grievances.''
    Under the First Amendment, ``government has no power to restrict 
expression because of its message, its ideas, its subject matter, or 
its content.'' Ashcroft v. ACLU, 535 U.S. 564, 573 (2002). This 
``profound'' commitment to free speech is even more necessary when the 
debate may include critical or sharp attacks on Government or its 
policies. See NY Times v. Sullivan, 376 U.S. 254, 270 (1964). And, of 
course, it is ``axiomatic'' that the Government may not ``induce, 
encourage, or promote private persons to accomplish what it is 
constitutionally forbidden to accomplish.'' Norwood v. Harrison, 431 
U.S. 455, 465 (1973). So, just as the Fourth Amendment does not permit 
a police officer to ask a landlord to conduct an unconstitutional 
search on behalf of that officer, so too the First Amendment does not 
permit Government officials to use third-party companies or platforms 
to censor lawful free speech indirectly that the Government itself 
would be prohibited from regulating directly. If anything, given the 
`abridging' language, the First Amendment protects against such 
machinations even more than the Fourth Amendment.
    Again, the Government cannot do indirectly through third parties 
what it cannot do directly. Congress must hold to that line. Otherwise, 
free speech is a dead letter, because the Executive branch has 
countless ways of influencing private parties to suppress their 
speech--as we have seen in Missouri v. Biden. Indeed, this kind of soft 
power exercised through third parties may be worse in the sense that it 
is harder to fight, harder to prove, and easier for the Government to 
get away with. Indeed, I daresay there are some in this room--on both 
sides of the aisle--who brush away the monumental efforts of the Biden 
administration to squelch speech on Twitter, Facebook, LinkedIn, and 
other social media sites as merely the actions of private companies. 
Not so. When the Government coerces or pressures a company with 
inducements or threats and the company responds by crushing private 
individuals, that is State action, and the First Amendment forbids it. 
Or when the Government has entangled its practices with a private 
company to where the company is relying on the Government to identify 
individuals and accounts to be censored, the First Amendment forbids 
that too. Or, if the Government writes and tests software to 
effectively monitor and shut down speech that the Government does not 
like and then turns that over to private operators to run the software 
program and execute the censorship it identifies, that is still state 
action.
    Is every person who was ever canceled on social media a victim of 
state action? Maybe not, but without discovery into the Government's 
unprecedented practices, NCLA and our co-counsel would never have 
uncovered how wide-spread this practice has been and how far up the 
chain of command it goes. We know the background level of censorship 
these companies engaged in before January 2021, especially Twitter 
given the disclosures of the Twitter files. And we know what they did 
in response to Government pressure in terms of ramping up the amount of 
censorship they were doing. So, there is plenty of evidence here to 
ascertain that this censorship was not conducted as independent, 
private action.
    But even the Fifth Circuit's test for Government action here is 
flawed. We don't need and should not invent a judicial standard for 
adjudging infringements on free speech. The Constitution already 
provides the standard. The only question for the courts is whether the 
Government's conduct has led to the ``abridging'' of speech. That is 
what the First Amendment's text proscribes. Not coercion. Not pressure. 
Not entanglement. Abridgment. And that is a very low bar. The First 
Amendment prohibits Government from ``abridging'' freedom of speech 
(contrasted with prohibited in the context of religion).
    The Bill of Rights' evolution demonstrates that the Framers 
purposefully decided to use the term ``abridging'' which is a different 
term than ``prohibiting'' which is used in the Free Exercise Clause. 
This was not a mere attempt to create linguistic variety. See 
Hamburger, Courting Censorship,--COLUMBIA L. J at 39. An earlier draft 
of what would become the First Amendment separated the guarantees to 
free exercise of religion and free speech into two adjacent paragraphs, 
using the term ``infringe'' to designate unlawful Government conduct in 
both contexts. Id. (citing House Committee Report (July 28, 1789), 
CREATING THE BILL OF RIGHTS: THE DOCUMENTARY RECORD FROM THE FIRST 
FEDERAL CONGRESS, 30 ed., Helen E. Veit, Kenneth R. Bowling, and 
Charlene Bangs Bickford (Baltimore: Johns Hopkins Univ. Press 1991)). 
The two paragraphs were combined in a subsequent iteration, which used 
``prohibit'' in the context of proscribed Government conduct with 
respect to free exercise of religion, and ``abridge'' for speech. Id.
    As Professor Hamburger writes: ``This contrast is revealing. An 
action prohibiting is one that involves coercion--in the sense of 
government force or at least the threat of it. So, when the First 
Amendment distinguishes abridging and prohibiting, it tells us 
something important. A law can abridge the freedom of speech, or the 
press, without prohibiting or otherwise coercively assaulting it.'' See 
Hamburger, Courting Censorship,--COLUMBIA L. J at 39. In other words, 
the Framers' conscious choice to use the terms ``abridging'' in the 
speech context and ``prohibiting'' in the religion context establishes 
that they sought to prevent Government from diminishing free speech to 
any extent. That means any action that the Government takes to impede 
free speech violates the First Amendment. By contrast, when it comes to 
religion, the Government's conduct must effectively ``forbid'' the free 
exercise, a much more severe action and a higher bar to clear.
    Finally, in terms of legal principles, recognize that the Supreme 
Court has held that even ``false statements, as a general rule'' are 
not ``beyond Constitutional protection.'' United States v. Alvarez, 567 
U.S. 709, 718 (2012). Thus, merely labeling disfavored speech as 
``disinformation,'' ``misinformation,'' or ``mal-information'' does not 
strip it of First Amendment protection. Of course even under the 
Government's own definitions, misinformation, disinformation, and 
malinformation are not necessarily false speech--often just 
inconvenient or unpleasant truthful speech.
    But the court has explained that `` . . . some false statements are 
inevitable if there is to be an open and vigorous expression of views 
in public and private conversation, expression the First Amendment 
seeks to guarantee.'' Id. (quoting United States v. Stevens, 559 U.S. 
460, 470 (2010)). ``Were the Court to hold that the interest in 
truthful discourse alone is sufficient to sustain a ban on speech . . . 
it would give Government a broad censorial power unprecedented in this 
Court's cases or in our Constitutional tradition. The mere potential 
for the exercise of that power casts a chill, a chill the First 
Amendment cannot permit if free speech, thought, and discourse are to 
remain a foundation of our freedom.'' Id. at 723.
    ``The theory of our Constitution is `that the best test of truth is 
the power of the thought to get itself accepted in the competition of 
the market.' '' Id. at 728 (quoting Abrams v. United States, 250 U.S. 
616, 630 (1919) (Holmes, J., dissenting)). ``The First Amendment itself 
ensures the right to respond to speech we do not like, and for good 
reason. Freedom of Speech and thought flows [sic] not from the 
beneficence of the state but from the inalienable rights of the person. 
And suppression of speech by the government can make exposure of 
falsity more difficult, not less so. Society has the right and civic 
duty to engage in open, dynamic, rational discourse. These ends are not 
well served when the Government seeks to orchestrate public discussion 
through content-based mandates.'' Id. at 728.
                       background on cisa and dhs
    Founded in 2018, CISA, a component of DHS, was initially created to 
protect ``critical infrastructure'' (information technology, 
telecommunications, chemical, transportation systems, emergency 
services, postal and shipping) from cybersecurity threats.\1\ It 
rapidly expanded its mission to combat foreign ``disinformation.'' See, 
e.g., CYBERSECURITY AND INFRASTRUCTURE SEC. AGENCY, #PROTECT2020 
STRATEGIC PLAN, at 20 (2020), https://www.cisa.gov/sites/default/files/
publications/ESI_Strategic_Plan_FINAL_2-7-20_508.pdf. That soon morphed 
into an attempt to control ``cognitive infrastructure'' in the context 
of elections, a term coined by Jen Easterly, former CISA director. See 
Maggie Miller, Cyber agency beefing up disinformation, misinformation 
team, THE HILL (Nov. 10, 2021).
---------------------------------------------------------------------------
    \1\ See https://judiciary.house.gov/sites/evo-subsites/republicans-
judiciary.house.gov/files/evo-media-document/cisa-staff-report6-26-
23.pdf at 5 (citing 6 U.S. Code  652).
    42 U.S.C. 5195c(e): Defines ``critical infrastructure'' to mean 
``systems and assets, whether physical or virtual, so vital to the 
United States that the incapacity or destruction of such systems and 
assets would have a debilitating impact on security, national economic 
security, national public health or safety, or any combination of those 
matters.'' CISA https://www.cisa.gov/topics/critical-infrastructure-
security-and-resilience.
    6 U.S.C.  650 Defines: ``cybersecurity risk'' to mean threats to 
and vulnerabilities of information or information systems and any 
related consequences caused by or resulting from unauthorized access, 
use, disclosure, degradation, disruption, modification, or destruction 
of such information or information systems, including such related 
consequences caused by an act of terrorism;
    And defines ``cybersecurity threat'' as ``an action, not protected 
by the First Amendment to the Constitution of the United States, on or 
through an information system that may result in an unauthorized effort 
to adversely impact the security, availability, confidentiality, or 
integrity of an information system or information that is stored on, 
processed by, or transiting an information system'' (emphasis added).
---------------------------------------------------------------------------
    Easterly's ``cognitive infrastructure'' spin conflicts with the 
definition of ``election infrastructure'' the then-DHS Secretary Jeh 
Johnson adopted in January 2017 when he designated election 
infrastructure as ``a critical infrastructure subsector:'' ``By 
`election infrastructure,' we mean storage facilities, polling places, 
and centralized vote tabulations locations used to support the election 
process, and information and communications technology to include voter 
registration databases, voting machines, and other systems to manage 
the election process and report and display results on behalf of State 
and local governments. https://toresays.com/wp-content/uploads/2022/08/
JohnsonStatement-ElectionInfrastructure.pdf.
    So, originally the term meant policing ``misinformation'' on social 
media, first about elections, but that soon crept into other areas too, 
including Covid (Easterly said, quoted in Hill article above: ``One 
could argue we're in the business of critical infrastructure, and the 
most critical infrastructure is our cognitive infrastructure, so 
building that resilience to misinformation and disinformation, I think, 
is incredibly important[.]'').
    In June 2021, DHS created the CISA Cybersecurity Advisory 
Committee, which in turn established the ``MDM [misinformation/
disinformation/malinformation] subcommittee].''\2\ See, e.g., CISA 
Cybersecurity Advisory Committee, Dec. 6, 2022 Meeting Summary Closed 
Session at 3. This committee (since disbanded) brought together 
government, big tech, and academic ``misinformation'' experts, 
including Kate Starbird from the University of Washington and Renee 
DiResta from Stanford. One of the committee's recommendations was that 
``CISA should approach the [misinformation and disinformation] problem 
with the entire information ecosystem in view. This includes social 
media platforms of all sizes, mainstream media, cable news, 
hyperpartisan media, talk radio, and other on-line resources.''
---------------------------------------------------------------------------
    \2\ Definitions: ``misinformation'' means false information that 
the disseminator thinks is true; ``disinformation'' is false 
information that the disseminator knows is false; and 
``malinformation'' is true information that ``lacks context.''
---------------------------------------------------------------------------
    CISA's mission expanded even further outside its original purview: 
internal documents providing updates say, for example, that CISA is 
``bringing on staff to address MDM related to the pandemic.''\3\ By 
2022, the CISA apparently believed its mission was ``to strengthen the 
security and resilience of the Nation's critical functions,'' or at 
least CISA's CSAC (Cybersecurity Advisory Committee) claimed that was 
CISA's mission.\4\
---------------------------------------------------------------------------
    \3\ See https://judiciary.house.gov/sites/evo-subsites/republicans-
judiciary.house.gov/files/evo-media-document/cisa-staff-report-6-26-
23.pdf at 16.
    \4\ https://www.cisa.gov/sites/default/files/publications/
June%202022%20CSAC%20Recom-mendations%20%E2%80%93%20MDM_0.pdf.
---------------------------------------------------------------------------
    And believing CISA had a mandate to ``strengthen the security and 
resilience of the Nation's critical functions,'' CISA CSAC proposed 
CISA focus on ``MD that risks undermining critical functions of 
American society including: (i) MD that suppresses election 
participation or falsely undermines confidence in election procedures 
and outcomes; (ii) MD that undermines critical functions carried out by 
other key democratic institutions, such as the courts, or by other 
sectors such as the financial system, or public health measures; (iii) 
MD that promotes or provokes violence against key infrastructure or the 
public; and (iv) MD that undermines effective responses to mass 
emergencies or disaster events.''\5\ Any attempt to limit CISA's 
purview to foreign actors by now had evaporated--the agency was 
explicit that it was involved in identifying domestic actors.\6\
---------------------------------------------------------------------------
    \5\ https://www.cisa.gov/sites/default/files/publications/
June%202022%20CSAC%20Recom- mendations%20%E2%80%93%20MDM_0.pdf.
    \6\ See https://judiciary.house.gov/sites/evo-subsites/republicans-
judiciary.house.gov/files/evo-media-document/cisa-staff-report6-26-
23.pdf at 13.
---------------------------------------------------------------------------
                   cisa's work with third parties \7\
---------------------------------------------------------------------------
    \7\ Note: the Fifth Circuit reversed the district court's 
injunction that covered these third parties. NCLA is asking the Supreme 
Court to reverse the Fifth Circuit on this point.
---------------------------------------------------------------------------
    CISA worked with third parties on a frequent basis, laundering the 
censorship through those third parties such as the Election Integrity 
Partnership (EIP) and the Virality Project (VP). Federal officials at 
CISA and GEC, and State officials through CISA funded EI-ISAC, work in 
close collaboration with the Stanford Internet Observatory (DiResta's 
organization) and other nonprofits.\8\
---------------------------------------------------------------------------
    \8\ See Proposed Findings of Fact at 285, Dkt. 212-3, Missouri v. 
Biden, (No. 3:22-cv-1213) (W.D. La 2023).
---------------------------------------------------------------------------
    Moreover, it has recently come to light that DHS/CISA set up the 
EIP.\9\
---------------------------------------------------------------------------
    \9\ See Alex Gutentag and Michael Shellenberger, New Documents 
Reveal US Department of Homeland Security Conspiracy to Violate First 
Amendment and Interfere in Elections (Nov. 7, 2023), https://
public.substack.com/p/new-documents-reveal-us-department.
---------------------------------------------------------------------------
    CISA engaged in ``switchboarding'': CISA officials forwarded 
content flagged by third parties, especially local election officials, 
to the social media companies, either explicitly asking that such 
material be removed, or implying that it should be.\10\ The Surgeon 
General's Office and other Federal officials likewise collaborated 
closely with the Stanford Internet Observatory's Virality Project. Id.
---------------------------------------------------------------------------
    \10\ See https://judiciary.house.gov/sites/evo-subsites/
republicans-judiciary.house.gov/files/evo-media-document/cisa-staff-
report6-26-23.pdf at 12.
---------------------------------------------------------------------------
    The Stanford Internet Observatory and others had portal systems, 
through which they would report to social media companies posts that 
they thought contained ``misinformation.'' The companies didn't always 
remove posts that SIO and other third-party groups flagged, but there 
was a high compliance rate. As an example, Virality Project flagged one 
of NCLA client Martin Kulldorff's tweets (which stated: ``Thinking that 
everyone must be vaccinated is as scientifically flawed as thinking 
that nobody should. COVID vaccines are important for older high-risk 
people, and their care-takers. Those with prior natural infection do 
not need it. Nor children.''). This tweet was censored, and Kulldorff's 
account was flagged as one that should be watched.
    The Virality Project also wrote a report in which another NCLA 
client, Brianne Dressen, was identified as a purveyor of 
``misinformation'' for discussing the adverse effects she suffered from 
the Astra Zeneca vaccine (following her participation in a vaccine 
trial) even though the NIH itself had diagnosed her as vaccine injured.
the u.s. court of appeals for the fifth circuit's findings in missouri 
v. biden with respect to cisa's involvement in social media censorship 
                                  \11\
---------------------------------------------------------------------------
    \11\ Whether or not CISA appeared to have violated the First 
Amendment was the main issue upon which we requested reconsideration in 
the Fifth Circuit, and upon which the Fifth Circuit granted and 
extended the injunction to CISA.
---------------------------------------------------------------------------
    The Fifth Circuit held that the evidence showed ``CISA's role went 
beyond mere information sharing. Like the CDC for Covid-related claims, 
CISA told the platforms whether certain election-related claims were 
true or false. CISA's actions apparently led to moderation policies 
being altered and content being removed or demoted by the recipient 
platforms.'' Missouri v. Biden, 83 F.4th 350, 365 (5th Cir. 2023) 
(decision after reconsideration). ``CISA also likely violated the First 
Amendment.'' Id. at 391. CISA was a ``primary facilitator'' of the 
FBI's interactions with the social media platforms and worked in close 
coordination with the FBI to push the platforms to change their 
moderation policies to cover ``hack and leak'' content.
    CISA's switchboarding operations were more than merely relaying 
information--it used frequent interactions with social media platforms 
to push them to adopt more restrictive policies on censoring election-
related speech. CISA told the platforms whether the content they had 
switchboarded was true or false--the platforms' censorship decisions 
``were made under policies that CISA has pressured them into adopting 
and based on CISA's determination of the veracity of the flagged 
information.''
                             ncla's clients
    The questions presented in the Murthy v. Missouri case are:
    (1) Whether respondents have Article III standing;
    (2) Whether the Government's challenged conduct transformed private 
        social-media companies' content-moderation decisions into state 
        action and violated respondents' First Am. rights; and
    (3) Whether the terms and breadth of the preliminary injunction are 
        proper.
    NCLA's clients in the Missouri v. Biden litigation are Dr. Jay 
Bhattacharya, Dr. Martin Kulldorff, Dr. Aaron Kheriaty, and Ms. Jill 
Hines. Their speech has revolved around the extent to which the 
Government's public health and public policy advice about COVID-19 is 
sound. Drs. Bhattacharya and Kulldorff were co-authors and signatories 
to the Great Barrington Declaration. They opposed lockdowns. Other 
speech included efforts to say that natural immunity is real, efforts 
to say that not every category of the populace needs the vaccine, 
efforts to oppose forced vaccination, efforts to say that natural 
immunity provides equal or greater protection than the vaccine.
    Note that several examples of suppressed speech were neither 
misinformation, disinformation, nor even malinformation. Indeed, the 
Government now admits that natural immunity exists and is effective 
against reinfection with COVID-19 for at least as long as the vaccine, 
though the Government still wants those folks vaccinated, saying that 
there is some marginal benefit to them. Note as well that several of 
the Government's false narratives were allowed to propagate widely on 
social media unrefuted. For example, the narrative against natural 
immunity and the narrative refuting that the Wuhan Institute of 
Virology was the source of the virus (via a leak from the lab) 
persisted.
    We have only been able to obtain limited discovery in the Murthy v. 
Missouri case because we are still at the preliminary injunction phase 
of litigation. The Supreme Court may or may not decide that we have 
enough discovery to establish connections to the extent its precedents 
will demand. That is in part because the Court might demand a coercion 
or significant encouragement standard that is higher than the 
``abridging'' standard set by the First Amendment itself. Such a 
standard would not be consistent with either the text of the First 
Amendment or jurisprudence in the area, and it would have disastrous, 
broad implications for Americans' First Amendment speech rights.
    If these plaintiffs are unable to succeed, it is hard to envision 
how future litigants will do so. Consider first that in this case there 
was a district court judge who was willing to order a modicum of pre-
injunction discovery. Second, we were able to turn up a fair bit of 
good discovery and identify at least some of the correct Government 
officials to seek information from--though the Government lied to us 
about the scope and identity of relevant officials. Third, we 
discovered this dishonesty because we also obtained third-party 
discovery from Facebook, which turned over dozens more emails and 
similar communications with Government officials that the Government's 
initial response to discovery had omitted. Fourth, we also were able to 
rely on the Twitter Files to some extent to find examples of 
censorship. That material only became available because Elon Musk 
bought Twitter and for no other reason. Fifth, we were able to rely on 
the investigative journalism work of Michael Shellenberger, Matt 
Taibbi, and others, who combed through the Twitter files and made some 
relevant information public. Finally, Congress used its oversight 
capacity to issue subpoenas that turned up some additional information. 
This came rather late in the game, so it has not been as beneficial as 
it would have been if it had come earlier, but it is still useful to 
have.
    To see how difficult these cases are to bring and win, consider 
that NCLA already lost a very similar case at the circuit court level, 
which we are still appealing. In the Sixth Circuit, we filed suit on 
behalf of three clients--Mark Changizi, Michael Senger, and Daniel 
Kotzin--whose messages were taken down from Twitter and in one instance 
our client was kicked off Twitter entirely. But the panel ruled against 
our clients on standing, saying that they could not trace their harm to 
Government conduct. In other words, the complaint supposedly did not 
state enough facts to meet the bare minimum necessary to allege 
Government wrongdoing.
    The district court in that case had denied us any discovery. The 
Court of Appeals then limited itself to the facts in the complaint, 
even though many more facts had come out by the time of the briefing on 
appeal and the oral argument. The Sixth Circuit, without reaching the 
merits of the First Amendment issues in the case, held that we had not 
met the minimum pleading standards to even survive a motion to dismiss.
    The court also said that our allegations against the Government 
were--and I quote--``not phantasmagoric'' which is a funny thing to say 
since all of our allegations were facts provable and proved from 
discovery obtained (albeit later) in the Missouri v. Biden litigation. 
Yet that was not enough for a panel in the Sixth circuit to even allow 
our clients to survive a motion to dismiss. Under such circumstances, 
where courts are willing to put blinders on to well-established facts, 
it is hard to see how other plaintiffs will be able to make any headway 
against Government censorship. Under this standard, most people being 
censored would never be able to plead their allegations with the degree 
of specificity apparently required to survive a motion to dismiss.
    Several of the modes of censorship used against our clients are 
surreptitious; that is, our clients did not even know they were being 
censored in some cases or on some platforms for a long time. They 
certainly were unaware of the Government's insidious involvement in 
their censorship, which for the most part was conducted via backdoor 
channels, behind closed doors. Thus, the Government has been able to 
evade democratic accountability for Federal conduct that violates core 
First Amendment-protected activity. You may wonder how extensive this 
censorship has really been. If so, recognize that information taken 
down has included: (1) known and open parody accounts; (2) information 
posted by experts from the Nation's top medical schools and 
universities; (3) In our Dressen v. Flaherty case, the Government 
stooped so low as to shut down support groups for vaccine-injured 
individuals. These are the equivalent of cancer support groups, private 
on-line groups where people can go for emotional support. Some people 
kicked off of these platforms have committed suicide and/or failed to 
get assistance (or failed to learn of better medical protocols) that 
could have led to better outcomes for them sooner. The Government wants 
people's personal reports of their own symptoms and experience, the 
most personal of truths, taken down. This is essentially private speech 
among people who want to engage in consensual speech with each other 
(i.e., conversation), and it is speech occurring among already-
vaccinated people who in reality had no chance of promoting vaccine 
hesitancy to the general public because the speech occurred in private 
forums. And yet even that was taken down. This is censorship to the nth 
degree.
                            recommendations
    In considering solutions to the Federal censorship conduct problems 
at DHS, CISA, and across the Federal Government, Congress needs to 
realize that there is very little recognition among the offending 
officials that they are blatantly violating the First Amendment. About 
the only recognition comes in those places where officials (mistakenly) 
seem to think that orchestrating censorship through third parties 
somehow insulates it from violating the First Amendment. Keeping that 
in mind, Congress should demand better education of front-line 
Executive branch officials about their Constitutional obligations and 
responsibilities. These officials who requested the takedown of lawful 
speech had an independent duty to uphold the First Amendment, which 
they ignored.
    (1) If this censorship were being done by State officials, 
        censorship victims could sue under Sec. 1983 for deprivation of 
        their civil rights. Congress could create a Federal cause of 
        action akin to Sec. 1983 for victims of censorship to sue 
        Federal officials who violate their First Amendment rights.
    (2) Congress should outright forbid anyone in the Executive branch 
        or Legislative branch from ever requesting lawful speech to be 
        taken down.
    (3) Where the Federal Government decides to request speech to be 
        taken down, because it is unlawful speech--and NOT just because 
        it violates a platform's internal policies--those requests 
        should only be made where they are transparent, immediately 
        public, and made by a named individual in the Federal 
        Government who can be held responsible for that decision by 
        Congress and the censored individual(s).
                               conclusion
    The censorship discussed here involved many topics, including 
election-related speech like the Hunter Biden laptop and climate 
change-related speech. The last of these was not part of the 
preliminary injunction as discovery was not taken at the preliminary 
injunction stage to support the complaint's claims on that topic. 
Still, the debate over nearly all things related to COVID-19 provides a 
perfect case study for Americans to realize the danger that exists when 
the Government pushes for the censorship of dissenting views. Without 
the Government's participation, it is doubtful that the media would 
have uniformly censored those stories, and the censorship gravely 
injured Americans' ability to make important decisions regarding their 
health and the health of their families. We have evidence, in the form 
of email exchanges, that the social media companies were caving to 
pressure from Government when they censored certain topics. For 
instance, as the Facebook Files demonstrated, the lab leak theory was 
censored on social media due to pressure from the White House. Meta 
Head of Global Affairs, Nick Clegg, asked a colleague in charge of 
content policy why the story had been censored, and the colleague 
responded, ``Because we were under pressure from the [Biden] 
administration and others to do more'' and that ``we shouldn't have 
done it.'' Meta acknowledged changing its policies regarding content 
discussing adverse events of the vaccine to avoid retaliation from the 
White House.
    This is conduct that violates the First Amendment rights of 
censored Americans--as well as the rights of every other American to 
listen to and learn from those censored perspectives to draw their own 
conclusions about the truth. As Justice Robert Jackson famously said in 
the West Virginia v. Barnette case: ``If there is any fixed star in our 
Constitutional constellation, it is that no official, high or petty, 
can prescribe what shall be orthodox in politics, nationalism, 
religion, or other matters of opinion or force citizens to confess by 
word or act their faith therein.'' West Virginia State Board of 
Education v. Barnette, 319 U.S. 624 (1943).
    Less famously, as Justice Jackson noted 2 years later in Thomas v. 
Collins, ``The very purpose of the First Amendment is to foreclose 
public authority from assuming a guardianship of the public mind 
through regulating the press, speech, and religion. In this field, 
every person must be his own watchman for truth, because the 
forefathers did not trust any government to separate the true from the 
false for us.'' Today's Federal Government has strayed far from this 
wise and Constitutionally-required path. I hope that this committee 
will ensure that the Executive branch corrects course.*
---------------------------------------------------------------------------
    *[Note.--Due to length, the witnesses' supporting documents have 
been retained in committee files.]

    Chairman Bishop. Thank you, Mr. Chenoweth. I now recognize 
Mr. Abdo for his 5 minutes.

   STATEMENT OF ALEX ABDO, LITIGATION DIRECTOR, KNIGHT FIRST 
            AMENDMENT INSTITUTE, COLUMBIA UNIVERSITY

    Mr. Abdo. Chairman Bishop, Ranking Member Ivey, and Members 
of the subcommittee, thank you for inviting me to testify 
today.
    My name is Alex Abdo, and I'm the litigation director of 
the Knight First Amendment Institute at Columbia University. 
The topic that this subcommittee has been exploring on the 
relationship between Government and social media platforms is 
an important one, in large part because it implicates many 
competing First Amendment interests. I'd like to offer several 
observations to clarify the Constitutional principles that 
should guide this subcommittee's work.
    First, as the Supreme Court held 60 years ago in Bantam 
Books v. Sullivan, the First Amendment forbids the Government 
from coercing private actors into silencing disfavored speech. 
That decision was correct because coercion, by definition, 
overrides the ability of people to decide for themselves what 
to say, what to listen to, and what communities to join. This 
rule is important not only in protecting individuals, but also 
in protecting the social media platforms, which now play a 
vital role in hosting and curating the speech of millions of 
people. The communities they create reflect their own 
expressive decisions, as well as the expressive and 
associational preferences of their users. Outside of very 
narrow exceptions, it would be inconsistent with the principle 
of self-government to allow officials to dictate the speech 
individuals may create and consume in these on-line 
communities, whether directly through official sanction or 
indirectly through official coercion.
    Second, while the First Amendment forbids the Government 
from coercing private actors into suppressing speech, it does 
not preclude the Government from trying to persuade private 
actors to embrace its views. A democratically-elected 
government must have the power to govern, and an indispensable 
tool in governing is attempting to galvanize public opinion. As 
the Supreme Court reaffirmed just a few years ago, governing 
necessarily involves taking a particular viewpoint and 
rejecting others. It is not easy to imagine, the court wrote, 
how government could function if it could not express its 
views. The public also has a strong interest in hearing what 
its government has to say. Hearing the Government's views helps 
ordinary citizens evaluate the Government's decisions and hold 
Government officials accountable for them. In addition, private 
actors often rely on the Government's expertise in making 
decisions about their own speech.
    In the years after 9/11, for example, news organizations 
welcomed the input of the Government in deciding whether to 
publish Classified information that had been leaked to them. 
This is not to say, of course, that anyone should defer to the 
Government's views, knowledge, or expertise. The Government 
often gets things wrong. But a rule requiring the Government to 
stand silent on matters of public policy would be paralyzing, 
as the Supreme Court has said.
    Third, and this is a point I really want to emphasize 
today, the First Amendment protects the right of researchers to 
study social media platforms and to share their findings with 
the public, the platforms, and the Government. It should not 
need to be said that when researchers study the social media 
platforms, they are exercising rights protected by the First 
Amendment. When they criticize the platform's content 
moderation policies and practices, the First Amendment protects 
them. When they press the platforms to take down speech, the 
First Amendment protects them. Yes, even when you and I 
disagree with their research findings and proposals, the First 
Amendment protects them. For these reasons, I think it's 
crucial for the subcommittee to tread carefully in this area. 
It's legitimate to investigate the Executive branch to see 
whether it has coerced or conspired with researchers to 
suppress protected speech, but investigations of and lawsuits 
against private researchers who acted independently of the 
Government are not a defense of the First Amendment. They are a 
grave threat to it.
    Finally, let me conclude by acknowledging what I hope is a 
common concern. The concentration of private power over public 
discourse is a threat to free speech. The First Amendment does 
not forbid the social media companies from assuming gatekeeper 
control over public discourse, nor does it insulate them, 
however, from careful regulation that would loosen that 
control. Congress can and should pass legislation that would do 
just that. It should require the platforms to design their 
systems to be interoperable so that users can switch to 
competing services without losing their social networks. It 
should enact a privacy law that gives users greater control 
over their personal data, making it easier for users to switch 
between competing services and harder for platforms to obtain 
and monopolize access to the data that drives their 
profitability. Congress should enact transparency laws that 
make it easier to study the platforms and the effects they're 
having on public discourse. Carefully-drafted laws of this kind 
would address some of the legitimate concerns with the 
platforms consistently with the First Amendment.
    Thank you again for the opportunity to testify today.
    [The prepared statement of Mr. Abdo follows:]
                    Prepared Statement of Alex Abdo
                           December 13, 2023
    Chairman Bishop, Ranking Member Ivey, and Members of the 
subcommittee, thank you for inviting me to testify today. My name is 
Alex Abdo, and I am the litigation director of the Knight First 
Amendment Institute at Columbia University.
    The topic that this subcommittee has been exploring on the 
relationship between the government and social media platforms is an 
important one--in large part because it implicates many competing First 
Amendment interests. I'd like to offer several observations to clarify 
the Constitutional principles that should guide this subcommittee's 
work.
    First, as the Supreme Court held 60 years ago in Bantam Books v. 
Sullivan, the First Amendment forbids the Government from coercing 
private actors into silencing disfavored speech.\1\
---------------------------------------------------------------------------
    \1\ Bantam Books, Inc. v. Sullivan, 372 U.S. 58, 71 (1963).
---------------------------------------------------------------------------
    That decision was correct because coercion, by definition, 
overrides the ability of people to decide for themselves what to say, 
what to listen to, and what communities to join. This rule is important 
not only in protecting individuals, but also in protecting the social 
media platforms, which now play a vital role in hosting and curating 
the speech of millions of people. The communities they create reflect 
their own expressive decisions as well as the expressive and 
associational preferences of their users. Outside of very narrow 
exceptions, it would be inconsistent with the principle of self-
government to allow officials to dictate the speech individuals may 
create and consume in these on-line communities, whether directly 
through official sanction or indirectly through official coercion.
    Second, while the First Amendment forbids the Government from 
coercing private actors into suppressing speech, it does not preclude 
the Government from trying to persuade private actors to embrace its 
views.
    A democratically-elected government must have the power to govern, 
and an indispensable tool in governing is attempting to galvanize 
public opinion. As the Supreme Court reaffirmed just a few years ago, 
governing ``necessarily [involves] tak[ing] a particular viewpoint and 
reject[ing] others.''\2\ ``[I]t is not easy to imagine,'' the Court 
wrote, ``how government could function''\3\ if it could not express its 
views.
---------------------------------------------------------------------------
    \2\ Matal v. Tam, 582 U.S. 218, 234 (2017); see also Walker v. Tex. 
Div., Sons of Confederate Veterans, Inc., 576 U.S. 200, 208 (2015) 
(``But, as a general matter, when the government speaks it is entitled 
to promote a program, to espouse a policy, or to take a position. In 
doing so, it represents its citizens and it carries out its duties on 
their behalf.'').
    \3\ Matal, 582 U.S. at 234 (internal quotation marks omitted) 
(quoting Pleasant Grove City, Utah v. Summum, 555 U.S. 460, 468 
(2009)).
---------------------------------------------------------------------------
    The public also has a strong interest in hearing what its 
government has to say. Hearing the Government's views helps ordinary 
citizens evaluate the Government's decisions and hold Government 
officials accountable for them. In addition, private actors often rely 
on the Government's expertise in making decisions about their own 
speech. In the years after 9/11, for example, news organizations 
welcomed the input of the Government in deciding whether to publish 
classified information that had been leaked to them.\4\
---------------------------------------------------------------------------
    \4\ See, e.g., James Risen & Eric Lichtblau, Bush Lets U.S. Spy on 
Callers Without Courts, N.Y. Times, Dec. 16, 2005, https://
www.nytimes.com/2005/12/16/politics/bush-lets-us-spy-on-callers-
without-courts.html (``After meeting with senior administration 
officials to hear their concerns, the newspaper delayed publication for 
a year to conduct additional reporting. Some information that 
administration officials argued could be useful to terrorists has been 
omitted.'').
---------------------------------------------------------------------------
    That's not to say, of course, that anyone should defer to the 
Government's views, knowledge, or expertise. The government often gets 
things wrong.\5\ But a rule requiring the Government to stand silent on 
matters of public policy ``would be paralyzing,'' as the Supreme Court 
has said.\6\
---------------------------------------------------------------------------
    \5\ See, e.g., `Group Think' Led to Iraq WMD Assessment, Fox News 
(July 11, 2004), https://www.foxnews.com/story/group-think-led-to-iraq-
wmd-assessment; Zeynep Tufekci, Why Telling People They Don't Need 
Masks Backfired, N.Y. Times (Mar. 17, 2020), https://www.nytimes.com/
2020/03/17/opinion/coronavirus-face-masks.html.
    \6\ Matal, 582 U.S. at 234; see also Bantam Books, 372 U.S. at 72.
---------------------------------------------------------------------------
    Third--and this is a point I really want to emphasize today--the 
First Amendment protects the right of researchers to study social media 
platforms, and to share their findings with the public, the platforms, 
and the Government.
    It should not need to be said that when researchers study the 
social media platforms, they are exercising rights protected by the 
First Amendment. When they criticize the platforms' content-moderation 
policies and practices, the First Amendment protects them. When they 
press the platforms to take down speech, the First Amendment protects 
them. And yes, even when you and I disagree with their research 
findings and proposals, the First Amendment protects them.
    For these reasons, I think it's crucial for the subcommittee to 
tread carefully in this area. It's legitimate to investigate the 
Executive branch, to see whether it has coerced or conspired with 
researchers to suppress protected speech. But investigations of and 
lawsuits against private researchers who acted independently of the 
Government are not a defense of the First Amendment; they are a grave 
threat to it.
    Finally, let me conclude by acknowledging what I hope is a common 
concern--the concentration of private power over public discourse is a 
threat to free speech.
    The First Amendment does not forbid the social media companies from 
assuming gatekeeper control over public discourse. Nor does it insulate 
them from careful regulation that would loosen that control.
    Congress can, and should, pass legislation that would do just that. 
It should require the platforms to design their systems to be 
``interoperable,'' so that users can switch to competing services 
without losing their social networks. It should enact a privacy law 
that gives users greater control over their personal data, making it 
easier for users to switch between competing services and harder for 
platforms to obtain and monopolize access to the data that drives their 
profitability. And Congress should enact transparency laws that make it 
easier to study the platforms and the effects they're having on public 
discourse.
    Carefully drafted laws of this kind would address some of the 
legitimate concerns with the platforms, consistently with the First 
Amendment.
    Thank you, again, for the opportunity to testify today.

    Chairman Bishop. Thank you, Mr. Abdo.
    I now recognize Mr. Lawkowski for 5 minutes for his opening 
statement.

 STATEMENT OF GARY M. LAWKOWSKI, SENIOR FELLOW, THE COUNCIL TO 
                      MODERNIZE GOVERNANCE

    Mr. Lawkowski. Mr. Chairman, Mr. Ranking Member, Members of 
the committee, thank you very much for this opportunity to 
testify today.
    My name is Gary Lawkowski. I'm a senior fellow with the 
council to modernize governance. I'd like to begin with a 
little bit of a story. For about the last 2 years or so, I've 
had the distinct pleasure of dating a lovely woman who lives up 
in Baltimore, Maryland. Now, I live in Virginia. If you've ever 
made that drive, that can be a bit of a challenge. Sometimes 
you're going up and down the GW Parkway, back and forth between 
Virginia and Baltimore. I've been doing that a lot over the 
past 2 years, and I have got to tell you, when I'm driving down 
that road, there are all these crazy people going down there. 
If it's not someone zipping past me on the right, it's someone 
plodding along in the left, blocking up traffic. It drives me 
crazy. There are all these other maniacs out there on the road. 
Someone really should do something about that. But the problem 
is, to me, regulating disinformation is a lot like regulating 
driving. I suspect if you took those other people, sat them in 
this chair, stood them up, have them raise their right hand, 
and make the same oath who swear to tell the truth, they would 
also say, hey, it's that crazy guy with those Virginia tags out 
there. He's the one who doesn't know how to drive, not me. In 
the words of the sage of our time, Taylor Swift, sometimes, 
maybe, though, it's me. Hi, I'm the problem. It's me. We all 
think we're good drivers, but it turns out we may well be the 
maniac. That's why we need to approach these issues with a fair 
degree of humility and recognize that we may not be the ones 
who know what's true, we may be the one who's wrong. That's why 
regulating disinformation, misinformation, these other things, 
is so dangerous, because it sort-of presumes this position that 
we're always right and that we can always get the answer right. 
That's particularly dangerous when it's coming from Government.
    So we've heard some talk already about what are the limits 
from the First Amendment and kind-of how far can we go with 
that, as though the First Amendment itself is kind-of the end-
all, be-all of this. While the First Amendment is incredibly 
important, I think it's even more important to look kind-of 
behind that and why we have a first amendment. Why do we care 
about this, why is this something that's in our Constitution? 
Why do we prioritize free expression at all?
    So, first and foremost, free expression, including, and 
perhaps especially the expression of ideas that most people 
think are wrong, people may think that person's a maniac, 
they're important, and they're necessary in the search for 
truth. Pursuing truth requires correcting errors, and that 
means standing up against prevailing narratives and standing up 
against what seemed to be consensus. Otherwise, we'd be locked 
into antiquated ideas. To take this kind-of one example, I grew 
up, I was a child in the 1990's. We had this food pyramid from 
the Department of Agriculture. That was the end-all, be-all of 
healthy eating. If you follow this, you'll stay healthy, you'll 
be in good shape. So I took that as the settled science. Well, 
it turns out since that time, it's been updated at least twice 
by the Department of Agriculture. It's also been called into 
question by numerous public health schools, such as the Harvard 
Public Health School. What we thought was true may have been 
wrong, even about something as elemental as eating, something 
that people have to do, have been doing as long as there have 
been people. We may still get that information wrong. This is 
one reason we need to tread very carefully around the free 
expression, because it allows us to correct these consensus, 
purportedly settled ideas when it turns out they may be wrong.
    A second thing, free expression sort-of lowers the 
temperature and the stakes for political contests. It's one 
thing if I'm wrong and you're right and I lose, then I can 
litigate that in the next election, I can litigate that at 
another opportunity. If I think I'm right and you think you're 
right, and whoever wins gets to shut the other person up, 
that's a big problem. That really raises the stakes in our 
political contests, because now it's no longer about coming 
back in the next election, now it's about this is the thing 
that settles this issue for all time. That's a huge problem, 
particularly at a time where there's already concern about 
political polarization.
    Third, free expression provides a window into what people 
believe. Just because we tell people they can't say something 
doesn't mean they stop believing that. They still do, they just 
become much more careful or much more discerning about who 
they're going to express those views to. Thus, bad ideas don't 
really go away just because you censor them, they just go 
underground, and that's not healthy for our society.
    Then fourth, and perhaps most fundamentally, one of the 
problems with regulating this sort of mis- and disinformation 
gets back to that driving question. It's who decides? I would 
say the Government is the last person you want making those 
decisions because it's the 800-pound gorilla in the room. Even 
if they don't say do this or else, there's always that implicit 
or else in what Government's doing.
    So what do we do about this? How do we go beyond just the 
four corners of the First Amendment to protect our rights going 
forward? First, we have to return to first principles. The 
Federal Government, particularly the Executive branch, should 
not be the arbiter of truth.
    Second of all, there should be bright lines protecting and 
preventing the Federal Government from interfering with 
Constitutionally-protected speech. In very limited 
circumstances that have been recognized by the court there may 
be a place to step in like child pornography, imminent threats. 
In other places, though, the Government really shouldn't be 
stepping in to try to tell people what they can and can't say 
on-line.
    Third, domestic-facing agencies, particularly the 
Department of Homeland Security, really should not be involved 
in this. This is not to absolve other agencies of 
responsibility, but it is to say that these agencies' goal and 
their main target audience is American citizens, and American 
citizens should not be restricted by their Government on what 
they can and can't say.
    Fourth, there's a slippery slope in the definitional 
changes that we've seen, and I believe that will be talked 
about a little more, about this idea that we've gone from 
critical infrastructure as physical things to cognitive 
infrastructure and the idea that we have to regulate ideas. 
That should not happen without, at very least, of a robust 
public debate. That has not happened.
    Fifth, the Government should cut Federal funding for anti-
disinformation programs to seek, deflect, and censor First 
Amendment projects. It's one thing to say these are private 
institutions, but it's another thing when they're being funded 
with our tax dollars.
    Finally, there must be avenues for personal accountability 
for people who do this.
    Thank you.
    [The prepared statement of Mr. Lawkowski follows:]
                Prepared Statement of Gary M. Lawkowski
                           December 13, 2023
    Mr. Chairman, Mr. Ranking Member, and Members of the committee, 
thank you for this opportunity to testify today.
                          i. introduction \1\
---------------------------------------------------------------------------
    \1\ Portions of this testimony are adopted from the Council to 
Modernize Governance report, Restoring Online Free Speech and Shutting 
Down the Censorship Industrial Complex, which is attached hereto. See 
Curtis Schube & Gary Lawkowski, Restoring Online Free Speech and 
Shutting Down the Censorship Industrial Complex, The Council to 
Modernize Governance (Dec. 2023).
---------------------------------------------------------------------------
    For about the past 2 years, I have had the distinct pleasure of 
dating a lovely woman. But there is a catch: I live in the great 
Commonwealth of Virginia, while she lives across the river and up the 
road in Baltimore, Maryland. This means I have spent a lot of time over 
the past 2 years going up and down the Baltimore-Washington Parkway, I-
295, and I-395.
    I started driving in high school. I have been doing it for a while. 
I think I have become pretty good at it. But something seems to happen 
as soon as I cross the river on the highway. If you have had the 
opportunity to make this trip a few times, you may have seen it as 
well. There are all these maniacs on the road. If they are not zipping 
past me at unsafe speeds on the right, they are plodding along blocking 
traffic on the left.
    But here is the amazing thing: I suspect if you tracked down those 
other drivers, sat them in this chair, and swore them to tell the 
truth, they would tell you that they are not the problem. It is 
everyone else, maybe even me, that guy with the Virginia tags.
    I apologize if you have heard this one before,\2\ but to me, 
``disinformation'' is a lot like driving. We all think we are good at 
identifying what is true, that the problem is everyone else, and that 
things would be so much better if we could just make them see that. 
But, in the words of Time Magazine's illustrious person of the year, it 
may be that ``it's me, hi, I'm the problem, it's me''\3\--we all may 
well be the maniac on the road.
---------------------------------------------------------------------------
    \2\ See Testimony of Mr. Gary M. Lawkowski, Senior Fellow, the 
Institute for Free Speech to the U.S. House of Representatives 
Committee on House Administration, Subcommittee on Elections (June 22, 
2022), https://docs.house.gov/meetings/HA/HA08/20220622/114910/HHRG-
117-HA08-WState-LawkowskiG-20220622.pdf.
    \3\ Taylor Swift & Jack Antonoff, Anti-Hero, Republic (Oct. 21, 
2022), https://www.youtube.com/watch?v=b1kbLwvqugk..
---------------------------------------------------------------------------
    The result is that it is imperative to approach questions of truth 
with a healthy dose of humility. Whether it is done directly or 
indirectly, censorship or seeking to suppress perceived ``dis-,'' 
``mis-,'' or ``malinformation'' takes the opposite approach.
    Unfortunately, over the past few years, Government officials have 
assumed increasingly assertive roles in attempting to police truth and 
falsity in public discourse, particularly on-line. The search for truth 
and the basic imperatives of self-government require breathing space in 
a free and open marketplace of ideas.\4\ This is completely 
incompatible with constant ``content moderation'' to strangle purported 
``misinformation.''
---------------------------------------------------------------------------
    \4\ See generally New York Times Co. v. Sullivan, 376 U.S. 254, 
271-72 (1964) (Recognizing ``[t]hat erroneous statement is inevitable 
in free debate, and that it must be protected if the freedoms of 
expression are to have the `breathing space' that they `need . . . to 
survive.' '' (quoting N.A.A.C.P. v. Button, 371 U. S. 415, 433 (1963)).
---------------------------------------------------------------------------
    Preserving and protecting this marketplace of ideas requires going 
beyond just the four corners of the First Amendment and restoring 
institutional respect for the values it protects. This involves actions 
in the courts, but it also requires administrative and legislative 
action to ensure Government--including domestic-facing agencies like 
the Department of Homeland Security and Federal Bureau of 
Investigation--respect proper limits on their actions.
                        ii. why free expression
    ``Disinformation'' and ``misinformation'' are real. There are bad 
actors who want to intentionally spread false information to serve 
their own ends. There are also people who honestly believe things that 
just are not true. Moreover, whether intentional or not, this false 
information can have real, negative consequences: from luring speakers 
into minor faux paus to potentially starting wars.
    In light of these threats, why do we value and prioritize the free 
expression of ideas--especially ideas that seem like they are wrong?
    First and foremost, free expression--including and perhaps 
especially the expression of ideas that many people believe are wrong--
is necessary in the search for truth. Knowledge is not static. People 
and institutions constantly learn new information or make mistakes in 
how they analyze old information. Pursuing truth requires correcting 
errors in prevailing narratives, which in turn means people must be 
free to challenge prevailing orthodoxy and beliefs.
    I grew up and went to school in the 1990's. When I was in school, 
we were taught about the food pyramid, the paragon of guidance for 
healthy eating. Considering the primacy placed on the food pyramid as 
``settled science''--at least for us elementary schoolers--it came as 
quite a surprise for me to learn that the U.S. Department of 
Agriculture has changed its recommended guidance graphic at least twice 
since the early 1990's, each time altering its guidance for healthy 
eating.\5\ Even after these changes, the current recommendations are 
still contentious and hotly debated. For example, the Harvard T.H. Chan 
School of Public Health almost immediately launched its own ``Healthy 
Eating Plate'' as an alternative to the Department of Agriculture's 
revised recommendations.\6\
---------------------------------------------------------------------------
    \5\ See William Neuman, Nutrition Plate Unveiled, Replacing Food 
Pyramid, N.Y. Times (June 2, 2011), https://www.nytimes.com/2011/06/03/
business/03plate.html.
    \6\ See Harvard researchers launch Healthy Eating Plate, Harvard 
T.H. Chan School of Public Health (Sept. 14, 2011), https://
www.hsph.harvard.edu/news/press-releases/healthy-eating-plate/.
---------------------------------------------------------------------------
    Eating food is one of the basic building blocks of life. Humans 
have been doing it since they first appeared on the Earth. Yet, we 
still do not fully understand or agree on what type of diet is best and 
how to describe it. Even in a field so basic and longstanding, the 
``science'' is not so ``settled'' as to be beyond debate. There is 
every reason to believe that questions that have arisen much more 
recently and that are much less elemental to the human experience can 
also benefit from a continued airing of debate and contrasting views.
    Second, free expression lowers the stakes for political contests. 
Our Constitution was drafted in 1787. The framers were well aware of 
the recent history of approximately 200 years of European wars of 
religion and, particularly, the history of the English Civil War, which 
ended a little over a century before. While there were many factors 
influencing each conflict, one recurring theme was the steadfast idea 
that one side knew the truth and was right, while the other side did 
not and was wrong.
    The settlement, reflected in the ideals of the founders' age, was 
to accept that one side could be wrong without needing to change their 
mind at the point of a sword. This is a principle that is being 
increasingly devalued in our political culture and it is one we 
disregard at our own peril. Recognizing the right to be wrong lowers 
the stakes of our political disputes. It allows the losing side in 
today's political debate to accept defeat gracefully, rather than 
viewing any setback as an existential threat.
    Third, free expression provides a window into what people believe. 
People do not necessarily stop believing the ``wrong'' things just 
because they are not able to express them. They simply get more careful 
about when and with whom they choose to express their true views. Thus, 
``bad'' ideas do not go away; they go underground. This is not a 
healthy state of affairs.
 iii. the problem with regulating dis-, mis-, and malinformation--who 
                                decides?
    The problem with regulating purported ``mis-,'' ``dis-,'' or 
``malinformation'' boils down to a simple question: who decides? 
Regulating these categories of speech requires someone to first 
determine what is and what is not true. This is an incredibly 
consequential power.
    In a free society, where Government derives its authority from the 
consent of the governed, the answer to this question cannot be the 
Government. Government--especially the Federal Government--is an 800-
pound gorilla. It wields vast power over individuals, companies, and 
the economy more broadly. If my neighbor thinks I am wrong, I can 
ignore his views. If the Government thinks I am wrong and has the 
authority to impose its view of truth, I do not have the same luxury.
    Moreover, government is ultimately a human institution. Even though 
the majority of government employees are dedicated to their work and 
want to do the right thing, they are still susceptible to the same 
flaws, cognitive biases, and self-interested behavior as any other 
people. Whether out of a well-meaning but misguided belief or self-
interested desires to hide inconvenient or embarrassing narratives, 
government officials can be--and often are--wrong about things.
    We have vividly seen these processes play out in many facets of 
life over just the past few years. For example, ideas that were 
initially suppressed in debates over COVID-19, such as concerns that 
COVID-19 may have leaked from a lab, have gained traction and greater 
acceptance.\7\ Similarly, the Hunter Biden laptop was initially 
dismissed as ``disinformation'' before being generally accepted as 
authentic.\8\ Likewise, in 2021, there was a lot of public controversy 
around accusations that U.S. Border Patrol agents whipped migrants at 
the Mexican border with the reins of their horses. Even the President 
of the United States weighed in, claiming ``people [were] being 
strapped'' and stating ``[i]t's outrageous. I promise you those people 
will pay.''\9\ But it turned out not to be true. As Customs and Border 
Protection found following an intensive investigation, ``[t]he 
investigation found no evidence that agents struck any person with 
horse reins.''\10\
---------------------------------------------------------------------------
    \7\ See generally Christiano Lima, Facebook no longer treating 
`man-made' Covid as a crackpot idea, Politico (May 26, 2021), https://
www.politico.com/news/2021/05/26/facebook-ban-covid-man-made-491053.
    Michael R. Gordon & Warren P. Strobel, Lab Leak Most Likely Origin 
of Covid-19 Pandemic, Energy Department Now Says, Wall St. J. (Feb. 26, 
2023), https://www.wsj.com/articles/covid-origin-china-lab-leak-
807b7b0a.
    \8\ See generally Craig Timberg, Matt Viser, and Tom Hamburger, 
Here's How The Post Analyzed Hunter Biden's Laptop, Wash. Post (Mar. 
30, 2022), https://www.washingtonpost.com/technology/2022/03/30/hunter-
biden-laptop-data-examined/.
    \9\ Remarks by President Biden on the COVID-19 Response and the 
Vaccination Program, The White House (Sept. 24, 2021), https://
www.whitehouse.gov/briefing-room/speeches-remarks/2021/09/24/remarks-
by-president-biden-on-the-covid-19-response-and-the-vaccination-
program-8/.
    \10\ CBP Releases Findings of Investigation of Horse Patrol 
Activity in Del Rio, Texas, U.S. Customs and Border Protection (Jul. 8, 
2022), https://www.cbp.gov/newsroom/national-media-release/cbp-
releases-findings-investigation-horse-patrol-activity-del-rio.
---------------------------------------------------------------------------
    Finally, the Federal Government--particularly the Executive branch, 
acting alone--attempting to arbitrate truth in public discourse is 
incompatible with self-government. The three most important words in 
the U.S. Constitution are the first three: ``We the people.'' With this 
simple introduction, the framers of our constitution set out a radical 
approach to government, one where the American people ultimately set 
the agenda for the Government and government is supposed to be 
responsive to the American people. Involving the Federal Government in 
regulating ``mis-,'' ``dis-,'' and ``malinformation'' undermines this 
relationship. It allows the Government to effectively set its own 
agenda, independent of the will of the American people. This is not and 
cannot be correct.
           iv. government efforts to regulate disinformation
    Unfortunately, we have seen a creeping erosion of time-honored 
lines protecting free expression from Government intrusion, 
particularly on social media.
    The internet is a tool and, like any tool, there is the potential 
for it to be misused for illegal purposes. The Supreme Court has 
recognized a ``few'' categories of speech ``long familiar to the bar'' 
where the Government can impose content-based restrictions, such as 
incitement to imminent lawless action, speech integral to criminal 
conduct, or child pornography.\11\ The Government can and does have a 
role in protecting the American people from actual criminal conduct, 
even when it occurs on-line. But this can be fulfilled clearly and 
transparently through traditional law enforcement channels.
---------------------------------------------------------------------------
    \11\ United States v. Alvarez, 567 U.S. 709, 717 (2012).
---------------------------------------------------------------------------
    That is not analogous to what has occurred over the past few years. 
What we have seen is a subtle but distinct shift from targeting 
nefarious actions to targeting disfavored ideas. The shift from concern 
about direct foreign attacks on election infrastructure, such as voting 
machines and voter rolls, to concerns about ill-advised memes 
illustrates this slippery slope.
    In early 2017, Homeland Security Secretary Jeh Johnson designated 
election infrastructure as a ``critical infrastructure subsector,'' 
giving the Department of Homeland Security the duty to protect it. 
Secretary Johnson clearly defined election infrastructure as physical 
facilities and systems used for elections: ``By `election 
infrastructure,' we mean storage facilities, polling places, and 
centralized vote tabulation locations used to support the election 
process, and information and communications technology to include voter 
registration databases, voting machines, and other systems to manage 
the election process and report and display results on behalf of State 
and local governments.''\12\
---------------------------------------------------------------------------
    \12\ Statement by Secretary Jeh Johnson on the Designation of 
Election Infrastructure as a Critical Infrastructure Subsector, 
Department of Homeland Security (Jan. 6, 2017), https://www.dhs.gov/
news/2017/01/06/statement-secretary-johnson-designation-election-
infrastructure-
eleccritical#:?:text=statement%20by%20Secretary%20Jeh%20Johnson,as%20a%2
0Critical- 
%20Infrastructure%20Subsector&text=I%20have%20determined%20that%20electi
on,Govern- ment%20Facilities%20critical%20infrastructure%20'sector.
---------------------------------------------------------------------------
    However, by 2019, a subtle shift occurred. While the Department 
still sought to protect ``election infrastructure,'' the perceived 
threat morphed from physical facilities and systems to protecting 
against ``foreign disinformation.''\13\ This shift put the Department 
squarely in the business of monitoring and seeking to influence what 
people think and say.
---------------------------------------------------------------------------
    \13\ Homeland Security Advisory Council Interim Report of The 
Countering Foreign Influence Subcommittee, Department of Homeland 
Security (May 21, 2019), https://www.dhs.gov/sites/default/files/
publications/ope/hsac/19_0521_final-interim-report-of-countering-
foreign-influence-subcommittee.pdf.
---------------------------------------------------------------------------
    By July 2020, the Department was actively meeting with outside 
groups seeking to suppress purported misinformation, including the 
collection of groups known as the ``Election Integrity Project'' 
(``EIP'').\14\ By its own claim, EIP was formed ``in consultation with 
[the Cybersecurity and Infrastructure Security Agency] and other 
stakeholders'' and identified the problem it was seeking to address as 
``election disinformation that originates from within the United 
States, which would likely be excluded from law enforcement action 
under the First Amendment and not appropriate for study by intelligence 
agencies restricted from operating inside the United States.''\15\
---------------------------------------------------------------------------
    \14\ See The Long Fuse: Misinformation and the 2020 Election at 21, 
Election Integrity Project (June 15, 2021) https://stacks.stanford.edu/
file/druid:tr171zs0069/EIP-Final-Report.pdf (EIP Post-election Report).
    \15\ Id. at 2.
---------------------------------------------------------------------------
    Analysis of the EIP's 2021 post-election report and the ticketing 
system that flagged various on-line speech offers the following data 
points:
  <bullet> 72 percent of ``tickets'' for flagged speech was 
        ``categorized as delegitimization,'' which appears to apply 
        regardless of if the information was true or false;\16\
---------------------------------------------------------------------------
    \16\ Id. at 31.
---------------------------------------------------------------------------
  <bullet> 49 percent of tickets involved an ``exaggerated issue;''\17\
---------------------------------------------------------------------------
    \17\ Id. at 33.
---------------------------------------------------------------------------
  <bullet> 26 percent of tickets involved an electoral process issue 
        incorrectly framed as partisan;\18\
---------------------------------------------------------------------------
    \18\ Id.
---------------------------------------------------------------------------
  <bullet> 18 percent of tickets featured content taken out of context 
        from other places or times to create false impressions of an 
        election issue;\19\
---------------------------------------------------------------------------
    \19\ Id.
---------------------------------------------------------------------------
  <bullet> 17 percent of tickets involved unverifiable claims, such as 
        friend-of-friend narratives.\20\
---------------------------------------------------------------------------
    \20\ Id.
---------------------------------------------------------------------------
    The claims presented in these ``tickets'' may have been true or 
they may have been false. What they largely appear not to be, however, 
is speech that would fall outside of traditional First Amendment 
protections.
    As a coda on the Election Integrity Project, following the 2020 
election the same 4 institutions primarily responsible for the EIP did 
not disband. Instead, they effectively rebranded with other partner 
organizations as the Virality Project to continue their censorship of 
on-line speech. This time they targeted narratives relating to COVID-19 
vaccines instead of focusing on election delegitimization.\21\
---------------------------------------------------------------------------
    \21\ ``Virality Project,'' accessed Dec. 11, 2023, https://
www.viralityproject.org/home.
---------------------------------------------------------------------------
    The story of the Department of Homeland Security's descent into 
domestic censorship illustrates several key features of what has been 
called the ``censorship industrial complex,'' including:
  <bullet> The use of a foreign threat to justify expansion into 
        censorship;
  <bullet> The redefinition of terms, such as critical infrastructure, 
        with little or no public debate;
  <bullet> The shift from purely foreign threats to domestic concerns;
  <bullet> The use of partnerships with ostensibly nongovernmental 
        organizations--often funded in part through Government grants--
        to act in places where First Amendment concerns would limit the 
        Government's ability to act indirectly; and
  <bullet> The evolving nature of the targets of domestic censorship 
        efforts, with efforts begun to address one discrete concern--
        such as foreign election interference--being repurposed for 
        others.
     v. finding solutions: six principles and proposals for reform
    Working with my colleague Curtis Schube and the Council to 
Modernize Governance, we have developed a set of six areas for 
improvement that can help arrest the growth of the censorship 
industrial complex. These ideas are listed and expanded upon further in 
our report, Restoring Online Free Speech and Shutting Down the 
Censorship Industrial Complex, which is attached to this testimony:*
---------------------------------------------------------------------------
    * The document is retained in committee files and can be found at 
https://modernizegovernance.org/wp-content/uploads/2023/12/
Censorship.pdf.
---------------------------------------------------------------------------
    First, we recommend returning to first principles. The Federal 
Government--particularly the Executive branch, acting on its own 
accord, should not be the arbiter of truth. Where there is ``bad'' 
speech, the Government should respond by presenting its own views and 
evidence--not seeking to suppress disfavored ideas.
    Second, there should be bright lines preventing the Federal 
Government from interfering with Constitutionally-protected speech. In 
the limited circumstances where there is a legitimate legal basis to 
suppress on-line speech--such as preventing the dissemination of child 
pornography--the involvement of Federal officials in identifying, 
flagging, or otherwise contributing to the removal should be clear, 
should be performed only by law enforcement, and should be open to both 
public and judicial scrutiny.
    Third, domestic-facing agencies, such as the Department of Homeland 
Security and the Federal Bureau of Investigation, should be prohibited 
from engaging in activities to restrict ``mis-,'' ``dis-,'' and 
``malinformation.'' This is not to absolve other ostensibly foreign-
facing agencies from scrutiny. Rather, it is a recognition that reform 
needs to start somewhere, and domestic-facing entities are clearly 
inappropriate vehicles for activities with significant implications for 
domestic free expression, particularly when the raison d'etre is to 
counter foreign disinformation.
    Fourth, the slippery slope in definitional changes that has allowed 
accepted missions, such as protecting ``critical infrastructure,'' to 
be stretched beyond any common understanding must be reined in. 
Significant changes to organizational missions must be presented to the 
public and properly debated before being implemented.
    Fifth, the Federal Government should cut Federal funding for anti-
disinformation programs that seek to flag and/or censor First 
Amendment-protected speech. The field of mis- and disinformation does 
not merely seek to correct inaccurate information through counter 
speech. It seeks to suppress what it views as untrue information. 
Accordingly, it functions as a high-tech inquisition that is 
irreconcilable with basic principles of free expression. The least that 
can be done is to close the spigot of taxpayer dollars being used to 
censor the American people.
    Sixth, there must be avenues for personal accountability for 
Federal officials who misuse their positions to censor American speech. 
The right to free speech is central to the proper functioning of a 
democratic society. Systematic violations of this right by Government 
officials wielding the power to regulate or shut down private actors 
presents tremendous danger to the future of political discourse. 
Whether it is conservative speech today or progressive speech tomorrow, 
it is wholly inappropriate for Federal officials to abuse their 
authority toward this end. However, as is clear in other areas, without 
the opportunity for personal accountability, the likelihood of 
preventing future abuse is low. Accordingly, there must be both 
employment consequences and potential liability for the most egregious 
cases, for repeated or blatant First Amendment violations.
    None of these proposals leaves the Federal Government helpless in 
the face of actual foreign disinformation campaigns. The solution to 
``bad'' speech today is the same as it has always been: more ``good'' 
speech. The Government can still engage in the marketplace of ideas as 
a participant--not a moderator--and seek to convince the American 
people that it is correct based on the persuasive force of its evidence 
and arguments.
                             vi. conclusion
    President Reagan warned ``Freedom is a fragile thing and it's never 
more than one generation away from extinction. It is not ours by way of 
inheritance; it must be fought for and defended constantly by each 
generation, for it comes only once to a people. And those in world 
history who have known freedom and then lost it have never known it 
again.''\22\
---------------------------------------------------------------------------
    \22\ Ronald Reagan, Inaugural Address, Ronald Reagan Presidential 
Library and Museum (Jan. 5, 1967), https://www.reaganlibrary.gov/
archives/speech/january-5-1967-inaugural-address-public-ceremony.
---------------------------------------------------------------------------
    We are, unfortunately, at an inflection point. Our core commitment 
to free expression is being challenged and assailed from many 
directions in new and unique ways. We must not be the generation that 
allows free expression, unmoderated by Government, to pass away 
quietly. We have the opportunity to preserve the free expression that 
has served our Nation well for the past 247 years. We must take it and 
resolve to approach questions of truth with proper humility, 
recognizing that the settled narrative today may be proven wrong 
tomorrow.
    Thank you very much for the opportunity to discuss these issues. I 
greatly appreciate your time and consideration.
                          additional resources
Curtis Schube & Gary Lawkowski, Restoring Online Free Speech and 
Shutting Down the Censorship Industrial Complex, The Council to 
Modernize Governance (Dec. 2023).

    Chairman Bishop. Thank you, Mr. Lawkowski.
    Members will be recognized by order of seniority for 5 
minutes of questioning. An additional round of questioning may 
be called after all Members have been recognized.
    I now recognize myself for 5 minutes of questioning.
    I want to begin. I wonder if, Mr. Ivey, if you would pull 
back up--your staff might pull back up the enlargement you had, 
the first one, the statement by a DHS official from November 
2023.
    Mr. Ivey. Mr. Novak.
    Chairman Bishop. I think that is right. If you have the 
enlargement.
    Let me say as I am beginning, or asking that to come up--
thank you. I will use in just a second if you hold it for me. 
First of all, it is interesting how little separates the views 
expressed on the panel and I think between me and the Ranking 
Member of the subcommittee. I think therein lies something that 
needs to be focused on. There are some red herrings or straw 
men here that can be knocked down pretty quickly.
    I agree. This is not about partisanship, by the way. I 
mean, I think there is some evidence that the conservatives 
were more frequently censored, but that is not at all the 
point. The problem is that it can affect and will affect both 
sides at the same time.
    Here is what troubles me, though. OK. This is a November 
2023 statement by Brandon Wales. He says CISA does not and has 
never censored speech or facilitated censorship. Any such 
claims are patently false. So it would be one thing if this 
turned out to be an excess or a misjudgment or something that 
grew up naturally out of the COVID pandemic or the election 
concern that people say, look, we went too far, we have 
curtailed that, we no longer do that. But that is not what is 
being said here. It is a categorical declaration that there has 
been no censorship. I have got to tell you, that deepens the 
concern, because if the situation were, OK, the Disinformation 
Governance Board has been abandoned because there was a huge 
public outcry, we would realize at CISA or DHS, that was a 
mistake. That is one thing. But for them to abandon it and for 
the effort to go subterranean, underground, and be popping up, 
but continue to be pursued, that is a very significant thing. 
It certainly justifies the continued examination into this 
topic.
    I would say with my friend from Maryland, the Ranking 
Member, this contention that the social media platforms were 
never compelled, that is the thing that continues to be said, 
and the Ranking Member has read the case, and so have I, from 
the Fifth Circuit that make clear the tests that are applied is 
not that you are lined up against the wall with a gun at your 
head to say you must take this information down off your social 
media platform, the question is the degree to which Government 
may be perceived to have been intensively involved, and thereby 
the censorship by the so-called private entity becomes 
Government action. It is a little bit like the notion, the old 
saying, you remember, nice little business you got there, it 
would be a shame if something were to happen to it. That is a 
threat, even though it isn't stated in threatening language.
    Mr. Shellenberger, how about that? We have got CISA taking 
down the video that had the fictional character Sharon urged to 
report as misinformation what her uncle was stating on-line. 
They have taken that down. They have done a number of things 
like that to telegraph that this isn't something we are going 
to do anymore. I took that to be the thrust of Jen Easterly's 
testimony in the Appropriations Committee. Yet this is a 
declaration we have never done it. There is not even an issue 
about whether we have done it or something that needs to get 
ironed out. What about that? Shouldn't we be concerned about 
that phenomenon?
    Mr. Shellenberger. Yes, I mean definitely. I mean if it 
were up to me, I think if there's important cybersecurity 
activities happening in CISA, that should continue, I think 
they need to be under a different agency because this agency 
actively not just participated, but led this creation of a 
censorship apparatus. Now that's them saying, oh, we were just 
doing research. It was a mass flagging and censorship operation 
that was coordinated with a broader effort to pressure the 
platforms to do more censorship. That was going on since 2016.
    So, yes, I think it's disingenuous to suggest that they 
were just doing research.
    Chairman Bishop. Mr. Chenoweth, as the litigation like 
Missouri v. Biden, you mentioned the Murthy case--I guess it is 
Murthy in the Supreme Court, I guess, is the name of it there. 
Courts have differed sometimes with themselves on what level of 
government actions constitute interference with freedom of 
speech. Why is that a challenge, and how should courts resolve 
it?
    Mr. Chenoweth. I think there's a concern that there may be 
a category mistake here, Mr. Chairman, because a lot of the 
precedents--because the Government hasn't done this kind of 
censorship, by and large, going back 10, 20, 40, 50 years. So 
the precedents that exist at the Supreme Court are largely 
precedents where there have been private entities that have 
been doing censorship and have been sued. Bantam Books is an 
example of this. Then the question is, well, was that private 
conduct turned into State action? So if you're suing a private 
entity and you're trying to--because if it is a private entity, 
it's truly private action, then the First Amendment doesn't 
apply. So if you're suing a private entity and saying that they 
engaged in state action, then there's precedents that suggest, 
how do you know that there's state action there? The tests have 
been things like coercion and so forth, also entanglement. 
Also, the way that you described it, Mr. Chairman, is just how 
involved are we here? But the reason for that is because we 
want to be very careful about saying that a private entity has 
become a public entity. We need to be very careful about that. 
We need to draw that line carefully, because if that private 
entity is treated as a public entity, then its liberties have 
really been constricted, particularly by the First Amendment 
then applying to it.
    But that's not what we're talking about here. In Murthy v. 
Missouri, we didn't sue any private entities. We're suing the 
Government. The question is, what's the standard that affects 
the Government when the Government is engaged in Government-led 
censorship? The standard there shouldn't be coercion, it 
shouldn't be the standard that applies when you're suing a 
private entity. It needs to be the First Amendment standard. 
The text of the First Amendment says abridge, and that means 
diminish. You're telling me that nothing that CISA did 
diminished free speech, that it didn't diminish speech? Of 
course it did. The whole point of it was to diminish speech.
    Chairman Bishop. Undoubtedly it did.
    Thank you, Mr. Chenoweth.
    My time is long since expired. I thank you for that.
    But I now recognize Ranking Member Ivey for 5 minutes for 
any questions he may have.
    Mr. Ivey. Thank you, Mr. Chairman.
    Yes, I think we have some different views on this. I will 
just tell you what my thinking is on some of this.
    I guess we draw the line in different places as to what 
role governments should play with respect to public speech or 
comments. For example, we have talked about this in previous 
hearings. I mean, tobacco, for example. When I was a young kid, 
there was an argument back and forth about whether it caused 
cancer or not, whether it was detrimental to health. I think we 
certainly hit the point, the 1980's or 1990's or so, where it 
became clear, I think scientifically, that it was causing a 
problem. The Government decided, in addition to private support 
from the medical community, that public service announcement 
campaigns across the country to try and reduce the level of 
smoking was in order. In fact, that was part of the settlement 
with the tobacco companies. So those ads started running. I 
think even you can find now people who dispute whether tobacco 
causes cancer or not. But I think it is pretty clear that that 
was the Government effort with respect to speech that took a 
stand that was in favor of public safety. Seatbelts is another 
one. We have got a number of these we could go through.
    COVID, I know, is controversial, so I hate to walk into the 
hornets nest, but some of those points, I appreciate the points 
you made, Mr. Chenoweth. Some of them I kind-of was definitely 
on the side of we need to do something like that, where like 
injecting bleach will cure you of COVID was one of those. So I 
take the point that, I guess that was Mr. Lawkowski on the trip 
from Virginia to Baltimore, was talking about how sometimes the 
Government is not right, sometimes it is. That is a fair point. 
But I think what I am hearing from the table, at least for Mr. 
Chenoweth and with Mr. Shellenberger, is Government should 
never be taking positions on what is accurate or true or 
correct, and that is not really my view.
    But, Mr. Chenoweth, I wanted to give you a chance to--if 
you give me a brief response, is there a line that you would 
draw where you think it is OK for the Government to take public 
statements, disagree with information that is out there? Then 
here is the line, I think, for the censorship piece, reach out 
to platforms and say, add content or flag it or whatever?
    Mr. Chenoweth. I don't have a problem with the Government 
taking a position on anything. I think that that's Government 
speech and that's fine. I think the problem is when you have 
the Government reaching out to platforms to shut down other 
speech, that becomes censorship. In terms of when they can and 
can't do that, if they're reaching out to a platform to shut 
down unlawful speech, which I would suggest----
    Mr. Ivey. Sure, that is fine.
    Mr. Chenoweth [continuing]. The child----
    Mr. Ivey. Yes, child porn. Sure. Terrorism.
    Mr. Chenoweth [continuing]. Pornography example. No problem 
with that at all.
    Mr. Ivey. OK.
    Mr. Chenoweth. But if you're reaching out to a platform to 
shut down lawful speech, such as Dr. Kulldorff's tweet about 
who should and shouldn't get vaccinated, that was lawful 
speech.
    Mr. Ivey. Well, let me ask you to draw the line on that, 
when you say shut down. Remove would be I guess what you mean 
by shut down. Is flagging it or adding comments to it, are you 
OK with that?
    Mr. Chenoweth. Well, I'm certainly not OK with the 
Government flagging it or the Government adding comments.
    Mr. Ivey. Well, Government asking the social--because 
Government is not controlling the social media platforms, but 
asking the social media, hey, can you flag? My view, too, is 
that that is the decision that is made by the social media 
platforms. I don't think it is the Sopranos coming to get them 
otherwise, but go ahead.
    Mr. Chenoweth. I think that's diminishing and therefore 
abridging speech and therefore a direct violation of the First 
Amendment.
    Mr. Ivey. So the Government asking, I don't know, Twitter 
or X, whatever they call it now, to flag statement X is an 
abridgement and a First Amendment violation?
    Mr. Chenoweth. Absolutely if that----
    Mr. Ivey. Automatically?
    Mr. Chenoweth [continuing]. Speech is lawful speech.
    Mr. Ivey. OK.
    Mr. Chenoweth. I think that's a very clear and easy line to 
draw.
    Mr. Ivey. OK. I define abridged a little differently than 
you do, I think, in the first Amendment context, but that is 
OK.
    I did want to read this piece here, too, though. This is 
from Yoel Roth. I think this is kind-of a fact issue. He is 
formerly at Twitter and testified here from the Oversight 
Committee on February 8. He is talking about threats that were 
coming over the internet. In an effort to get ahead of these 
kinds of threats, Twitter and other tech companies worked to 
build closer information-sharing relationships with law 
enforcement, such as the FBI. In the recent reporting known as 
the Twitter files, there was an attempt to portray interactions 
between Twitter and other social media platforms and the FBI's 
politically-driven interference. My experience of these 
interactions was different. Across the FBI, DHS, and other 
agencies, the professionals responsible for combating malign 
foreign interference in elections did so with integrity and the 
utmost care and respect for the laws of this country, including 
the First Amendment.
    I would ask that we make this part of the record.
    I see I am over my time.
    Chairman Bishop. Without objection, so ordered.
    [The information follows:]
 Statement of Yoel Roth, PhD, Former Head of Trust & Safety, Twitter, 
                                  Inc.
                            February 8, 2023
Hearing on ``Protecting Speech from Government Interference and Social 
        Media Bias, Part 1: Twitter's Role in Suppressing the Biden 
        Laptop Story''
            Before the House of Representatives Committee on Oversight 
                    and Accountability
    Thank you, Chairman Comer, Ranking Member Raskin, and Members of 
the Committee, for the opportunity to speak with you here today.
    In nearly 8 years at Twitter, I worked in and led a division called 
Trust & Safety. Trust & Safety's core duty is content moderation: 
Labeling or removing Tweets that violate Twitter's terms of service, 
and suspending or banning users who repeatedly break the rules. This 
work is sometimes dismissed merely as censorship--but it represents a 
key way that Twitter and other companies live up to their 
responsibility to keep the users of their products safe.
    Much of this work is uncontroversial and obviously good: For 
example, taking down accounts that engage in child sexual exploitation 
or promote terrorism. Although this content represents a tiny fraction 
of the overall volume of conversation on social media, the dangers it 
poses means platforms like Twitter have a responsibility to find it and 
remove it promptly. The scale of this work is considerable: In the 
second half of 2021, Twitter removed over 33,000 accounts for promoting 
terrorism or violent extremism, more than 100,000 for promoting the 
sale of illegal goods and services, and nearly 600,000 for engaging in 
child sexual exploitation.\1\
---------------------------------------------------------------------------
    \1\ ``Rules Enforcement, July--December 2021,'' Twitter 
Transparency Center, Twitter, last modified July 28, 2022, https://
transparency.twitter.com/en/reports/rules-enforcement.html#2021-jul-
dec.
---------------------------------------------------------------------------
    If all trust and safety work was just about universally abhorrent 
content, there would be no controversy. We would all agree that content 
moderation is unambiguously good. The gray area of this work is when 
trust and safety teams have to make decisions about so-called ``lawful 
but awful'' material: Content that may be legal in many jurisdictions, 
but isn't something most people would want to see or experience.\2\ 
Think of things like posting someone else's home address without their 
permission; or sharing graphic videos of animal abuse; or bullying 
someone for a disability or for how they look.
---------------------------------------------------------------------------
    \2\ Daphne Keller, ``Lawful but Awful? Control over Legal Speech by 
Platforms, Governments, and Internet Users,'' The University of Chicago 
Law Review Online, June 28, 2022. https://lawreviewblog.uchicago.edu/
2022/06/28/keller-control-over-speech/.
---------------------------------------------------------------------------
    A free-speech absolutist might say, ``Yes, that kind of content is 
unpleasant, but it's not against the law. What right do you have to 
remove it?'' The answer is that, as businesses, social media platforms 
must be appealing to their own users, if they hope to survive.\3\ 
Consistently, in its own research, Twitter found that users were 
unhappy with the platform's approach to content moderation--and that 
this dissatisfaction drove away both users and advertisers. In other 
studies, we found that some portions of Twitter's user base stopped 
using Twitter for the opposite reason: Because they felt Twitter was 
too overbearing and censored too much. In short, the company had to 
look for a middle-ground solution that would appeal to both sides of 
this spectrum, while still addressing the very real harms that can come 
from social media.
---------------------------------------------------------------------------
    \3\ Yoel Roth, ``I Was the Head of Trust and Safety at Twitter. 
This Is What Could Become of It,'' New York Times, November 18, 2022, 
https://www.nytimes.com/2022/11/18/opinion/twitter-yoel-roth-elon-
musk.html.
---------------------------------------------------------------------------
    A key harm we talked a lot about on the Trust & Safety team was 
chilling effects: The idea that one person's unrestricted freedom of 
speech could have the consequence of stifling someone else's--the 
proverbial ``Heckler's Veto'' of First Amendment law. Again and again, 
we saw the ``lawful but awful'' speech of a small number of abusive 
users drive away countless others. Unrestricted free speech, 
paradoxically, results in less speech, not more.\4\ Trust & Safety's 
job is to try to find a balance between one person's free speech, and 
the impacts of their free speech on the ability of others to 
participate. Getting this right is difficult, but essential to the 
success of a platform like Twitter.
---------------------------------------------------------------------------
    \4\ Danielle Citron, Hate crimes in cyberspace (Harvard University 
Press, 2014). Mary Anne Franks, ``Fearless speech,'' First Amendment 
Law Review 17 (Symposium, 2018).
---------------------------------------------------------------------------
    But the importance of trust and safety work goes far beyond whether 
or not Twitter succeeds as a private business. There are broader 
national security implications for this work, too. In 2016, we saw 
significant interference in an American election by the Russian 
government, through social media platforms such as Twitter.\5\ I led 
the team at Twitter that uncovered that interference.\6\ I still 
remember the rage I felt when I saw accounts with names like ``Pamela 
Moore'' and ``Crystal Johnson''--accounts purporting to be real 
Americans, from Wisconsin and New York, but with phone numbers tracing 
back to St Petersburg, Russia.\7\ These accounts were operated by 
agents of a foreign government, and their mission was to stoke culture 
war issues on social media to try to further divide Americans.\8\ My 
team and I exposed and banned hundreds of thousands of these accounts, 
from Russia, but also from Iran, China, and beyond.\9\
---------------------------------------------------------------------------
    \5\ Kathleen Hall Jamieson, Cyberwar: How Russian hackers and 
trolls helped elect a president: What we don't, can't, and do know 
(Oxford University Press, 2018).
    \6\ Twitter, ``Update on Twitter's review of the 2016 US 
election,'' Twitter Blog, January 19, 2018, https://blog.twitter.com/
official/en_us/topics/company/2018/2016-election-update.html.
    \7\ U.S. Department of Justice, Report on the Investigation Into 
Russian Interference in the 2016 Presidential Election, Volume I of II, 
March 2019, https://s3.documentcloud.org/documents/5955240/Full-
Mueller-Report.pdf.
    \8\ Ahmed Al-Rawi and Anis Rahman, ``Manufacturing rage: The 
Russian Internet Research Agency's political astroturfing on social 
media,'' First Monday 25, no. 9, http://dx.doi.org/10.5210/
fm.v25i9.10801.
    \9\ ``Moderation Research,'' Twitter Transparency Center, Twitter, 
accessed February 4, 2023, https://transparency.twitter.com/en/reports/
moderation-research.html.
---------------------------------------------------------------------------
    And the kinds of attacks that we saw go far beyond fake Americans 
with Russian phone numbers. The actors targeting American elections are 
well-funded and increasingly sophisticated, and have continuously 
gotten better at covering their tracks. In 2016, Russian military 
intelligence carried out a sophisticated hack and leak campaign 
targeting the U.S. elections; the details of it weren't declassified 
until long after election day,\10\ after the damage had been done. As 
Congress investigated what happened, a clear finding was that tech 
platforms and law enforcement had failed to appropriately work together 
to address these threats.\11\ Twitter, and other companies, were 
widely--and I think rightfully--criticized for their inaction. We were 
told in no uncertain terms, by the public and by Congress, that we had 
a responsibility to do a better job protecting future elections.
---------------------------------------------------------------------------
    \10\ U.S. Intelligence Community, Assessing Russian Activities and 
Intentions in Recent US Elections, January 6, 2017, https://
www.intelligence.senate.gov/sites/default/files/documents/
ICA_2017_01.pdf.
    \11\ U.S. Congress, Senate, Select Committee on Intelligence, 
Russian Active Measures and Interference In the 2016 U.S. Election, 
116th Cong., 2d sess., S. Rep. 116-290, https://
www.intelligence.senate.gov/publications/report-select-committee-
intelligence-united-states-senate-russian-active-measures. 
---------------------------------------------------------------------------
    In an effort to get ahead of these kinds of threats, Twitter and 
other tech companies worked to build closer information-sharing 
relationships with law enforcement such as the FBI.\12\ In the recent 
reporting known as the Twitter Files, there was an attempt to portray 
interactions between Twitter and other social media platforms and the 
FBI as politically-driven interference.\13\ My experience of these 
interactions was different. Across the FBI, DHS, and other agencies, 
the professionals responsible for combating malign foreign interference 
in elections did so with integrity, and the utmost care and respect for 
the laws of this country--including the First Amendment.
---------------------------------------------------------------------------
    \12\ Salvador Rodriguez, ``The FBI visits Facebook to talk about 
2020 election security, with Google, Microsoft and Twitter joining,'' 
CNBC, September 4, 2019, https://www.cnbc.com/2019/09/04/facebook-
twitter-google-are-meeting-with-us-officials-to-discuss-2020-election-
security.html.
    \13\ Matt Taibbi, ``Capsule Summaries of all Twitter Files Threads 
to Date, With Links and a Glossary,'' Racket, January 4, 2023, https://
www.racket.news/p/capsule-summaries-of-all-twitter.
---------------------------------------------------------------------------
    Which brings us to Hunter Biden's laptop and the New York Post. In 
2020, the Trust & Safety team noticed activity related to the laptop 
popping up on Twitter, and that activity, at first glance, bore a lot 
of similarities to the 2016 Russian hack and leak operation. Twitter 
had to decide what to do. The only information we had to go on to make 
this decision was what had been publicly reported. And in that moment, 
with limited information, Twitter made a mistake: Under the 
Distribution of Hacked Material Policy,\14\ the company decided to 
require the New York Post to delete several Tweets linking to stories 
about the laptop, and prevent links to those stories from being shared 
across the service. This policy was not meant to be a tool to censor 
news: It was written to prohibit hacking groups from using Twitter to 
launder stolen documents--the same activity the Russian government had 
engaged in in 2016. And in this instance, the company's initial 
assessment was that the activity bore enough similarities to the 2016 
hack and leak that it warranted enforcement.
---------------------------------------------------------------------------
    \14\ ``Distribution of Hacked Material Policy,'' Help Center, 
Twitter, archived version last modified March 2019, https://
web.archive.org/web/20190717143909/https://help.twitter.com/en/rules-
and-policies/hacked-materials.
---------------------------------------------------------------------------
    I've been clear that, in my judgment at the time, Twitter should 
not have taken action to block the New York Post's reporting. I 
recommended to Twitter leadership that we take a milder step while we 
tried to learn more: My recommendation was that we prevent the articles 
from being actively recommended or amplified by Twitter's algorithms, 
rather than blocking them altogether. However, in an effort to be 
consistent with the specifics of the Hacked Materials Policy, which 
didn't provide for the milder step I recommended, Twitter decided to 
follow a strict interpretation of the policy, and removed the New York 
Post's Tweets. Just 24 hours after doing so, the company acknowledged 
its error,\15\ and ultimately changed its policies as a result.\16\ But 
this isn't a case where I was right, and others were wrong: The 
decisions here aren't straightforward, and hindsight is 20/20. It isn't 
obvious what the right response is to a suspected, but not confirmed, 
cyber attack by another government on a Presidential election. Twitter 
erred in this case because we wanted to avoid repeating the mistakes of 
2016.
---------------------------------------------------------------------------
    \15\ Kate Conger and Mike Isaac, ``In Reversal, Twitter Is No 
Longer Blocking New York Post Article,'' New York Times, October 16, 
2020, https://www.nytimes.com/2020/10/16/technology/twitter-new-york-
post.html.
    \16\ ``Distribution of Hacked Materials Policy,'' Help Center, 
Twitter, last modified October 2020, https://help.twitter.com/en/rules-
and-policies/hacked-materials.
---------------------------------------------------------------------------
    And so the basic job of trust and safety remains to try to strike 
this balance: Between the harms of restricting too much speech, and the 
dangers of doing too little. Some of the decisions we had to make, like 
taking down images of animal abuse, were obvious; others, like how to 
address various forms of misinformation about COVID, are less clear. 
But someone has to make a call. Companies like Twitter--teams like 
mine--have to exercise judgment about where to draw the line on this 
content and implement that judgment consistently at the scale of 
hundreds of millions of unique posts per day.
    I'll be the first to admit that we didn't always get it right. 
Individual content moderation decisions will always be contentious, and 
reasonable minds can differ about whether a specific choice was right 
or wrong. I'm sure we'll talk about some of those choices here today. 
But what we tried to do at Twitter--across every decision--was to 
create a rules-based system of governance that would make clear what's 
allowed, or not, on Twitter, and why.
    Transparency is at the heart of this work, and it's where I think 
Twitter--and all of social media--can and must do better.
    Trust is built on understanding--and right now, the vast majority 
of people don't understand how or why content moderation decisions are 
made. Much of the knowledge about how platforms like Twitter make 
decisions is known only to the tiny number of people working at the 
companies themselves. This is particularly problematic for key 
decisions, like those impacting elections, where a company's actions 
are of immense public concern to millions of voters.
    During my tenure at Twitter, we started down a path of increased 
transparency by beginning to pull back the curtains on these decisions. 
In 2018, we took the unprecedented step of publishing comprehensive 
archives of Russian election interference during and after the 2016 
elections.\17\ We released similar data about dozens of other 
campaigns, spanning hundreds of millions of Tweets and terabytes of 
media, unearthing government-backed troll farms around the world.\18\ 
Through newer programs like the Twitter Moderation Research Consortium, 
we aimed to expand this even further, sharing data about key policy 
decisions in areas like misinformation with hundreds of 
researchers.\19\ I'm concerned by recent reports that suggest this 
program has been canceled, with no staff left at Twitter to oversee 
it.\20\
---------------------------------------------------------------------------
    \17\ Vijaya Gadde and Yoel Roth, ``Enabling further research of 
information operations on Twitter,'' Twitter Blog, October 17, 2018, 
https://blog.twitter.com/en_us/topics/company/2018/enabling-further-
research-of-information-operations-on-twitter.
    \18\ Twitter, ``Disclosing state-linked information operations 
we've removed,'' Twitter Blog, December 2, 2021, https://
blog.twitter.com/en_us/topics/company/2021/disclosing-state-linked-
information-operations-we-ve-removed.
    \19\ Yoel Roth, ``The Twitter Moderation Research Consortium is now 
open to researchers,'' Twitter Blog, September 22, 2022, https://
blog.twitter.com/en_us/topics/company/2022/twitter-moderation-research-
consortium-open-researchers.
    \20\ Sheila Dang, ``Twitter research group stall complicates 
compliance with new EU law,'' Reuters, January 28, 2023, https://
www.reuters.com/technology/twitter-research-group-stall-complicates-
compliance-with-new-eu-law-2023-01-27/.
---------------------------------------------------------------------------
    Twitter's relationship with Government employees would benefit from 
similar levels of transparency. While the Twitter Files show a lot of 
discussions between Twitter employees and political staff on both sides 
of the aisle, some key context is missing: We were careful to keep the 
teams involved in those interactions cordoned off from the 
implementation of our rules. Twitter's Government relations staff--the 
people you see in the Twitter Files answering emails from campaign 
staff and Members of Congress--did not have any kind of decision-making 
authority over policy enforcement. But how would anyone know that, 
especially when other big companies blur the lines between these 
functions?\21\ Twitter set up its teams to promote impartiality; but in 
the absence of transparency, people reasonably assume that there's 
opportunity for abuse.
---------------------------------------------------------------------------
    \21\ Emily Birnbaum, ``Facebook staff complained for years about 
their lobbyists' power,'' Politico, October 25, 2021, https://
www.politico.com/news/2021/10/25/facebook-fatal-flaw-technologists-
lobbyists-516927.
---------------------------------------------------------------------------
    Legislation and regulation can help here. The bipartisan Platform 
Accountability and Transparency \22\ and Digital Services Oversight and 
Safety \23\ Acts, for example, would require platforms to provide data 
to independent researchers, and empower the FTC to compel them to do 
so. And, Chairman Comer, your proposal in the Protecting Speech from 
Government Interference Act to restrict how Government employees may 
pressure social media companies to moderate content would be an 
important step forward in establishing clear boundaries between 
Government and the private sector.\24\ Understanding what platforms are 
doing and why--and what the influences on them are--is the cornerstone 
of reestablishing public trust in social media.
---------------------------------------------------------------------------
    \22\ Editorial Board, ``A small step toward solving our social 
media woes,'' The Washington Post, January 17, 2022, https://
www.washingtonpost.com/opinions/2022/01/17/legislative-step-toward-
solving-our-social-media-woes/.
    \23\ Justin Hendrix, ``Reps. Trahan, Schiff, & Casten Introduce 
Digital Services Oversight and Safety Act,'' Tech Policy Press, 
February 23, 2022, https://techpolicy.press/reps-trahan-schiff-casten-
introduce-digital-services-oversight-and-safety-act/.
    \24\ Committee on Oversight and Accountability, ``Comer, McMorris, 
Rodgers, Jordan Introduce Bill to Stop Biden Administration from 
Pressuring Social Media Companies to Censor Americans,'' Press Release, 
January 12, 2023, https://oversight.house.gov/release/comer-mcmorris-
rodgers-jordan-introduce-bill-to-stop-biden-administration-from-
pressuring-social-media-companies-to-censor-americans-2/.
---------------------------------------------------------------------------
    It is often said that humor can be an effective antidote to stress. 
On some of the more challenging days, I've joked that, in trust and 
safety, there are no good options; just a bunch of bad ones, and your 
job is to try to pick what the least bad one is. While I was Head of 
Trust & Safety at Twitter, I strove to do this work with impartiality 
and a commitment to the fair enforcement of Twitter's written rules. 
Each day at Twitter, my team and I worked to build trust with the 
platform's millions of users around the world: By proactively 
addressing the harms that can come from social media; and by doing that 
work in a principled, consistent, and transparent way. But whether it's 
me, or Elon Musk, or another future policy maker, someone will have to 
make choices about the governance of on-line spaces. Those decisions 
shouldn't be made behind closed doors, or based on personal whims. I 
hope that we can work together to find ways to bring greater trust and 
transparency to social media, and I look forward to answering the 
committee's questions about any of these topics to the best of my 
ability.

    Mr. Ivey. I do have a couple of other articles here and 
testimony. One is the testimony of Kate Starbird, director of 
the Center for an Informed Public at the University of 
Washington. The other is Marc Rogers, co-founder of the Cyber 
Threat Intelligence League.
    Chairman Bishop. Without objection, ordered to be submitted 
with the record.
    [The information follows:]
Statement of Dr. Kate Starbird, Associate Professor and Director of the 
        Center for an Informed Public, University of Washington
                           December 13, 2023
    Chairman Bishop, Ranking Member Ivey, and Members of this 
subcommittee, thank you for the opportunity to provide this statement 
describing the threats of mis- and disinformation to election integrity 
specifically and democracy more broadly.
    I currently am an associate professor at the University of 
Washington (UW) where I also direct the Center for an Informed Public 
(CIP). For more than a decade, my research has explored how 
misinformation and disinformation spread on-line during crises and 
breaking news events. My team and I have published more than 50 
academic papers and articles on the topic and have watched as rumors, 
conspiracy theories, and disinformation campaigns have become 
increasingly prominent within social media platforms--leading to a 
range of harms, including diminished trust in information, in our 
fellow citizens, and in democracy more broadly.
    Earlier this year, I provided voluntary testimony to this 
subcommittee and to the House Judiciary Committee in separate 
transcribed interviews which include additional details on my academic 
background and current research. For the sake of brevity, I will 
refrain from rehashing that content here.
    I would like to comment on the threat disinformation poses to 
America's elections and on the chilling effect on disinformation 
researchers from harassment and threats.
   how pervasive mis- and disinformation threaten election integrity
    Within our modern information environment, the spread of 
misinformation (defined as information that is false, but not 
necessarily intentionally false) and disinformation (defined as 
misleading information that is intentionally seeded and/or spread for 
political, financial, or reputational gain) is pervasive.
    Although the problems are difficult to precisely quantify, 
researchers have repeatedly documented how on-line rumors and 
misinformation spread much further and faster than their 
corrections,\1\ how disinformation campaigns have infiltrated on-line 
conversations and on-line communities,\2\ and how false conspiracy 
theories have metastasized within large, international networks of 
connected internet users and inspired acts of terrorism across the 
globe.\3\
---------------------------------------------------------------------------
    \1\ Vosoughi, Soroush, Deb Roy, and Sinan Aral. ``The spread of 
true and false news online.'' Science 359, no. 6380 (2018): 1146-1151.
    \2\ Ong, Jonathan Corpus, and Jason Vincent A. Cabanes. 
``Architects of networked disinformation: Behind the scenes of troll 
accounts and fake news production in the Philippines.'' (2018).
    \3\ Smith, Patrick. ``The Buffalo shooting is part of a global 
network of white nationalist terror.'' NBC News. (May 17, 2022).
---------------------------------------------------------------------------
    Contributors to the spread of falsehoods have included social media 
platforms that are designed to optimize for and monetize attention, and 
that have supercharged the spread of accidental misinformation and have 
been manipulated to spread intentional disinformation. Over time, these 
dynamics have reshaped the networks (the connections between accounts 
through which information spreads) and the algorithms (the computer 
programs that power the recommendations systems that determine who and 
what we see on social media), leading to some parts of our social media 
systems becoming ``wired'' to spread mis- and disinformation. Many 
influencers, i.e., accounts with large followings that play an outsized 
role in shaping on-line discourse, have gained reputation and 
visibility by sharing unsubstantiated claims, especially during high 
uncertainty events like crises and elections. Audiences have become 
primed to believe and are incentivized to share misleading or 
unsubstantiated content--and this is particularly true within 
conversations about election integrity.
    Unfortunately, the pervasive spread of mis- and disinformation has 
negative consequences. In particular, falsehoods about voting processes 
and election results, including both intentional mischaracterizations 
and unintentional misinterpretations, can cause harm to election 
integrity--and to democracy more broadly in several different ways:
    (1) In a democracy, we don't have to agree on the best candidates, 
        but we do have to agree upon the rules that govem how those 
        candidates are elected, just as we must agree to abide by 
        election outcomes. Disinformation about election integrity 
        threatens to undermine the ``common knowledge'' necessary for a 
        healthy democracy''.\4\
---------------------------------------------------------------------------
    \4\ Farrell, Henry, and Bruce Schneier. ``Common-knowledge attacks 
on democracy.'' Berkman Klein Center Research Publication 2018-7 
(2018).
---------------------------------------------------------------------------
    (2) Falsehoods about election processes--e.g., when, where, and how 
        to vote--can interfere with participation and disenfranchise 
        voters. Intentionally misleading people about when and where to 
        vote is illegal, and indeed we have seen prosecutions of 
        ``social media influencers'' for this crime in recent years.\5\ 
        Accidental misinformation, for example due to 
        misinterpretations around varying laws about when mail-in 
        ballots are due, can be just as damaging to the process if the 
        confusion it causes leads to someone missing their opportunity 
        to vote.
---------------------------------------------------------------------------
    \5\ https://www.justice.gov/opa/pr/social-media-influencer-
sentenced-election-interference-2016-presidential-race.
---------------------------------------------------------------------------
    (3) Similarly, false claims about violence at the polls can result 
        in voter suppression. False rumors about violence at polling 
        locations, which resonate with historical strategies of voter 
        suppression, can discourage people from voting in person.
    (4) False and misleading claims that delegitimize the outcomes of 
        elections can undermine trust in election outcomes and in 
        democracy more broadly, and, in extreme cases, can lead to 
        disruptions in the peaceful transfer of power. After the 2020 
        election, wide-spread misinformation about voting and false 
        allegations of a ``rigged election'' were mobilized into the 
        violent events of January 6, 2021--where political operatives 
        and activists attempted to stop the certification of the 
        Presidential election.\6\
---------------------------------------------------------------------------
    \6\ https://www.govinfo.gov/collection/january-6th-committee-final-
report?path=/GPO/- 
January%206th%20Committee%20Final%20Report%20and%20Supporting%20Material
s%20- Collection.
---------------------------------------------------------------------------
    (5) False claims about election integrity have motivated wide-
        spread harassment and threats against election officials,\7\ 
        causing some officials to leave their jobs and discouraging 
        others from taking on these roles. Since 2020, numerous 
        election officials have resigned from their positions, many 
        citing threats related to misinformation about their work.\8\ 
        This dynamic threatens the very foundations of our elections, 
        and our democracy.
---------------------------------------------------------------------------
    \7\ For example, recently election officials in several States 
received envelopes with suspicious letters and white substances, 
including fentanyl: https://www.npr.org/2023/11/09/1212045794/
envelopes-with-fentanyl-or-other-substances-were-sent-to-several-
elections-offic.
    \8\ https://abcnews.go.com/US/us-false-accusations-election-fraud-
prompt-election-workers/story?id=88739763.
---------------------------------------------------------------------------
    (6) Pervasive mis- and disinformation about election integrity can 
        lead to maladaptive changes to election procedures that make 
        election outcomes more uncertain. Scholars have long explained 
        that uncertainty powers the rumor mill, creating conditions 
        where people are more vulnerable to rumoring and manipulation. 
        In response to false claims about election procedures, we have 
        seen election processes changed in ways that add uncertainty to 
        the process, for example by delaying the processing or counting 
        of ballots or removing systems that check for people who are 
        registered to vote in multiple states.\9\ These changes can 
        lead to more misinformation, feeding a kind of ``unvirtuous 
        cycle'' where misinformation reduces election integrity.
---------------------------------------------------------------------------
    \9\ For example, after conspiracy theories targeted the ERIC system 
which helps to maintain voter rolls and check for duplicates across 
States, multiple States have exited the program. https://
www.washingtonpost.com/politics/2023/03/06/election-deniers-voter-
rolls.
---------------------------------------------------------------------------
    (7) Additionally, pervasive mis- and disinformation about voting 
        processes and election results creates a ``boy who cried wolf'' 
        situation where real threats to election integrity could be 
        overlooked, lost within the noise of false claims. Bad actors, 
        including foreign adversaries, may seek to exploit these 
        conditions to advance their aims through actual attacks on 
        election integrity.
    (8) Foreign adversaries are known to use active measures and 
        disinformation to undermine trust in democratic processes and 
        results. The pervasive spread of falsehoods about U.S. 
        elections creates informational conditions that render us 
        increasingly vulnerable to outside manipulation, and foreign 
        actors may attempt to exploit these conditions--both by 
        amplifying domestically-created rumors and by seeding new 
        falsehoods--to advance their aims.
           the chilling effect on disinformation researchers
    Alongside the rise of mis- and disinformation which rattles 
confidence in our elections and electoral processes, we have also 
witnessed a multi-dimensional attack on the researchers and academics 
who seek to understand misinformation and its impacts. Quite 
personally, over the past year my team and I have been subjected to 
persistent negative reporting in partisan media, on-line harassment, 
threats, lawsuits, subpoenas, Congressional probes, and dozens of 
public records requests. These have become a significant tax on our 
time, financial resources, and well-being. Many other researchers are 
experiencing the same.
    This attack on our field is having a marked chilling effect on the 
speech of misinformation researchers. Prominent voices in public debate 
have gone silent, encumbered by legal stress and institutional 
pressure. Some institutions, fearful of the political blowback, are 
stepping back from publicly supporting their researchers and in some 
cases are pressuring their researchers to refrain from public comment, 
even to refrain from defending themselves against false allegations. 
Additionally, some junior scholars are expressing fears about working 
within a field where future institutions may be reluctant to take on 
the risk of hiring them.
    At a time when pervasive disinformation has become a critical 
challenge for democratic societies, the very people who study and 
provide insights into addressing that challenge are being silenced by 
those who purport to stand for ``free speech'' and falsely frame our 
work as ``censorship''. But, just as the First Amendment protects the 
rights of U.S. citizens to openly express their opinions about our 
elections, even if some turn out to be false, it also certainly 
protects the rights of researchers to call out powerful people and 
platforms for spreading misinformation and disinformation.
                                 ______
                                 

[GRAPHIC(S) NOT AVAILABLE IN TIFF FORMAT]
                                 

    Mr. Chenoweth. Mr. Chairman, could I respond to the Yoel 
Roth point? Is that possible?
    Chairman Bishop. Well, let me see, Mr. Chenoweth. I think 
there is a reasonably good likelihood we will enter a second 
round. We want to stick to the time so no Members are 
disadvantaged.
    That is true. I will tell you, let me see, we will see 
whether we get through the other witnesses. We will try to 
remember to come back to the point at some point in time, if we 
can, if a Member's time permits. Sorry about that, Mr. 
Chenoweth.
    With that, I recognize Ms. Greene for 5, is that right, Ms. 
Greene? Ms. Greene for 5 minutes of questioning.
    Ms. Greene. Thank you. Thank you so much. Thank you for 
doing this hearing.
    CISA claims that it has not engaged in censorship, and that 
is a complete and total lie. Mr. Shellenberger, I read an 
article recently that you had written and it was about me and 
the fact that I had been censored. It was through CISA engaging 
with the DNC, the NAACP, homeland security, flagging my tweets, 
writing tickets on them. Also, amazingly, which to my shock, I 
read details of these tickets, making up complete falsehoods 
about me. Talk about misinformation. This is taxpayer-funded 
Government agencies lying about a Member of Congress, about 
what I said, taking other people's statements and writing it in 
context of what I said on my own social media, then taking down 
my actual social media post, which is shocking, absolutely 
shocking.
    So, Mr. Shellenberger, I would like to ask you a little bit 
more. You worked on the Twitter files, and I want to thank you 
for that work and thank you for writing this article, calling 
attention to the fact that me, as a Member of Congress, had my 
own First Amendment violated. That is also a First Amendment 
violation on behalf of my entire district because they elected 
me and sent me here to represent them. So thank you. Thank you 
very much for that. What most surprised you or further alarmed 
you when you learned everything you did through Twitter Files?
    Mr. Shellenberger. Thank you for the question, 
Congresswoman.
    I mean I think I was shocked to see Members of Congress 
being censored. That was shocking to me. We were shocked to see 
how many Government employees were constantly emailing Twitter. 
Carlos Monje, an executive I cited in my Twitter Files on the 
Hunter Biden laptop, complained about all the pressure that 
they were getting from the Federal Government. I think the most 
shocking thing, though, was it was sort-of like what you're 
saying is that the censorship was actually in service of 
disinformation efforts, and that what you're really looking at 
when you're looking at the Cyber Threat Intelligence League is 
an operation. It looks like a military intelligence operation 
that clearly they drew right from fighting terrorists abroad 
and they turned those tools against the American people. So 
censorship was just one of the countermeasures that they had 
set up.
    But with the Hunter Biden laptop, it was a disinformation 
campaign aimed at tying the laptop to the Russians, even though 
there was no evidence for it. So you might have a situation 
where Yoel Roth is like, oh, I've got a good relationship with 
the FBI, but he's the target of an operation that was aimed at 
convincing him that there was something suspicious about the 
Hunter Biden laptop, even though they had the receipt from 
Hunter Biden and they had the FBI subpoena taking the laptop in 
December 2019. So, in fact, their own review of the laptop, 
they came back that it was not the result of a hack. So what 
you see is that, I think, to what Mr. Chenoweth was describing, 
is it's not just coercion. They're actually sort-of--I don't 
know, how do you describe it--they're kind-of working, these 
guys. They're using a lot of--they're being very sweet often. 
It's often very kind and friendly, a lot of trying to be like, 
we're all on the same team here. You have to remember, I think 
it was like, over 96 percent of all Twitter executive donations 
went to Democrats. So it's a very partisan institution to begin 
with. So they're already primed to believe that there may be 
something wrong with that Hunter Biden laptop.
    So what was important is not just that it was censored, but 
really that Twitter participated in the disinformation effort 
to create the perception that there was something illegitimate 
about it and that it was a result of a hacking leak.
    Ms. Greene. Right. So did Facebook.
    Mr. Shellenberger. Yes.
    Ms. Greene. So did Google.
    Mr. Shellenberger. That's right.
    Ms. Greene. Largely the internet.
    Speaking of the partisan difference there, we have who was 
being censored? President Donald J. Trump, Senator Thom Tillis, 
Speaker Newt Gingrich, Governor Mike Huckabee, Congressman 
Thomas Massey, Congresswoman Marjorie Taylor Greene, Newsmax, 
the Babylon Bee, Sean Hannity, Mollie Hemingway, Harmeet 
Dhillon, Charlie Kirk, Candace Owens, Jack Posobeic, Tom 
Fitton, James O'Keefe, Benny Johnson, Michelle Malkin, Sean 
Davis, Dave Rubin, Paul Sperry, Tracy Beanz, Chanel Rion. Then 
add in the most offensive--what I consider to be the most 
offensive, an untold number of everyday Americans of all 
political affiliations. These are people that don't have 
powerful platforms like me as a Member of Congress, these are 
average American citizens that rely on the Government to 
protect their rights, their freedom of speech. It is 
outrageous.
    Mr. Chairman, I certainly would like to completely defund 
CISA. It is an agency that should not exist. It has violated 
the American people's rights. We should completely get rid of 
it, and it shouldn't be entitled to do this anymore.
    Thank you.
    I yield back.
    Chairman Bishop. The gentlewoman yields back.
    I recognize Ms. Clarke for 5 minutes of question.
    Ms. Clarke. Thank you, Mr. Chairman, thank you, Ranking 
Member Ivey, and good afternoon.
    Before I begin, I want to correct some statements made by 
the Chairman about Jen Easterly and CISA. First, Jen Easterly 
never recommended regulating cognitive infrastructure. I ask 
unanimous consent to submit into the record an article from The 
Hill containing her full quote.
    [The information follows:]
      Cyber Agency Beefing Up Disinformation, Misinformation Team
By Maggie Miller--11/10/21 2:52 PM ET, The Hill
    The Cybersecurity and Infrastructure Security Agency (CISA) is 
beefing up its disinformation and misinformation team in the wake of a 
divisive Presidential election that saw a proliferation of misleading 
information online.
    ``I am actually going to grow and strengthen my misinformation and 
disinformation team,'' CISA Director Jen Easterly said during virtual 
remarks at the RE:WIRED conference on Wednesday.
    Easterly noted that earlier this week she had a meeting with ``six 
of the nation's experts'' in the disinformation and misinformation 
space. She stressed her concerns around this being a top threat for 
CISA, which is charged with securing critical infrastructure, to 
confront.
    ``One could argue we're in the business of critical infrastructure, 
and the most critical infrastructure is our cognitive infrastructure, 
so building that resilience to misinformation and disinformation, I 
think, is incredibly important,'' Easterly said.
    ``We are going to work with our partners in the private sector and 
throughout the rest of the government and at the department to continue 
to ensure that the American people have the facts that they need to 
help protect our critical infrastructure,'' she added.
    Despite the political pressure, the rumor control site remains up. 
Easterly pledged in September to continue using the page, and CISA did 
indeed use the rumor control site to counter election disinformation 
and misinformation during the recent 2021 elections in 30 States, 
including the closely watched Virginia Governor's race.
    ``We now live in a world where people talk about alternative facts, 
post-truth, which I think is really, really dangerous if you get to 
pick your own facts, and it's particularly corrosive when you talk 
about matters of election security,'' Easterly said Wednesday.
    ``There is a certain percentage of the American people that are not 
going to be convinced and are not going to listen to the government, we 
get that, but there is a certain part of the American public that do 
still trust the government and that do still come to us and that get 
facts about things that can be difficult to understand,'' she said.
    Microsoft President and Vice Chairman Brad Smith on Wednesday 
separately sounded the alarm about online disinformation and 
misinformation impacting issues including elections and COVID-19 
vaccine rollout.
    Smith specifically warned about the ability of foreign governments 
to use disinformation to meddle in another country's affairs, an issue 
that became particularly concerning following Russian efforts to spread 
disinformation to sway the 2016 U.S. Presidential election in favor of 
Trump.
    ``It has become in some ways almost a tool of choice to disrupt a 
democracy, to sow dissent, to cause people to question even fundamental 
facts like who won the election and is this vaccine safe, or does it 
work,'' Smith said in a speech at the Sciences Po Paris School of 
International Affairs. ``In some ways, it may be far more effective, 
it's certainly less expensive, to launch a government-sponsored 
disinformation campaign than it is to build a hypersonic missile, and 
we have some countries that have the resources easily to do both.''

    Ms. Clarke. On a related manner, aside from cyber incident 
reporting, CISA is not a regulator. It has no authority to 
regulate critical infrastructure outside of cyber incident 
reporting.
    Second, when asked at an appropriations hearing, Jen 
Easterly responded to questions about switchboarding in the 
present tense. It is true that CISA no longer engages in 
switchboarding. Switchboarding occurred during the previous 
administration.
    Finally, the CISA advisory committee's MDM subcommittee 
does not exist any longer and hasn't existed for over a year. 
Every recommendation the subcommittee made while it has existed 
is on the website.
    So, having said that, there has been a lot of discussion 
and fear-mongering about the work of DHS and CISA in particular 
and I appreciate this opportunity to set the record straight.
    Mr. Shellenberger, in your testimony, you advocate for 
abolishing CISA, an agency created by legislation led by former 
committee Chairman Mike McCaul, a Republican, and signed into 
law by former President Donald Trump. At the time, President 
Trump stated that CISA would, and I quote, ``lead Federal 
Government's civilian response to cyber threats against our 
Nation''. We have had many, many threats. The men and women of 
the new Cybersecurity and Infrastructure Security Agency will 
be on the front lines of our cyber defense. They will partner 
with the private sector and all levels of government to defend 
America's power grids, banks, telecommunications, and other 
critical parts of our economy. As the cyber battleship evolves, 
this new agency will ensure that we confront the full range of 
threats from nation-states, cyber criminals, and other 
malicious actors, of which there are many. This is an enormous 
mission.
    Over the past 5 years, CISA has rapidly built capacity to 
help State and local governments and critical infrastructure 
defend against and build resilience to a range of cyber 
threats. CISA spends $45 million of its nearly $3 billion 
budget on election security.
    So, Mr. Shellenberger, do you know what percent of CISA's 
budget, overall budget that is? Let me tell you that that is 
about 1.5 percent of its overall budget--about 1.5 percent. Of 
the $45 million CISA spends on election security, about $2 
million of those funds are used to support efforts to counter 
influence operations.
    Mr. Shellenberger, do you know what percentage of CISA's 
budget that is?
    Mr. Shellenberger. Too much.
    Ms. Clarke. It is not even one-tenth of a percent of CISA's 
overall budget.
    Mr. Shellenberger. Yet, here we are debating it.
    Ms. Clarke. Excuse me. I am reclaiming my time.
    Mr. Chairman, at the outset, it is clear that CISA has not 
engaged in any nefarious or unconstitutional activity. There is 
simply no evidence of it. But suggesting to abolish an agency 
because you disagree with less than 2 percent of what it does 
is just not a serious recommendation.
    So let me thank you, Mr. Chairman, and I yield back the 
balance of my time.
    Chairman Bishop. The gentlewoman yields back.
    I now recognize Mr. Crane for 5 minutes of questioning.
    Mr. Crane. Thank you, Mr. Chairman, for holding this 
hearing today. I want to say thank you to those of you on the 
panel for showing up.
    I want to start with just asking the panel, generally, do 
you trust the Federal Government to censor speech? I will start 
with you, Mr. Shellenberger.
    Mr. Shellenberger. No.
    Mr. Chenoweth. I do not.
    Mr. Abdo. The government should not be censoring speech.
    Mr. Lawkowski. Absolutely not.
    Mr. Crane. Would all of you gentlemen say that generally, 
you are students of history? Generally.
    Mr. Shellenberger. Generally.
    Mr. Crane. OK. What kind of governments typically are most 
likely to censor their people?
    Mr. Shellenberger, I will start with you.
    Mr. Shellenberger. Authoritarian and totalitarian ones.
    Mr. Crane. Yes. What about you, sir?
    Mr. Chenoweth. I agree.
    Mr. Abdo. I agree.
    Mr. Crane. Mr. Lawkowski.
    Mr. Lawkowski. I agree. I would add ones that aren't 
confident in their own abilities to govern.
    Mr. Crane. Yes, absolutely. Now, why do you think these 
types of governments typically want to control and censor the 
speech of their own citizens?
    Mr. Shellenberger. Because they are behaving 
undemocratically in a variety of ways, and they don't want to 
be called out for it.
    Mr. Crane. Absolutely.
    What about you, Mr. Chenoweth.
    Mr. Chenoweth. I think there's many reasons. I think they 
want to hold on to power. Anything that's happening in their 
society that appears to be out of control, that's out of their 
power, is something that is a threat to them being dislodged 
from power. So they want to control the information atmosphere 
in order to hold on to power.
    Mr. Crane. Mr. Abdo.
    Mr. Abdo. Generally to silence dissent.
    Mr. Crane. Mr. Lawkowski.
    Mr. Lawkowski. I would say it's out of a sense of 
arrogance, the sense that they're right and that anyone who 
disagrees with them is wrong, and that that needs to be 
corrected through a proper degree of humility.
    Mr. Crane. Mr. Lawkowski, do you see any of those signs 
that you just pointed out, the arrogance, in this Federal 
Government?
    Mr. Lawkowski. Absolutely. I think it was on vivid display 
during the COVID response and in a number of other areas.
    Mr. Crane. Mr. Shellenberger, how about you? Do you see any 
of those signs in this current Government?
    Mr. Shellenberger. Yes, many signs.
    Mr. Crane. Do you think it is rational to believe that a 
private company, even one as large as Twitter or Facebook, 
might feel intimidated or coerced if the most powerful 
Government in the history of the world contacted them to alert 
them to a post that they found problematic?
    Mr. Shellenberger. Yes, and we saw that intimidation 
repeatedly in the Twitter files.
    Mr. Crane. What about the rest of you guys? You think they 
might feel coerced or intimidated?
    Mr. Chenoweth. Absolutely. We've had four Federal judges 
who have found that, in fact, that happened.
    Mr. Crane. In your opinion, do you think the American 
people have any reason to question the official narratives put 
out by this Government, both this one right now and past 
Governments?
    Mr. Abdo. Yes, many reasons.
    Mr. Crane. Mr. Shellenberger, can you go into a short list 
of official positions that they have released on certain things 
that you found to be problematic and rightly see the American 
people being rational to question those narratives?
    Mr. Shellenberger. I would say the Afghanistan pull-out, 
the Ukraine war, the efficacy of the COVID vaccine, the lack of 
transparency on COVID origins, the cost of the Inflation 
Reduction Act, viability of renewables. Anyway, how long do you 
have?
    Mr. Crane. Yes, I had some of those same ones on my list. 
What about the Hunter Biden laptop? Would that be on your list, 
sir?
    Mr. Shellenberger. Yes, for sure. I mean, it was clearly a 
disinformation campaign that involved existing and former 
Government officials.
    Mr. Crane. Yes. What do you gentlemen typically think when 
you see the billboards pulled up with official statements from 
individuals at CISA? You know, nothing to see here, nothing to 
see here. What do you guys think about that? Just more of the 
same CYA, cover your ass, type deals?
    Mr. Shellenberger, I will start with you.
    Mr. Shellenberger. I'm mixed between it being sinister and 
comedic.
    Mr. Crane. Yes. What about you, Mr. Chenoweth?
    Mr. Chenoweth. I think that there's a misimpression on the 
part of some of these individuals that if they act through 
third parties that they're not violating the First Amendment. 
They're wrong about that, but they're not all lawyers, I get 
that. But they need to understand that they are blatantly 
violating the First Amendment when they work through third 
parties to achieve censorship.
    Mr. Crane. Mr. Abdo, do you have anything to add to that?
    Mr. Abdo. Yes, Congressman, I think the question, the 
Constitutional one that the Supreme Court set out in 1963, is 
whether the Government has coerced the suppression of speech. 
I'll give you just a couple of examples where I think it's 
actually important for the Government to be able to contribute 
to public discourse and also to contribute to persuading 
private actors into making decisions about the speech.
    In 2004, the New York Times was leaked information about 
the Bush administration's warrantless wiretapping program, and 
members of the Bush administration met with the New York Times 
and convinced the New York Times that to disclose that 
information in 2004 would result in deaths in the disclosure of 
undercover sources. The New York Times held on to that story 
for a year. I happen to think the New York Times probably made 
the wrong decision in being persuaded by the Bush 
administration to hold on to that story for a year. But I think 
it's relevant to the New York Times' decision making what the 
Government thinks about the likelihood that disclosing that 
information would cause real harm to the national security 
interests of the United States, even though the New York Times' 
publication of that story was unquestionably Constitutionally-
protected.
    So I think there is a role for Government in persuading 
private actors to take into account the harms of the 
independent editorial decisions they make.
    Mr. Crane. Thank you, Mr.----
    Mr. Chenoweth. But that was the New York Times' own speech 
that it was holding back on, not a third party's speech.
    Mr. Abdo. I think that the Bantam Books case is the case 
about third-party speech. It was a lawsuit brought against--I 
think inconsistently what you said earlier, Mr. Chenoweth--it 
was a lawsuit brought against the Rhode Island Commission on 
Morality and Youth, arguing that that commission had exceeded 
its authority in attempting to coerce book distributors and 
publishers into taking off their shelves material that the 
commission had deemed to be obscene or offensive.
    Mr. Crane. Thank you. Thank you.
    I yield.
    Chairman Bishop. Thank you, Mr. Crane.
    I thank the witnesses. I would actually love to hear from 
all of you more. Our time is unfortunately limited. We have 
another panel.
    The Members of the subcommittee may have additional 
questions for this panel of witnesses. We would ask the 
witnesses to respond to those in writing. Pursuant to committee 
rule VII(D), the hearing record will remain open for 10 days 
for that.
    These witnesses are dismissed and the committee will be in 
recess for 15 minutes to commence with the second panel.
    [Recess.]
    Chairman Bishop. The Committee on Homeland Security 
Subcommittee on Oversight, Investigations, and accountability 
will come to order.
    I am pleased to have as our second panel a panel of 
witnesses from the Department of Homeland Security before us 
today to speak on this very important topic.
    I ask that our witnesses please rise and raise your right 
hands.
    [Witnesses sworn.]
    Chairman Bishop. Thank you. You may be seated.
    Let the record reflect that the witnesses have answered in 
the affirmative.
    I would now like to formally introduce our additional 
witnesses. I hope I am going to get your name right, sir. Mr. 
Iranga Kahangama is the assistant secretary for cyber, 
infrastructure, risk, and resilience at the Department of 
Homeland Security. Ms. Mona Harrington is the assistant 
director for the National Risk Management Center at the 
Cybersecurity and Infrastructure Security Agency.
    I thank these witnesses for being here today.
    The Chair will now recognize each witness for oral 
statements. Each oral statement will be limited to 5 minutes, 
but submitted written statements by witnesses will appear in 
the hearing record in their entirety.
    I now recognize Mr. Kahangama for 5 minutes for his opening 
statement.

  STATEMENT OF IRANGA KAHANGAMA, ASSISTANT SECRETARY, CYBER, 
   INFRASTRUCTURE, RISK, AND RESILIENCE, OFFICE OF STRATEGY, 
    POLICY, AND PLANS, U.S. DEPARTMENT OF HOMELAND SECURITY

    Mr. Kahangama. Thank you.
    Chairman Bishop, Ranking Member Ivey, and distinguished 
Members of the subcommittee, thank you for inviting me here 
today to discuss the Department of Homeland Security's efforts 
to counter the impacts of foreign influence operations and 
disinformation impacting our homeland security.
    I serve as the Department's assistant secretary for cyber, 
infrastructure, risk, and resilience. In this role, I lead the 
Department's efforts on cybersecurity and critical 
infrastructure policy. Nation-state adversaries, such as 
Russia, China, and Iran, are likely to continue to conduct 
overt and covert influence operations to shape U.S. policy and 
undermine trust in U.S. Government institutions, social 
cohesion, and democratic processes. With the upcoming election 
cycle of 2024, our adversaries are likely seeking more 
opportunity than ever before.
    The U.S. intelligence community's Annual Threat Assessment 
for 2023 notes that the People's Republic of China seeks to 
expand its malign influence campaigns to better support its 
political, economic, and security goals. Beijing utilizes a 
broad array of highly sophisticated covert, overt, licit, and 
illicit means to conduct these operations. Their U.S.-based 
influence operations are focused on shaping U.S. policy and the 
American public's perception of the DRC. Russia presents one of 
the most serious foreign influence threats to the United States 
because it utilizes its intelligence services, proxies, and 
wide-ranging influence tools to try to sow discord inside the 
United States and divide Western allies. Moscow views U.S. 
elections as opportunities for malign influence as part of its 
broader foreign policy strategy.
    While these risks are not new, our interconnected world, 
the anonymous nature of the internet, and emerging technologies 
change the nature of that threat. For example, these same 
adversaries are likely to use generative artificial 
intelligence tools and strategies to improve the quality, 
scope, and scale of their influence operations. The wide-spread 
proliferation and accessibility of these AI tools will boost 
foreign malign influence campaigns by enabling threat actors to 
create synthetic text, audio, and images at a lower cost and 
with higher quality.
    DHS is charged with safeguarding the United States against 
threats to its security. In recent years, many of those threats 
have been exacerbated by disinformation. As part of its 
mission, DHS has worked across multiple administrations to 
address and mitigate different forms of disinformation that 
threaten authorized missions of the Department. Examples of 
such efforts include working to combat human smuggling, 
protecting critical infrastructure, and responding to foreign 
malign influence. In the context of these threats, the 
Department takes seriously our responsibility to safeguard the 
United States, its people, and its values. Providing the public 
with accurate information in response to foreign malign 
influence campaigns is critical to fulfilling DHS's 
Congressionally-mandated mission.
    The Department is committed to carrying out its mission in 
a way that ensures that privacy, civil rights, and civil 
liberties are protected for all Americans. This includes the 
freedom of speech. These rights are fundamental to our freedom 
and to who we are as a Nation. Like everything we do, the work 
of DHS to address foreign influence operations must be 
consistent with the Constitution and in compliance with U.S. 
laws, regulations, and policies. The Department works every day 
to ensure that all of our activities are carried out in a 
manner that protects these values. DHS is committed to 
continuing to build resilience to foreign influence operations 
and disinformation in close coordination with our interagency 
partners. In these efforts, DHS will continue operating within 
our authority in accordance with all legal requirements with 
respect for the Constitutional rights and civil liberties of 
all Americans.
    I thank you again for the opportunity to testify here 
today, and I look forward to taking your questions.
    Thank you.
    [The joint prepared statement of Mr. Kahangama and Ms. 
Harrington follows:]
    Joint Prepared Statement of Iranga Kahangama and Mona Harrington
                           December 13, 2023
                              introduction
    Chairman Bishop, Ranking Member Ivey, and Members of the 
subcommittee, we appreciate the opportunity to appear before you today 
to discuss the Department of Homeland Security's (DHS or the 
Department) efforts to counter the impacts of foreign influence 
operations and disinformation impacting homeland security.
    First and foremost, at the core of the Department's mission is a 
commitment to safeguard the American people, our homeland, and our 
values. We are committed to carrying out this mission in a manner that 
protects the privacy, civil rights, and civil liberties, including the 
freedom of speech, of all Americans. These rights are fundamental to 
our freedom and to who we are as a Nation. The Department works every 
day to ensure that all our activities are carried out in a manner that 
protects these values.
    In its Homeland Threat Assessment for 2024, the Department's 
Intelligence Enterprise assesses Russia, China, and Iran likely see the 
upcoming election season in 2024 as an opportunity to conduct overt and 
covert influence campaigns aimed at shaping favorable U.S. policy 
outcomes and undermining U.S. stability, and they will likely ramp up 
these efforts in advance of the election. These adversarial states are 
likely to use generative artificial intelligence (AI)-enabled 
technologies to improve the quality, scope, and scale of their 
influence operations targeting U.S. audiences.
    Further, nation-state adversaries likely will continue to conduct 
influence operations aimed at undermining trust in Government 
institutions, our social cohesion, and democratic processes. The 
proliferation and accessibility of emergent cyber and AI tools probably 
will help these actors bolster their malign information campaigns by 
enabling the creation of low-cost, synthetic text-, image-, and audio-
based content with higher quality. Russia, China, and Iran continue to 
develop the most sophisticated malign influence campaigns on-line. Many 
of the tactics these adversaries use to influence U.S. audiences will 
likely be used in the lead-up to the 2024 election.
    This risk is not new. In its 2023 Annual Threat Assessment, the 
U.S. intelligence community noted that China largely concentrates its 
U.S.-focused influence efforts on shaping U.S. policy and the U.S. 
public's perception of the People's Republic of China (PRC) in a 
positive direction but has shown a willingness to meddle in select 
election races that involved perceived anti-PRC politicians. For 
example, Beijing's growing efforts to actively exploit perceived U.S. 
societal divisions using its on-line personas move it closer to 
Moscow's playbook for influence operations.
    Russia presents one of the most serious foreign influence threats 
to the United States because it uses its intelligence services, 
proxies, and wide-ranging influence tools to try to sow discord inside 
the United States. Moscow views U.S. elections as opportunities for 
malign influence as part of its larger foreign policy strategy. Moscow 
has conducted influence operations against U.S. elections for decades, 
including as recently as the U.S. midterm elections in 2022. Russia's 
influence actors have adapted their efforts to increasingly hide their 
hand, laundering their preferred messaging through a vast ecosystem of 
Russian proxy websites, individuals, and organizations that appear to 
be independent sources.
                    election infrastructure mission
    In 2017, the Secretary of Homeland Security established election 
infrastructure as a critical infrastructure subsector. To manage risks 
to the Nation's election infrastructure on behalf of the Department, 
the Cybersecurity and Infrastructure Security Agency (CISA) works 
collaboratively with State and local governments, election officials, 
Federal partners, and private-sector partners. The collaboration 
includes working in a nonpartisan, voluntary manner with State and 
local election officials, who are the trusted and expert voices within 
their communities, to hold secure elections in their jurisdictions and 
to equip the American public with accurate information about the 
conduct and security of elections.
    CISA provides publicly-available resources on election security for 
both the public and election officials in its efforts to protect 
America's election infrastructure against new and evolving threats. For 
example, CISA recently publicly released the No Downtime in Elections 
Guide to Mitigating Risks of Denial of Service. Moreover, CISA has 
partnered with the Federal Bureau of Investigation to publish election 
security-related Public Service Advisories; and CISA has compiled a 
toolkit of free services and tools intended to help State and local 
government officials, election officials, and vendors enhance the 
cybersecurity and cyber resilience of U.S. election infrastructure.
    CISA also provides numerous voluntary and no-cost election security 
services, such as cybersecurity assessments, cyber threat hunting, 
cyber incident response, training, and exercises to State and local 
government officials and private-sector election infrastructure 
partners. In addition, CISA reduces risk to U.S. critical 
infrastructure by building resilience to foreign influence operations 
and disinformation intended to impact critical infrastructure.
    Through these efforts, DHS helps the American people understand the 
scope and scale of activities targeting election infrastructure and 
enables them to take action to mitigate associated risks. The 
Department's efforts include an emphasis on transparency with respect 
to sharing accurate information about election infrastructure security, 
as well as increasing awareness about the threat posed by foreign 
influence operations and disinformation.
            foreign influence operations and disinformation
    DHS is charged with safeguarding the United States against threats 
to its security. In recent years, many of those threats have been 
exacerbated by disinformation. As part of its mission, DHS has worked 
across multiple administrations to address and mitigate different forms 
of disinformation that threaten the authorized missions of the 
Department. Countering disinformation that threatens the homeland and 
providing the public with accurate information in response are critical 
to fulfilling DHS's Congressionally-mandated missions. DHS efforts are 
limited to combating disinformation that threatens the homeland and 
homeland security missions, such as border security, emergency 
response, and infrastructure security. Examples of such efforts include 
working to combat human smuggling, protecting critical infrastructure, 
and responding to malign foreign influence efforts.
    CISA's work on foreign influence operations and disinformation 
targeting election infrastructure is of limited scope and focuses 
predominantly on its impact to public confidence in election 
infrastructure security. Out of CISA's $2.9 billion budget, less than 
0.07 percent is spent on these efforts. CISA's work has been 
transparent, briefed to Congress many times, and is available to the 
public on its website at cisa.gov.
    In support of these efforts, CISA has developed voluntary resources 
to help individuals identify and mitigate the threats of foreign 
influence and disinformation operations. Recently, CISA has released 
guides that highlight tactics, such as manipulating content service 
providers or defacing public websites, used by foreign actors engaged 
in disinformation campaigns that seek to negatively impact U.S. 
critical infrastructure and disrupt American life. Such public products 
help Americans understand how automated programs like social media bots 
simulate human behavior on social media platforms and how foreign 
malign actors use them to spread false or misleading information, shut 
down opposition, and elevate their own platforms for further 
manipulation.
    Additionally, CISA provides context to common disinformation 
narratives and themes that relate to the security of election 
infrastructure through our Election Security Rumor vs. Reality website. 
Last, CISA seeks to combat foreign disinformation by amplifying 
accurate election security-related information shared by State and 
local officials with the public.
                               conclusion
    DHS is committed to continuing to build resilience to foreign 
influence operations and disinformation, in close coordination with our 
interagency partners. In these efforts, DHS will continue operating 
within our authority and in accordance with all legal requirements, and 
with respect for the Constitutional rights and civil liberties of all 
Americans.
    Thank you again for the opportunity to appear before you today, and 
we look forward to continuing to work closely with you to keep our 
homeland safe and secure.

    Chairman Bishop. Thank you, Mr. Kahangama.
    I now recognize Ms. Harrington for 5 minutes for her 
opening statement.

STATEMENT OF MONA HARRINGTON, ASSISTANT DIRECTOR, NATIONAL RISK 
 MANAGEMENT CENTER, CYBERSECURITY AND INFRASTRUCTURE SECURITY 
          AGENCY, U.S. DEPARTMENT OF HOMELAND SECURITY

    Ms. Harrington. Thank you.
    Chairman Bishop, Ranking Member Ivey, and Members of the 
subcommittee, thank you for the opportunity to testify on the 
National Risk Management Center's efforts to build resilience 
to the impacts of foreign influence, operations, and 
disinformation targeting election infrastructure.
    First and foremost, at the core of the Department's mission 
is a commitment to safeguard the American people, our homeland, 
and our values. We carry out this mission in a manner that 
protects privacy, civil rights, civil liberties, including the 
freedom of speech of all Americans. These rights are 
fundamental to our freedom and to who we are as a Nation.
    I began serving as the assistant director of the National 
Risk Management Center, the NRMC, in October 2022. I have over 
20 years of Federal Government experience working in different 
leadership roles. My expertise spans cybersecurity, strategy, 
risk management, critical infrastructure, human capital 
operations, and the implementation of best practices in 
critical infrastructure environments. I have led efforts to 
further the NRMC's critical analytics support to CISA's mission 
to understand, manage, and reduce risk to the cyber and 
physical infrastructure Americans rely on every day. Our work 
enables CISA and other Federal, State, local, Tribal, 
territorial, and critical infrastructure partners to apply 
actionable analysis in support of risk management decisions. 
Over the last year, we have produced 1,600 tailored products 
and engaged over 6,300 stakeholders to improve security of U.S. 
critical infrastructure.
    The election security and resilience team is one of many 
efforts within the NRMC. The election security and resilience 
team works collaboratively with election officials, Federal, 
and private-sector partners. The collaboration includes working 
in a non-partisan manner on a voluntary basis with State and 
local election officials to improve the security of election 
infrastructure necessary for the elections they are responsible 
for administering. CISA provides voluntary support to these 
officials with intelligence and information sharing, guidance, 
and best practices, and no-cost security services such as cyber 
incident response, cybersecurity assessments, and exercises.
    CISA's work on foreign influence, operations, and 
disinformation is a very small part of the election security 
and resilience team and it's narrowly scoped. CISA's work in 
this space includes developing publicly-available resources to 
inform and assist stakeholders and the public. For example, we 
released a guide that highlights tactics used by foreign 
actors, such as manipulating content service providers or 
defacing public websites. These products are intended to build 
awareness of how foreign malign actors spread false or 
misleading information. CISA's work has been transparent, 
briefed to Congress many times, including this committee, and 
is available to the public on its website at CISA.gov.
    Thank you again for this opportunity and I look forward to 
your questions.
    Chairman Bishop. Thank you, Ms. Harrington.
    Members will now be recognized, by order of seniority for 5 
minutes of questioning. An additional round of questioning may 
be called after all Members have been recognized.
    I recognize myself for 5 minutes of questioning.
    Ms. Harrington, there was a CISA video on YouTube that had 
the fictional character--I think her name was Susan or Sharon--
and she said that the idea was that she had interacted with her 
uncle on social media, he was posting things that were 
disinformation or mal information or something like that. It 
concluded with a recommendation that she report the 
disinformation from her uncle. CISA took that down. Why did 
CISA take that video down?
    Ms. Harrington. Representative, respectfully, I'm not aware 
of that. That must predate my time. I'm not at all familiar 
with that.
    Chairman Bishop. How about Mr. Kahangama? Do you know what 
I am talking about?
    Mr. Kahangama. Thank you, Mr. Chair. I'm not familiar with 
that video.
    Chairman Bishop. All right. Let me ask you generally, Mr. 
Kahangama, and then I will go back to Ms. Harrington, how have 
DHS and CISA's efforts or activity concerning dealing with 
disinformation, misinformation, malinformation changed as in 
consequence of the Missouri v. Biden preliminary injunction 
that has been upheld by the Fifth Circuit or otherwise since 
the last election?
    Ms. Harrington. Thank you, Chair, for the question.
    While I understand and am aware of the Missouri v. Biden 
case, I understand that that is still on-going pending 
litigation in front of the Supreme Court and so I'm unable to 
speak to the specifics of that case.
    But what I will say is that the Department and its work in 
combating disinformation in defense of its specific mission 
area is done with robust oversight in coordination with civil 
rights and civil liberties, our statutorily-mandated offices, 
as well as in close coordination with our Office of General 
Counsel.
    Chairman Bishop. Well, see, that is what concerns me is 
that has been said to us for a number of years. In fact, it has 
always been said by CISA, by DHS, the recital that we are 
concerned about rights under the First Amendment and we always 
are carefully taking action to avoid infringing those or 
abridging free speech. Yet a District Court has found, and an 
Appellate Court has affirmed that--and, of course, it is still 
pending for final determination, so I am not asking you about 
the facts or the determinations in that case, what I am asking 
you is--let me put it this way, because I asked you how things 
have changed, whether things have changed. Since that decision 
has been made has DHS changed the way it deals with 
disinformation?
    Mr. Kahangama. Again, thank you for the question, Chair.
    I am not in a position to answer anything as it relates 
specific to the implications of that case.
    Chairman Bishop. All right, let me ask this then. Since the 
last election--disregard the case if you want to--how is DHS 
dealing with disinformation differently than it did then?
    Mr. Kahangama. Thank you, Chair, for the question.
    DHS's approach to election security has been around 
election infrastructure, making sure that they are preventing 
the infrastructure from being impacted by cybersecurity issues 
and working to advance the mission of State and local partners 
that we trust as the authoritative voices on elections in this 
election space.
    Chairman Bishop. But I didn't ask you about how you are 
protecting elections infrastructure from hacking and so forth. 
What I am asking you about are your efforts vis-a-vis 
disinformation.
    Let me just ask you, you still have an MDM team, don't you?
    Mr. Kahangama. I do not have one at the Department of 
Homeland Security.
    Chairman Bishop. All right, Ms. Harrington, is there still 
an MDM team at CISA?
    Ms. Harrington. Representative, yes, we still have an MDM 
team.
    Chairman Bishop. How is the MDM team and the other efforts 
relating to the MDM team concerning disinformation, how have 
you changed those at CISA?
    Ms. Harrington. Representative the work that we do around 
MDM are threefold. One, we are putting out literacy packets----
    Chairman Bishop. No, no, no, don't give me a discourse 
about three with three parts. What I am asking is what has 
changed? What has changed, if anything? If you are proceeding 
and dealing with disinformation in exactly the way you did 
then, which you have contended respects all First Amendment 
rights, notwithstanding evidence to the contrary, say that. But 
otherwise, I want you to tell me how it has changed. How have 
you changed your practices in this area?
    Ms. Harrington. Representative, respectfully, I'm not aware 
of direct changes to the on-going litigation.
    Chairman Bishop. No, I am not trying to qualify in terms--
in fact, we covered that with Mr. Kahangama. What I am asking 
is, leave aside the litigation, since the election in 2020, how 
have you changed, how has CISA changed the way you are dealing 
with disinformation?
    Ms. Harrington. Representative, I can tell you the three 
ways that we deal with disinformation and counter foreign 
influence, which are----
    Chairman Bishop. So you can't tell me how you have changed 
them?
    Ms. Harrington. First of all, going back to 2020, that 
predates my tenure at the agency, but I'm happy to tell you 
what we are doing.
    Chairman Bishop. Are you aware, by virtue of policies you 
have been exposed to, managerial discussions at CISA, whether 
there have been changes to the way CISA addresses 
disinformation?
    Ms. Harrington. Representative I'm not aware of what you're 
referencing as far as changes.
    Chairman Bishop. OK, you are not aware of any? That is 
concerning to me.
    By what justification does a Government agency tasked with 
curtailing and preventing computer hacking stray into governing 
or babysitting Americans' free speech on social media?
    Ms. Harrington. Representative, respectfully, we don't 
censor.
    Chairman Bishop. OK. What is the source of authority for 
DHS--Ms. Clarke said in her questioning on our first panel, and 
I think she is exactly right, that CISA and--Excuse me, I see 
my time has expired and I have let it go over.
    Let me just stop there and yield back.
    I recognize the Ranking Member, Mr. Ivey, for his 5 
minutes.
    Mr. Ivey. If I might, I would let Mr. Thanedar go.
    Chairman Bishop. Dr. Thanedar is recognized.
    Mr. Thanedar. Chairman Bishop, thank you for holding this 
hearing. Ranking Member Ivey, thank you for your incredible 
kindness to let me speak here out of order. Maybe a little 
earlier than I am supposed to, but thank you so much.
    Well, CISA has been incredibly transparent about its 
interactions with social media companies on the topic of 
election-related mis- and disinformation. In numerous hearings 
before this committee and others, witnesses from CISA 
repeatedly told Congress that they were in regular 
communication with social media companies and even told us that 
these companies were taking a very aggressive posture toward 
election-related misinformation.
    Chairman Bishop, I would like to enter into the record the 
transcripts of a hearing this committee held in 2019 regarding 
how CISA was preparing for the 2020 election.
    Chairman Bishop. Without objection, so ordered.*
---------------------------------------------------------------------------
    * The document has been retained in committee files and is 
available at https://www.govinfo.gov/content/pkg/CHRG-116hhrg40456/pdf/
CHRG-116hhrg40456.pdf.
---------------------------------------------------------------------------
    Mr. Thanedar. In fact, I think it is incredible--in fact, I 
think it is interesting that it was not until Donald Trump lost 
the 2020 election that my Republican colleagues began to take 
issues with CISA's disinformation activities.
    Ms. Harrington, can you speak to CISA's transparency 
efforts in this area and describe what the agency has done to 
explain to Congress, the media, and the public its election-
related disinformation work?
    Ms. Harrington. Representative, thank you for the question.
    CISA has all of its materials on its website. We are 
incredibly transparent. We have all of our publications 
regarding disinformation, encountering foreign influence 
published publicly. All of that information can be found there. 
We regularly work with State and local partners. All of our 
partnerships and communication around the work that we do can 
be found publicly, and it's on our website.
    Mr. Thanedar. All right.
    Well, thank you so much. Thank you. Appreciate both of you 
being here and for your testimony.
    Chairman Bishop, I yield back.
    Chairman Bishop. Thank you, Mr. Thanedar.
    I recognize Mr. Ezell for his 5 minutes of questioning.
    Mr. Ezell. Thank you, Mr. Chairman, and thank you for being 
here today.
    Recently, documents were obtained under the Freedom of 
Information Act by Americans for Prosperity regarding DHS 
Disinformation Governance Board, which was stood up by the 
Biden administration and was almost immediately shut down due 
to massive public pushback. Behind me today are two of these 
documents. Well, besides the title, there isn't much that we 
can learn from these documents.
    Mr. Kahangama, help me fill in some of the words on this 
blank page. What authorities does DHS believe it has to counter 
misinformation, disinformation, and malinformation?
    Mr. Kahangama. Thank you, representative, for the question.
    DHS believes its authorities to authorize its specific 
mission use cases provides us the authority to provide correct 
accurate information in response to false information that may 
directly impact the operations of the Department.
    Mr. Ezell. Also behind me as well is a completely redacted 
memo titled ``Ukraine MDM Playbook''. Do you think DHS has the 
authority to control public conversations on foreign wars? If 
so, where do you believe this is under their mission?
    Mr. Kahangama. Thank you for the question. Congressman.
    Could you please repeat the question?
    Mr. Ezell. Do you think DHS has the authority to control 
public conversations on foreign wars?
    Mr. Kahangama. No, DHS does not have that authority. We do 
not monitor the content of American speech.
    Mr. Ezell. Is suppressing domestic speech included in the 
memos strategy?
    Mr. Kahangama. I'm sorry?
    Mr. Ezell. Is suppressing domestic speech included in the 
memo's strategy?
    Mr. Kahangama. I'm not familiar with the memo that you're 
referencing.
    Mr. Ezell. The Homeland Security Advisory Committee 
recommended to DHS that it should, ``bring disinformation to 
the attention of platforms hosting these falsehoods''. I ask 
that DHS shares to the committee their communications with 
these platforms on this topic. Is that something you can 
provide?
    Mr. Kahangama. Respectfully, Congressman, I would have to 
defer to our Office of Legislative Affairs, who I believe is 
already in contact with the committee staff about document 
production and anything else that can be shared. But we'd be 
happy to.
    Mr. Ezell. Thank you very much.
    Ms. Harrington, does CISA have any plans to combat MDM 
during the 2024 election?
    Ms. Harrington. Representative, respectfully, CISA will 
continue doing the work that it's currently doing, which is 
essentially amplifying election official voices. We have a 
rumor control page up on CISA.gov, and we also are putting out 
literacy publications so the American people can spot 
disinformation tactics and learn about the tactics that foreign 
adversaries are using to essentially spread disinformation.
    Mr. Ezell. Thank you.
    Recently, the director of CISA testified before Congress 
that ``The most critical infrastructure is our cognitive 
infrastructure. Building that resilience to misinformation and 
disinformation, I think is incredibly important''. I want to 
repeat that again. The director of CISA testified before 
Congress, and I quote, ``The most critical infrastructure is 
our cognitive infrastructure. Building that resilience to 
misinformation and disinformation, I think is incredibly 
important''. I look at CISA's website, and cognitive 
infrastructure is not listed as a sector CISA is tasked with 
protecting. What does cognitive infrastructure mean?
    Ms. Harrington. Representative, in executing our mission we 
are guided by the definition of critical infrastructure in 
Presidential Policy Directive 21. That is, the U.S. Government 
determines critical infrastructure by that PPD 21. There are 16 
critical infrastructure sectors that are considered vital to 
the United States, includes their asset systems and networks, 
whether physical or virtual, that are so important that their 
incapacitation or destruction would have a debilitating effect 
on security, National economic security, National public health 
or safety, or any combination thereof.
    Mr. Ezell. Again, what does cognitive infrastructure mean? 
I don't get it.
    Ms. Harrington. Representative, respectfully, that is how 
we execute our mission, with the definition of critical 
infrastructure defined in PPD 21.
    Mr. Ezell. Do you think that DHS has this authority?
    Ms. Harrington. Our authorities are outlined in PPD 21.
    Mr. Ezell. Have you discussed the cognitive infrastructure 
with Director Easterly?
    Ms. Harrington. Representative, again, critical 
infrastructure is defined in PPD 21. It's got the 16 sectors of 
which are the sectors which make up critical infrastructure of 
the United States.
    Mr. Ezell. I am concerned that we continue to find examples 
that seem clear that the Biden administration is weaponizing 
the Federal Government against its citizens. These agencies are 
out of control, and this committee will not stop until we hold 
folks accountable for that.
    Mr. Chairman, I yield back.
    Chairman Bishop. The gentlemen yields back.
    I recognize the Ranking Member, Mr. Ivey, for 5 minutes.
    Mr. Ivey. Thank you, Mr. Chairman.
    I just want a couple of follow-up points from our previous 
panel. I did want to say we had a number of questions 
addressing--or actually statements suggesting that the social 
media platforms were coerced by the Government and that they 
didn't have the ability to resist Government requests or 
flagging of information. I did want to reiterate the point that 
I made in my opening statement about how these social media 
platforms have dealt with this. So a post flag by the EIP, 
Election Integrity Partnership, platforms took action on 35 
percent, 21 percent of those were labeled, 13 percent were 
removed, and 1 were left soft-blocked, which I believe means 
that they don't permit the algorithm to allow it to go viral. 
No action was taken on 65 percent of these interactions. So we 
might disagree about whether they should be doing this or not, 
but I don't think Elon Musk has had any trouble resisting or 
disagreeing with the Biden administration. My recollection from 
when I worked with Microsoft was that they didn't have trouble 
disagreeing with the Government at the time either. So.
    With respect to the issue about rumor control and 
disinformation tactics, Ms. Harrington, I wanted to ask you to 
elaborate a little bit on that. What does that mean? What kinds 
of activities are you taking or is your entity taking with 
respect to those kinds of situations?
    Ms. Harrington. Representative, so we have a rumor control 
page set up which helps to amplify election official voices. So 
the State and locals that are running the elections, we have a 
number of rumor narratives and the reality providing factual 
information. Again, that could be found transparently on our 
website. We work closely with State and local election 
officials, and we have that all cross-linked to, for example, 
the National Association of Secretaries of States, also the 
National Association of State Election Director websites, and 
there are a number of other sources, so that Americans can read 
that information and make their own decisions about the facts 
surrounding how election administration works.
    So that is one mechanism that we have where we amplify 
election official voices and put out actual information to 
educate and ensure that we are putting out literacy information 
to the American people to make good decisions.
    Mr. Ivey. All right. So in Maryland, I believe we had a 
misinformation scenario that spread about the last day to 
request a mail-in ballot and about the process of voting in 
person. Are those the types of scenarios that you are 
referencing, or would that be addressed by a different 
mechanism?
    Ms. Harrington. Representative, we don't go into specific 
detail around the rules for each specific jurisdiction, if you 
will, but we have more broad narratives that are corrected on 
there. As you know, elections are decentralized, and each State 
has their own specific rules and requirements that govern how 
they run their elections. So we don't get into that level of 
granularity, but more broad narratives.
    Mr. Ivey. Well, give me an example of a scenario where you 
would have gotten involved.
    Ms. Harrington. So, for example, we have an entry on Rumor 
vs. Reality that says voting system hardware and software 
undergo testing from Federal, State, and/or election 
authorities. The rumor on that is that voting system software 
is not at all reviewed or tested, period. So that would be an 
example of an entry, broad entry.
    Mr. Ivey. All right. Then what would you do to address 
that? Or if that is actual, how did you respond?
    Ms. Harrington. That's an actual listing on the Rumor vs. 
Reality web page. So I'm just demonstrating the broad 
narratives that we try to correct.
    We have other entries on there, such as voters are 
protected by State and Federal law from threats or 
intimidations at polls, including from election observers. So 
that's another reality that we have on there. The rumor 
associated with that reality is observers in polling places are 
permitted to intimidate voters, campaign, and or interfere with 
voting. So you could see they're broad narratives that we just 
put out to educate, but we don't get into the granularity of 
specific jurisdictions, per your question.
    Mr. Ivey. All right.
    Well, I see my time has expired, so I yield back.
    Chairman Bishop. The gentleman yields back.
    The Chair now recognizes Mr. Strong for 5 minutes of 
questioning.
    Mr. Strong. Thank you, Chairman Bishop.
    Ms. Harrington, at an event for the Center for Strategic 
and International Studies on November 1, 2022, CISA Director 
Jen Easterly said, and I quote, ``We make sure people 
understand the tactics around disinformation and that Americans 
understand, you know, how to build resilience against it, how 
to recognize it, how to investigate it, asking about the 
source, questioning it, not amplifying it''. Who does CISA 
suggest as a credible source during these education efforts, 
and how does CISA make that determination?
    Ms. Harrington. Representative, could you please repeat the 
question?
    Mr. Strong. How does CISA suggest a credible source during 
these educational efforts, and how does CISA make the 
determination of that credible source?
    Ms. Harrington. Respectfully, I apologize. I still am not 
clear on what your question is.
    Mr. Strong. OK. I will move further. Does CISA partner with 
any outside experts or entities in developing its educational 
MDM content? Do you use outside sources to do this effort?
    Ms. Harrington. Representative, I just want to make sure 
we're talking about the same thing. We put out literacy 
publications to educate around disinformation, encountering 
foreign influence tactics. They're educational materials. They 
can be found on our website.
    Mr. Strong. Thank you. I appreciate that. My question is, 
do you use outside sources or do you do it all within your 
team?
    Ms. Harrington. Representative, let me get back to your 
staff on that.
    Mr. Strong. I will reclaim my time. That is not a hard 
question.
    Ms. Harrington. I'm not certain if----
    Mr. Strong. I will make it easy. I will move on.
    Ms. Harrington [continuing]. There's a contractor that 
assists with publication.
    Mr. Strong. I will move on. Ms. Harrington, what types of 
MDM efforts does CISA currently have under way? What type of 
efforts?
    Ms. Harrington. Representative, the three efforts that we 
have and that we continue to work on, as I previously stated, 
are the rumor control page, and I gave some examples just a 
moment ago, literacy publications. We've got things like 
tactics of disinformation, disinformation stops with you, other 
infographics, social media bots, infographic set, optical 
illusions, other publications that you can find on our website. 
We amplify election official voices as the State and locals who 
know best how their processes and systems work.
    Those are the three efforts that CISA has within the 
disinformation, countering foreign influence.
    Mr. Strong. Thank you.
    Does CISA work with other DHS components on combating MDM? 
If they do, which ones do they work with?
    Ms. Harrington. Representative, respectfully, I'm not aware 
of any coordination across other components.
    Mr. Strong. Thank you.
    Sir, the next question. On November the 15th of this year 
you spoke at an Aspen Institute summit where you said that DHS 
has many different operational applications of AI that we are 
actively using, whether that is generative AI or more 
traditional machine learning. What operation using AI has DHS 
already undertaken? What are they already doing?
    Mr. Kahangama. Thank you, representative. Thank you for the 
question.
    Obviously, generative AI has been very much popular in the 
news and so this has been a really interesting space for us to 
do a lot of work for the Department operationally across many 
of the components. Our OCIO recently put out some guidance 
about how employees can propose projects and to use AI as a 
means to make work more efficient and a better use of an 
employee's time.
    For instance, on the cybersecurity mission, when we are 
working to protect Federal networks, we can apply machine 
learning so that we can inject indicators of compromise, 
malware samples, computer viruses. We can use machine learning 
and AI tools to automate that so that we're more able to 
quickly identify where vulnerabilities may exist and how to 
patch them.
    We also want to explore the ability to use AI in different 
mission spaces. Our Homeland Security Investigations is using 
it on the countering child sex exploitation and CSAN material, 
that we can better identify victims and protect those 
communities using artificial intelligence. We also have pilots 
going where we want to use them on the border to better scan 
for goods in the customs and border protection mission.
    So we have a lot of actual good news stories in this space 
that we're excited about.
    Mr. Strong. Thank you, Mr. Chairman.
    I yield back.
    Chairman Bishop. The gentleman yields back.
    The Chair now recognizes Mr. Crane for 5 minutes.
    Mr. Crane. Thank you, Mr. Chairman.
    This is for both of you. Were you here for the panel prior?
    Ms. Harrington. We were in another room, but we were able 
to watch some of it on the TV.
    Mr. Crane. OK.
    I am going to start with you, Mr. K. I will just say Mr. K. 
Is that all right? Go ahead and tell me how to pronounce it.
    Mr. Kahangama. You could say Kahangama.
    Mr. Crane. Kahangama. OK.
    Do you trust the Government to censor American speech?
    Mr. Kahangama. Respectfully, Congressman, the Department of 
Homeland Security does not censor content.
    Mr. Crane. OK. Did you hear Mr. Shellenberger's evidence 
about how our Government was using some of its institutions and 
organizations to censor the speech of Americans on social 
media? Were you here for that?
    Mr. Kahangama. I saw the hearing, the first part, yes.
    Mr. Crane. OK. So are you arguing that that wasn't 
censorship?
    Mr. Kahangama. I'm not familiar with what exactly you're 
referencing.
    Mr. Crane. OK. Well, he had emails going from our 
Government to social media platforms flagging and requesting 
the removal of social media posts. Do you classify that as 
censorship?
    Mr. Kahangama. So while I heard the testimony of Mr. 
Shellenberger, I haven't reviewed the specific documents that 
you are referencing, so I can't speak to the veracity of them.
    Mr. Crane. OK. Well, let's just go general then. Do you 
think that it is censorship for the Federal Government to be 
reaching out to social media platforms and asking them to 
remove postings from American citizens?
    Mr. Kahangama. Thank you, Congressman.
    I would reiterate that the Department of Homeland Security 
does not engage in content moderation conversations with social 
media companies.
    Mr. Crane. OK. That is not what I asked you.
    OK. Do you study history, Mr. K?
    Mr. Kahangama. Generally.
    Mr. Crane. Generally? OK. What about you, ma'am, Ms. 
Harrington. Generally?
    Ms. Harrington. Generally.
    Mr. Crane. OK. Typically, what types of governments censor 
their own people? Go ahead, either of you.
    Ms. Harrington. Authoritative?
    Mr. Crane. Yes. Sir?
    Mr. Kahangama. Yes, I would agree.
    Mr. Crane. Do totalitarian governments do that? Yes? No? It 
is not hard.
    Mr. Kahangama. Broadly, yes.
    Mr. Crane. Do communistic governments do that? Socialistic 
governments do that? Why do you think they do that? Why do they 
think that they try and control the speech of their own people? 
Ma'am? Ms. Harrington.
    Ms. Harrington. Yes, I think that's correct, probably 
political control.
    Mr. Crane. Yes, absolutely.
    Mr. K.
    Mr. Kahangama. Yes, I would agree.
    Mr. Crane. Do you think it is important that we try not to 
become like them?
    Mr. Kahangama. I believe this Government is not like them. 
I believe we are respectful of our Constitutional rights. We 
ensure that all the work that we are doing is protected by our 
civil liberties and civil rights offices, and we do that with 
respect to all of our freedoms, including----
    Mr. Crane. Well, thank you, but I would actually 
respectfully disagree with that point of view. As a matter of 
fact, if you were paying attention to some of the evidence 
produced in the last panel, you would know that. As somebody 
who is involved in law enforcement, that was evidence, sir. 
That is what any law enforcement officer would consider 
evidence. Those emails going from our Government to social 
media platforms, flagging and requesting the removal of posts 
and speech from American citizens. So you can sit there and you 
can give me all the little canned answers you want, but when 
you actually open your mind and are willing to look at the 
evidence being presented, it is obvious.
    Now, this shouldn't be a partisan issue. We all know that 
on this panel. It shouldn't be a Democrat or Republican issue. 
It should be are we willing to become like other totalitarian 
governments, communistic governments, socialistic governments 
that censor the speech of our own people. I hope you two take 
this very seriously, because I am sure that many of the people 
that have participated in some of these communistic, 
totalitarian governments in history felt like they were doing 
the right thing. So I hope that you guys take this very 
seriously, and I hope you take our Constitution very seriously 
and free speech. Because I will tell you this, it is most 
important to protect free speech not when you agree with 
people, but when you disagree with them.
    Thank you.
    I yield back.
    Chairman Bishop. The gentlemen yields back.
    In the Chair's discretion, we will do another round of 
questioning for the witnesses.
    So I will recognize myself for 5 minutes.
    Ms. Harrington----
    Mr. Ivey. Mr. Chairman, if I might, perhaps the Chair could 
do another round of questions.
    Chairman Bishop. You don't care to?
    Mr. Ivey. I do have some time constraints.
    Chairman Bishop. No one has to stay. No one has to stay and 
we are not going to be long, but I have got another 5 minutes. 
You don't have to stay.
    Mr. Ivey. Yes, sir. No objection to that? No objection to 
that.
    Chairman Bishop. All right, good. Thank you, sir.
    It is at the election of every Member whether they have 
further questions they want to ask.
    So the Chair will ask 5 minutes of questioning. If you will 
restore my time to 5 minutes, please.
    Ms. Harrington, you have referenced a number of times that 
CISA operates a rumor control website where you correct things 
you have identified that are misinformation. You understand 
from the prior testimony and the questions of Members, no one 
has an objection to CISA having a website publishing what it 
contends are corrections of rumors that are false? Right? You 
understand that?
    Ms. Harrington. Yes.
    Chairman Bishop. Do you understand what the committee is 
concerned about in terms of CISA's prior conduct? Are you 
unaware of the subject matter that we are concerned about?
    Ms. Harrington. I am aware. I'm aware of what you're 
concerned about. Censorship, essentially. I am aware of that.
    Chairman Bishop. OK. Do I understand your testimony 
previously be that CISA really hasn't changed its policies to 
avoid censoring?
    Ms. Harrington. Representative, respectfully, we don't 
censor.
    Chairman Bishop. OK.
    Ms. Harrington. I can tell you what we are doing.
    Chairman Bishop. OK. No, hold on a second.
    So do you know what switchboarding is?
    Ms. Harrington. I was made familiar with that recently.
    Chairman Bishop. OK. Did----
    Ms. Harrington. I was not at the agency when that----
    Chairman Bishop. I am really talking about CISA, not really 
talking about specific to your career, obviously. You are here 
as a representative of CISA. Did CISA switchboard?
    Ms. Harrington. Yes.
    Chairman Bishop. OK.
    Ms. Harrington. But please allow me to explain what I 
understand that----
    Chairman Bishop. Well, I just want to know, because I 
understand we may get lost in exactly what switchboarding kind-
of includes, but you have a notion in your mind of what it is. 
Is CISA continuing to switchboard?
    Ms. Harrington. CISA is not switchboarding. CISA is not 
sending emails on behalf of election officials from both 
parties to social media companies.
    Chairman Bishop. OK.
    Ms. Harrington. That is not happening.
    Chairman Bishop. When did CISA stop switchboarding?
    Ms. Harrington. My understanding, although it predates me, 
is that CISA stopped after the 2020 cycle.
    Chairman Bishop. Why did it stop?
    Ms. Harrington. Representative, respectfully, again, this 
predates me, but my understanding is that CISA makes decisions 
to prioritize efforts based on where the most impact is and to 
align resources with priorities. That was an agency decision. 
Again, that predates me, but my understanding is it has stopped 
and it is no longer happening now and it stopped in the 2020 
cycle.
    Chairman Bishop. See, my concern is if CISA stopped 
switchboarding because it thought switchboarding was a 
questionable practice or one that was exceedingly disapproved 
of, then that might satisfy me more. But what I understand you 
are saying is it is simply a resource allocation or 
prioritization determination, so you could resume 
switchboarding next week if you want to. Is that what you 
think?
    Ms. Harrington. Representative, respectfully, I understand 
that was an agency decision. Again, it predates me and that 
activity is not occurring.
    Chairman Bishop. Yes, but that is not what I asked you. I 
asked you whether you believe it to be true that CISA could 
resume switchboarding next week.
    Ms. Harrington. Representative, again, switchboarding is 
not occurring and that stopped in the 2020 cycle. Forwarding 
emails to social--a limited number of emails from both parties 
to social media companies is not happening.
    Chairman Bishop. In that case--you would agree with me, 
would you not, that there is no reason that Congress shouldn't 
restrict CISA's authority to make sure that it cannot 
switchboard? Since you are not doing it, right?
    Ms. Harrington. Representative, we are not censoring.
    Chairman Bishop. So we can provide that in law, make sure 
that that is a clear guardrail, correct?
    Ms. Harrington. Representative, respectfully, it is already 
in law.
    Chairman Bishop. Oh, really?
    Ms. Harrington. That we shouldn't censor? It is the First 
Amendment.
    Chairman Bishop. That you shouldn't switchboard. I agree. I 
mean, you have kind-of hit the nail on the head with that last 
statement.
    Ms. Harrington. We are not censoring----
    Chairman Bishop. Because the problem is----
    Ms. Harrington. CISA doesn't censor.
    Chairman Bishop. The problem is whether switchboarding is 
censoring, and I think you just conflated the two, which is 
exactly the problem.
    Let me ask this question. Is CISA meeting on a regular 
basis with social media platforms?
    Ms. Harrington. CISA does not meet with social media 
platforms.
    Chairman Bishop. You said does not. Did it meet with social 
media platforms on a periodic basis?
    Ms. Harrington. I understand that it was meeting with them 
at a time, yes.
    Chairman Bishop. Monthly and then weekly during the run-up 
to the 2020 elections, correct?
    Ms. Harrington. I am not certain on completely what that 
cadence is.
    Chairman Bishop. OK. I will represent to you that that is 
what it was since you don't know, but you should. They met with 
them monthly and then weekly leading up to the 2020 elections. 
Are those sorts of periodic meetings with social media 
companies still going on?
    Ms. Harrington. Representative, CISA is not meeting with 
social media companies.
    Chairman Bishop. Why did you stop?
    Ms. Harrington. I understand that that activity stopped in 
October 2022.
    Chairman Bishop. Why?
    Ms. Harrington. Because the staff were communicating 
information to interagency partners as well as social media 
companies on basic 101 election information and it was not good 
use of their time given other priorities that would yield an 
impact.
    Chairman Bishop. All right.
    My 5 minutes of questioning. The second round has expired.
    Mr. Ivey, you don't have further questions?
    Mr. Ivey. No, Mr. Chairman.
    Chairman Bishop. All right.
    In that case, I thank these witnesses for your valuable 
testimony and the Members for their questions.
    The Members of the subcommittee may have additional 
questions for the witnesses and would ask the witnesses to 
respond to those in writing. Pursuant to committee rule VII(D), 
the hearing record will be held open for 10 days.
    Without objection, this subcommittee stands adjourned.
    [Whereupon, at 4:17 p.m., the subcommittee was adjourned.]

                                 [all]
</pre></body></html>
