ARTIFICIAL INTELLIGENCE (AI): INNOVATIONS WITHIN THE LEGISLATIVE BRANCH ---------- January 30, 2024 Committee on House Administration, House of Representatives, Washington, DC. The Committee met, pursuant to notice, at 10:33 a.m., in room 1013, Longworth House Office Building, Hon. Bryan Steil  presiding. Present: Representatives Steil, Loudermilk, Griffith, Murphy, Bice, Carey, Morelle, Sewell, Torres, and Kilmer. Also present: Representative Lieu. Staff present: Caleb Hays, Deputy Staff Director, General Counsel, Parliamentarian; Jessica Smith, Professional Staff; Jordan Wilson, Director of Member Services; Caitlin O'Dell, Legal Assistant and Deputy Clerk; Kristen Monterroso, Legislative Clerk; Khalil Abboud, Minority Deputy Staff Director, Chief Counsel; Matt DeFreitas, Minority Director of House Communication Standards Commission; and Jamie Fleet, Minority Staff Director. OPENING STATEMENT OF HON. BRYAN STEIL, CHAIRMAN OF THE COMMITTEE ON HOUSE ADMINISTRATION, A U.S. REPRESENTATIVE FROM WISCONSIN Chairman Steil. The Committee on House Administration will come to order. I note that a quorum is present. Without objection, the Chair may declare a recess at any time. Also, without objection, the meeting record will remain open for 5 legislative days so Members may submit any materials they wish to include therein. Thank you, Ranking Member Morelle, Members of the Committee, and our witnesses, for participating in today's hearing. AI has sparked an interest around the world. With any new technology, there comes risks and rewards. Recently, we have seen it used to mimic President Biden's voice in a recent election robocall. We have also seen it used to spur important research and reduce burdensome Government paperwork. We must ensure Congress is ready to manage the risks AI poses while leaning into its rewards. Today, we will explore how the legislative branch is developing AI governance plans for Congress to innovate effectively and efficiently. In the early months of 2023, generative AI disrupted multiple industries, including Government operations. It triggered a global conversation about the power of AI and its social implications. By the middle of last year, the Committee took steps to meet with each of our legislative-branch entities to discuss the power of AI and the need to develop responsible governance plans. By the end of year, we saw several AI use cases emerging from our legislative-branch agencies. For example, we have seen innovative experiments with optical character recognition to assist visually impaired Library patrons. The U.S. Copyright Office is using AI to improve digital accessibility to copyright registration records and other data. Natural language processing has helped rapidly summarize legislation. Testing now enhanced search tools could help the public more quickly find Government publications. These use cases are just some examples of what will enable Congress to be more effective. The Committee is dedicated to promoting transparency around these use cases. This transparency is essential to ensure Congress maintains a detailed understanding of the use of AI for this institution and for the American people. Congress must also ensure our legislative-branch agencies are developing comprehensive AI governance plans. These plans are foundational IT best practices and are necessary to effectively manage AI over the long term. The NIST AI framework is a critical resource that can help legislative-branch agencies turn AI principles into specific Government policies. As the legislative branch experiments and develops these governance plans, we must also be looking ahead to the need for upskilling the legislative-branch workforce. AI is new to many of us, making training a critical element of successful implementation. I was once told that AI will not replace humans but humans that use AI could replace those that are not using AI. I look forward to hearing how legislative-branch staff will be upskilling and made familiar with generative AI technology. The Committee on House Administration is focused on ensuring the legislative branch is able and equipped to address the challenges AI presents while utilizing its benefits. I look forward to hearing from each of our witnesses today. I am pleased to welcome later today into this room Congressman Obernolte and Congressman Lieu to the Committee to discuss AI.  PREPARED STATEMENT OF CHAIRMAN OF THE COMMITTEE ON HOUSE ADMINISTRATION BRYAN STEIL AI has sparked an interest around the world. With any new technology, there comes risks and rewards. Recently, we have seen it used to mimic President Biden's voice in a recent election robocall. We have also seen it used to spur important research and reduce burdensome Government paperwork. We must ensure Congress is ready to manage the risks AI poses while leaning into its rewards. Today, we will explore how the legislative branch is developing AI governance plans for Congress to innovate effectively and efficiently. In the early months of 2023, generative AI disrupted multiple industries, including Government operations. It triggered a global conversation about the power of AI and its social implications. By the middle of last year, the Committee took steps to meet with each of our legislative-branch entities to discuss the power of AI and the need to develop responsible governance plans. By the end of year, we saw several AI use cases emerging from our legislative-branch agencies. For example, we have seen innovative experiments with optical character recognition to assist visually impaired Library patrons. The U.S. Copyright Office is using AI to improve digital accessibility to copyright registration records and other data. Natural language processing has helped rapidly summarize legislation. Testing now enhanced search tools could help the public more quickly find Government publications. These use cases are just some examples of what will enable Congress to be more effective. The Committee is dedicated to promoting transparency around these use cases. This transparency is essential to ensure Congress maintains a detailed understanding of the use of AI for this institution and for the American people. Congress must also ensure our legislative-branch agencies are developing comprehensive AI governance plans. These plans are foundational IT best practices and are necessary to effectively manage AI over the long term. The NIST AI framework is a critical resource that can help legislative-branch agencies turn AI principles into specific Government policies. As the legislative branch experiments and develops these governance plans, we must also be looking ahead to the need for upskilling the legislative-branch workforce. AI is new to many of us, making training a critical element of successful implementation. I was once told that AI will not replace humans but humans that use AI could replace those that are not using AI. I look forward to hearing how legislative-branch staff will be upskilling and made familiar with generative AI technology. The Committee on House Administration is focused on ensuring the legislative branch is able and equipped to address the challenges AI presents while utilizing its benefits. I look forward to hearing from each of our witnesses today. I am pleased to welcome later today into this room Congressman Obernolte and Congressman Lieu to the Committee to discuss AI. With that, I will yield to the Ranking Member for 5 minutes for opening remarks, and I now recognize you, Mr. Morelle. OPENING STATEMENT OF HON. JOSEPH MORELLE, RANKING MEMBER OF THE COMMITTEE ON HOUSE ADMINISTRATION, A U.S. REPRESENTATIVE FROM NEW YORK Mr. Morelle. Thank you so much, Mr. Chairman, for the introduction and also for convening this important hearing. I am very grateful to you and your staff, who have worked tirelessly to make this a bipartisan conversation. It is critically important, and I look forward to discussing the ways that recent innovations in generative artificial intelligence can improve the efficiency of the legislative-branch operations and help us better serve our constituents. I want to express appreciation to all the folks who have gathered with us to speak on this issue. I am looking forward to listening to them. We have witnesses, as you have said, from the Library of Congress, Government Publishing Office, Government Accountability Office, and Chief Administrative Office. I am grateful to all of you and your organizations, which are the backbone of Congress and on which we rely each and every day to provide us with administrative research and technical tools that we need to carry out all of our constitutional duties. I am looking forward to discussing your work with AI so far and how the Committee can help best support your efforts in each of your responsibilities. Over the past several years, the combination of enhanced computer power or proliferation of data, improvements to underlying models, and an increased availability of AI tools has led to widespread use of AI across sectors. Today, it would be difficult, if not impossible, to find a single business or single industry that has not or will not soon be impacted by advancements in this technology. The U.S. Government is no exception. Here in the legislative branch, for instance, the Library of Congress is using AI to create standardized records from e-books, extend data from historic documents, and help blind and print-disabled patrons access Library resources. At the same time the Copyright Office is grappling with how it should consider registration applications for AI-produced works, the Government Publishing Office is using AI to transcribe meetings and is exploring ways to make proofreaders more efficient, public information more accessible, and data more secure. The House Chief Administrative Office is using AI to supplement its help-desk services and working with Members' offices to use the technology to deconflict schedules and assist in constituent correspondence--things that we are all intimately involved in. The Government Accountability Office has established a lab to design and implement new AI technologies as well as an internal working group to analyze AI governance issues. All these are critically important and all very exciting. AI can simplify complex tasks, provide insights into data, build capacity, improve workflows, and more. For all the exciting opportunities that AI presents, we must also be cognizant of its threats and its risks. We have seen some of the dangers associated with AI in the headlines recently. Last week, an unknown party attempted to confuse and disenfranchise New Hampshire voters using AI- generated robocalls imitating the voice of President Biden in advance of the primary election. Recognizing that grave threat that AI may pose to our elections, I asked the Attorney General of the United States to immediately investigate this attempt at election subversion and to ward off future actors who would attempt to use generative AI to undermine our Nation's elections. Deepfake pornography, which makes up 96 percent of all deepfakes online, almost exclusively targets women and is becoming increasingly pervasive. Astoundingly, it is not a Federal crime, although I have a bill, bipartisan bill, that I have introduced with Congressman Kean, the Preventing Deepfakes of Intimate Images Act, which would change that. We have seen elements of that with Taylor Swift's situation in the past week. Threats and risks exist here in the legislative branch too, and we need to be mindful of them as we establish what will be the operating culture for congressional AI use for years to come. What are the implications for the institutional workforce here? How do we control for bias and other data quality issues that affect the trustworthiness of these systems? There are certainly questions that are important to sort out as we work through this. To that end, I am grateful that the Committee and our institutional partners have utilized the administration's National Institute of Standards and Technology AI framework and related executive orders as models for the legislative branch as it relates to AI governance policies. With these as a guide, Congress, I think, will be better equipped to minimize risk and adopt this technology responsibly and ethically. It has great promise, great risks, but I think the fact that we are gathered here--and, Mr. Chairman, thank you again, to you and your staff, for bringing us together and bringing all the witnesses to testify on this incredibly important issue. With that, I yield back. Thank you.  PREPARED STATEMENT OF RANKING MEMBER OF THE COMMITTEE ON HOUSE ADMINISTRATION JOSEPH MORELLE Over the past several years, the combination of enhanced computer power or proliferation of data, improvements to underlying models, and an increased availability of AI tools has led to widespread use of AI across sectors. Today, it would be difficult, if not impossible, to find a single business or single industry that has not or will not soon be impacted by advancements in this technology. The U.S. Government is no exception. Here in the legislative branch, for instance, the Library of Congress is using AI to create standardized records from e-books, extend data from historic documents, and help blind and print-disabled patrons access Library resources. At the same time the Copyright Office is grappling with how it should consider registration applications for AI-produced works, the Government Publishing Office is using AI to transcribe meetings and is exploring ways to make proofreaders more efficient, public information more accessible, and data more secure. The House Chief Administrative Office is using AI to supplement its help-desk services and working with Members' offices to use the technology to deconflict schedules and assist in constituent correspondence--things that we are all intimately involved in. The Government Accountability Office has established a lab to design and implement new AI technologies as well as an internal working group to analyze AI governance issues. All these are critically important and all very exciting. AI can simplify complex tasks, provide insights into data, build capacity, improve workflows, and more. For all the exciting opportunities that AI presents, we must also be cognizant of its threats and its risks. We have seen some of the dangers associated with AI in the headlines recently. Last week, an unknown party attempted to confuse and disenfranchise New Hampshire voters using AI- generated robocalls imitating the voice of President Biden in advance of the primary election. Recognizing that grave threat that AI may pose to our elections, I asked the Attorney General of the United States to immediately investigate this attempt at election subversion and to ward off future actors who would attempt to use generative AI to undermine our Nation's elections. Deepfake pornography, which makes up 96 percent of all deepfakes online, almost exclusively targets women and is becoming increasingly pervasive. Astoundingly, it is not a Federal crime, although I have a bill, bipartisan bill, that I have introduced with Congressman Kean, the Preventing Deepfakes of Intimate Images Act, which would change that. We have seen elements of that with Taylor Swift's situation in the past week. Threats and risks exist here in the legislative branch too, and we need to be mindful of them as we establish what will be the operating culture for congressional AI use for years to come. What are the implications for the institutional workforce here? How do we control for bias and other data quality issues that affect the trustworthiness of these systems? There are certainly questions that are important to sort out as we work through this. To that end, I am grateful that the Committee and our institutional partners have utilized the administration's National Institute of Standards and Technology AI framework and related executive orders as models for the legislative branch as it relates to AI governance policies. With these as a guide, Congress, I think, will be better equipped to minimize risk and adopt this technology responsibly and ethically. It has great promise, great risks, but I think the fact that we are gathered here--and, Mr. Chairman, thank you again, to you and your staff, for bringing us together and bringing all the witnesses to testify on this incredibly important issue. Chairman Steil. The gentleman yields back. Without objection, all other Members' opening statements will be made part of the hearing record if they are submitted to the Committee clerk by 5 p.m. today. Today we have one witness panel. We welcome Hon. Hugh Halpern, Ms. Judith Conklin, Mr. John Clocker, and Mr. Taka Ariga. We appreciate you being with us today, and I look forward to all of your testimony. Pursuant to paragraph B of Committee Rule 6, the witnesses will please stand and raise their right hands.  Chairman Steil. Let the record show the witnesses all answered in the affirmative and may be seated. I will now proceed to introduce our panel of witnesses. Our first witness, Honorable Hugh Halpern, is the U.S. Government Publishing Office Director, the agency's chief executive officer. Donald Trump nominated Mr. Halpern to be GPO Director and the U.S. Senate confirmed him in 2019. Our next witness, Ms. Judith Conklin, is the Chief Information Officer for the Library of Congress. She serves as the primary advisor to the Librarian of Congress on all technology matters and is a member of the Library's Executive Committee. She chairs the legislative branch CIO Council and is the Library's senior agency official for records management. Our next witness, Mr. John Clocker, serves as Deputy Chief Administrative Officer for the House of Representatives. Mr. Clocker has over three decades of legislative-branch experience, which touches all aspects of the administrative, financial, and technical operations of the House. Our next witness, Mr. Taka Ariga, is the Chief Data Scientist and Director of the Innovation Lab, Science, Technology Assessment, and Analytics and has helped GAO develop and implement advanced analytical capabilities for its auditing practices. We appreciate each of you being here today, and we look forward to your testimony. Let me remind the witnesses that we have read your written statements and they will appear in full in the hearing record. Under Committee Rule 9, you are to limit your oral presentation to a brief summary of your written statements. I will now recognize Mr. Hugh Halpern for 5 minutes. STATEMENTS OF HON. HUGH HALPERN, DIRECTOR, U.S. GOVERNMENT PUBLISHING OFFICE; JUDITH CONKLIN, CHIEF INFORMATION OFFICER, LIBRARY OF CONGRESS; JOHN CLOCKER, DEPUTY CHIEF ADMINISTRATIVE OFFICER, U.S. HOUSE OF REPRESENTATIVES; AND TAKA ARIGA, CHIEF DATA SCIENTIST AND DIRECTOR, INNOVATION LAB STATEMENT OF HUGH HALPERN Mr. Halpern. Thank you, Mr. Chairman, Ranking Member Morelle, and Members of the Committee. I am pleased to appear here before you today to share some potential uses of AI and related technologies at GPO. GPO is fundamentally a manufacturing operation. We publish, produce, and maintain materials for all three branches of Government. Our 1,600 craftspeople and professionals produce virtually all of Congress's documents, along with numerous other publications, as well as manufacture secure-credential products like the U.S. passport. We also provide digital information, either through our own trusted digital repository, GovInfo.gov, or by serving data to our partners like the Library of Congress, where they use that data on Congress.gov. No matter what you call it--artificial intelligence, machine learning, or a large language model--GPO's operations are just as susceptible to disruption as any commercial firm's. That is not necessarily a bad thing. My written testimony describes GPO's policy approach to this new generation of tools, so today I am going to focus on three potential applications for AI and related technologies in our day-to-day operations. First, we believe these tools can improve our quality- assurance process by automatically recognizing defects that a human inspector might miss. We already use a rudimentary form of this technology in the production of the current version of the U.S. passport. GPO uses equipment that optically scans the pages that will become the identity page in a personalized passport. This equipment looks at each strip of three pages for variances that exceed the specifications from the material and rejects them as pages that do not conform to the standard. AI technology has the potential to further refine this review, allowing machines to learn what may constitute a natural variation and what is not. This has the potential to reduce defect rates, lower waste, and free up our quality- assurance team to focus on solving more difficult quality problems as they arise. I also expect future printing presses acquired by GPO to incorporate similar technology. Second, we see tremendous potential for supplementing our proofreading team. Proofreaders are very difficult to hire, and we need to free them from making routine, repetitive corrections and allow them to focus on more subtle issues that require a human being to interpret. One example is capitalization. GPO style says that we capitalize the ``S'' in the word ``State'' when referring to a political subdivision in the United States. Currently, we use scripts that perform global search-and-replace functions on documents to correct our most common errors. Those scripts are blunt instruments. They cannot tell the difference between the State of Wisconsin and a ``New York State of mind.'' AI holds the promise of tools that understand context and know when text refers to one kind of ``state'' or the other. That will cut down on the need for our proofreaders to review and correct material that has already been run through our automated tools, freeing them up to focus on more difficult contextual issues. My final example comes from GPO's public information mission. We have had great success making congressionally mandated reports publicly available, with nearly 200 available on GovInfo. Most of those reports come to us as PDFs. While that is a good format to show how the printed document looks, it is not always the best format for viewing on a phone, tablet, or for those who may have vision or other impairments. While GPO would like to get these reports in more flexible formats like XML, the agencies offering the reports are not always equipped to supply them that way. AI technologies hold the promise of allowing us to extract the information from a PDF, understand the document structure, and produce an alternative view that works on different kinds of devices, all without manual, time-consuming work from our team. These are just three examples where we see applications in GPO's operations and are considering pilots in the future. All of these are intended to act as a force multiplier for our team, allowing our folks to be more productive and deliver a higher value for our customers and taxpayers. Mr. Chairman, Ranking Member Morelle, thank you for the opportunity to testify before the Committee today. I look forward to any questions you may have.   Chairman Steil. Thank you very much, Mr. Halpern. Mr. Morelle. May I--may I just interrupt for 1 second? As a Representative of the Empire State, script notwithstanding, ``New York State of Mind'' should always be capitalized. I want to make that point. Chairman Steil. I will hold back on my Wisconsin comment there. Thank you very much, Mr. Halpern. We will now recognize Ms. Judith Conklin for 5 minutes. STATEMENT OF JUDITH CONKLIN Ms. Conklin. Chairman Steil, Ranking Member Morelle, and Members of the Committee, thank you for this opportunity to appear on behalf of the Library of Congress to share our work with artificial intelligence. As the Library's CIO, I work directly for the Librarian of Congress, Dr. Carla Hayden. We agree technology is baked into all facets of the Library of Congress. AI has recently become a focus in Government and industry, but the Library began working with AI and machine-learning technologies more than a decade ago. The Library of Congress is fortunate to possess data necessary for thoughtful AI adoption. We serve Congress and the American people with a universal and enduring source of knowledge and creativity. We steward vast collections of cultural heritage materials. We also function as the research arm of Congress through the Congressional Research Service and the Law Library of Congress. We are home to the U.S. Copyright Office and have an abundance of copyright deposits, rich historical records and data, and legislative and policy materials in our care. We trace the beginning of our work with AI to optical character recognition more than 10 years ago. We saw the power of this technology to enhance the ability to search our collections. The most compelling example of this early AI in action can be seen in our ``Chronicling America'' initiative, where we have empowered users to search more than 20 million digitized historic newspaper pages. We have seen how aspects of AI can help researchers, genealogists, historians, educators, and creators to cast a wider net and journey through our vast collections faster than ever before. The Library's AI experiments have a consistent finding: AI, when properly understood, empowers, but it cannot replace humans. The role of people at the Library of Congress informs how we use AI. Every day, hundreds of cataloguers create detailed records for material in hundreds of languages to help researchers across the globe navigate our collections. Legislative analysts help Congress and the American people understand complex issues and bill language through historic and legal lenses. Our colleagues in the U.S. Copyright Office promote creativity and support research and commerce by providing access to records of over a century of registered copyrighted works and recordations. For over 5 years, the Library has engaged with the public to experiment with our collections data. As much as possible, we make our curated data sets available to the public. CRS has embarked on several AI activities. Currently, OCIO and CRS are conducting a controlled experiment to determine AI approaches that could assist with the creation of high-quality and trustworthy bill summaries. OCIO is collaborating with the U.S. Copyright Office to discern ways AI can help make digitized historical copyright records more discoverable. In October 2023, the Library released its new strategic plan, ``A Library for All.'' The Library once had a separate digital strategy. As a sign of our growing digital maturity, our new strategic plan embeds digital strategy throughout. We also engage in external conversations. The Library monitors AI executive-branch actions, participates in the GSA AI Community of Practice, and engages with NIST regarding AI risks. We are a leading member of the International AI for Libraries, Archives, and Museums, AI4LAM. We have also provided reports to this Committee on our progress with both AI experiments and governance. We established an agency-wide AI working group co-led by the Principal Deputy Librarian of Congress and myself. Early last year, CRS established their internal AI working group to examine developments, policy implications, and AI potential. In addition to these activities, I serve as chair of the legislative branch CIO Council. Members have shared their AI initiatives and discussed the technical aspects of AI. We will establish an AI working group to further explore AI opportunities and challenges. This will enable us to inform Congress on our technological AI capabilities and properly safeguard our data. In closing, for more than two centuries, the Library of Congress has embraced the Herculean charge of keeping pace with human knowledge. Computers can perform remarkable tasks with data, but we will always need people at the center of this work if we are to truly remain a source of authentic, enduring knowledge and creativity. AI is empowering the Library of Congress in remarkable ways. More will be accomplished with this technology in the future. None of this would be possible without your continued support. Thank you for this opportunity to share our work today.   Chairman Steil. Thank you very much, Ms. Conklin. Mr. Clocker, you are now recognized for 5 minutes. STATEMENT OF JOHN CLOCKER Mr. Clocker. Thank you, Chairman Steil, Ranking Member Morelle, and Members of the Committee, for holding today's hearing on AI integration--specifically, emerging generative AI. With me here today, representing the CIO's Innovation Division, is Senior Director for Innovation Stephen Dwyer. Also with me today, representing our cybersecurity teams, is our Deputy Chief Information Security Officer, Addie Adeniji. These two and their teams are at the forefront of this endeavor for the CAO, making sure the House strikes the right balance between innovation and security. Over the past few years, AI advancements have gained significant momentum and prominence with the advent of gen AI, large language modules capable of analyzing massive data sets and producing original, human-like content. This technology has transformative potential for House operations. For Member offices faced with an ever-increasing volume of constituent engagement and oversight responsibilities, AI has the potential to augment staff workload capacity. It can also help the House, as an institution, improve business efficiencies. To support its integration, the CAO, with the support of this Committee, implemented a disciplined, methodical approach. We have conducted legal and security reviews of available products. As a result of our security and legal reviews, the Committee has initially approved ChatGPT Plus for limited use in the House environment. We have established a House-wide advisory group to collect, analyze, and share information about how Member, Committee, and leadership offices can use this technology. Last spring, our House Digital Services team established the AI advisory group because it is important we understand these tools' capabilities and also the tool limitations within the House environment. The advisory group is conducting its case studies in two phases. The first phase included over 200 House staffers, representing approximately 150 Member, Committee, and leadership offices. Initial feedback has been very positive. Offices have touted these tools as great for proofreading; as very effective for producing first drafts of memos, press releases, letters; summarizing reports, transcripts, and large data sets. However, they have also experienced limitations. The tools are not quite ready for drafting legislation or producing legal documents. The tools do not necessarily always understand the certain context of social media. The tools today do not adequately capture a Member's voice and style. The advisory group's second phase will focus on experimenting within institutional offices, supporting such functions as quality assurance or summarizing complex procurement responses and much more. We have conducted a governance assessment to identify needed improvements. This is all very exciting, but we need to be careful. The House will face elevated cyber risks. Our Nation's adversaries and cyber criminals will use these tools to try to harm the House. Because of this, we must evolve and be increasingly vigilant about the AI tools and websites we access. Just because an employee can access a site through their House device does not mean it is safe. We need to develop AI-specific policies and processes. We need to develop guidance and training opportunities for House staff. When ready, we need to provide expanded access to House- validated AI tools. Working with this Committee, the CIO will develop a new AI- specific policy. It will also determine how our security protocols need to be expanded. There will be costs associated with this expansion. We plan to establish guidance and training opportunities so offices can correctly optimize use of AI tools. We also recommend offices adopt internal AI policies customized to each Member's preference and risk tolerance for the use of these tools. Finally, when ready, the House needs to expand access to secure and validated AI tools. If we execute these correctly and deliver validated and safe tools, we believe these tools will significantly improve our capacity to serve Members and the American people. Thank you.   Chairman Steil. Thank you, Mr. Clocker. Mr. Ariga, you are now recognized for 5 minutes. STATEMENT OF TAKA ARIGA Mr. Ariga. Chairman Steil, Ranking Member Morelle, and distinguished Members of the Committee, thank you for today's hearing on AI innovations within the legislative branch. As I previously testified before Congress, we are living in an algorithmic renaissance where the confluence of data, cloud computing, and mathematics is allowing us to do things that were once in the realm of fiction only a few years ago. Today, we can use common descriptions to create images or functioning software codes and extrapolate existing research into exciting scientific findings. Yet these incredible advances are offset by real impacts on jobs, privacy, and equity. That is why GAO established the AI Accountability Framework in 2021 to serve as a blueprint for responsible implementations of AI. The framework is a beacon for the Oversight Committee and from which a growing body of GAO's AI work follows. We are heartened to see recent executive-agency action toward similar accountability goals and strongly believe that robust oversight is essential as AI technologies continue to leap forward at a remarkable pace. An integral part of strengthening GAO's AI capacity is developing our own hands-on technical know-how. This allows us to separate hype from reality, but, more importantly, allows us to grasp nuanced complexities of machine-learning techniques so that we can design meaningful AI solutions for the benefit of GAO. I am proud to lead the data scientists and technologists working on groundbreaking AI projects within GAO's Innovation Lab. The eight described in our AI use-case inventory exemplify GAO's boundary-pushing ingenuity. The value proposition is simple: GAO's effective use of AI means we can better serve Congress and the American people. We recently crossed an important milestone with our successful deployment of a large language model. This is allowing us to benefit from generative AI on trusted data while meeting our core values of accountability, integrity, and reliability. We are hard at work to make sure that GAO's reports and recommendations can be summarized effortlessly on any particular topic; GAO leadership can improve interpretation of feedback from our annual employee experience survey to ensure GAO remains the best midsize agency to work for; and GAO employees can ask routine questions 24/7 on operational policies or IT-related issues with instantaneous responses. While generative AI has garnered recent attention, we are also exploring internal use of more general AI. One prototype applies neural networks to automate copyediting functions based on GAO's extensive style guide. This means that our analysts can focus more time on refining clarity of GAO reports. We are also looking to embed computer vision models using extended reality glasses to improve site visit collaboration while reducing safety risks. Through strong internal governance and following the principles of our AI Accountability Framework, we are using AI to amplify critical mission and operational functions with a sense of urgency. AI is not a technological fad. That is why GAO continues to carry out vigorous oversight and foresight work on AI. Just last month, we reported on the current state of AI implementations across Federal agencies. We also issued several technology assessments, including one on AI modeling for natural disasters, and have large-scale efforts focused on generative AI underway. Since 2018, GAO has issued nearly 250 products on AI. Today, we have 20 ongoing AI engagements, with many more planned. This volume of work means GAO's capacity-building on AI must be broad and holistic. We are strategically using direct hiring authority to expand a cadre of specialists with hard-to- find skills. We are scaling digital literacy and technical training opportunities. We are modernizing our compute infrastructure in the cloud to support the next generation of AI development. We are keeping close tabs on a variety of AI issues across a global network of academic, industry, policy, and oversight entities. GAO is committed to credibly embrace promises of AI while shedding light on its adverse impacts. In short, we are applying human intelligence to achieve sound use of artificial intelligence. As a watchdog, GAO remains a steadfast partner to Congress on matters related to AI and other emerging technologies. Our data scientists, technologists, engineers, and cybersecurity professionals are always available to advise both chambers and provide timely technical assistance. We appreciate this Committee's continued support, and I am happy to answer any questions you may have.   Chairman Steil. Thank you, Mr. Ariga. Thank you all for your testimony today. I will begin questions today, followed by the Ranking Member. We will then alternate between the parties. I would now recognize myself for the purpose of questioning our witnesses. I will let everybody get set here. Alright. Let us just start with you, if I can, Mr. Ariga. In particular, your agency, the GAO, reported that the Federal Government made $247 billion in improper payments, including roughly $200 billion in overpayments, last year. I know the Innovation Lab has been working with the executive branch to strengthen payment integrity using technologies such as AI. I think it could be a real game-changer here for congressional oversight. In your submitted statement, you mentioned using AI to organize large volumes of text, like public comments from regulation.gov. Is that the same system or something that could help identify some of these improper payments? Could you give us a little color into that? Mr. Ariga. Thank you, Chairman. Certainly, improper payment is a significant concern for the Comptroller General. We currently have a project looking at something similar across the Federal single audits to identify persistent and systemic issues that may indicate instances of improper payments. We are sort of extrapolating that to say what might be the future likelihood of those systemic issues continuing to persist. I think this is something that--you know, as long as we can get the right data governance structure in place, something that holds tremendous promise for us. Chairman Steil. Thank you very much. I appreciate the work you are doing in that space. Let me jump to you, Mr. Clocker, if I can. In your submitted testimony, you had mentioned that the House has approximately 160 approved cloud service providers in use today throughout our Member and Committee offices. That is a lot of different pieces of software, companies for CAO to manage in support of this institution. We are working to build these tools to make sure that this software is moving us in the right direction. How do you plan to evaluate providers as it relates to AI for both legal, cybersecurity concerns, and that we do not avoid the rush to roll out but we are also leaning into the advantages they provide? Mr. Clocker. That is a great question. We know there is going to be a transition time where we are using our existing risk-management framework to evaluate products. We think that is a useful approach right now, but it is going to need to evolve and evolve very quickly. We are going to have to have AI-specific frameworks, similar to in this framework, and we are going to have AI-specific protocols and procedures to evaluate these products. We are already talking to the vendors about how their products handle House data, protect House data, and how those products use AI in various use cases. We are developing the questions that we need to ask these vendors. We do not have all the answers to those questions yet, so it is an ongoing process. Chairman Steil. Do you think you have the human capital to be able to make that evaluation of the vendors? Mr. Clocker. I think that is a great question, right? We have got--you mentioned the 160 products. These are cloud products we have authorized for use by Members and Committees and leadership. Right now, we have an annual process to review these products. When we do review those products, we review the quality of the firm. Are they a mature firm providing technology? That is a great foundation, but we are going to have to add some resources to do this correctly. Well, we are going to have to cut down the number of products that we have authorized here in the House. It is a challenge. Chairman Steil. Thank---- Mr. Clocker. And--yep. Chairman Steil. No, finish your thought. Mr. Clocker. I think the final point on that is, you know, I just--please be increasingly vigilant about the products you use in your office and the data you use for it during this transition. Chairman Steil. Thank you very much. I think this is going to be an ongoing dialog as work to continue to evaluate the technological products that are in front of us to make sure that we are leveraging the benefits but also managing any downside risk. Let me shift to you, if I can, Ms. Conklin. In your written testimony, you talked about improving discoverability as it relates to supporting the U.S. Copyright Office. I think that is an area where we have great potential here for a use case in AI. Can you walk through a little bit more as it relates to the Copyright Office registration records and how AI could be leveraged in that space? Ms. Conklin. As I mentioned--thank you for the question. As I mentioned, we do have a significant amount of historical data that includes historical copyrighted records, and we are currently performing an experiment on the records---- Chairman Steil. Could I just ask you to just double-check your mike? I can hear you, but I know those listening at home might not be able to. Ms. Conklin. Thank you. We have a current experiment with the Copyright Office on their historical records. Due to the--within the agency, we have a significant amount of historical data, and we are currently exploring the--we are currently experimenting with the Copyright Office historical data. That will make the data more discoverable on those digitized records that exist today. The difference between digitizing the records and making them discoverable via AI is, a machine can search much faster using AI technologies. That is what our hope is, that researchers can use that data for their research. Chairman Steil. Thank you very much. Thank you all for your testimony today. I will now recognize Mr. Morelle for 5 minutes. Mr. Morelle. Thank you. Again, thank you all for your testimony and your good work. I wanted to just step back a little bit. I think the benefits of AI to Congress--any other institution, but particularly as it relates to Congress--is how it contributes to our system of democracy, which ultimately relies on a trustworthy data governance strategy. It seems to me that the task is two ways. Congress generates as well as collects data. If the data governance is to succeed in building trust, which I think is really at a critical juncture in our moment in history now, data has to be accessible, transparent, and representative. I just wondered if you could each step back and just give me a little snippet of how you think we can appropriately use artificial intelligence to increase trust in the institution of Congress and what concerns we ought to have relative to increasing mistrust or distrust in the institution. Sort of broadly speaking, and in your mission, how you think about that. I will put the burden on you first, but--Mr. Halpern will have it easiest, because he will have had the benefit of having heard each one of you. I would just be curious, big picture, how you think about that. Mr. Ariga. Thank you, Ranking Member Morelle. I absolutely agree; data governance is crucial, making sure that the data we use to train and run AI systems are complete, accurate, timely. GAO has a lot of experience dealing with data-quality challenges historically. What I also think is important is whether users of AI systems can interpret information in a probabilistic way. AI, by definition, gives a sort of value, a confidence value, on what the outcome might look like. What that means is, it is never 100-percent certain. Do the users of AI understand how to interpret that information, then act upon that information? I think digital literacy is an important attribute of a successful implementation and usage of AI. Mr. Morelle. I am sorry to interrupt, but I think you make a really important point. This is about probabilities. People who are using it should not assume that the data is always 100 percent correct, because it is clearly based on probabilities based on huge data sets. Is that correct? Mr. Ariga. That is right. Mr. Morelle. Yes. Sorry. Mr. Clocker? Mr. Clocker. It is a great question. It is one we are already thinking a lot about. I think, for the CAO, we do need to improve our data governance, right? We do have good controls around our procurement data, our H.R. data, our financial data, but there are other types of data we are going to have to look at if it starts ingesting or being analyzed by AI. I think improving trust--I think the Committee has already taken a lead on this by being transparent about how we are using these tools in the House and, you know, publishing use cases and being honest when we are using AI to analyze data or produce data. Then a final thought is, I really think we really need to focus on always reminding folks where are the authoritative sources of data, right? They are on GovInfo.gov, they are on Congress.gov, they are on House.gov. Mr. Morelle. Ms. Conklin? Ms. Conklin. Thank you. The Library of Congress established an agency data management initiative to take a look at all of our data, not just our collections data or our copyrighted data, but the financial data--all aspects. From an AI perspective, we believe that the--and I use the term ``humans in the loop''--are integral in determining what we can do with our data in the AI experiments and AI production. We need the humans. The experts at the Library of Congress need to train the tools prior to AI utilization. Then, after the AI output, humans will be needed--are needed to determine the quality of that data from an authoritative, nonpartisan--for congressional data, and ensure that it is accurate. Humans are still required, but we have an agency--an AI working group, as I stated in my oral testimony, and we are looking at all aspects of that. We have a very robust AI experimentation process, and we follow that very closely. Mr. Morelle. Mr. Chairman, if I may ask Mr. Halpern---- Chairman Steil. Absolutely. Please, go ahead. Mr. Halpern. Thank you, Mr. Morelle. I actually want to take a step back, because your question dealt with how do we improve trust in the institution. One of the ways to do that is to give our fellow Americans and people around the world a view into how we make laws. That is really GPO's mission. Our vision is for an America informed. To the extent that AI tools can increase our speed and accuracy in delivering that kind of transparent, primary information to those folks trying to figure out how Congress is working, that is a benefit to the agency and, we think, ultimately, a benefit to Americans and citizens of the world. Mr. Morelle. Thank you all for your thoughtful answers. I am sure we will have many more opportunities to connect. I appreciate your indulgence. I yield back. Thank you, Mr. Chairman. Chairman Steil. The gentleman yields back. Mr. Loudermilk is recognized for 5 minutes. Mr. Loudermilk. Well, thank you, Mr. Chairman. I appreciate you having this hearing. This is a very important topic and very timely. You know, artificial intelligence is a topic that spans every jurisdiction of every Committee that we have, and it is something that we need to get in front of, not behind. I think we are still away from C3PO chairing any of these Committees, but, in the view of a lot of people out there, they are concerned---- Chairman Steil. Well, thank goodness, Mr. Loudermilk, that that is still the case. Mr. Loudermilk. I opened a can of worms there, didn't I? Seriously, Mr. Clocker, over the course of 2023, I understand there were many competing AI frameworks that agencies could have followed. Here in the House, we have a very complicated ecosystem, and we are in a situation where everyone is better off when we all row in the same direction, instead of proverbially rowing in different directions and ending up going in circles--which, in fact, we are very good at, you know, in Congress. What framework did the CAO decide to use? Mr. Clocker. Mr. Loudermilk, I am glad you recognize this is a very difficult environment sometimes. We are using the NIST framework for AI. We think it is a good framework. It is very thoughtful. It is general, and we are going to tailor it for the challenging environment here in the House of Representatives. When we do that, we are going to be working with this Committee, we are going to be working with the Sergeant at Arms, we are going to work with the clerk and the other officers of the House. Because they all use the same--when we adopt cyber policies for the House, we send them to the Committee, the Committee approves them, and all the officers and institutional offices follow them. Mr. Loudermilk. OK. I may have missed it, but did you just--did you say which framework that you are---- Mr. Clocker. It is NIST. We will be using the NIST---- Mr. Loudermilk. The NIST. Okay. Mr. Clocker. We will use NIST. We will tailor it for our environment; we just---- Mr. Loudermilk. Right. Mr. Clocker . do not take it. Yes. Mr. Loudermilk. Okay. Mr. Clocker. Yes. Mr. Loudermilk. Is that the same framework--and you may be addressing this in your comment. Your intention is, all House agencies to use that same framework then? Mr. Clocker. It is. It is. Yes. For example, when we adopt the framework and the Committee approves it--you know, it is a decision-making framework; it is how you evaluate risk. The Sergeant at Arms will use it, and, you know, at the end of the day, the Sergeant at Arms will make the risk assessment with the available facts the framework produces. Mr. Loudermilk. Oh, great. We are going to end up having robocops too, right? Yes. Boy, what Hollywood has done with this environment. Can you walk us through which function of the framework you have actually focused on first? Mr. Clocker. Our primary interest right now is governance, right? Getting the governance right, building that basic foundation of the policies. We are also focusing on mapping the existing functions of the House--you know, understanding where AI is being used or considered being used in the House today. That is the use-case inventory that has been developed so far. We are going to use that use-case inventory to understand how people intend to use these tools so we can, you know, implement this framework correctly to understand where the risk really is, whether it is using these tools with financial data, using these tools with procurement data, or constituent data at the right time. Mr. Loudermilk. Have you reached out to other House offices to make sure that we are going in the same direction, that everyone is prepared to adopt these policies, the framework that you are leading on? Mr. Clocker. It is an ongoing conversation. We have certainly talked to the clerk. We have certainly talked to Legislative Counsel. We have talked to over 200 staffers and Member, Committee, and leadership offices to understand how are they using those tools. These conversations need to continue. I think we will have a draft policy to the Committee probably in 2 or 3 months. And---- Mr. Loudermilk. Okay. Mr. Clocker . we would expect additional back- and-forth as we develop the final policy. Mr. Loudermilk. Coming from an IT background, one thing about AI is, its output is only as good as the data that is used in the input. Is there any consideration of clarifying or making sure that everything that we use it for is coming from a good data set? Mr. Clocker. I think that is one of the most important elements to the use of AI. The answer to that is going to be different depending on the data set. I think we envision a future state where you will have AI tools in your office that will work on your data. It is your data, right? Today, the tools we have been testing so far, it is the entire internet, right? It is--we know there is bias, we know that is---- Mr. Loudermilk. Yes. Mr. Clocker . probably not where we want to be long term. Mr. Loudermilk. Surprising, there is bias on the internet. I thought---- Mr. Clocker. Yes, exactly. Mr. Loudermilk . everything there was true. Mr. Clocker. Yes. Mr. Loudermilk. Well, one thing--if you could use AI to figure out how to get the escalators in Rayburn to work, that would be an awesome achievement. With that, Mr. Chairman, I yield back. Chairman Steil. The gentleman yields back. Ms. Sewell is recognized for 5 minutes. Ms. Sewell. Thank you, Mr. Chairman. I want to thank all of our witnesses. I actually want to drill down on what this last conversation was about. We have spent a lot of time talking about the positive benefits of AI. I would like to drill down on some of the associated risks of AI--in particular, biasness and ethics and cybersecurity. Let us start with bias. One particularly difficult challenge of these tools is they inherit the biases of their source, which is often the internet at large. The internet is filled with biases across all spectrums of opinion, and these opinions are often presented as facts. In addition, many of the existing data sources derived are derived predominantly from White, Anglo-Saxon, mostly American- speaking or English-speaking academics, and that leaves underrepresented communities of different race and gender and language without the same weight of consideration in the creation of these systems. The AI will then deliver what appears to be facts and data-based, when, in fact, it is not. I know that time is limited, so I am going to ask this question of you, Mr. Halpern, with respect to the GPO and to you, Ms. Conklin, with respect to the Library of Congress. Mr. Halpern. It may be a simpler answer or a more complex answer to your question, but GPO does not create content. We deliver content. So---- Ms. Sewell. You stand by the content by which you deliver, right. Mr. Halpern. Which is created by our customers. We are authenticating the fact that this hearing, when it is published, came from Congress. We are not creating the material inside of that hearing. Ms. Sewell. Gotcha. Maybe my question is more for the Library of Congress. In particular, if you could also talk a little bit about the copyright and ethics concerns around copyright. The New York Times recently sued OpenAI for copyright infringement for using content to create a ChatGPT. Plagiarism's unacceptable; I know that and we all know that. Are languages, texts, videos, images generated by machines also allowable? Ms. Conklin. Thank you---- Ms. Sewell. Bias and ethics. Ms. Conklin. I will cover bias first. Ms. Sewell. Okay. Ms. Conklin. Thank you. We have been including the issue of bias and ethics in our research and collaboration since 2018 when we began considering AI and its impacts. Our strategic plan--our new strategic plan for the agency has a pair of objectives that reflect the Library's commitment to providing trustworthy and authoritative data and building and enriching Library collections and content to serve Congress and America's communities. Examining and expanding our collections with our strong guardrails of data security and data provenance for AI are cornerstones of the Library of Congress. We adhere to the NIST risk framework to understand the spectrum of biases. And---- Chairman Steil. Will--just to check your microphone. Again, in the room we can hear you, but I know online we might not. Ms. Conklin. I will put it closer. Chairman Steil. Thank you. Ms. Conklin. The Library agrees that bias is an important issue that needs to be addressed in AI. Transparency is imperative and often not part of the current AI commercial products---- Ms. Sewell. I am down to the last minute, and---- Ms. Conklin. Oh, Okay. Ms. Sewell . I really do want to ask Mr. Clocker. I will allow you to--if you could submit something to the record with respect to that, that would be great. Ms. Conklin. Thank you. Ms. Sewell. Mr. Clocker, when it comes to information, we know that there is disinformation, misinformation. As keeper of the administration of Congress, you are deluged with information, and how do you protect against cybersecurity threats with respect to that information, whether that has personal identifiable information that you get through employment records or the like? Can you speak a little bit about the guardrails that you have in place to protect us against cybersecurity? Mr. Clocker. Certainly. This is obviously a very significant concern of ours as these tools become more and more prevalent. I can tell you, we have very strong controls and technology controls around our administrative data, whether it is H.R. data about Members or staff, whether it is financial data, procurement data. These areas are probably where we will be most careful and implement AI technologies later in the process as we develop it. I do think, you know, Members will be overwhelmed with data soon, because these tools are going to be very ubiquitous, producing, you know, more constituent engagement, which could be real, which could be real content--but you will get more of it--and not all of it may be real, right? That is something we are thinking about--you know, how can we work to give Members the tools to sift through potentially fake data. Ms. Sewell. Mr. Chairman, we should really dig a little deeper when it comes to some of the threats, especially cybersecurity. Thank you all for your testimony. Chairman Steil. The gentlewoman yields back. Mr. Griffith is recognized for 5 minutes. Mr. Griffith. Thank you, Mr. Chairman. I am going to play off of that, a slightly different tack, and rearrange the way I was going to ask my questions. Mr. Clocker, you were talking about data for Members. One of the things I think could be a real opportunity for us in AI is to do things like quickly and automatically have an AI create bill summaries. Getting hearing transcripts a lot faster, that can help us internally. Two of the other things I think would help the institution, both on the floor and Committee activity, would be a voice recording of all of the documents so that--a lot of people fly. They can read on the airplane if they want to. I drive home, 4 hours each way, and then I drive all over my district. I listen to a lot of stuff in the car. If suddenly, you know, without too much trouble, I can get--and I know there are some apps I could purchase that would convert them, but you have got to take pictures of them and run them through. If we could get those things done quickly so that we could listen to reports, bills, amendments. Then last but not least, again, helping Members get through all the data, I believe AI could help us do, you know, almost instantaneously--not instant, but close to it--amendments on the fly on the floor that would really help us out in making the process go forward. Are you all looking at some of those things? Mr. Clocker. We are. I think what is--I think interests, but all those use cases--is, a lot of that is the work your staff do today for you to prepare you or to provide a summary for you as you travel home---- Mr. Griffith. Well, and what I do is---- Mr. Clocker. Yes. Mr. Griffith . I actually read the text of any bill that I think I am going to vote for, which is a lot of them--and then I get dissuaded as I read them. If I think I am going to vote for it, I read all the words. It sure would be a lot easier to listen to it. Then, if I have got a problem on page 14 or page 5,000-- Okay, they are not quite that bad, but sometimes in the thousands--I can call my staff and say, get me the text to read that specifically; you know, email me that particular section of the bill. Do you think you all could work on that? Mr. Clocker. I do, absolutely. A lot of those use cases you talk about are about summarizing public information---- Mr. Griffith. Yes. Mr. Clocker . right? I think we can move rapidly on those. When you talk about drafting amendments, I think that is a very different story, involving Leg Counsel. I can kind of tell you, they are concerned about the appropriate use of drafting legislative language---- Mr. Griffith. Well, I think that is up for the Member to decide---- Mr. Clocker. Sure. Mr. Griffith . but it is a tool where, if you hear something and you want to make a quick---- Mr. Clocker. Great. Mr. Griffith . amendment--I mean, I can remember Don McEachin and I both agreed on something in Committee that needed to be changed, and everybody was like, ``Well, let us get staff to do that.'' Don and I could have probably plugged that into AI and had it out in about 5 minutes. We might have been able to do it on paper in about 10. Mr. Clocker. Yes. Mr. Griffith. They wanted to get it through and run it through the staff. I think we could be more efficient. Mr. Halpern wants to answer on this, I think. Mr. Halpern. Well, to facilitate a lot of these applications, you need good data underneath. That is one of the things that GPO tries to do, is, we will take text trials from a lot of folks involved in the process here; we try and convert that into good, machine-readable data, XML-based. The legislative-branch standard is based around United States Legislative Markup. That is our flavor of XML. The more documents we can deliver in that format, the broader the range of applications you will have. Whether it is reader applications, whether it is the ability to synthesize that data, the more of that that is in that machine-readable data format, the more flexibility we are going to have going forward. Mr. Griffith. I appreciate that. Mr. Clocker, I am going to switch back to what was originally my first question, but I was feeding off of Ms. Sewell's questions. Are you all exploring whether AI could be helpful in tracking utility costs or other operating costs on the Hill? As an example, I was told one time that everything in Rayburn is pretty much on the same system, and so we really do not know what costs are in this area or that area. Are you looking at ways that--for commercial operations, or if a particular office, even if it is my office, that uses more electricity, you know, by 15 or 20 percent more than other offices--so that we might be able to figure out ways to bring down our utility costs and our use of that energy or utilities? Mr. Clocker. What we are exploring is looking at public House data about how the House spends money and using the AI tools to analyze it and look for opportunities, whether it is certain products Members are buying that we need to be a little more quicker about finding a better price. The Architect of the Capitol, you know, runs the facility, and I am sure they are thinking about those things around utility costs. If these tools are going to be appropriate for those use cases, you are going to have to think--you know, be careful about what data you are putting into it at this stage, if that makes sense. Mr. Griffith. We have some privacy concerns, too. Mr. Clocker. Yes. Mr. Griffith. My time is up, and so I will yield back. Chairman Steil. The gentleman yields back. Mr. Kilmer is recognized for 5 minutes. Mr. Kilmer. Thank you, Mr. Chairman. Thanks for being with us. I spent 4 years chairing the Modernization Committee, and now I am ranker on the Subcommittee. I want to thank each of you for your work in trying to help us get some of the recommendations of that Committee actually implemented. I want to use my time to ask about some of those. Ms. Conklin, I remain interested in the potential of artificial intelligence to help Members and their staff just do their jobs more efficiently, and the Select Committee made a handful of recommendations in that regard. One of them was No. 120, which states that Congress.gov should do a clearer accounting of Member contributions to legislation. Oftentimes we will introduce, you know, bills that may be singles or doubles, and they get put into a big bill, like the NDAA or something like that. Right now, if a Member's bill is part of the NDAA, there is not really a way to figure that out on Congress.gov. One of the recommendations was to make sure that Members, so that their constituents know it and our colleagues know it, actually sort of get credit on Congress.gov for when they have a bill part of a broader bill. Any status update on that, on the implementation of that recommendation? Do you need anything from this further-- anything further from this Committee to get that cooking? Ms. Conklin. Thank you. Thank you, Congressman Kilmer, for all the attention you have given to legislative branch technology. We continue to make progress on this recommendation. In March, we expect to deploy new bill summary workflow tools which use natural language processing. That will do two things: assign bills to legislative analysts and CRS based on subject and identify similar bills, so bill comparison. There are other bill relationship enhancement services related to Congress.gov that are being implemented in collaboration with our legislative branch data partners. Congress.gov is downstream of the legislative process, so it is downstream from the House and the Senate and makes congressional authoritative data available to the public. This information has been included in the June 2023 Congress.gov update study. We appreciate your recommendations. In response to your question about your support regarding this recommendation, the CRS analyst tool we plan to implement may require funding for additional licenses to expand access to Congress. We are implementing it within CRS for the analysts, but if we were to bring it to Congress, Congress to use, that would require additional funding. Mr. Kilmer. This notion specifically of--the notion of identifying when a Member's bill is part of a broader bill---- Ms. Conklin. Yes. Mr. Kilmer . that may be part of this updated tool. Ms. Conklin. Yes. Mr. Kilmer. Great. Let me ask about one other thing on that front. Mr. Clocker, you already spoke to the bill summaries. It sounds like that is work in progress and maybe, as a first draft, not too shabby. Have you looked at using AI to have a--you know, right now there is a related bills tab in Congress.gov. Has there been a contemplation of doing like a previously related bills tab where Members and staff and the public can look at the history of bills with a longer history, you know, when they first started, who was involved, how they changed over time, which can be helpful as Members evaluate legislation? Is that something that you have or could look into as you do this Congress.gov update? Ms. Conklin. It will be part of the tool. We are also doing an experiment on CRS bill summaries and to determine, from a generative AI perspective, and that will help, depending on the results of the experiment. Our hope is that it will generate an initial bill summaries with the items you are talking about. Mr. Kilmer. Being able to look at from a past Congress. Ms. Conklin. From a past. Mr. Kilmer. Okay. Ms. Conklin. Well, and currently legislative analysts have that ability within CRS with a tool they have; but with what we are delivering in March, they will be able to do that further. Mr. Kilmer. Great. I have another question, but I think I only have 20 seconds, so I will yield back. Thanks. Chairman Steil. The gentleman yields back. Dr. Murphy is recognized. Dr. Murphy. Thank you, Mr. Chairman. This has like opened up a huge Pandora's box, and we kind of--as we all know, a box of chocolates can give us a lot of good things and a lot of bad things too. I have been in medicine for now 35 years and I have been able, fortunately, to witness so many different transformative changes in medicine. I look at the first two decades, this, that, and the other stuff. The last 5 to 8 years in medicine has been an absolute explosion with new technology. We are really required in medicine to adapt every day for new technologies, new medicines, and all these other things for the improvement of our patients. The whole idea of disruptive behavior, if it will, is not foreign to me. I know it is for some, you know, governmental bureaucracies, and that is absolutely understandable. This is the major challenge I would see that you guys are facing, because this is something unlike--it is actually unlike anything we have ever seen before in medicine, but absolutely understandable, unlike anything that has happened in a Government bureaucracy. You know the old ``Terminator'' movies we are all now afraid of; that Skynet becomes aware, and this is where the old human in the loop. I do not like to look at it that way. I like to see the humans holding the loop, because we are probably at some point going to need AI that is over-watching the AI. Because, to Representative Sewell's comments, there are going to be biases in, because all this is doing is giving us information but then correlating it, subsidizing it, and pulling it down correctly just into a quick response. It is not anything that does queries or any type of analysis really of any type of import that a human would do. My main queries really are going to be about security concerns, because I will tell you--now being in politics for about 7 years. I was in the private sector for a very long time. Where are we going with making sure that we are having watchdogs not only within the Government but outside the Government? Because I think sometimes we get a little bit cloistered in our thoughts as far as the Government. I would love us to have a private-public partnership with anything like this. I would be interested, Mr. Clocker or Ms. Conklin, if you have any comments about that. Mr. Clocker. Dr. Murphy, those are some very challenging questions that we are going to have to face. You mentioned in the area of medicine. Well, within the CAO, we have many professions. We have financial professionals. We have cybersecurity professionals. We have creative professionals. You know, the integration of those tools into those professions is going to have transformative effects. You are exactly right; these tools are nowhere ready to replace human judgment. The CAO will not use these tools to replace human judgment anytime soon, and I cannot imagine us doing that anytime soon. You are also absolutely right. You know, we need to talk to industry. We need to talk with executive branch partners. We need to talk with/see what other legislatures are doing and how are they dealing with these challenges. It is just not an inward-looking issue. We need to talk across various parts of America. Dr. Murphy. This is happening in every single segment of our society. I really honestly would love something like Deloitte to come in and actually start auditing our own Government agencies. Because if you take CBO, for example, I have come to-- always thought it was the great almighty really judge of things but found it to be vastly inaccurate. Why couldn't we use these private agencies, which do a really good job at some of these things, to do some of these things for us? Ms. Conklin, and maybe the same thing with Mr. Clocker, are we going to be able to use this--and when I say ``security,'' I am talking about not only security of data but about security of the House, being able to look at the--work with the DOD, work with other administrations to make sure that our Members are safe/secure in all the different attacks now. I think the Chairman was stating there has been a 300-percent increase in the number of threats against House Members. Anything like that? Mr. Clocker. From a cyber perspective, we see an increase in the size, scope, and sophistication of the cyber attacks on the House. We are responding. We are concerned about it. We are--we will need to add more resources. We will need to add more tools, and at some point we are going to need to add more funds to all of that. Dr. Murphy. Yes, that is the big problem, is we need more funds. Maybe AI can tell us how we cannot need more funds. This is going to be different. Just last question: Over the last 6 months, the NIST Framework has emerged as the benchmark for Federal agencies, private agencies. Quickly, do you guys have an AI governance plan in place, or is that still something that is still being assimilated? Mr. Halpern. We have had an AI governance directive in place for about a month and a half. Our AI Governance Committee actually had its inaugural meeting yesterday, and it is based off of the NIST Framework. We are starting to move forward on that. Dr. Murphy. Who comprises that plan? Mr. Halpern. The Governance Committee. It is representatives of a variety of our business units. It is chaired by our chief information officer, but our chief technology officer is also part of it as well as representatives from our major business units at GPO. Dr. Murphy. Do you have--so you have private individuals coming in? Mr. Halpern. It is internal to us. We are consulting--GPO is--essentially runs as a business. Dr. Murphy. Right. Mr. Halpern. We are consulting all the time with folks from industry, because we need to adopt the latest tools to make sure that we remain competitive for our customers. Dr. Murphy. Great. Thank you. With that, I will yield back, Mr. Chairman. Chairman Steil. The gentleman yields back. Mrs. Torres is recognized for 5 minutes. Mrs. Torres. Thank you, Chairman Steil and Ranking Member Morelle, for convening us today on these very important issues. Most of all, thanks to everyone in the audience today for your interest in being here to listen to what AI can do for us in the future. Artificial intelligence is a powerful, transformative tool that can improve the efficiency, effectiveness, and accountability of Congress. However, AI could also bring unintended consequences. It opens the door to issues about authenticity and quality of work. As this Committee looks at AI in the legislative branch, we must diligently look at AI innovation and its impacts on our society. Is AI going to be used to write bills, to solve some of mankind's greatest problems? How will we continue to center the human experience on legislation? Is AI going to be used to automate and expand the ability of special interests to influence Members of Congress or our staff? I are hope that this hearing is the start of a much larger conversation, and I look forward to working with all of my colleagues on responsible and ethical AI innovation, respecting the rights and dignity of all Americans, and upholding the core values of our democracy. Let me give you an example, and my questions are going to be to Mr. Clocker. Congressional casework staff help constituents access critical Federal benefits that oftentimes are denied, and they need that human moral value in order to have some oversight over opinions on these cases. However, congressional offices can have huge numbers of casework, and it is overwhelming for our district staffs to deal with some of that. How can AI help improve our staff--and I say ``improve,'' not replace, our staff--when dealing with casework issues? Mr. Clocker. That is a great question. We agree; it is not going to replace staff. Constituents want to talk to a human. They are not going to want to talk to a chatbot; we know that. We have not seen--you know, these chatbot technologies have been out there a long time. We have not seen those implemented by Member offices, because it just does not work for that relationship. Mrs. Torres. I wrote a letter recently asking this very question: How can AI be improved to help staff monitor their casework load, right, to help improve communication, responses to our constituents? That is what I am looking for. Mr. Clocker. Yes. Mrs. Torres. Assistance for the staff. Mr. Clocker. I think where we should focus on right now, we know the tools that we have today are very good at helping staff produce the first draft or to summarize information. I think the focus to help caseworkers or other staff, you know, handling constituent inquiries, just focus on the training, right? Here is what these tools are good for today, and here is how to safely integrate into your current operation while we look at the technology tools that are available to your office. Mrs. Torres. How do we protect personal data that is very sensitive personal data that is shared with our offices if we utilize a system like AI to help process these casework? Mr. Clocker. I think that is the hard problem here, right? We will--this is one area we will probably be extraordinarily cautious before we integrate AI tools, looking into, you know, private PII constituent data, which has health information, all sorts of information that we need to protect. Mrs. Torres. I hope when we are convening these meetings with professionals that are knowledgeable on all of these issues that this conversation is happening. Protecting the privacy of our constituents has to be a priority. Ensuring that our staff has every tool available to them to improve their job has to be a priority, but in many of these jobs, you just cannot replace a human being with a computer. Take that to heart and take that serious. Mr. Clocker. We agree. Mrs. Torres. Thank you. I yield back. Chairman Steil. The gentlewoman yields back. Mrs. Bice is recognized for 5 minutes. Mrs. Bice. Thank you, Mr. Chairman. Thank you for the witnesses for joining us this morning/ afternoon. First, I am going to make a shameless plug. The Modernization Subcommittee will also be holding some AI hearings in the near future. This seems to be a very interesting topic, because I do not often see this room packed full of visitors. Feel free to join the Subcommittee when we post that particular hearing. We have seen AI in the legislative branch assist library patrons with optical character recognition, building LLM models to allow experimentation and tests based on high-quality Government data or reports, and work to upskill legislative branch staff to become familiar with generative AI technology. The first question I have, in the 2023 year-end report on the Federal judiciary, Chief Justice Roberts cautioned the judicial branch that, quote, ``Any use of AI requires caution and humility.'' I think we are here today in that spirit to acknowledge the first steps of the legislative branch must be cautious, humble, thoughtful and forward-looking. If I can start with Mr. Halpern, the GPO completed a formal AI directive and issued--that was issued internally in October, correct? Can you explain the directive and the impact it has had on GPO operations over the last few months? Mr. Halpern. Sure. The--we are in the nascent stages of implementing that directive. Largely the directive incorporated the NIST Framework into our own decision-making process. As I mentioned, our AI Governance Committee established by that directive held its inaugural meeting yesterday. We actually authorized three pilot programs to move forward using AI technologies. One was a simple intranet chatbot for search. Another is a module for our Contract Lifecycle Management system to test that to see if that can assist our acquisitions process. Then also looking at tools to assist our public information search. As I said, the directive is to provide that framework for our decisions as we look at these technologies and incorporate them into GPO's operations. Really, you know, our first stage is to do no harm, so to test things thoroughly before they move into production. Mrs. Bice. Great. Thank you. Mr. Clocker, you talked earlier about the need for potentially staff in reviewing and evaluating vendors, and I think it is an important point. Certainly, we want to make sure that there is a thorough vetting of any applications that are getting put forward to use by House offices. I also think we have to think through the speed at which we do that, because technology is changing at a very rapid pace. If we are taking 6 months or a year to actually vet and approve these types of applications, it is a, you know, giving--putting us I think at a competitive disadvantage to be able to actually utilize those programs. Large language models are being weaponized. In December, VentureBeat published an article about LLM attacks against members of the U.K. Parliament. In this instance, hackers used them to personalize emails and kept sending new emails in rapid succession until they got through. Mr. Clocker, is there anything like this happening in the House today? Mr. Clocker. I do not think we have seen that specific example. We are certainly concerned about it. We have seen increased speed and sophistication of cyber attacks. Our adversaries, those who want to harm the House, whether politically motivated or they are just fraudulent fraudsters, these tools are going to be widely available. They are going to use it to generate emails that look like constituent letters, social media posts that looks like they are coming from constituents. We are going to have to figure out how to get in front of that. Mrs. Bice. Absolutely. Have you--has the CAO actually identified any caseworker-related AI use cases? Mr. Clocker. We have. I think we are starting with one of the Modernization Subcommittee priorities, which was to anonymize and aggregate casework information. We are not using AI in that project right now. We are being very cautious. There is sensitivity. It is anonymized data, but there is still sensitivity about that data. We want to prove that project as we roll it out with the additional pilot participants. I do think, once that dataset gets large enough, there is definitely opportunities to use AI. Not this year. You know, maybe next year. Mrs. Bice. Perfect. Thank you for those answers. Mr. Chairman, I yield. Chairman Steil. The gentlewoman yields back. We appreciate having Mr. Lieu on our Committee with us today. Mr. Lieu, you are now recognized for 5 minutes. Mr. Lieu. Thank you, Chairman Steil and Ranking Member Morelle, for allowing me to be on this Committee today. I really appreciate it. Thank you to the witnesses for your presentations and your work. I am a recovering computer science major. I am aware of both the benefits as well as the risks that AI poses. I have some questions first to Mr. Clocker. You all had approved ChatGPT Plus on a limited basis. You had not approved Microsoft's Bing Chat or, for example, Google was barred, other large language models. What would be some of the risks of a House office using those large language models? Mr. Clocker. We talked to all those companies, and we are still talking to them. ChatGPT Plus, which is, as you know, run by OpenAI, we have some stated terms and conditions around protection of House data, protection of Member data, and they agreed to them. The other products have not. It is really about how they handle your data and, for example, to make sure they do not share it with anybody else. Until they agree to that, we probably will not authorize them. Mr. Lieu. OpenAI has said, anything that a House office views through that particular license, they are not going to incorporate into training or sharing or anything like that. Mr. Clocker. That is correct. That is correct. Now, one of---- Mr. Lieu. All our computers are under that license, or how does that work? If I just go on my laptop and use ChatGPT Plus---- Mr. Clocker. No, it is the paid version only. I think it is about $20 a month. It is very low cost. You do have to go in and get the ChatGPT Plus version, not the free version. If you use---- Mr. Lieu. It has to be specifically through that license that they do not share that information? Mr. Clocker. That is correct. Yes, yes. Mr. Lieu. If I go on my desktop and use Microsoft's Bing Chat---- Mr. Clocker. That is correct. Mr. Lieu . then the risk is my queries could sort of go somewhere into their, I do not know, large---- Mr. Clocker. Obviously, the risk is very low. We do not know what the typical House staffer is going to do with the data they put in through those tools. It is more than just are they going to use the data to train the model, right? There are some requirements in our terms and conditions around reporting on cyber incidents, that sort of thing. These are all fine companies. Obviously, Google is a very mature company. Where we are today is just the ChatGPT Plus. Mr. Lieu. Thank you. I did want to follow up on something that Representative Bice said about LLM's targeting and being weaponized against other folks, including legislators. You may have seen that there was a fake audio of Joe Biden's voice in a recent election. There is technology called liveness detection technology that is pretty good, that will be pretty darn accurate in letting you know if the voice at the other end is a human being or not a human being. Could the CAO look at that technology and see whether it might be useful to incorporate? Mr. Clocker. Absolutely. We think we are going to need to use technology in a lot of instances. Is it a real voice? Is it a real message generated by AI that is coming in? We definitely think there is an opportunity to use that technology. Mr. Lieu. Thank you. I have some questions for Mr. Ariga. Am I saying that correctly? Mr. Ariga. Yes. Mr. Lieu. Your agency is developing your own large language model. As you know, one of the issues of large language models is they are not designed to seek the truth. They are essentially designed to seek the most popular response to your query. What sometimes happens is they do this very techno term called ``hallucination,'' where they have a perfectly grammatically correct paragraph that is bonkers, totally false. One of the ways they try to correct for that is they literally, after they have the OpenAI model, go 6 months and hire thousands of human beings that basically go through and make sure it does not say bonkers things. Is your agency going to do that and have all these human beings test that model when you develop it? Mr. Ariga. Yes. Our approach to large language model, it takes a slightly different approach than what Mr. Clocker may have described. We chose to deploy a large language model inside GAO so we can control what comes in and what goes out. Specifically, that is allowing us to then adding GAO- trusted data sources, for example, GAO published reports or even Congress.gov, as a source of information for us to add. Just as a--and perhaps an anecdote, when we first started experimenting with generative AI technology, we asked a very basic question: What was Abraham Lincoln's opinion of GAO's AI accountability framework? Not surprisingly, it told us Abraham Lincoln hated our framework. That sort of told us that there is certainly a danger for hallucination, and that really informed our approach in terms of how can we augment this pretrained model with trusted data, and then also be able to sort of describe the rationale in which those answers are being described. It is a combination of technology and digital literacy for us to make sure that we can recognize signatures of hallucinations. Mr. Lieu. Thank you. I yield back. Chairman Steil. The gentleman yields back. Mr. Carey is recognized for 5 minutes. Mr. Carey. I want to thank the Chairman, and I want to thank Ranking Member Morelle for holding this hearing. You know, I can see how AI can be confusing. Last Sunday, I was sitting in my--at my house, and somebody sent me something that was generated. I opened it. I really thought that there was going to be a ``Back to the Future 4'' movie coming out. Now, this was something very lighthearted, but it was something that really looked like we were, in fact, going to have that movie. I know, Mr. Clocker, you described a lot of this stuff in your testimony, but I do want to go to what Ms. Sewell said earlier about the AI logarithms and how we can do things to avoid any type of unintended consequences, if you will. Briefly, if you could, how does the CAO regulate, collect, and inventory AI use cases? Mr. Clocker. We started talking to staffers and Members and Committee leadership offices. We have---- Mr. Carey. How many offices have you surveyed? Mr. Clocker. We had 150 offices total who participated in the pilot. Mr. Carey. How many Committees would you say? Mr. Clocker. I think it is about half the Committees, so roughly 10. Mr. Carey. Along that, the CAO's ChatGPT working group, what has been the most common popular office use, and what do you think were some of the biggest shortcomings? Mr. Clocker. The most popular uses are very similar uses you have heard in other areas. It is really that--producing that first draft and then giving it to a human to go from there--first draft of testimony, first draft of witness questions, first draft of a speech. A lot of times what people talked about, it gets you over that writer--if you have writer's block, it is going to get you over that writer's block, and it is going to give you a good framework to actually customize in the Member's voice. The pitfalls of what we have heard here, right; it does hallucinate. It is also very confident, right, that it knows what it is talking about. It sounds very confident even though it is hallucinating. We will address--we need to address that through training and how to use the tools effectively. Mr. Carey. I think the thing that scares me the most is that we are going to have a system where we are going to have AI-generated letters which we receive from constituents that are then going to be AI-generated letters back to those AI- generated--it is just going to be this vicious circle. To whatever extent--I know that Mrs. Bice mentioned that we are going to be doing some more investigating that. Again, Mr. Chairman, I appreciate the hearing. I appreciate all of your testimony, and thank you for everybody being here today. With that, I will yield back, Mr. Chairman. Chairman Steil. Thank you very much. The gentleman yields back. We have concluded the questions for our witnesses. I will yield to the Ranking Member for any concluding remarks. Mr. Morelle. Yes. I just want to say thank you to, first of all, Chairman Steil and the staff on both sides, who have been working so hard at pulling this together. I know this will be, I am sure, just one of many, many conversations on this topic. I am grateful to the Chairman for his leadership and his friendship. I want to thank all the witnesses for the work--not only for being here today, but the work you are doing day in and day out to help secure and to improve this Congress and the work that we do and the Members are doing to support those Members. I look forward to more conversations. This is obviously a very, very big topic. Again, I want to thank the Members and thank Mr. Lieu for joining us as well today. Thank you, Mr. Chairman. With that, I will yield back. Chairman Steil. Thank you very much. I also just want to reiterate my appreciation for our witnesses coming in and testifying. This is going to be an ongoing conversation about how we can leverage the benefits of this new technology and managing the downside risk. I think we will have the potential risk for all of our Members of looking back to some of the early hearings as it related to email and as Members talked about email, and now we look back and have a good chuckle. I think as AI develops and moves forward, I think we are going to see some amazing opportunities that we may not know of today. I think this conversation is an opportunity to make sure we are leveraging the benefits of this technology and managing the downside risk. One thing I heard time and again is that AI will not replace people. I think it is a real opportunity to make sure that we are using AI, allowing people to upskill with that and allowing people to leverage the technology to improve the work that is being produced at the end of the day. I appreciate all of our testimony today. Without objection, each Member will have 5 legislative days to insert additional materials into the record or to revise and extend their remarks. Members of the Committee may have some additional questions for you, our witnesses, and we ask that you respond to those questions in writing. Also now, pursuant to paragraph (b) of rule 14 of the rules of the Committee, I announce the vacancy of the position of clerk of the Committee and hereby appoint Kristen Monterroso to fill the vacancy. Without objection, a letter announcing the vacancy as well as a letter announcing the appointment of Kristen Monterroso as clerk will be placed into the record.   Chairman Steil. A copy of these letters will be made available to all Committee Members. If there is no further business, I want to thank the Members for their participation. Without objection, the Committee stands adjourned.   