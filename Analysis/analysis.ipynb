{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Hallucination Types in Structured Language Model Outputs\n",
    "\n",
    "This section introduces the major types of hallucinations observed in structured reasoning tasks over diamond-graph prompts. Each hallucination reflects a specific failure mode of the language model, often influenced by its training priors, commonsense reasoning, or logical extrapolations.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Attribute Transfer\n",
    "**Definition**: The model incorrectly assigns attributes, roles, or behaviors from one entity to another due to contextual proximity or relational assumptions.\n",
    "\n",
    "**Common Causes**:\n",
    "- Role substitution (e.g., \"A poses as B\" → B gets A’s traits).\n",
    "- Transitive relationships extended incorrectly (A → B, B → C → A → C).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Commonsense Hallucination\n",
    "**Definition**: The model fills in gaps using commonsense knowledge that isn't explicitly present in the prompt.\n",
    "\n",
    "**Common Causes**:\n",
    "- Assuming intent or outcome from real-world expectations (e.g., \"jobs\" implies \"economic benefit\").\n",
    "- Normative reasoning: “Since A normally leads to B in the real world, it must here too.”\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Extrinsic Hallucination\n",
    "**Definition**: The model imports external knowledge or facts not grounded in the prompt at all.\n",
    "\n",
    "**Common Causes**:\n",
    "- Named entity connections drawn from training data, not the prompt.\n",
    "- Fictitious relationships or causality hallucinated out of co-occurrence.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Intrinsic Hallucination\n",
    "**Definition**: The hallucination arises purely from misinterpreting the internal structure or logic of the prompt.\n",
    "\n",
    "**Common Causes**:\n",
    "- Flipping cause and effect within the given paths.\n",
    "- Misattributing actions or events between co-mentioned entities.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Misleading Prior (Training Bias)\n",
    "**Definition**: The model overrides the prompt with memorized associations or real-world priors from pretraining.\n",
    "\n",
    "**Common Causes**:\n",
    "- Injecting general facts like “NIH is under HHS” even if the prompt says otherwise.\n",
    "- Letting training bias override prompt logic (e.g., assuming Congress regulates pipelines).\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Other / Unclassified\n",
    "**Definition**: Hallucinations that don’t cleanly fall into any structured category, often involving contradictory or incoherent answers.\n",
    "\n",
    "**Common Causes**:\n",
    "- Answer/explanation mismatch.\n",
    "- Incoherent or circular reasoning.\n",
    "- Irrelevant justification.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Path Extrapolation\n",
    "**Definition**: The model invents a valid-looking logical path between entities that isn’t present in the prompt.\n",
    "\n",
    "**Common Causes**:\n",
    "- Incorrect transitive leaps (A ↔ B, B ↔ C → hallucinated A ↔ C).\n",
    "- Filling in skipped or missing intermediate steps.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Symmetric Completion\n",
    "**Definition**: The model assumes all relationships are bidirectional and mirrors the path incorrectly.\n",
    "\n",
    "**Common Causes**:\n",
    "- If A thanks B → model assumes B thanks A.\n",
    "- A part of B → model assumes B is part of A.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Temporal Hallucination\n",
    "**Definition**: The model infers an incorrect order of events or timelines between actions, agents, or institutions.\n",
    "\n",
    "**Common Causes**:\n",
    "- Assuming causal/temporal order where none is stated.\n",
    "- Flipping past/future inference (X happened before Y) without explicit evidence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Attribute Transfer Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Entity Substitution | A is (or poses as) B. A does X. Can we infer B does X? | The model confuses roles, assigning A’s actions or traits to B due to name or identity blending. | `diamond_1748`, `diamond_1749` |\n",
    "| $\\mathbf{2}$ | Transitive Trait Propagation | A $\\rightarrow$ B, B $\\rightarrow$ C. Can we infer A $\\rightarrow$ C? | The model falsely assumes transitivity, transferring properties across multiple hops without direct evidence. | `diamond_1810`, `diamond_1873`, `diamond_1937`, `diamond_1988` |\n",
    "| $\\mathbf{3}$ | Institutional Role Transfer | A is part of Institution B. Institution B does X. Can we infer A does X? | Model assumes individuals within an organization inherit or perform the org’s actions. | `diamond_1884`, `diamond_952`, `diamond_1092` |\n",
    "| $\\mathbf{4}$ | Role Expansion via Collaboration | A collaborates with B. B does X. Can we infer A does X? | Collaboration is mistaken for full participation or role equivalence. | `diamond_836`, `diamond_854`, `diamond_870` |\n",
    "| $\\mathbf{5}$ | Organizational Link as Causality | A created/is part of B. B does X. Can we infer A caused X? | The model confuses structural association for causality or responsibility. | `diamond_1850`, `diamond_1004` |\n",
    "| $\\mathbf{6}$ | Geographic/Locational Trait Transfer | A operates in B. B does X. Can we infer A does X? | Traits or actions of a region are transferred to entities in that region without justification. | `diamond_1074` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Commonsense Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Goal/Outcome Assumption | A is part of or supports B. B is discussed alongside outcome C. Can we infer: B is designed to achieve C? | The model assumes that presence implies intent or design, filling in with commonsense expectations of purpose. | `diamond_765`, `diamond_2610`, `diamond_1743` |\n",
    "| $\\mathbf{2}$ | Normative Knowledge Insertion | A and B are mentioned together. C is a commonly known purpose/outcome. Can we infer: A causes or supports C? | Uses general knowledge about norms, e.g., “science contributes to knowledge,” even if the text never says so. | `diamond_879`, `diamond_931`, `diamond_937`, `diamond_1992` |\n",
    "| $\\mathbf{3}$ | Causal Chain Overreach | A causes B. B causes C. Can we infer: A causes C? | The model creates longer causal chains than the prompt supports, often relying on commonsense logic. | `diamond_1704`, `diamond_1574`, `diamond_573`, `diamond_1924` |\n",
    "| $\\mathbf{4}$ | Role-Based Expectation | Person A is involved in task B. Can we infer: A performed or is thanked for B? | Assumes behaviors or gratitude based on roles, e.g., thanking witnesses or supporting policies. | `diamond_1126`, `diamond_2458`, `diamond_1092`, `diamond_2349` |\n",
    "| $\\mathbf{5}$ | Institution Purpose Projection | Organization A is mentioned with topic B. Can we infer: A exists to support B? | Projects generic institutional goals (e.g., universities spread knowledge, Congress helps the world) into the inference. | `diamond_1265`, `diamond_2611`, `diamond_830` |\n",
    "| $\\mathbf{6}$ | Value-Based Generalization | A helps B. B is valued (e.g., jobs, safety, resilience). Can we infer: A solves societal issues or ensures C? | General benefit is exaggerated as a specific guaranteed outcome. | `diamond_661`, `diamond_2426`, `diamond_765`, `diamond_2459` |\n",
    "| $\\mathbf{7}$ | Missing Link Completion | A → ? → C; B is somehow involved. Can we infer: B → C? | The model fills in missing nodes using plausible bridges rather than explicit text. | `diamond_1850`, `diamond_1453`, `diamond_895`, `diamond_2079` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Extrinsic Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Fabricated Entity Relation | A is mentioned with B. Can we infer A works with B? | Model fabricates a working relationship or collaboration not supported by any path. | `diamond_1707`, `diamond_1719`, `diamond_1916`, `diamond_1945` |\n",
    "| $\\mathbf{2}$ | Role Reversal or Causal Flip | A does X to B. Can we infer B does X to A? | Model swaps cause and effect or actor and recipient roles. | `diamond_1697`, `diamond_1739` |\n",
    "| $\\mathbf{3}$ | Fictional Causality | A is mentioned in context C. Can we infer A causes C? | Model assumes or invents causality from co-occurrence or vague context. | `diamond_1702`, `diamond_1707`, `diamond_1874`, `diamond_1940` |\n",
    "| $\\mathbf{4}$ | Unsupported Attribute Projection | A is in a group or topic. Can we infer A has attribute X? | Model projects a role, identity, or position onto A without input support. | `diamond_1705`, `diamond_1702`, `diamond_1730`, `diamond_1934` |\n",
    "| $\\mathbf{5}$ | Hallucinated General Knowledge | A does X. B usually relates to X. Can we infer A does something about B? | Model brings external world knowledge that isn't in the prompt. | `diamond_1723`, `diamond_1725`, `diamond_1756`, `diamond_1876` |\n",
    "| $\\mathbf{6}$ | Named Entity Injection | A is mentioned in path 1. B is mentioned in path 2. Can we infer A is related to B? | Model connects names/entities without grounding. | `diamond_1766`, `diamond_1767`, `diamond_1845`, `diamond_1867` |\n",
    "| $\\mathbf{7}$ | Temporal or Factual Drift | A happened. B is assumed to follow or be true now. | Model drifts beyond the provided timeline or facts. | `diamond_1757`, `diamond_1908`, `diamond_1910`, `diamond_1943` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Intrinsic Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Unsupported Inference from Identity or Role | A is thanked or referred to in a role. Can we infer A is part of institution X or serves its goals? | Model overinterprets role mentions or relationships (e.g., being thanked = being a member of a group). | `diamond_1700`, `diamond_1703`, `diamond_1727`, `diamond_1716` |\n",
    "| $\\mathbf{2}$ | Causality Assumed from Proximity | A is discussed with B. Can we infer A causes or is responsible for B? | Co-occurrence or adjacency is misinterpreted as causation or intentional action. | `diamond_1717`, `diamond_1769`, `diamond_1741`, `diamond_1751`, `diamond_1791` |\n",
    "| $\\mathbf{3}$ | Role Confusion Between Named Entities | A interacts with B. Can we infer C (related to B) did X? | Model assigns actions to the wrong actor, often based on shared context or organization. | `diamond_1714`, `diamond_1792`, `diamond_1794`, `diamond_1755` |\n",
    "| $\\mathbf{4}$ | Fabricated Logic Chain | A is linked to B; B to C. Can we infer A→C even though no path supports it? | The model builds a logically sound-looking but unsupported chain of reasoning. | `diamond_1711`, `diamond_1709`, `diamond_1788`, `diamond_1793`, `diamond_1808` |\n",
    "| $\\mathbf{5}$ | Misuse of Institutional Responsibility | A is in org B. B has a duty X. Can we infer A performs X? | Org-level duties are incorrectly attributed to individuals or unrelated actors. | `diamond_1700`, `diamond_1777`, `diamond_1716`, `diamond_1815` |\n",
    "| $\\mathbf{6}$ | Premature Generalization | A is mentioned once doing X. Can we infer A generally or consistently does X or represents group Y? | A single statement or mention is generalized to universal behavior or identity. | `diamond_1768`, `diamond_1759`, `diamond_1796`, `diamond_1797` |\n",
    "| $\\mathbf{7}$ | False Reversal or Time Jump | A was affected by B. Can we infer B caused or intended A? | Model introduces temporal or directional assumptions not grounded in the data. | `diamond_1795`, `diamond_1802`, `diamond_1822`, `diamond_1805` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Misleading Prior (Training Bias)\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Memorized Fact Injection | A mentions B. Can we infer: C (real-world known fact about B)? | Model overrides the context with memorized info from training (e.g., “NIH is under HHS”). | `diamond_4329`, `diamond_2130`, `diamond_1419` |\n",
    "| $\\mathbf{2}$ | Real-World Logic Override | A occurs. Can we infer: B (expected outcome from prior knowledge)? | Model hallucinates based on expectations (e.g., “Congress regulates pipelines” without prompt support). | `diamond_1277`, `diamond_939`, `diamond_1955` |\n",
    "| $\\mathbf{3}$ | Famous Entity Completion | Entity A is mentioned. Can we infer: A does famous/expected thing X? | Model completes prompts using what it knows about public figures/orgs. | `diamond_1801`, `diamond_1527`, `diamond_3035` |\n",
    "| $\\mathbf{4}$ | Government Action Assumption | Government or agency is mentioned. Can we infer: it implements policy X? | Model assumes typical government behavior without evidence. | `diamond_3095`, `diamond_1419`, `diamond_5659` |\n",
    "| $\\mathbf{5}$ | Role-Based Attribution | A is part of organization B. B does X. Can we infer: A does X? | Model misuses role or membership to infer unsupported responsibility. | `diamond_1716`, `diamond_5570`, `diamond_1002` |\n",
    "| $\\mathbf{6}$ | Negation via Learned Bias | A is not mentioned. Can we infer: A does not exist or didn’t happen? | Model incorrectly infers absence from silence. | `diamond_1419`, `diamond_717`, `diamond_2302` |\n",
    "| $\\mathbf{7}$ | Semantic Drift Hallucination | A and B are weakly related. Can we infer: C (abstract conclusion)? | Model drifts logically due to high-level abstraction or associative bias. | `diamond_2087`, `diamond_1723`, `diamond_2269` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Path Extrapolation Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Graph-Based Shortcut Inference | A is connected to B and C separately. Can we infer B and C are related? | Model hallucinates a link between nodes based on co-participation in shared context or chain of associations. | `diamond_991`, `diamond_3365`, `diamond_5050`, `diamond_384` |\n",
    "| $\\mathbf{2}$ | Implicit Policy/Agency Link | A supports infrastructure. B is under A. Can we infer B manages infrastructure? | Model assumes oversight or implementation roles across hierarchies without textual support. | `diamond_3365`, `diamond_3431`, `diamond_3366`, `diamond_178` |\n",
    "| $\\mathbf{3}$ | Causal Leap via Shared Topic | A is about efficiency/safety. B acts in that domain. Can we infer B uses A to do it? | Model builds causality from co-thematic links, like drones = response time = safety. | `diamond_3366`, `diamond_3431`, `diamond_4643` |\n",
    "| $\\mathbf{4}$ | Temporal/Structural Collapsing | A commits to X. X is used in Y. Can we infer A commits to Y? | Model shortens timelines or event chains, skipping necessary intermediate steps. | `diamond_5250`, `diamond_178` |\n",
    "| $\\mathbf{5}$ | Named Entity Substitution via Shared Context | Person A acts with B. B acts with C. Can we infer: A acts with C? | The model extrapolates indirect participation based on shared involvement. | `diamond_991`, `diamond_3996`, `diamond_384` |\n",
    "| $\\mathbf{6}$ | Concept Reinforcement Loop | A brings B to C. C brings B to A. Can we infer B and C are mutually linked? | Circular paths are interpreted as mutually reinforcing relationships. | `diamond_3996`, `diamond_5050`, `diamond_4643` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Symmetric Completion Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | False Bidirectionality | A does X to B. Can we infer: B does X to A? | Model assumes all relationships are symmetric even when directionality is clearly one-way. | `diamond_1830`, `diamond_1862`, `diamond_1947`, `diamond_1992` |\n",
    "| $\\mathbf{2}$ | Entity Role Reversal | A thanks B. Can we infer: B thanks A? | The model infers reciprocal roles from unidirectional statements like gratitude or recognition. | `diamond_2654`, `diamond_582`, `diamond_1081`, `diamond_1210` |\n",
    "| $\\mathbf{3}$ | Organization Identity Swap | Entity A is part of B. Can we infer: B is part of A? | Membership or group relations are reversed improperly. | `diamond_1947`, `diamond_1489`, `diamond_575` |\n",
    "| $\\mathbf{4}$ | Relationship Generalization | A is linked to B in Path 1. B is linked to C in Path 2. Can we infer A–C link? | The model extrapolates beyond valid links using transitive symmetry. | `diamond_960`, `diamond_3366`, `diamond_3104` |\n",
    "| $\\mathbf{5}$ | Authority Role Misassignment | A is questioned by B. Can we infer: A questions B? | Reverses evaluative or investigative roles without textual support. | `diamond_1871`, `diamond_812`, `diamond_3061` |\n",
    "| $\\mathbf{6}$ | Labeling or Affiliation Swap | A is a member of B. Can we infer: B is defined by A? | Organizational identity is assigned incorrectly to its member or subset. | `diamond_1952`, `diamond_724`, `diamond_2924` |\n",
    "| $\\mathbf{7}$ | Testimony & Hearing Role Flipping | A testifies before B. Can we infer: B testifies to A? | Speaker and audience roles are swapped, ignoring the context of proceedings. | `diamond_575`, `diamond_969`, `diamond_1081` |\n",
    "| $\\mathbf{8}$ | Bidirectional Thanking Loop | A is thanked by B. Can we infer: A thanks B? | Mutual gratitude is inferred without evidence. | `diamond_1617`, `diamond_1210`, `diamond_582` |\n",
    "| $\\mathbf{9}$ | Participation Implied as Agreement | A does X. B also does X. Can we infer: A agrees with B? | Co-action or co-mention misread as ideological alignment or support. | `diamond_1210`, `diamond_1835`, `diamond_1992` |\n",
    "| $\\mathbf{10}$ | Implicit Witness Inference | A hears from B. Can we infer: B is a witness for A? | Model assumes witnessing or testimony roles based on indirect mention. | `diamond_1947`, `diamond_575`, `diamond_1871` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Temporal Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Inferred Order Without Timeline | A mentions X; B mentions Y. Can we infer X happens before Y? | The model infers event sequences without temporal markers or supporting order. | `diamond_5356`, `diamond_5867`, `diamond_5022`, `diamond_3332` |\n",
    "| $\\mathbf{2}$ | Role Misattribution Over Time | A is part of B. B reports to C. Can we infer A interacted with C? | The model assumes actors interacted across institutional chains based on static roles, not time. | `diamond_906`, `diamond_233`, `diamond_2320` |\n",
    "| $\\mathbf{3}$ | Policy/Event Timing Collapse | Policy X and Outcome Y are mentioned. Can we infer X caused Y or happened before Y? | The model compresses long-term timelines into immediate causal links. | `diamond_771`, `diamond_5745`, `diamond_5823` |\n",
    "| $\\mathbf{4}$ | Confused Recurrence or Frequency | Event A happens. B is also mentioned. Can we infer A happened multiple times or on specific dates? | Model assumes repetition or regularity based on vague cues. | `diamond_529`, `diamond_5867` |\n",
    "| $\\mathbf{5}$ | Geolocation-Based Timing Assumption | X occurred in Region A. Y also occurred in Region A. Can we infer: X occurred after/before Y? | Model assumes order from spatial overlap, not temporal clues. | `diamond_5356`, `diamond_4857`, `diamond_5823` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Generic Prompt Patterns Causing Other / Unclassified Hallucination\n",
    "\n",
    "| $\\textbf{Pattern \\#}$ | $\\textbf{Name}$ | $\\textbf{Generic Template}$ | $\\textbf{Hallucination Trigger}$ | $\\textbf{Example Diamond IDs}$ |\n",
    "|------------------------|------------------|-------------------------------|----------------------------------|-------------------------------|\n",
    "| $\\mathbf{1}$ | Contradictory Answer vs Explanation | A says “can’t infer,” but answers TRUE (or vice versa). | Model gives a confident answer that contradicts its own reasoning, showing internal inconsistency. | `diamond_1604`, `diamond_1689`, `diamond_5014`, `diamond_385` |\n",
    "| $\\mathbf{2}$ | Ambiguous Reasoning with Irrelevant Evidence | A explains with off-topic or tangential logic. Can we infer: B? | Explanation cites irrelevant facts (e.g., FERC or Taylor Swift) to justify an answer. | `diamond_5468`, `diamond_3726` |\n",
    "| $\\mathbf{3}$ | Misaligned Logic in Absence of Evidence | No info supports the claim, but model assumes it does or dismisses the absence improperly. | The model \"fills in the gap\" with uncertain logic despite saying the info is insufficient. | `diamond_3063`, `diamond_1438`, `diamond_5014` |\n",
    "| $\\mathbf{4}$ | Contradiction Within Explanation | The explanation itself states something and then contradicts it immediately. | Model says “no info available” → concludes TRUE (or vice versa). | `diamond_385`, `diamond_1604`, `diamond_1689` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
